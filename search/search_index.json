{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"00_Frontend/readme/","title":"Overview","text":"<p>Check here : https://github.com/lekhrajdinkar/01-front-end-pack/blob/master/readme.md</p>"},{"location":"00_Springboot/00_others/","title":"Others","text":""},{"location":"00_Springboot/00_others/#lombok","title":"lombok","text":"<ul> <li>https://chatgpt.com/c/67429341-6080-800d-a368-578db5ca75d2</li> </ul>"},{"location":"00_Springboot/00_others/#maven","title":"Maven","text":"<ul> <li>https://chatgpt.com/c/91ef161a-3b62-474b-8171-4575b49557e2</li> <li>https://chatgpt.com/c/05d997e3-b7b5-471a-ad1e-dc239c8c85db</li> <li>interview question : https://chatgpt.com/c/674288e0-5774-800d-aa67-e6a3e14051b2</li> <li>https://chat.deepseek.com/a/chat/s/1d48393c-791e-4d20-9c28-c934ff151b15 - BOM,POM. modules</li> </ul>"},{"location":"00_Springboot/00_others/#git","title":"git","text":"<ul> <li>merge vs rebase : https://chatgpt.com/c/325c3956-8c00-4d9f-8056-9350020cc1fc</li> <li>interview question : https://chatgpt.com/c/67428185-c2e4-800d-a691-97f034a12433</li> </ul>"},{"location":"00_Springboot/00_others/#model-mapper","title":"model mapper","text":"<ul> <li>kickoff : https://chatgpt.com/c/6742d97f-5798-800d-bf8e-f0f0939ae338</li> </ul>"},{"location":"00_Springboot/00_others/#map-struct","title":"map struct","text":"<ul> <li>kickOff : https://chatgpt.com/c/6742d8e6-6fcc-800d-a5e1-feda0b7bf067</li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/","title":"Spring - Core","text":""},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#references","title":"reference/s","text":"<ul> <li>bauleng:</li> <li>https://www.baeldung.com/spring-tutorial</li> <li>https://www.baeldung.com/spring-dependency-injection</li> <li>https://www.baeldung.com/spring-exceptions</li> <li>chatgpt </li> <li>question: https://chat.openai.com/c/33d0d06d-0aaa-4791-bce9-da8ea3f5dd53</li> <li>interview question (spring core): https://chatgpt.com/c/673d9844-6528-800d-92eb-fa5f45362570</li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#a-dependency-injection","title":"A. Dependency Injection","text":""},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#key-concept","title":"key concept:","text":"<ul> <li><code>dependency</code></li> <li><code>IoC</code> : inversion of control of create object from Code to configuration(metadata) + resolve dependency</li> <li><code>DI</code> : pattern/design for IoC.</li> <li><code>Beans</code> : </li> <li><code>@Scope</code>(ConfigurableBeanFactory.SCOPE_SINGLETON)</li> <li>singleton (for stateless bean)</li> <li>prototype - hold state and are not thread-safe by default</li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#developer-primary-2-tasks","title":"developer primary 2 tasks","text":"<p>don't use xml config at all. think of java config only.</p> <ul> <li>task-1: create/define beans in meta-config </li> <li>way-1: <code>@Configuration</code> &gt; <code>@Bean</code></li> <li> <p>way-2: <code>@Component</code> </p> <ul> <li>get created with default constructor, if parameterized not present.</li> <li>if parameterized present with arg-1 (Type:BeanX). then beanX object must be present.</li> <li><code>@Repository</code></li> <li><code>@Service</code> </li> <li><code>@Controller</code></li> <li>fact with generic class.</li> <li>@Component public class MyGenericBean&lt;PT,CT extends Item&gt; {} --&gt; this will NOT create a bean. </li> <li>@Component public class StringItemBean extends MyGenericBean&lt;String, Item&gt; {} --&gt; will create</li> <li>@Bean --&gt;  new MyGenericBean&lt;String, Item&gt; myGenericBean() --&gt; will create</li> </ul> </li> <li> <p>task-2: Inject Dependency</p> </li> <li> <p>manual</p> <ul> <li><code>@Configuration</code> + add this for additional bean lookup <code>@ComponentScan</code>(\"\")</li> <li><code>@Bean</code> m(){ return new object() ;}<ul> <li>name = {\"customBeanName1\", \"customBeanName2\"}</li> <li>initMethod = \"init\"</li> <li>destroyMethod = \"cleanup\"</li> <li>autowireCandidate = false/true</li> </ul> </li> <li><code>@Bean</code> m( bean1 b1 ){ bean2 o = new object(); o.setb1(b1) ; return o; }  -  setter injection (manual) <ul> <li>use-case: for mandatory dependency</li> </ul> </li> <li><code>@Bean</code> m( bean1 b1 ){ bean2 o = new object(b1);  return o; } -  contructor injection (manual) <ul> <li>use-case: for optional dependency</li> <li>override dependency, previously set by construction injection.</li> </ul> </li> </ul> </li> <li> <p>Autowire - <code>@Autowired (required=t/f)</code> </p> <ul> <li>https://www.baeldung.com/spring-autowire</li> <li>ResolvableType class for  superclass, interface, generic types.</li> <li>injection happens with reflection api</li> <li>used inside bean created with @component</li> <li>classes with a single constructor can omit the @Autowired annotation</li> <li>apply on :</li> <li><code>property</code> </li> <li><code>method</code> --&gt; get applied to <code>method arg</code>, then.</li> <li><code>constructor</code> --&gt; get applied to <code>constructor arg</code>, then.</li> </ul> </li> <li>Autowire more<ul> <li>issue while autowire:</li> <li><code>no-bean</code> found.</li> <li><code>multiple-bean</code> found (Conflict)  NoUniqueBeanDefinitionException. resolve:<ul> <li><code>@Qualifier</code>(BeanName)</li> <li><code>@primary</code></li> </ul> </li> <li><code>Circular dependencies</code>:<ul> <li>use @<code>order</code>(1) </li> <li>use @<code>DependsOn</code>(\"beanName\")</li> <li>refactor code</li> <li>avoid using constructor Injection </li> </ul> </li> <li>inject - map, list, set   <pre><code>  - create @Bean b1, b2, b3, of Bean1 type\n  - @Autowire list&lt;Bean1&gt; listofbean1 --&gt; inject/add b1,b2,b3 into listofbean1\n</code></pre></li> <li>@Resource(name = \"myCustomBean\") from J2EE. can also use in spring project.</li> </ul> </li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#b-annotation","title":"B. Annotation","text":""},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#profile","title":"<code>@profile()</code>","text":"<ul> <li>bean will create for that profile</li> <li>Spring profile : local, dev,qa,prod</li> <li>app.prop --&gt; add this spring.profiles.active=local</li> <li>env var : SPRING_PROFILES_ACTIVE</li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#lookup","title":"<code>@lookup</code>","text":"<ul> <li>handle scope mismatch.</li> <li>scenario-1 : inject SingleBean --&gt; prototype bean : ok</li> <li>scenario-2 : SingleBean &lt;-- inject prototype bean : one issue </li> <li>it will not create new instance of proto member.</li> <li>if we write custom code get new instance, spring won't manage it and could create memory leak, if not cleaned by manually.</li> <li>solution : use @Lookup</li> <li>it's recommended to avoid injecting prototype beans into singleton beans</li> <li>```     @Component     public class MySingletonBean {<pre><code> @Lookup\n public MyPrototypeBean getPrototypeBean() {\n       // This method body will be ignored\n        return null;\n }\n</code></pre> <p>} ```</p> </li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#order","title":"<code>@Order</code>","text":"<ul> <li>in context of: </li> <li>collection :  insertion order.</li> <li>multiple Aspect - Apply order.</li> <li>load bean in container.</li> <li>Ordered.LOWEST_PRECEDENCE | HIGHEST_PRECEDENCE</li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#dependson","title":"@DependsOn","text":""},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#component-dependsonbeana-beanc-public-class-beanb-bean-implementation","title":"<pre><code>@Component\n@DependsOn({\"beanA\", \"beanC\"})\npublic class BeanB {\n    // Bean implementation\n}\n</code></pre>","text":""},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#c-spring-ioc-container","title":"C. Spring IOC container","text":""},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#bean-life-cycle","title":"bean Life Cycle","text":"<ul> <li>also check : Spring_02_lifeCycle.md</li> <li>manage bean scopes</li> <li>singleton : create along with IoC container on start up.</li> <li> <p>prototype : create on demand</p> </li> <li> <p>stage-1 : create creation + injection</p> </li> <li>step-1 bean creation : by calling constructor + inject mandatory dependency</li> <li>step-2 bean dependency injection :  resolve conflict, if comes</li> <li>step-3 call aware</li> <li> <p>step-4 call Bean Post Processor</p> <ul> <li>@component class Hook_1 implements BeanPostProcessor {} - need to register it. </li> </ul> </li> <li> <p>BEAN READY  :green_circle:</p> </li> <li> <p>stage-2 : initialization</p> </li> <li>I:InitializingBean &gt; call afterPropertiesSet(){...}</li> <li> <p><code>@PostConstruct</code> m() {...}</p> </li> <li> <p>stage-3 : Destruction</p> </li> <li>I:DisposableBean &gt; call destroy(){...}</li> <li> <p><code>@PreDestory</code> m() {...}</p> </li> <li> <p>Step-4 : after container is up:</p> </li> <li>@Component CommandLineRunner/s &gt; run()</li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#d-code-sample-programs","title":"D. Code / sample programs","text":""},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#1-scheduled-task","title":"1. scheduled task","text":"<ul> <li>@EnableScheduling @Configuration class Config1</li> <li>@Scheduled(cron = \"0 15 10 15 * ?\") m() {...}</li> <li>@Scheduled(fixedRate = 5000) m() {...}</li> <li>ScheduledConfig.java</li> </ul>"},{"location":"00_Springboot/01_Spring-core/01_Spring_Core/#2-custom-annotation","title":"2. Custom Annotation","text":"<ul> <li>get class/s</li> <li>get all method/s</li> <li>anno = method.getAnnotation(myAnno1.class)</li> <li>anno.attribute1(), ...</li> <li>run you logic around it. <pre><code>public void CustomAnnotationTest(){\n        Method method = Runner1.class.getMethod(\"testMethod1\");\n        MyAnnotation annotation = method.getAnnotation(MyAnnotation.class);\n\n        if (annotation != null) {\n            System.out.println(\"Value: \" + annotation.value());\n            System.out.println(\"Count: \" + annotation.count());\n        }\n    }\n</code></pre></li> </ul>"},{"location":"00_Springboot/01_Spring-core/02_Spring_bean_lifeCycle/","title":"Spring Bean Lifecycle","text":""},{"location":"00_Springboot/01_Spring-core/02_Spring_bean_lifeCycle/#lifecycle","title":"lifecycle","text":"<ul> <li>The lifecycle of a Spring bean consists of several stages, from instantiation to destruction.</li> <li>performing initialization</li> <li>performing cleanup tasks.</li> <li>fact: don't use aware, better way is to inject.   <pre><code>@Autowired    private BeanFactory beanFactory;\n@Autowired    private ApplicationContext applicationContext;\n</code></pre></li> </ul>"},{"location":"00_Springboot/01_Spring-core/02_Spring_bean_lifeCycle/#stages-beans-lifecycle","title":"<code>stages</code> : bean's lifecycle","text":"<p>1.<code>Instantiation And populate Properties</code>: - The bean is created using its constructor or a factory method. - Dependencies and properties are set on the bean, either through setters or fields.</p> <ol> <li><code>Aware Interfaces</code>:</li> <li>If the bean implements Aware interface</li> <li>BeanNameAware,</li> <li>BeanClassLoaderAware,</li> <li> <p>BeanFactoryAware, or ApplicationContextAware,etc</p> <ul> <li>Note: can also @autowired them directly.</li> </ul> </li> <li> <p><code>BeanPostProcessors</code>:</p> </li> <li><code>hooks</code> for customizing the bean lifecycle,</li> <li>If there are any BeanPostProcessor implementations <code>registered</code> in the context, they are applied.</li> <li>These can modify the bean instance before and after initialization, which is next step.</li> </ol> <p>bean is Constructed</p> <ol> <li><code>Initialization</code>:</li> <li>If the bean implements <code>InitializingBean</code>, Spring calls its <code>afterPropertiesSet()</code> method.</li> <li><code>@PostConstruct</code> annotated method is called.</li> </ol> <p>Ready for Use </p> <ol> <li><code>Destruction</code>:</li> <li> <p>If the bean implements DisposableBean, Spring calls its \"destroy()\" method,  when the bean is no longer needed. -@PreDestroy annotated method, it is called.</p> </li> <li> <p><code>Destroy</code>:</p> </li> <li>The bean is destroyed and its resources are released.</li> </ol>"},{"location":"00_Springboot/01_Spring-core/02_Spring_bean_lifeCycle/#more-notes","title":"More Notes:","text":"<ul> <li>It's important to note that not all beans go through every stage of the lifecycle.</li> <li>For example, beans that are singleton-scoped only go through the lifecycle once,</li> <li>while prototype-scoped beans go through the lifecycle each time they are requested from the container.</li> </ul>"},{"location":"00_Springboot/01_Spring-core/03_AOP_concept/","title":"AOP Concept","text":""},{"location":"00_Springboot/01_Spring-core/03_AOP_concept/#-httpschatgptcomc2616aaed-2668-4b78-85c8-f5c81f5ed6a0","title":"- https://chatgpt.com/c/2616aaed-2668-4b78-85c8-f5c81f5ed6a0","text":""},{"location":"00_Springboot/01_Spring-core/03_AOP_concept/#apo","title":"APO","text":"<ul> <li><code>Aspect</code> - aspect is a modular unit of cross-cutting concern, <code>eg : metrics</code></li> <li><code>join-point</code> - points in the execution at code. <code>eg : method execution</code></li> <li><code>point-cut</code> - expression/criteria to define joint-point <code>eg: annotated method</code></li> <li> <p><code>Advice</code> - code</p> </li> <li> <p>J P A</p> </li> <li>s3 bucket publish example </li> <li><code>Aspect</code> : publish report into s3 bucket.</li> <li><code>pointcut</code> - @After(\"expression to find report method\")publish_s3() { // logic is <code>advise</code> } </li> <li>at end of method execution is <code>jointpoint</code></li> </ul>"},{"location":"00_Springboot/01_Spring-core/03_AOP_concept/#aspects","title":"Aspects","text":"<ul> <li>Spring AOP encapsulate Cross cutting concept, like</li> <li>logging </li> <li>transaction management</li> <li>security </li> <li><code>metric</code> </li> <li>exception</li> <li> <p>could be anything, <code>publish s3</code>, etc</p> </li> <li> <p>applied across Spring beans, multiple classes, methods, etc without modifying the original classes.</p> </li> <li>defined using annotations.</li> <li>implemented using proxies.</li> </ul>"},{"location":"00_Springboot/01_Spring-core/03_AOP_concept/#join-points","title":"Join points","text":"<ul> <li>Aspects are applied to the code at specified join-points</li> <li>points in the execution of the application.</li> <li>example:<ul> <li><code>Method call</code>: Join points where a method is called.</li> <li><code>Method execution</code>: Join points where a method is invoked or executed.</li> <li><code>Constructor execution</code>: Join points where a constructor is invoked or executed.</li> <li><code>Field access</code>: Join points where a field is accessed (read or written).</li> <li><code>Exception handling</code>: Join points where an exception is thrown or caught.</li> <li><code>Object initialization</code>: Join points where an object is initialized.</li> <li><code>Static initialization</code>: Join points where a class is initialized.</li> </ul> </li> </ul>"},{"location":"00_Springboot/01_Spring-core/03_AOP_concept/#pointcut","title":"Pointcut","text":"<ul> <li>It defines the criteria/expression for matching join points.</li> <li>notice expression below</li> <li>Types: before, after(irrespective, normally, exception), around(before+after)</li> <li> <p>2.1. Before:</p> <ul> <li>advice runs before the join point,</li> <li>and does not have the ability to prevent the execution of the join point's method.</li> <li><code>@Before(\"@annotation(org.springframework.security.access.annotation.Secured)\")</code> </li> </ul> </li> <li> <p>2.2. After:</p> <ul> <li>advice runs after the join point, </li> <li>regardless of whether the join point  completes normally or by throwing an exception.</li> <li><code>@After(\"execution(* com.example.service.*.*(..))\")</code></li> </ul> </li> <li> <p>2.3. After returning:</p> <ul> <li>advice runs, after the join point completes normally.</li> <li>without throwing an exception</li> <li><code>@AfterReturning(\"execution(* com.example.service.*.*(..))\")</code></li> </ul> </li> <li> <p>2.4. After throwing :</p> <ul> <li>advice runs, if the join point exits by throwing an exception.</li> <li><code>@AfterThrowing(pointcut = \"execution(* com.example.service.*.*(..))\", throwing = \"ex\")</code></li> </ul> </li> <li> <p>2.3. Around:</p> <ul> <li>advice surrounds the join point, allowing you to run custom code</li> <li>before and after the join point's execution.</li> <li><code>@Around(\"execution(* com.example.service.*.*(..))\")</code></li> </ul> </li> </ul>"},{"location":"00_Springboot/01_Spring-core/03_AOP_concept/#advice","title":"Advice","text":"<ul> <li>code being runs at a particular join point.</li> </ul> <ul> <li>multiple aspects defined for same join point, then can run then in order by using <code>@order</code> <pre><code>@Aspect\n@Order(1)\npublic class LoggingAspect {\n    // Aspect implementation\n}\n\n@Aspect\n@Order(2)\npublic class ValidationAspect {\n    // Aspect implementation\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/01_Spring-core/04_spring_properties/","title":"Spring Properties","text":"<ul> <li>https://chat.openai.com/c/d75560a0-1c06-4195-80fc-563ec8449bc5</li> <li>https://www.baeldung.com/configuration-properties-in-spring-boot</li> </ul>"},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#application-properties","title":"Application properties","text":""},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#1-register","title":"1. Register","text":""},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#automatically-registered-files","title":"Automatically registered files:","text":"<ul> <li>application.property - default file</li> <li>application-.properties"},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#register-custom-properties-file","title":"Register custom properties-file","text":"<ul> <li>use <code>@propertySource / @propertySources</code></li> <li>keep here - src/main/resources : sb has utility method to read from resource folder.</li> <li>check : ReadConfigFromGlobalProperty.javaReadConfigFromGlobalProperty.java</li> <li>can have env/profile specific files too, as shoen below. <pre><code>@Configuration  \n@PropertySources(value = {\n        @PropertySource(value = \"classpath:global-database-${spring.profiles.active}.properties\"),\n        @PropertySource(value = \"classpath:global-rabbit-mq-${spring.profiles.active}.properties\")\n})\n</code></pre></li> <li>external property files <pre><code>1. JVM ARG :: java -jar my-app.jar --spring.config.location=&lt;path&gt;/application.properties\n2. env var :: export SPRING_CONFIG_LOCATION=/config/external/application.properties\n3. Command Line Arguments  :: ?\n</code></pre></li> </ul>"},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#2-binding-into-custome-class","title":"2. Binding into custome class","text":"<ul> <li>check : ConfigurationPropertiesByPrefixBean.java</li> <li>property --&gt; sb does binding bts --&gt; into Object (of ConfigurationPropertiesByPrefixBean class)</li> <li>@ConfigurationProperties <pre><code>@ConfigurationProperties(prefix = \"mail\")\n@ConfigurationPropertiesScan // register bean\npublic class ConfigurationPropertiesByPrefixBean\n{\n    ...\n}\n</code></pre> <pre><code>// Using @ConfigurationProperties on a @Bean Method\n// pending...\n</code></pre></li> <li>more ways to register above class as bean - ConfigurationPropertiesByPrefixBean</li> <li>EnableConfigurationProperties({c1.class, c2.class}) --&gt; enable/register explicitly, may be in Application.java file</li> <li>add @ConfigurationPropertiesScan Apply on class c1/c2 (done above)</li> <li>add @Component</li> <li>add @Configuration</li> </ul>"},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#in-built-binding","title":"in-built binding","text":"<ul> <li>property name must match - b/w prop and java class fields. <pre><code>all these works\n- mail.hostName\n- mail.hostname\n- mail.host_name\n- mail.host-name\n- mail.HOST_NAME\n</code></pre> <pre><code># prefix = mail\n\n# ------ String  --------\nmail.hostname =    mailer@mail.com\n\n# ------ number  --------\nmail.port     =    9000\n\n# ------ List / set --------\nmail.defaultRecipients[0]=admin@mail.com\nmail.defaultRecipients[1]=owner@mail.com\n\n# ------- Object  -------\nmail.credentials1.username=john\nmail.credentials1.password=password\nmail.credentials1.authMethod=SHA1\n\n# ------- Map&lt;String,String&gt;  ---------\nmail.additionalHeaders.redelivery=true\nmail.additionalHeaders.secure=true\n\n# ------- Map&lt;String,Object&gt;  ---------\nmail.map1.credentials1.username=mani\nmail.map1.credentials1.password=password1\nmail.map1.credentials2.username=lek\nmail.map1.credentials2.password=password12\n\nmap :\ncredentials1=object:{mani,password1}\ncredentials2=object:{lek,password2}\n\n# ------- Map&lt;String,list&lt;Object&gt;&gt;  ---------\n\n# ----- Duration,DataSize ------\n</code></pre></li> <li>check this for more Map binding example:</li> <li>Prop2Map.java</li> </ul>"},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#custom-binding","title":"custom binding","text":"<ul> <li>create converter class:</li> <li>1 annotate with @ConfigurationPropertiesBinding</li> <li>2 implement Converter --&gt; @override TargetType convert(SourceType)<ul> <li>Prop2Map.javaCustomConverter_1.java</li> <li>string to Credential binding</li> <li><code>mail.credentials2 = john2,password2</code></li> </ul> <li>3 add validation (JSR-380 format), if needed     <pre><code>@NotBlank\n@length(min,max)\n@Max(1025)\n@Min(1025)\n@Pattern(regexp = \"^[a-z0-9._%+-]+@[a-z0-9.-]+\\\\.[a-z]{2,6}$\")\n</code></pre></li>"},{"location":"00_Springboot/01_Spring-core/04_spring_properties/#3-read-properties","title":"3. Read properties","text":"<ul> <li><code>@Autowired Environmnet</code> env.</li> <li><code>@value</code> </li> <li>hardcode static value</li> <li>SpEL</li> </ul>"},{"location":"00_Springboot/01_springboot/01_SB_kickoff/","title":"SpringBoot","text":""},{"location":"00_Springboot/01_springboot/01_SB_kickoff/#references","title":"Reference/s","text":"<ul> <li>https://www.baeldung.com/spring-boot</li> <li>https://www.baeldung.com/spring-boot-annotations</li> <li>https://www.baeldung.com/spring-boot-starters</li> <li>https://www.baeldung.com/spring-exceptions</li> </ul>"},{"location":"00_Springboot/01_springboot/01_SB_kickoff/#topics","title":"Topics","text":""},{"location":"00_Springboot/01_springboot/01_SB_kickoff/#core-spring-concepts","title":"Core Spring Concepts:","text":"<ul> <li>Dependency Injection (DI),</li> <li>Aspect-Oriented Programming (AOP)</li> <li>Inversion of Control (IoC).</li> </ul>"},{"location":"00_Springboot/01_springboot/01_SB_kickoff/#spring-boot-basics","title":"Spring Boot Basics:","text":"<ul> <li>Spring Boot CLI</li> <li>admin setup : https://chatgpt.com/c/478413ee-1707-408e-b3f3-d13ee00e7471</li> <li>Spring Boot Starter project</li> <li>Spring MVC</li> <li>RESTful Web Services</li> <li>Spring Data JPA</li> <li>Spring Security</li> <li>Auto-Configuration</li> <li>customize Auto-Configuration</li> <li>create own custom starter project<ul> <li>02_SB_AutoConfig.md</li> <li>customize : we write our custom auto-configurations, we want Spring to use them conditionally.</li> <li>create your own class with @Configuration - new bean + Override Method. eg:WebSecurity, Datasource,etc</li> <li>Apply then conditionally - @ConditionalOnProperty, etc.</li> <li>properties.</li> </ul> </li> <li>more:      </li> <li>Overview of SB.</li> <li>bootstrap simple webApp</li> <li>Spring vs SB</li> <li><code>@SpringBootApplication</code> --&gt; @EnableAutoConfiguration, @Configuration, @ComponentScan</li> <li>worked on --&gt; web, jpa, test, okta, rmq, ibmmq, doc, okta, etc.</li> <li><code>@WebFilter</code></li> <li><code>banner.txt</code> keep in resources folder</li> </ul>"},{"location":"00_Springboot/01_springboot/01_SB_kickoff/#later-topics","title":"later topics","text":"<ul> <li>Spring Boot Actuator: https://chatgpt.com/c/7094d3bf-5952-4b93-bd73-a8abf39ebda1</li> <li>Testing in Spring Boot:</li> <li>Microservices with Spring Boot</li> <li>Spring Cloud</li> </ul>"},{"location":"00_Springboot/01_springboot/02_SB_AutoConfig/","title":"Auto Configuration","text":"<ul> <li>https://chatgpt.com/c/795ed757-ef25-48fc-a1c5-6755aab9bb03</li> <li>https://www.baeldung.com/spring-boot-annotations</li> </ul>"},{"location":"00_Springboot/01_springboot/02_SB_AutoConfig/#auto-config","title":"Auto-Config","text":"<ul> <li>Starter project &gt; <code>spring.factories</code> = listOfConfigClasses (which can be applied conditionally)</li> <li>SpringApplication.run() &gt; create AC, Loads:</li> <li>Standard beans</li> <li>Conditional-1(Is webApp)--&gt; beans-1</li> <li> <p>Conditional-2 : beans-2</p> </li> <li> <p>Notice this pattern </p> </li> <li>@Configuration Class-1 implements interface-1 &gt;&gt; Override method --&gt; gives new bean. </li> <li>this is sb config customization way.</li> <li><code>public class MyWebConfig implements WebApplicationInitializer {        onStartup(ServletContext servletContext) {          ...        }     }</code></li> <li>note: WebApplicationInitializer, provides spring way to configure ServletContext</li> </ul>"},{"location":"00_Springboot/01_springboot/02_SB_AutoConfig/#conditions","title":"Conditions","text":"<ol> <li>@ConditionalOnClass and @ConditionalOnMissingClass</li> <li>@ConditionalOnBean and @ConditionalOnMissingBean</li> <li>@ConditionalOnProperty</li> <li>@ConditionalOnResource</li> <li>@ConditionalOnWebApplication and @ConditionalOnNotWebApplication</li> <li>@ConditionalExpression</li> <li> <p><code>@Conditional</code> : Custom condition</p> </li> <li> <p>Apply these on</p> </li> <li>@Configuration class</li> <li>@Bean method</li> </ol>"},{"location":"00_Springboot/01_springboot/02_SB_AutoConfig/#custom-starter-project","title":"Custom starter project","text":"<ol> <li>create new Spring project, call it your starter.</li> <li>Create Auto-configuration/s:</li> <li>@Configuration Class-1 --&gt; with Bean with conditions ,to enable/disable,</li> <li>@Configuration Class-2 --&gt; with Bean with conditions ,to enable/disable, ...</li> <li> <p>@Configuration Class-N --&gt; with Bean with conditions ,to enable/disable</p> </li> <li> <p>Register Auto-Configuration Classes</p> </li> <li> <p>resource/META-INF/spring.factories=Class-1, Class-2, ... Class-N</p> </li> <li> <p>DONE</p> </li> <li> <p>Now package it and use it other project : </p> <p><code>mvn clean package/install</code> --&gt; local Maven repo.</p> </li> <li> <p>If want to exclude to Class-1:</p> </li> <li>@SpringBootApplication(exclude={Class-1})</li> </ol>"},{"location":"00_Springboot/01_springboot/03_SB_starter_test/","title":"Starter & Testing","text":"<p>--- Testing --- https://www.baeldung.com/spring-boot-data-sql-and-schema-sql 1. @sql, @sqlConfig - a declarative way to initialize and populate our test schema.</p>"},{"location":"00_Springboot/02_web/00%20WEB_start/","title":"Web Start","text":""},{"location":"00_Springboot/02_web/00%20WEB_start/#boiler-plate-code-remove-lombok-mapstruct-modelmapper","title":"&gt; boiler plate code remove : lombok, mapstruct, modelMapper","text":"<ul> <li>https://chatgpt.com/c/7d23b0fe-a7a5-43d5-9ced-69d4a344e31a - error handling</li> <li>https://chatgpt.com/c/f4a0c9cd-c6cb-414e-888c-605c2d50340c - ext server deploy</li> </ul>"},{"location":"00_Springboot/02_web/00%20WEB_start/#web","title":"web","text":""},{"location":"00_Springboot/02_web/00%20WEB_start/#0-web-request","title":"0 web request","text":"<ul> <li>idempotent : PUT</li> <li>non-idempotent</li> </ul>"},{"location":"00_Springboot/02_web/00%20WEB_start/#1-websocket-connection-intro","title":"1 WebSocket connection - intro","text":"<ul> <li>persistent(stateful), bi-directional communication channel between a client and a server over a single, long-lived TCP connection. </li> <li>WebSocket connections remain open and allow for real-time data exchange between the client and the serve.</li> <li></li> </ul>"},{"location":"00_Springboot/02_web/00%20WEB_start/#2-web-aware-spring-applicationcontext-webapplicationcontext","title":"2 web-aware Spring ApplicationContext : <code>WebApplicationContext</code>","text":"<ul> <li>IAC container for springMVC application.</li> <li>AC aware of the web-specific features and contexts in a Servlet environment.<ul> <li>can access the <code>ServletContext</code>, provides access to the Servlet API</li> <li>access the <code>ServletConfig</code></li> </ul> </li> <li>supports web-scopes for beans<ul> <li>request - bean is created for each HTTP request</li> <li>session -</li> <li>global session - never used</li> <li>Web socket - bean is created for each WebSocket connection</li> </ul> </li> </ul>"},{"location":"00_Springboot/02_web/00%20WEB_start/#3-cors","title":"3 CORS","text":"<ul> <li>https://chatgpt.com/c/79fe00c5-9852-4956-b0ec-be9a6657359c</li> </ul>"},{"location":"00_Springboot/02_web/00%20WEB_start/#4-security-threats","title":"4 security threats","text":"<ul> <li>XSS and CSRF </li> <li>https://chatgpt.com/c/c86b5fd1-c1b8-4a6b-bb8b-bbd832a606aa</li> <li>https://chatgpt.com/c/734bd77f-75d3-4be2-acbc-d80ef8b61b21</li> <li>https://chatgpt.com/c/e1547ff9-6ce4-4645-8fae-56d1924daa47</li> </ul>"},{"location":"00_Springboot/02_web/00%20WEB_start/#5-mime-type","title":"5 MIME type","text":"<ul> <li>consumes <pre><code>\"application/json\"                    Accepts JSON input\n\"application/xml\"                     Accepts XML input\n\"text/plain\"                          Accepts plain text\n\"multipart/form-data\"                 Accepts file uploads\n\"application/x-www-form-urlencoded\"   Accepts form data\n</code></pre></li> <li>produces <pre><code>\"application/json\"  Returns JSON\n\"application/xml\"   Returns XML\n\"text/html\"         Returns HTML\n\"text/csv\"          Returns CSV\n\"application/pdf\"   Returns PDF\n\n\nAPPLICATION_OCTET_STREAM - Generic binary (default)\nAPPLICATION_PDF - For PDF files\nIMAGE_JPEG/IMAGE_PNG - For images\nAPPLICATION_ZIP - For ZIP archives\n\nContent-Disposition Header\n- attachment forces download dialog\n- filename suggests the saved filename\n</code></pre></li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/","title":"Things developer does for REST API:","text":""},{"location":"00_Springboot/02_web/00_general_web_task/#1-customizing-rest-endpoints-and-controllers","title":"1. Customizing REST Endpoints and Controllers","text":"<ul> <li>Endpoint Design: Follow RESTful principles, ensuring that URIs represent resources and use appropriate HTTP methods (GET, POST, PUT, DELETE, etc.).</li> <li>Controller Annotations: Use @RestController to define RESTful controllers and @RequestMapping or more specific annotations like @GetMapping, @PostMapping, etc., to map HTTP requests to handler methods.</li> <li>Path Variables and Request Parameters: Use @PathVariable and @RequestParam to capture and process data from the URI and query parameters.</li> <li>Request Body: Use @RequestBody to bind the HTTP request body to a Java object for POST and PUT requests.</li> <li>Response Entity: Return ResponseEntity to have full control over the HTTP response, including status codes and headers.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#2-content-negotiation","title":"2. Content Negotiation","text":"<ul> <li>Multiple Representations: Support different representations (JSON, XML) by configuring content negotiation.</li> <li>Media Types: Use produces and consumes attributes in request mapping annotations to specify supported media types.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#3-request-validation-and-formatting","title":"3. Request Validation and Formatting","text":"<ul> <li>Custom Validators: Create custom validation annotations and logic for request parameters and bodies.</li> <li>Date and Time Formatting: Customize date and time formats in request and response bodies.</li> <li>Validator library:     <code>&lt;artifactId&gt;spring-boot-starter-validation&lt;/artifactId&gt;   &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt;   &lt;artifactId&gt;validation-api&lt;/artifactId&gt;</code></li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#4-custom-exception-handling-and-error-responses","title":"4. Custom Exception Handling and Error Responses","text":"<ul> <li>Global Exception Handling: Use @ControllerAdvice along with @ExceptionHandler to handle exceptions globally and provide consistent error responses.</li> <li>Custom Error Response Structure: Define a custom error response structure to return meaningful error messages and codes.</li> <li>Validation Errors: Use @Valid to trigger validation and handle validation errors gracefully.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#5-request-and-response-logging","title":"5. Request and Response Logging","text":"<ul> <li>Logging Interceptors: Implement interceptors to log incoming requests and outgoing responses for debugging and monitoring purposes.</li> <li>Log Filters: Use filters to log request and response details conditionally, based on configurations.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#6-security","title":"6. Security","text":"<ul> <li>CORS Configuration: Configure CORS to allow or restrict cross-origin requests based on security policies.</li> <li>Authentication and Authorization: Implement security mechanisms using Spring Security, including JWT (JSON Web Token) for stateless authentication.</li> <li>CSRF Protection: Ensure protection against Cross-Site Request Forgery (CSRF) attacks.</li> <li>Role-Based Access Control (RBAC): Define roles and restrict access to endpoints based on roles.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#7-rate-limiting-and-throttling","title":"7. Rate Limiting and Throttling","text":"<ul> <li>Rate Limiting Filters: Implement rate limiting to protect the API from abuse and ensure fair usage.</li> <li>Throttling Policies: Define and apply throttling policies to control the rate of requests from clients.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#8-api-documentation","title":"8. API Documentation","text":"<ul> <li>Swagger/OpenAPI Integration: Use Swagger or Springdoc OpenAPI to generate interactive API documentation.</li> <li>Annotations: Use Swagger annotations (@Api, @ApiOperation, etc.) to provide metadata for API documentation.</li> <li></li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#9-api-versioning","title":"9. API Versioning","text":"<ul> <li>URI Versioning: Include version numbers in the URI (e.g., /api/v1/resource).</li> <li>Header Versioning: Use custom headers to specify API versions.</li> <li>Content Negotiation Versioning: Use the Accept header to specify version (e.g., application/vnd.example.v1+json).</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#10-pagination-and-sorting","title":"10. Pagination and Sorting","text":"<ul> <li>Spring Data JPA: Utilize Spring Data JPA's built-in pagination and sorting capabilities.</li> <li> </li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#custom-pagination-implement-custom-pagination-logic-if-required","title":"Custom Pagination: Implement custom pagination logic if required.","text":""},{"location":"00_Springboot/02_web/00_general_web_task/#11-hateoas-hypermedia-as-the-engine-of-application-state","title":"11. HATEOAS (Hypermedia as the Engine of Application State)","text":"<ul> <li>Implementing HATEOAS: Use Spring HATEOAS to add hypermedia links to the API responses, enabling clients to navigate the API dynamically.</li> <li>Resource Assemblers: Use ResourceAssembler classes to encapsulate the logic of creating resource representations with links.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#12-asynchronous-processing","title":"12. Asynchronous Processing","text":"<ul> <li>Async Controllers: Use @Async and CompletableFuture to handle long-running requests asynchronously.</li> <li>Deferred Results: Use DeferredResult or WebAsyncTask to return responses asynchronously.</li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#13-testing","title":"13. Testing","text":"<ul> <li>Unit Tests: Write unit tests for controllers using MockMVC.</li> <li>Integration Tests: Implement integration tests to verify the entire API flow.</li> <li>API Contract Testing: Use tools like Postman or Pact to ensure API contracts are met.</li> <li></li> </ul>"},{"location":"00_Springboot/02_web/00_general_web_task/#14-handling-file-uploads-and-downloads","title":"14. Handling File Uploads and Downloads","text":"<ul> <li>MultipartFile: Use MultipartFile to handle file uploads.</li> <li>Streaming Responses: Stream large files to clients to manage memory efficiently.</li> <li>By customizing these aspects, you can create a robust, secure, and scalable REST API tailored to your specific needs.</li> </ul>"},{"location":"00_Springboot/02_web/01_servlet_3/","title":"Servlet 3","text":""},{"location":"00_Springboot/02_web/01_servlet_3/#-httpschatgptcomcd7dba5ab-7f7a-4c1c-a443-f67f15ca09a2-green_circle","title":"- https://chatgpt.com/c/d7dba5ab-7f7a-4c1c-a443-f67f15ca09a2 :green_circle:","text":""},{"location":"00_Springboot/02_web/01_servlet_3/#servlet-3","title":"Servlet 3","text":""},{"location":"00_Springboot/02_web/01_servlet_3/#new-features","title":"new feature/s","text":"<ul> <li>programmatically register servlets,filter and lister into it ServletContext / SC , using <code>WebApplicationInitializer</code></li> <li> <p>eliminating need of web.xml</p> </li> <li> <p><code>public class MyWebAppInitializer implements WebApplicationInitializer {     @Override     public void onStartup(ServletContext servletContext) throws ServletException {         ServletRegistration.Dynamic servlet = servletContext.addServlet(\"exampleServlet\", new ExampleServlet());         servlet.addMapping(\"/example\");     }     }</code></p> </li> <li>Anno based - <code>@WebServlet</code>, <code>@WebFilter</code>, <code>@WebListener</code></li> <li>allows asynchronous request processing <pre><code>@WebServlet(urlPatterns = \"/asyncServlet\", asyncSupported = true)\npublic class AsyncServlet extends HttpServlet {\n    @Override\n    protected void doGet(HttpServletRequest request, HttpServletResponse response)\n            throws ServletException, IOException {\n        AsyncContext asyncContext = request.startAsync();\n        asyncContext.start(() -&gt; {\n            try {\n                // Simulate long-running task\n                Thread.sleep(5000);\n                response.getWriter().write(\"Async Response\");\n                asyncContext.complete();\n            } catch (Exception e) {\n                e.printStackTrace();\n            }\n        });\n    }\n}\n</code></pre></li> <li>programmatically configure security settings, but will use sb-security-starter.</li> <li>Enhanced file upload capabilities with the <code>@MultipartConfig</code> </li> </ul>"},{"location":"00_Springboot/02_web/01_servlet_3/#weblistener","title":"@webListener","text":"<ul> <li>used to perform actions in response to various events in a web application</li> <li>event eg : creation and destruction of the sessions and request objects</li> <li>based  on event already parent listener present, just create subclass out of it<ul> <li>HttpSessionListener</li> <li>ServletRequestListener</li> <li>... <pre><code>@WebListener\npublic class MyServletRequestListener implements ServletRequestListener {\n\n    @Override\n    public void requestInitialized(ServletRequestEvent sre) {\n        System.out.println(\"Request initialized\");\n        // Perform tasks such as logging request details, initializing request-specific data, etc.\n    }\n\n    @Override\n    public void requestDestroyed(ServletRequestEvent sre) {\n        System.out.println(\"Request destroyed\");\n        // Perform tasks such as cleaning up request-specific data, logging request end, etc.\n    }\n}\n</code></pre></li> </ul> </li> </ul>"},{"location":"00_Springboot/02_web/01_servlet_3/#servlet-context-sc","title":"Servlet Context / SC","text":"<ul> <li>like spring IAC - AC or hibernate - PC, we have web container - SC</li> <li>sample code: <pre><code>  - InputStream inputStream = servletContext.getResourceAsStream(\"/WEB-INF/resource.txt\");\n\n  - String paramValue = servletContext.getInitParameter(\"paramName\");\n\n  - servletContext.setAttribute(\"attributeName\", attributeValue);\n    Object attributeValue = servletContext.getAttribute(\"attributeName\");\n    servletContext.removeAttribute(\"attributeName\");\n\n  - servletContext.addServlet(\"dynamicServlet\", new MyServlet()); \n</code></pre></li> </ul>"},{"location":"00_Springboot/02_web/01_servlet_3/#webfilter","title":"@WebFilter","text":"<ul> <li>Components that can perform filtering tasks on request and response objects</li> <li>before and after the request is processed by a servlet.</li> <li>logging, </li> <li>authentication, </li> <li>input validation, </li> <li>transformation of response content. - intercept <pre><code>@WebFilter(\n    urlPatterns = \"/*\",\n    initParams = {\n        @WebInitParam(name = \"paramName\", value = \"paramValue\")\n    }\n)\npublic class ConfigurableFilter implements Filter {\n\n    private String paramValue;\n\n    @Override\n    public void init(FilterConfig filterConfig) throws ServletException {\n        paramValue = filterConfig.getInitParameter(\"paramName\");\n    }\n\n    @Override\n    public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain)\n            throws IOException, ServletException {\n        // Use the initialization parameter in the filter logic\n        System.out.println(\"Initialization Parameter: \" + paramValue);\n\n        // Pass the request and response to the next filter or servlet in the chain\n        chain.doFilter(request, response);\n    }\n\n    @Override\n    public void destroy() {\n        // Cleanup code, if needed\n    }\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/02_web/02_spring_MVC/","title":"spring MVC","text":""},{"location":"00_Springboot/02_web/02_spring_MVC/#overview-green_circle","title":"overview :green_circle:","text":"<ul> <li>flow with - handler mapping, view resolver, view renderer, interceptor/inbuilt-filter</li> <li>https://chatgpt.com/c/efc733ec-0a20-4be2-88da-df50535517b3 - basic flow overflow.</li> </ul>"},{"location":"00_Springboot/02_web/02_spring_MVC/#bean-webmvcconfigurer","title":"@Bean <code>WebMvcConfigurer</code>","text":"<ul> <li>create anonymous class out of it and override below method:</li> <li>public void addCorsMappings(CorsRegistry registry) {...</li> <li>public void addResourceHandlers(ResourceHandlerRegistry registry) { ...</li> <li>public void configureViewResolvers(ViewResolverRegistry registry)</li> <li>public void addInterceptors(InterceptorRegistry registry) {</li> <li>public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {</li> <li>... <pre><code>@Configuration\npublic class WebMvcConfig {\n\n    @Bean\n    public WebMvcConfigurer webMvcConfigurer() {\n        return new WebMvcConfigurer() {\n\n            // Configure Cross-Origin Resource Sharing (CORS)\n            @Override\n            public void addCorsMappings(CorsRegistry registry) {\n                registry.addMapping(\"/**\")\n                        .allowedOrigins(\"http://localhost:3000\") // Adjust allowed origins\n                        .allowedMethods(\"GET\", \"POST\", \"PUT\", \"DELETE\")\n                        .allowedHeaders(\"*\")\n                        .allowCredentials(true);\n            }\n\n            // Configure resource handlers for serving static files\n            @Override\n            public void addResourceHandlers(ResourceHandlerRegistry registry) {\n                registry.addResourceHandler(\"/static/**\")\n                        .addResourceLocations(\"classpath:/static/\")\n                        .setCachePeriod(3600); // 1 hour caching\n            }\n\n            // Configure view resolvers\n            @Override\n            public void configureViewResolvers(ViewResolverRegistry registry) {\n                registry.viewResolver(new InternalResourceViewResolver(\"/WEB-INF/views/\", \".jsp\"));\n            }\n\n            // Configure interceptors\n            @Override\n            public void addInterceptors(InterceptorRegistry registry) {\n                registry.addInterceptor(new CustomInterceptor())\n                        .addPathPatterns(\"/**\")\n                        .excludePathPatterns(\"/login\", \"/error\");\n            }\n\n            // Configure content negotiation (e.g., JSON/XML response format)\n            @Override\n            public void configureContentNegotiation(ContentNegotiationConfigurer configurer) {\n                configurer.favorParameter(true)\n                        .parameterName(\"format\")\n                        .defaultContentType(org.springframework.http.MediaType.APPLICATION_JSON)\n                        .mediaType(\"json\", org.springframework.http.MediaType.APPLICATION_JSON)\n                        .mediaType(\"xml\", org.springframework.http.MediaType.APPLICATION_XML);\n            }\n\n            // Configure message converters for HTTP request/response\n            @Override\n            public void configureMessageConverters(List&lt;HttpMessageConverter&lt;?&gt;&gt; converters) {\n                // Add custom converters if needed\n            }\n\n            // Configure path match options\n            @Override\n            public void configurePathMatch(PathMatchConfigurer configurer) {\n                configurer.setUseTrailingSlashMatch(false);\n            }\n        };\n    }\n\n    // Locale resolver for internationalization\n    @Bean\n    public LocaleResolver localeResolver() {\n        AcceptHeaderLocaleResolver resolver = new AcceptHeaderLocaleResolver();\n        resolver.setDefaultLocale(Locale.US);\n        return resolver;\n    }\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/","title":"Spring Boot Starter Web","text":""},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#-httpschatgptcomc831f36a0-bce4-4372-87d4-9ab6528babc5","title":"- https://chatgpt.com/c/831f36a0-bce4-4372-87d4-9ab6528babc5","text":""},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#sb-starter-web","title":"sb-starter-web","text":""},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#a-features","title":"A. features","text":"<ul> <li>necessary dependencies (jackson, springMVC), </li> <li>embedded server</li> <li>default exception</li> <li>Actuator</li> </ul>"},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#b-useful-customization-class","title":"B. useful customization class","text":""},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#1-class-webserverfactorycustomizer","title":"1. class: WebServerFactoryCustomizer","text":"<ul> <li>interface provided by Spring Boot </li> <li>allows you to customize the configuration of embedded web servers</li> <li>setting ports, </li> <li>enabling SSL, </li> <li>configuring timeouts</li> </ul> <pre><code>@Component\npublic class MyTomcatCustomizer implements WebServerFactoryCustomizer&lt;TomcatServletWebServerFactory&gt; {\n\n    @Override\n    public void customize(TomcatServletWebServerFactory factory) \n    {\n        factory.setPort(8081);  \n        factory.setContextPath(\"/myapp\");  \n\n        // Additional customization can be done here\n        factory.addConnectorCustomizers(connector -&gt; {\n\n        });\n\n        // SSl\n        Ssl ssl = new Ssl();\n            ssl.setKeyStore(\"classpath:keystore.jks\");\n            ssl.setKeyStorePassword(\"password\");\n            ssl.setKeyPassword(\"password\");\n        factory.setSsl(ssl);\n    }\n}\n</code></pre>"},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#2-class-servletregistrationbean","title":"2. class: ServletRegistrationBean","text":"<ul> <li>Register a New Servlet (spring boot way)</li> <li>similarly have @Bean <code>FilterRegistrationBean&lt;MyFilter&gt;</code></li> </ul> <pre><code>@Configuration\npublic class ServletConfig \n{\n    @Bean\n    public ServletRegistrationBean&lt;CustomServlet&gt; customServletRegistrationBean() \n    {\n        ServletRegistrationBean&lt;CustomServlet&gt; registrationBean = new ServletRegistrationBean&lt;&gt;(new CustomServlet(), \"/custom\");\n        registrationBean.setLoadOnStartup(1);\n        return registrationBean;\n    }\n}\n</code></pre>"},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#3-class-springbootservletinitializer","title":"3. Class: SpringBootServletInitializer","text":"<ul> <li>used when you want to deploy a Spring Boot application to an external servlet container</li> <li>check below for more.</li> </ul>"},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#c-typical-things","title":"C. Typical things:","text":""},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#1-update-embedded-server","title":"1. update embedded server","text":"<ul> <li>update pom </li> <li>add spring-boot-starter-undertow / spring-boot-starter-jetty</li> <li>exclude &lt;spring-boot-starter-tomcat from <code>spring-boot-starter-web</code></li> </ul>"},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#2-shut-down-project","title":"2. shut down project","text":"<ul> <li>ApplicationContext context = SpringApplication.run(DemoApplication.class, args);</li> <li>context.close();</li> </ul>"},{"location":"00_Springboot/02_web/03_spring_boot_stater_web/#3-remove-any-embedded-server-deploy-on-external-server","title":"3. Remove any embedded Server / Deploy on external Server","text":"<ul> <li>remove dependencies for embeded server</li> <li>change to war : war</li> <li>extend SpringBootServletInitializer -&gt; override Configure. <pre><code>   @SpringBootApplication\n   public class DemoApplication extends SpringBootServletInitializer {\n\n    public static void main(String[] args) {\n        SpringApplication.run(DemoApplication.class, args);\n    }\n\n    @Override\n    protected SpringApplicationBuilder configure(SpringApplicationBuilder application) {\n        return application.sources(DemoApplication.class);\n    }\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/02_web/04_REST/","title":"REST","text":""},{"location":"00_Springboot/02_web/04_REST/#references","title":"references","text":"<ul> <li>https://www.baeldung.com/rest-with-spring-series</li> <li>web filter : https://chatgpt.com/c/34abc85f-eabb-47ac-b525-7c2c6af8023a </li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#rest-actions","title":"REST Actions","text":""},{"location":"00_Springboot/02_web/04_REST/#1-actions-list-1","title":"1 actions list-1","text":"<ul> <li>https://chatgpt.com/c/0471007c-7d4e-4a04-bd37-d6262d5f9aaf - REST Actions</li> <li><code>create</code></li> <li><code>logging interceptor/filter</code> --&gt; not doing, having common logging.</li> <li><code>Content Negotiation</code> - Support different representations : <code>produces/consumes</code> = MediaType.APPLICATION_JSON</li> <li><code>API versioning</code></li> <li><code>API DOC</code></li> <li><code>security</code> - using OAuth2.0</li> <li><code>Validation</code> - using hibernate JSR validator + custom validator anno.</li> <li><code>Formatting</code> - using jackson - custom serialization/de-S..</li> <li><code>CORS</code> setup - add frontend url</li> <li><code>Pagination and Sorting</code> - pageable and page"},{"location":"00_Springboot/02_web/04_REST/#2-more-actions-list-2-pending","title":"2 more actions list-2 (pending)","text":"<ul> <li>Async Controllers: </li> <li>Use @Async(\"taskExecutor-1\") and CompletableFuture to handle long-running requests asynchronously </li> <li>AsyncController.java</li> <li>@EnableAsync - enable</li> <li> <p>create @Bean(name = \"taskExecutor-1\") ThreadPoolTaskExecutor : AsyncConfig.java</p> </li> <li> <p>HATEOS</p> </li> <li>https://chatgpt.com/c/67414b1b-9018-800d-a683-8a632932177a</li> <li>return EntityModel from api method. <li>use WebMvcLinkBuilder to create Link <pre><code>User user1 = new User(id, \"John Doe\", \"john.doe@example.com\"); // current api result\n...\nLink allUsersLink = WebMvcLinkBuilder\n .linkTo(\n     WebMvcLinkBuilder\n        .methodOn(UserController.class)\n        .getAllUsers())                     &lt;&lt;&lt; another controller/api method\n .withRel(\"all-users\");\n ...\n return EntityModel&lt;User&gt;.of(user1, allUsersLink);\n</code></pre></li> <li>sample response : <code>_links</code> <pre><code>{\n  \"id\": 1,\n  \"name\": \"John Doe\",\n  \"email\": \"john.doe@example.com\",\n\n  \"_links\": {\n      \"all-users\": {\n          \"href\": \"http://localhost:8080/api/users\"\n      }\n  }\n}\n</code></pre></li>"},{"location":"00_Springboot/02_web/04_REST/#a-create-api","title":"A Create API","text":"<ul> <li>check JewelleryController.java</li> <li>@ResponseBody + <code>@Controller</code> =<code>@RestController</code></li> <li>Modify HttpResponse</li> <li>inject <code>HttpServletResponse response</code> as method arg directly and manipulate response.</li> <li>ResponseEntity&lt;?&gt; ResponseEntityBuilder --&gt;  statusCode, headers and body.</li> <li>@ResponseBody - serialized into JSON</li> <li>Bind <code>Map&lt;String,String&gt;</code> with</li> <li>RequestHeader</li> <li>RequestBody</li> <li>PathVariable</li> <li>RequestParam</li> <li>can make above input optional. can set default value for above input.</li> <li>eg:  @PathVariable(value=\"pathVariable2\", required = false) String pathVariable2_optional :</li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#b-validation-jsr-380","title":"B. Validation / JSR 380","text":"<ul> <li>apply on DTO/Bean/ENTITY</li> <li>https://chatgpt.com/c/a04dc001-e879-43e0-a39d-acd01b9ef2c7</li> <li>Add dependeny : spring-boot-starter-validation</li> <li>annotation: <code>@email</code>, <code>@size</code>, <code>@NotBlank(\"\")</code>, etc</li> <li>use <code>@Valid</code> annotation to trigger validation in Controller or where ever binding happens:<ul> <li>@Valid @ResquestBody dto //method arg</li> <li>Apply on method return.</li> </ul> </li> <li>validate response: https://chatgpt.com/c/b8c60911-2df5-478b-9804-67c3ecf9506d</li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#custom-validator","title":"Custom validator","text":"<ul> <li>check hibernate_validator</li> <li>can inject BindingResult as well.</li> <li>just implement <code>ConstraintValidator&lt;Anno,feildType&gt;</code></li> <li>```   // Apply @NameCheckAnnotation_1 on feilds</li> </ul> <p>public class NameValidator implements ConstraintValidator {   @Override   public boolean isValid(String value, ConstraintValidatorContext context) {      return true;   }   }   ``` <ul> <li>implement ResponseBodyAdvice class </li> <li>The default Spring validation mechanism does not automatically validate objects wrapped in ResponseEntity. </li> <li>However, you can achieve this by creating a custom ResponseBodyAdvice implementation.</li> <li>@Valid / @validated :: cannot perform on ResponseEntity.</li> <li>check : https://chatgpt.com/c/591c7b06-4ac0-4f03-a328-038cde9cf7ca</li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#c-formatting-serialize-de-serialize","title":"C. Formatting ( Serialize / De-serialize)","text":"<ul> <li>more: 05_Jackson.md</li> <li>binding happens with internal Serialize/De-serialize by jackson, </li> <li>has inbuilt serializer and de-serializer</li> <li>can create custom ones too.</li> <li>customize objectMapper, check JacksonConfig.java</li> <li>note: String to LocalDateTime : <code>@DateTimeFormat</code> (From SB, not jackson)</li> <li>HttpMessageConverter</li> <li>new MappingJackson2HttpMessageConverter()</li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#d-version","title":"D. Version","text":"<ul> <li>https://chatgpt.com/c/7fa2c12d-eada-4991-944f-cfad8d084805</li> <li>@RequestMapping(\"/api/v1\")</li> <li>@GetMapping(value = \"/users\", <code>params = \"version=1\"</code>)<ul> <li>while consuming, set requestParam :  version=1</li> </ul> </li> <li> <p>@GetMapping(value = \"/users\", <code>headers = \"X-API-VERSION=1\"</code>)</p> <ul> <li>while consuming, set header : X-API-VERSION=1</li> </ul> </li> <li> <p>@GetMapping(value = \"/users\", <code>produces = \"application/vnd.company.app-v1+json\"</code>)</p> <ul> <li>while consuming, set header : Accept=application/vnd.company.app-v1+json</li> </ul> </li> <li> <p>Choosing the Right API versioning Approach:</p> <ul> <li>URI Path Versioning: Clear and straightforward, widely used.</li> <li>Request Parameter Versioning: Useful for flexibility in request parameters.</li> <li>Header Versioning: Keeps the URL clean, suitable for clients that can easily add headers.</li> <li>Content Negotiation Versioning: Good for complex API evolution but can be harder to debug.</li> </ul> </li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#e-rest-consume-pending","title":"E. REST : consume <code>Pending...</code>","text":"<ul> <li>https://chatgpt.com/c/9719e1f6-c4e4-4fac-8941-178c26acc484</li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#resttemplate","title":"RestTemplate","text":""},{"location":"00_Springboot/02_web/04_REST/#webclient","title":"webClient","text":""},{"location":"00_Springboot/02_web/04_REST/#f-hateoas-pending","title":"F. HATEOAS <code>Pending...</code>","text":"<ul> <li>add hypermedia links to the API responses, enabling clients to navigate the API dynamically</li> <li>hands-on pending.</li> </ul>"},{"location":"00_Springboot/02_web/04_REST/#project-pending","title":"project : <code>Pending...</code>","text":"<ul> <li>SetTimeouts API</li> <li>API to download file.</li> <li>Filters and Interceptors / <code>InterceptorRegistry</code></li> <li>webClient and RestTemplate</li> <li>custom Binder</li> <li>ResponseBodyAdvice program</li> <li><code>@WebFilter</code></li> <li>Send response other than JSON</li> </ul>"},{"location":"00_Springboot/02_web/05_Jackson/","title":"jackson","text":""},{"location":"00_Springboot/02_web/05_Jackson/#reference","title":"reference","text":"<ul> <li>https://chatgpt.com/c/0f8b8a16-cab5-4fbb-8f0e-1c7949dd97f4 - anno 1</li> <li>https://chatgpt.com/c/cbe3f6c3-c238-4db8-99e5-a0c9c9ddffec - anno 2</li> <li>https://chatgpt.com/c/4334405c-e8c0-4e88-a138-a53b14ae52b5 - object mapper</li> <li>https://www.baeldung.com/jackson</li> </ul> <ul> <li>Json , JsonStr , Object , JsonNode(asText(), readTree())</li> <li>Objectmapper / Xmlmapper API</li> <li>@ResquestBody and @responseBody behind the scene perform S and D using OM.</li> <li>Advance Section pending : https://www.baeldung.com/jackson</li> </ul>"},{"location":"00_Springboot/02_web/05_Jackson/#common-task","title":"Common task","text":"<ol> <li>Serialize and Deserialize </li> <li>Class, generic-Class</li> <li>interface and abstractClass : Does not work.</li> <li>property order, alias, root</li> <li>Type/property </li> <li>@JsonAlias</li> <li>@JsonUnwrapped - performs flattening. {a,{b,c}} === {a,b,c}</li> <li>@JsonSetter is an alternative to @JsonProperty that marks the method as a setter method.</li> <li>@JsonIgnore, @JsonIgnoreType, @JsonFilter - conditionally ignore.</li> <li>@JsonInclude(Include.NOT_NULL) , @JsonIncludeProperties class</li> <li>globally set : om.setSerializationInclusion(Include.NON_NULL);</li> <li>formatting : date, time, number, etc : </li> <li>@DateTimeFormat(fromSB)</li> <li>om.setDateFormat(new SimpleDateFormat(\" \"))</li> <li>handle collection.</li> <li>@JsonCreator(apply on constructor/method to create/return object)    tune the constructor/factory used in deserialization.</li> </ol> <p><pre><code>    - String jsonCarArray =\"[{ \\\"color\\\" : \\\"Black\\\", \\\"type\\\" : \\\"BMW\\\" }, { \\\"color\\\" : \\\"Red\\\", \\\"type\\\" : \\\"FIAT\\\" }]\";\n      List&lt;Car&gt; listCar = objectMapper.readValue(jsonCarArray, new TypeReference&lt;List&lt;Car&gt;&gt;(){});\n\n    - String json = \"{ \\\"color\\\" : \\\"Black\\\", \\\"type\\\" : \\\"BMW\\\" }\";\n      Map&lt;String, Object&gt; map = objectMapper.readValue(json, new TypeReference&lt;Map&lt;String,Object&gt;&gt;(){});\n</code></pre> 5. handle raw json 6. handle Enums - @JsonValue for S, @JsonCreator for D      ```    // Default    public enum Status {SUCCESS,FAILURE,PENDING}       String json = mapper.writeValueAsString(Status.SUCCESS); //  \"\\\"SUCCESS\\\"\"       Status status = mapper.readValue(json, Status.class); // SUCCESS</p> <p>// @JsonValue for S, @JsonCreator for D     public enum Status {String v;SUCCESS(\"S\"),FAILURE(\"F\"),PENDING(\"P\");     Status(string v){}      @JsonValue getValue(v)     @JsonCreator m(v){...}    }      String json = mapper.writeValueAsString(Status.SUCCESS); //  \"\\\"S\\\"\"      Status status = mapper.readValue(json, Status.class); // S    <code>7. Don't use Optional&lt;T&gt; as json property.    - Add Dependencies : jackson-datatype-jdk8.    - objectMapper.registerModule(new Jdk8Module());    -</code>      @JsonInclude(JsonInclude.Include.NON_ABSENT) // Optional fields are included if present      public class Event {         private String name;         private Optional description;      }      ``` 8. handle visibilty: @JsonAutoDetect(fieldVisibility = Visibility.ANY) // Private feild. etc. 9."},{"location":"00_Springboot/02_web/05_Jackson/#advance-task","title":"Advance task","text":"<ol> <li>inject<ul> <li>@JacksonInject indicates that a property will get its value from the injection and not from the JSON data.    <pre><code>   InjectableValues inject = new InjectableValues.Std().addValue(int.class, 1);\n   BeanWithInject bean = new ObjectMapper()\n                         .reader(inject)\n                         .forType(BeanWithInject.class)\n                         .readValue(json);\n</code></pre> 2.</li> </ul> </li> </ol>"},{"location":"00_Springboot/02_web/05_Jackson/#objectmapper","title":"Objectmapper","text":"<ul> <li>Builder pattern</li> </ul>"},{"location":"00_Springboot/02_web/05_Jackson/#serialize","title":"Serialize","text":"<ul> <li>writeValue(obj) or </li> <li>writeValueAsString(obj)</li> <li>Apply Filter :</li> <li>@JsonFilter(\"Filter-1\") class</li> <li>om.writer(SimpleFilterProvider p).writeValue(obj) //p.addFilter(\"Filter-1\", filterObject eg:SimpleBeanPropertyFilter)</li> </ul>"},{"location":"00_Springboot/02_web/05_Jackson/#de-serialize","title":"De-serialize","text":"<ul> <li>readvalue (json, TypeReference) <li>readerFor(T).readValue(obj)</li>"},{"location":"00_Springboot/02_web/05_Jackson/#config","title":"Config","text":"<ul> <li> <p>unknown/incomplete</p> <ul> <li>FAIL_ON_UNKNOWN_PROPERTIES , @JsonIgnoreProperties(ignoreUnknown = true) MyClass</li> <li>FAIL_ON_NULL_FOR_PRIMITIVES : unmarshalling an incomplete JSON :  @JsonProperty(required = false.True)</li> </ul> </li> <li> <p>mapper.enable(DeserializationFeature.UNWRAP_ROOT_VALUE);</p> </li> <li>WRITE_DATES_AS_TIMESTAMPS,</li> <li>DEFAULT_VIEW_INCLUSION,</li> <li>INDENT_OUTPUT </li> <li>OM &gt;&gt; register module &gt;&gt; add custom S and D</li> <li>OM.configure(k,v)</li> <li>on DTO &gt;&gt; Apply annotation</li> <li>https://chatgpt.com/c/0f8b8a16-cab5-4fbb-8f0e-1c7949dd97f4</li> <li>https://chatgpt.com/c/cbe3f6c3-c238-4db8-99e5-a0c9c9ddffec</li> <li>spring.jackson..=true,false<ul> <li>spring.jackson.serialization.indent_output=true</li> <li>spring.jackson.deserialization.fail-on-unknown-properties=false</li> <li>spring.jackson.mapper.auto-detect-fields=true // @JsonAutoDetect</li> <li>spring.jackson.parser.allow-comments=true</li> <li>spring.jackson.generator.escape-non-ascii=true   <pre><code>      return new ObjectMapper()\n          .enable(SerializationFeature.INDENT_OUTPUT)             // Enable pretty printing\n          .disable(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES) // Ignore unknown properties\n          .enable(MapperFeature.AUTO_DETECT_FIELDS)              // Auto-detect fields\n          .enable(JsonParser.Feature.ALLOW_COMMENTS)             // Allow comments in JSON\n          .enable(JsonGenerator.Feature.ESCAPE_NON_ASCII); \n</code></pre></li> </ul> <ul> <li>UnrecognizedPropertyException : objectMapper.configure(DeserializationFeature.FAIL_ON_UNKNOWN_PROPERTIES, false);</li> <li>extends Std/JsonSerializer --&gt; serialize(T object, JsonGenerator jsonGenerator, SerializerProvider serializer) {...} <li>extends Std/JsonDeserializer  --&gt; T deserialize(JsonParser parser, DeserializationContext deserializer) {...} <li>@JsonCreator : Apply on contructor (@jsonproperty on arg). that constructor is used while unmarshalling</li> <li>@JsonDeserialize(as = Cat.class) Animal a ; // Animal is Interface.</li> <li>@JsonFormat : specifies a format when serializing Date/Time values</li> <li>usally used for java,util.Date, Double price (patter=\"#0.00\")</li> <li>@JsonFormat(shape = JsonFormat.Shape.String, pattern=\"\") Date // </li> <li>@JsonFormat(shape = JsonFormat.Shape.NUMBER) Date //Timeinmilliseconds</li> <li>@JsonFormat(with = JsonFormat.Feature.ACCEPT_CASE_INSENSITIVE_PROPERTIES) class  // IMP</li>"},{"location":"00_Springboot/02_web/06_swagger/","title":"Swagger","text":""},{"location":"00_Springboot/02_web/06_swagger/#enable-swagger","title":"Enable swagger","text":"<ul> <li>add dependeny <pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;io.springfox&lt;/groupId&gt;\n    &lt;artifactId&gt;springfox-boot-starter&lt;/artifactId&gt;\n    &lt;version&gt;3.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n\n or\n\n &lt;dependency&gt;\n    &lt;groupId&gt;org.springdoc&lt;/groupId&gt;\n    &lt;artifactId&gt;springdoc-openapi-ui&lt;/artifactId&gt;\n    &lt;version&gt;1.5.12&lt;/version&gt;\n&lt;/dependency&gt;\n\nor\n\n&lt;dependency&gt;\n    &lt;groupId&gt;io.springfox&lt;/groupId&gt;\n    &lt;artifactId&gt;springfox-swagger2&lt;/artifactId&gt;\n    &lt;version&gt;3.0.0&lt;/version&gt;\n&lt;/dependency&gt;\n\nor\n\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springdoc&lt;/groupId&gt;\n    &lt;artifactId&gt;springdoc-openapi-starter-webmvc-ui&lt;/artifactId&gt;    &lt;&lt;&lt; worked, didnt add anything else\n    &lt;version&gt;2.1.0&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre></li> <li>add config </li> <li>Docker bean</li> <li>@EnableSwagger2WebMvc <pre><code>@Configuration\n@EnableSwagger2WebMvc / @EnableSwagger2\npublic class SwaggerConfig {\n\n    @Bean\n    public Docket api() {\n        return new Docket(DocumentationType.SWAGGER_2)\n                .select()\n                .apis(RequestHandlerSelectors.basePackage(\"com.example.demo\"))\n                .paths(PathSelectors.any())\n                .build();\n    }\n}\n</code></pre></li> <li>http://localhost:8080/swagger-ui/index.html</li> </ul>"},{"location":"00_Springboot/02_web/06_swagger/#customize","title":"Customize","text":"<ul> <li>check : controller</li> <li>Annotation:</li> <li>@Tag/@Api,</li> <li>@ApiOperation,</li> <li>@ApiResponse,</li> <li>@ApiParam.</li> </ul>"},{"location":"00_Springboot/02_web/07_error_handling/","title":"Global Error handling","text":""},{"location":"00_Springboot/02_web/07_error_handling/#a-in-spring-mvc-project","title":"A. in <code>spring MVC project</code>","text":""},{"location":"00_Springboot/02_web/07_error_handling/#1-send-html-response-for-specific-error-code-404","title":"1. send html response for specific error code - 404","text":"<ul> <li>add html page --&gt; resource/templates/404.html </li> <li>add property server.error.404 = /error/path-404</li> <li>add controller.</li> <li>extract <code>ErrorAttributes</code> from  <code>WebRequest</code> <pre><code>@Controller\npublic class ErrorController\n{\n    @Autowired  ErrorAttributes errorAttributes    &lt;&lt;&lt;\n\n    @RequestMapping(\"/error/path-404\")\n    public String handle404Error(WebRequest webRequest) \n    {\n        ErrorAttributeOptions options = ErrorAttributeOptions.of(\n            ErrorAttributeOptions.Include.MESSAGE, \n            ErrorAttributeOptions.Include.EXCEPTION\n            );\n\n        Map&lt;String, Object&gt; errorAttributes = this.errorAttributes.getErrorAttributes(webRequest, options);\n        // errorAttributes has exception detail, which can be include in html page.\n        // add it to model object.\n        // in html - ${errorAttribite.xxxxx}\n\n        return \"404\"; //view name\n    }\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/02_web/07_error_handling/#b-in-rest-api","title":"B. in <code>REST API</code>","text":""},{"location":"00_Springboot/02_web/07_error_handling/#default-handling-flow","title":"Default handling flow","text":"<ul> <li>when an exception occurs, it is automatically routed to below path.</li> <li>define server.error.path = /error</li> <li>BasicErrorController is mapped to this path. </li> <li>it processes and send out json response</li> <li>```   // Sample resposne:</li> </ul> <p>{   \"timestamp\": \"2024-11-20T00:00:00.000+00:00\",   \"status\": 404,   \"error\": \"Not Found\",   \"message\": \"No message available\",   \"path\": \"/some-endpoint\"   }   <code>``   - fact: add more attribute in above response     - @Component public class CustomErrorAttributes extends</code>DefaultErrorAttributes` : just add this bean     - check: CustomErrorAttributes.java     - add custome attribute</p>"},{"location":"00_Springboot/02_web/07_error_handling/#customization-1-basicerrorcontroller","title":"customization-1 : BasicErrorController","text":"<ul> <li>note: don't define server.error.404,etc</li> <li>when any Exception occurs, it is automatically routed to below path</li> <li>define server.error.path = /my-error-path </li> <li>or just keep /error</li> <li>add new @RestController for above path</li> <li>extract ErrorAttributes  from webRequest. like above.</li> <li>will send out json response.</li> <li>@Component class MyBasicErrorController extends ErrorController { @GetMapping(/my-error-path) m()}</li> <li>MyBasicErrorController.java</li> </ul>"},{"location":"00_Springboot/02_web/07_error_handling/#customization-2-controlleradvice","title":"customization-2 (@ControllerAdvice)","text":"<ul> <li>httpRequest send &gt; No issue - no 401,no 500, etc &gt; controller method m1() gets executed.</li> <li>next m1() throws exceptions</li> <li>can have different handler for different exception type.</li> <li>@ExceptionHandler(Exception.class) RE&lt;&gt; m1(Exception e, WebRequest request) { use e ... }</li> <li>@ExceptionHandler(Exception2.class) RE&lt;&gt; m1(Exception2 e, WebRequest request) {...}</li> <li>...</li> </ul>"},{"location":"00_Springboot/02_web/07_error_handling/#customization-3-disable-tomcat-whitelabel-errorpage","title":"customization-3 :: Disable tomcat Whitelabel-ErrorPage","text":"<ul> <li>@EnableAutoConfiguration(exclude = {<code>ErrorMvcAutoConfiguration.class</code>}) --&gt; shows Tomcat page then.</li> <li>or, server.error.whitelabel.enabled=false</li> </ul>"},{"location":"00_Springboot/02_web/07_error_handling/#inbound-outbound-flows-green_circle","title":"inbound / outbound flows :green_circle:","text":"<p>case:1 : incoming request failed, then: -  /error + BasicErrorController (already). -  /my-error + MyBasicErrorController (custom) + inject ErrorAttribute.</p> <p>case-2 : incoming requested success, but business code failed with Exception. - Global Exception Handling - @ControllerAdvice/@RestControllerAdvice + @ExceptionHandler(Exception.class)</p>"},{"location":"00_Springboot/02_web/08_gRPC%2Bwebflux/","title":"gRPC (Google <code>Remote Procedure Call</code>)","text":"<ul> <li>open-source</li> <li>language-agnostic</li> <li>highly efficient for <code>microservices</code> comm.</li> <li><code>binary</code> serialized Protobuf payloads  (Harder to debug)</li> </ul>"},{"location":"00_Springboot/02_web/08_gRPC%2Bwebflux/#grpc-over-http2-default","title":"gRPC over HTTP/2 (default)","text":"<ul> <li>gRPC with HTTP/1.1 (Less Common but Possible)</li> <li>reduced latency </li> <li>bi-directional streaming - Server streaming, client streaming, and bi-directional streaming.</li> <li>multiplexing -  multiple calls on a single connection</li> <li>load balancing</li> <li>built in - Authentication, compression, SSL, and retries</li> </ul>"},{"location":"00_Springboot/02_web/08_gRPC%2Bwebflux/#grpc-webfor-browser-clients","title":"gRPC-Web((For Browser Clients)","text":"<ul> <li>ng/react uses </li> <li>gRPC-Web, which uses HTTP/1.1 or HTTP/2 in the browser to communicate with the backend gRPC services</li> </ul>"},{"location":"00_Springboot/02_web/08_gRPC%2Bwebflux/#steps","title":"Steps","text":"<ul> <li>proto file : user.proto.bkp</li> <li>pom.xml</li> <li>mvn compile.</li> <li>check target folder for stub. <pre><code>&lt;plugin&gt;\n                &lt;groupId&gt;org.xolstice.maven.plugins&lt;/groupId&gt;\n                &lt;artifactId&gt;protobuf-maven-plugin&lt;/artifactId&gt;\n                &lt;version&gt;0.6.1&lt;/version&gt;\n                &lt;executions&gt;\n                    &lt;execution&gt;\n                        &lt;goals&gt;\n                            &lt;goal&gt;compile&lt;/goal&gt;\n                            &lt;goal&gt;compile-custom&lt;/goal&gt;\n                        &lt;/goals&gt;\n                    &lt;/execution&gt;\n                &lt;/executions&gt;\n                &lt;configuration&gt;\n                    &lt;protoSourceRoot&gt;src/main/proto&lt;/protoSourceRoot&gt;\n                    &lt;pluginId&gt;grpc-java&lt;/pluginId&gt;\n                &lt;/configuration&gt;\n&lt;/plugin&gt;\n</code></pre> <pre><code>        &lt;!--g-rpc--&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.grpc&lt;/groupId&gt;\n            &lt;artifactId&gt;grpc-netty&lt;/artifactId&gt;\n            &lt;version&gt;1.57.0&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.grpc&lt;/groupId&gt;\n            &lt;artifactId&gt;grpc-protobuf&lt;/artifactId&gt;\n            &lt;version&gt;1.57.0&lt;/version&gt;\n        &lt;/dependency&gt;\n        &lt;dependency&gt;\n            &lt;groupId&gt;io.grpc&lt;/groupId&gt;\n            &lt;artifactId&gt;grpc-stub&lt;/artifactId&gt;\n            &lt;version&gt;1.57.0&lt;/version&gt;\n        &lt;/dependency&gt;\n</code></pre></li> <li>client code: <pre><code>import io.grpc.ManagedChannel;\nimport io.grpc.ManagedChannelBuilder;\nimport com.example.grpc.UserProto;\nimport com.example.grpc.UserServiceGrpc;\n\npublic class UserGrpcClient {\n    public static void main(String[] args) {\n        ManagedChannel channel = ManagedChannelBuilder.forAddress(\"localhost\", 9090)\n            .usePlaintext()\n            .build();\n\n        UserServiceGrpc.UserServiceBlockingStub blockingStub = UserServiceGrpc.newBlockingStub(channel);\n\n        // Create a request\n        UserProto.UserRequest request = UserProto.UserRequest.newBuilder()\n            .setUserId(\"123\")\n            .build();\n\n        // Make a gRPC call\n        UserProto.UserResponse response = blockingStub.getUser(request);\n        System.out.println(\"User Details: \" + response.getName() + \", \" + response.getEmail());\n\n        channel.shutdown();\n    }\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/02_web/09_webflux/","title":"webflux (in progress)","text":"<ul> <li>websocket</li> <li>Http 2/3</li> </ul>"},{"location":"00_Springboot/03_data-layer/00_common_task/","title":"Common task","text":""},{"location":"00_Springboot/03_data-layer/00_common_task/#set-default-value","title":"Set Default value","text":"<ul> <li>@Column(columnDefinition = \"varchar(255) default 'John Snow'\")</li> <li>Inside Entity class </li> <li>private String firstName = \"John Snow\";</li> </ul>"},{"location":"00_Springboot/03_data-layer/00_common_task/#constraint-nullable","title":"constraint - <code>Nullable</code>","text":"<ul> <li>@Column(nullable=t/f)</li> <li>@Basic(optional=t/f)</li> <li>hibernate validator - <code>@NotNull</code> </li> <li>can apply on any bean, not just entity eg:jackson.</li> </ul>"},{"location":"00_Springboot/03_data-layer/00_common_task/#constraint-unique","title":"Constraint - <code>unique</code>","text":"<ul> <li>@Column(unique=t/f) : Single column</li> <li>unique composite key:   <pre><code>@Table(uniqueConstraints = {\n   @UniqueConstraint(columnNames = { \"personNumber\", \"isActive\" }) ,\n   @UniqueConstraint(columnNames = { \"personNumber\" }) \n }, ...)\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/","title":"JPA","text":"<ul> <li>Reference</li> <li>all topics: https://www.baeldung.com/learn-jpa-hibernate</li> <li>inheritance : https://www.baeldung.com/hibernate-inheritance</li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/#jpa","title":"JPA","text":""},{"location":"00_Springboot/03_data-layer/01_JPA/#intro","title":"Intro","text":"<ul> <li>JPA Specification --&gt; ORM layer (focus)</li> <li>interact with a relational database without any SQL.</li> <li>eg: Hibernate framework</li> <li>first/Second level Cache. </li> <li>Entity</li> <li>lifecycle state : New/Transient &gt; managed &gt; detached &gt; removed/Deleted(markedForDelete).</li> <li>Transient - POJO which has no representation in the PC.</li> <li>relationships </li> <li>inheritance </li> <li>(EntityManager / EntityManagerFactory) or  (Session / sessionFactory in Hibernate)</li> <li>heap(object) &lt;&gt; PC(managed entity) &lt;&gt; Database</li> <li>provide API to interact with PC. more on PC 02_presistence-context.md<ul> <li>session.persist : mark for save</li> <li>session.merge : move to pc</li> <li>session.refresh : sync with DB</li> <li>session.remove : marked for delete</li> <li>session.detach : remove from pc</li> <li>session.flush</li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/#a-key-componentsbean-to-build-for-develop","title":"A. key components/bean to build for develop:","text":"<ul> <li>SessionFactory<ul> <li>heavy, Created at startup in SB project</li> <li>rename bean : @Bean(name = \"entityManagerFactory\") LocalSessionFactoryBean m(){...}</li> </ul> </li> <li>TransactionManager <ul> <li><code>PlatformTransactionManager</code> --impl--&gt; HibernateTransactionManager, JpaTransactionManager</li> </ul> </li> <li>TransactionTemplate <ul> <li>HibernatePostgresConfig.java</li> <li>can set global ISOLATION LEVEL here </li> </ul> </li> <li>Datasource <ul> <li>database connections pool</li> <li>eg: hikari, javax.sql.DataSource, etc</li> <li>use DataSourceBuilder</li> </ul> </li> <li>repositories<ul> <li>way-1: @Repository public interface ProductRepository extends JpaRepository { ... } <li>has @PersistenceContext(type = PersistenceContextType.TRANSACTIONAL)</li> <li>way-2: https://chat.deepseek.com/a/chat/s/8e1072c2-9522-4d97-8c6b-d6cdc8ef7c97</li> <li>this is custom repo</li> <li>check more eg: StudentRepository.java <pre><code>@Repository\npublic class ExtendedPersistenceContextRepository \n{\n    @PersistenceContext(type = PersistenceContextType.EXTENDED)\n    //@PersistenceContext(type = PersistenceContextType.TRANSACTIONAL)\n    private EntityManager entityManager;\n\n    public void addToPersistenceContext(User user) {        entityManager.persist(user);     }\n\n    @Transactional\n    public void saveChanges() {        entityManager.flush();     }  // explicit flush  &lt;&lt;&lt;\n    ...\n}\n</code></pre></li>"},{"location":"00_Springboot/03_data-layer/01_JPA/#b-jpa-entity-lifecycle-events","title":"B JPA Entity - Lifecycle Events","text":"<ul> <li>create MyListener.class</li> <li>add method/s and annotate with :</li> <li>@PrePersist m(), @PostPersist m(),</li> <li>@PreRemove m(), @PostRemove m(),</li> <li>@PreUpdate m(), @PostUpdate m(),</li> <li>@PostLoad m()</li> <li>go to @Entity MyEntity</li> <li>annotate entity class with <code>@EntityListeners</code>(MyListener.class) </li> <li>fact : </li> <li>@GeneratedValue - expect key to available in @PostPersist.</li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/#c-relationship","title":"C Relationship","text":"<ul> <li>owner owns the foreign key and defines @JoinColumn(name=\"newName\")</li> <li>uni-directional or bi-directional : both has references of each other.</li> <li>project : entities</li> <li></li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/#1-2-1","title":"<code>1-2-1</code>","text":"<ul> <li>any class can be owner</li> <li>other class : mapperBy=propertyName mentioned in owner-class.</li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/#c11-2-m-and-c2m-2-1owner-many-side","title":"<code>C1:1-2-M and C2:M-2-1(owner : many side)</code>","text":"<ul> <li>C1:mapperBy=propertyName mentioned in owner-class</li> <li>more anno:</li> <li><code>@order</code> + <code>@BatchSize</code> + @OneToMany</li> <li><code>@fetch(FetchMode.SELECT/JOIN/SUBSELECT)</code> + @OneToMany(fetch = FetchType.LAZY/EAGER)</li> <li>@fetch() : from Hibernate <ul> <li>defines <code>how</code> the associated entities are fetched from the database. meaning <code>SQS queries</code>.</li> <li>@Fetch(FetchMode.XXXXXX)</li> <li>SELECT: Specifies that associated entities should be fetched lazily, using a separate SELECT statement.</li> <li>JOIN: Specifies that associated entities should be fetched eagerly using a single JOIN query.</li> <li>SUBSELECT: Specifies that associated entities should be fetched lazily using a single SELECT query with a subselect.</li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/#c1m-2-m-and-c2m-2-m","title":"<code>C1:M-2-M and C2:M-2-M</code>","text":"<ul> <li>no one is owner.</li> <li>create @JoinTable.</li> <li>use this to filter data : <code>@WhereJoinTable</code> </li> <li>can check: https://www.baeldung.com/hibernate-wherejointable</li> <li>use @order, @BatchSize, @fetch here as well <pre><code>    @WhereJoinTable(clause = \"col of join table\" = \"value-1\")   &lt;&lt;&lt;\n\n    @ManyToMany\n    @JoinTable(\n      name = \"student_course\",\n      joinColumns = @JoinColumn(name = \"student_id\"),\n      inverseJoinColumns = @JoinColumn(name = \"course_id\")\n    )\n</code></pre></li> <li>Cascade operation in relationship : ALL ,PERSIST, MERGE, REMOVE, REFRESH, DETACH</li> <li>https://www.baeldung.com/jpa-cascade-types</li> <li>@OneToMany( Cascade operation )</li> </ul>"},{"location":"00_Springboot/03_data-layer/01_JPA/#d-inheritance","title":"D Inheritance","text":"<ul> <li>let's have </li> <li>parent-Entity (2 col,2 record) </li> <li>Child-1-Entity(2 col, 2 record)</li> <li>Child-2-Entity (2 col, 2 record)`</li> <li>Strategies:</li> <li><code>Single table</code> (6 col) <ul> <li>for all 3 entities with <code>discrminator</code> column / lots of null /</li> </ul> </li> <li><code>table per class</code> :<ul> <li>parent class table1 - 2 col - won't be used, will be having 0 record</li> <li>Child-1 class table2 - 4 col</li> <li>Child-2 class table3 - 4 col</li> </ul> </li> <li><code>Joined</code> :<ul> <li>meaning Joined subclass. child joined to parent</li> <li>Like table per class, but child table will have only prop defined in entity, not from parent.</li> <li>parent class table1 - 2 col</li> <li>Child-1 class table2 - 2+1 col (additional 1 FK to parent table)</li> <li>Child-2 class table3 - 2+1 col (additional 1 FK to parent table)</li> </ul> </li> <li><code>MappedSuperclass</code> \u2013 the parent classes, can\u2019t be entities.<ul> <li>Child-1 class table2 - 2+2 col</li> <li>Child-2 class table3 - 2+2 col</li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/02_presistence-context/","title":"Persistence Context","text":"<ul> <li>https://chatgpt.com/c/9a8dd8ab-71b5-49d6-bcfe-8d9b0aa31971</li> <li>@PersistenceContext(unitName = \"entityManagerFactory_for_postgres\") private EntityManager entityManagerPostgres; </li> </ul>"},{"location":"00_Springboot/03_data-layer/02_presistence-context/#persistencecontext-pc","title":"persistenceContext / PC","text":""},{"location":"00_Springboot/03_data-layer/02_presistence-context/#a-intro","title":"A Intro","text":"<ul> <li>Like Spring IAC.</li> <li>runtime environment in which entity instances and lifecycle are managed. </li> <li>EntityManager or Session(H) </li> <li>thread not safe : meaning C R U D methods does not have sync and lock code.</li> <li>used to interact with pc</li> <li> <p><code>@persistenceContext</code> Session session : inject like this.</p> </li> <li> <p>acts as a first-level cache. </p> </li> <li>reduce Db calls</li> <li>improved porformance</li> <li>manages entity life cycle</li> <li>states:: <ul> <li><code>Transient</code>(new) &gt; <code>managed</code>(merged()) &gt; <code>detached</code> (detach()) </li> <li>managed :: delete(markedForDelete)</li> <li>managed :: persist(markedForDelete)</li> <li>managed :: update(update existing managed entity)</li> <li>managed :: merged&amp;Update(load and update entity)</li> </ul> </li> <li>keeps track of changes made to managed entities.</li> <li>flush <code>dirty entities</code> to DB, on txn::commit</li> <li>session/em API <ul> <li>persist,merge,detach,find,remove,refresh / Flush and close</li> <li>utility: view allManagedEntity, dirtyEntity,etc</li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/02_presistence-context/#b-types","title":"B Types","text":""},{"location":"00_Springboot/03_data-layer/02_presistence-context/#1-transaction-scoped-default-in-sb","title":"1 Transaction-scoped (default in sb) **","text":"<ul> <li>tied to the transaction.</li> <li>It is created when the transaction starts and is closed when the transaction ends.</li> <li>eg: Spring-boot-jpa -  @EnableTransactionManagement c, then @Transaction m()</li> <li>fact:</li> <li>used in cg maps</li> <li>not need for micro-services arch.</li> </ul>"},{"location":"00_Springboot/03_data-layer/02_presistence-context/#2-extended","title":"2 Extended.","text":"<ul> <li>workflows where a sequence of operations spans multiple transactions / stateful App. @PersistenceContext(type = PersistenceContextType.EXTENDED)</li> <li>Scenario/usecase for extended PC: stateful App <pre><code>  A multi-step checkout process in an e-commerce application where a user needs to add items to the cart,\n  provide shipping details, and make a payment. Each step might be handled by separate transactions,\n  but the cart and order entities need to be kept consistent throughout the process.\n</code></pre></li> <li>Downsides:</li> <li>Requires explicit flush to synchronize with database </li> <li>can introduce complexity in handling concurrency and transaction boundaries.</li> <li>Increased Memory Usage + the risk of stale data.</li> <li>Longer response times and potential deadlocks if not managed carefully</li> </ul>"},{"location":"00_Springboot/03_data-layer/02_presistence-context/#c-scenarios","title":"C Scenarios","text":""},{"location":"00_Springboot/03_data-layer/02_presistence-context/#multi-http-request-environment-in","title":"multi-Http request environment (in ||)","text":"<ol> <li>PC per request</li> <li>http req1 --&gt; thread-1 --&gt; txn-1 --&gt; PC-1 --&gt; commit --&gt; flush to DB</li> <li>http req2 --&gt; thread-2 --&gt; txn-2 --&gt; PC-2 --&gt; commit --&gt; flush to same DB. (override)</li> <li>Summary:</li> <li>Each HTTP request typically runs in its own thread and transaction.</li> <li>Transactions are isolated from each other, but \"concurrency-control-mechanisms\"/isolation ensure data consistency.</li> <li>Persistence contexts are tied to transactions and are independent for each request, ensuring that changes made in one request do not affect others until committed.</li> <li>Careful design and configuration are necessary to handle concurrency and transaction management effectively in a multi-request environment.</li> <li> <p>Developer has to write thread-safe code/ concurrent access code, etc</p> </li> <li> <p>PC shared by multiple request.</p> </li> <li>Service class &gt; @PC(Extended) Session/Em &gt; @T m1() + @T m2() + ...</li> <li> <p>PROS : less DB call, fast | CONS : handle concurrency</p> </li> <li> <p>Global PC</p> </li> <li>use second level cache.</li> <li> <p>PROS : very less DB call, faster | CONS : handle global concurrency</p> </li> <li> <p>check more : https://chatgpt.com/c/9a8dd8ab-71b5-49d6-bcfe-8d9b0aa31971</p> </li> </ol>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/","title":"ACID & Locks","text":"<ul> <li>https://chatgpt.com/c/22d9f577-17f2-4d43-9013-401b18ca58e0</li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#1-acid-principle","title":"1. ACID principle","text":"<ul> <li>All DB has underlying solution for ACID</li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#atomicity","title":"Atomicity","text":"<ul> <li>start txn</li> <li>unit of work </li> <li>commit txn</li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#consistency","title":"Consistency","text":"<ul> <li>pk</li> <li>fk</li> <li>constraints</li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#isolation","title":"ISOLATION","text":"<ul> <li>READ_UNCOMMITTED &gt;&gt; READ_COMMITTED &gt;&gt; REPEATABLE_READ &gt;&gt; SERIALIZABLE</li> <li>code <pre><code>@Transactional(isolation = Isolation.READ_COMMITTED)\n    public void standardOperation() {\n        // ...\n    }\n\nSHOW default_transaction_isolation;  -- Typically \"read committed\"\nALTER SYSTEM SET default_transaction_isolation = 'repeatable read';  &lt;&lt;&lt;\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#1-write-lock-present-default","title":"1. write lock (present default)","text":"<ul> <li>problem : <code>no concurrency at all</code></li> <li>txn1 , txn2 --&gt; both are writing same record same time.</li> <li>solution is <code>write-lock</code></li> <li>txn-1 took w-lock &gt; performing write</li> <li>txn-2 waits</li> <li>txn-1 done</li> <li>txn-2 took w-lock</li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#2-readwrite-lock","title":"2. read/write lock","text":"<ul> <li>problem : <code>Dirty read</code> (READ_UNCOMMITTED) :left_point:</li> <li>txn1  --&gt; writing same record same time.</li> <li>txn3 --&gt; reading</li> <li>solution is <code>read/write lock</code> (READ_COMMITTED) :left_point:<ul> <li>txn-1 took w-lock &gt; performing write</li> <li>txn-3 waits</li> <li>txn-1 done</li> <li>txn-2 took R-lock &gt;&gt; read</li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#3-versionsanpshot","title":"3. version/sanpshot","text":"<ul> <li>problem : <code>no repeating read</code></li> <li>txn-1 took w-lock &gt; performing write</li> <li>txn-2 waits</li> <li>txn-1 done</li> <li>txn-2 took R-lock &gt;&gt; Read </li> <li>txn-1 took w-lock &gt; performing write AGAIN :left_point:</li> <li>txn-2 should read it again and get updated value.</li> <li>solution is <code>version/sanpshot</code> (REPEATABLE_READ) :left_point:<ul> <li>txn-2 will get latest from latest version</li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#4-range-lock","title":"4. range lock","text":"<ul> <li>problem : <code>phantom read</code></li> <li>solution - range lock (SERIALIZABLE) :left_point:</li> </ul> <p><pre><code>## SUMMARY ##\n\nIsolation_Level     Dirty_Reads     Non-Repeatable-Reads    Phantom-Reads\nREAD_UNCOMMITTED    \u2717               \u2717                       \u2717\nREAD_COMMITTED      \u2713               \u2717                       \u2717\nREPEATABLE_READ     \u2713               \u2713                       \u2717\nSERIALIZABLE        \u2713               \u2713                       \u2713\n</code></pre> <pre><code># postgres\nBEGIN TRANSACTION ISOLATION LEVEL SERIALIZABLE;\n\n# jdbc\nConnection conn = dataSource.getConnection();\nconn.setTransactionIsolation(Connection.TRANSACTION_SERIALIZABLE);\n</code></pre></p>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#durability","title":"Durability","text":"<ul> <li>data never crashes</li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#2-lock","title":"2. Lock","text":""},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#optimistic-locks","title":"optimistic Locks","text":"<ul> <li>read TS, Write TS, etc (TS=timestampe and version)</li> <li>add in entity : <code>@Version</code> private long version;</li> <li><code>ObjectOptimisticLockingFailureException</code></li> <li>Advantages</li> <li>Better performance than pessimistic locking</li> <li>No database locks held </li> <li>Works well for low-contention scenarios</li> <li>Suitable for web applications with short transactions</li> </ul>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#pessimistic-locks-postgresql","title":"pessimistic Locks (postgresQL)","text":""},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#row-level-lock","title":"Row level lock","text":"<ul> <li>mechanism</li> <li>SELECT FOR UPDATE (Row-Level Write Lock)</li> <li>SELECT FOR SHARE (Row-Level Read Lock)</li> <li>SELECT FOR NO KEY UPDATE (Weaker Write Lock)</li> <li> <p>SELECT FOR KEY SHARE (Weakest Lock)</p> </li> <li> <p>Locking Options</p> </li> <li>NOWAIT : Fails immediately if lock cannot be acquired</li> <li>SKIP LOCKED :  Skips already locked rows</li> </ul> <pre><code>BEGIN;\nSELECT * FROM accounts WHERE id = 1 FOR UPDATE;\n-- The row is now locked for updates by other transactions\nUPDATE accounts SET balance = balance - 100 WHERE id = 1;\nCOMMIT;\n\nBEGIN;\nSELECT * FROM accounts WHERE id = 1 FOR SHARE;\n-- Other transactions can read but cannot update this row\nCOMMIT;\n\nBEGIN;\nSELECT * FROM customers WHERE id = 1 FOR NO KEY UPDATE;\n-- Locks row but allows updates on non-key columns\nCOMMIT;\n\nBEGIN;\nSELECT * FROM orders WHERE id = 1 FOR KEY SHARE;\n-- Only prevents key changes\nCOMMIT;\n</code></pre>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#table-level-lock","title":"table level lock","text":"<p><pre><code>BEGIN;\nLOCK TABLE accounts IN ACCESS EXCLUSIVE MODE;\n-- Prevents all access to the table\nCOMMIT;\n</code></pre> - more(extra)   - ACCESS SHARE - Weakest lock, acquired automatically by SELECT queries (only conflicts with ACCESS EXCLUSIVE).   - ROW SHARE - Acquired by SELECT FOR SHARE, allows concurrent reads but blocks exclusive writes.   - ROW EXCLUSIVE - Acquired automatically by UPDATE/DELETE/INSERT (blocks SHARE, SHARE ROW EXCLUSIVE, EXCLUSIVE, ACCESS EXCLUSIVE).   - SHARE UPDATE EXCLUSIVE - Used by VACUUM/ANALYZE, blocks same mode and stronger (except ACCESS SHARE).   - SHARE - Acquired by CREATE INDEX, allows concurrent reads but blocks all writes (conflicts with ROW EXCLUSIVE and stronger).   - SHARE ROW EXCLUSIVE - Rarely used explicitly, blocks SHARE and same mode.   - EXCLUSIVE - Blocks all concurrent writes and SHARE locks (only allows ACCESS SHARE reads).   - ACCESS EXCLUSIVE - Strongest lock, acquired by ALTER TABLE/DROP TABLE, blocks all operations</p>"},{"location":"00_Springboot/03_data-layer/03_ACID%2BLocks/#pg_lock-monitor","title":"pg_lock (Monitor)","text":"<pre><code>SELECT locktype, relation::regclass, mode, pid\nFROM pg_locks\nWHERE relation = 'accounts'::regclass;\n</code></pre>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/","title":"Hibernate Annotations & Converter","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#-anno-httpschatgptcomc1375c062-4b67-437d-860b-e065a2980f57","title":"- anno : - https://chatgpt.com/c/1375c062-4b67-437d-860b-e065a2980f57","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#hibernate","title":"Hibernate","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#annotation","title":"Annotation","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#common-annotation","title":"Common Annotation","text":"<ul> <li><code>@Entity</code>(name=\"new_entityname\"),  @version feild</li> <li><code>@Basic</code>(fetch=FetchType.EAGER,optional=true).<ul> <li>this is already added by default on all column.</li> <li>basic mapping, field to a db column.</li> </ul> </li> <li><code>@Table</code>(name=\"new_tablename\") </li> <li><code>@Column</code>(name=\"new_colname\", updateble=f/t), more <ul> <li>Lenght=255, string-valued column length. / @Length</li> <li>Precision and Scale. for decimal feild.</li> </ul> </li> <li><code>@Transient</code></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#relationship","title":"relationship","text":"<ul> <li>@OneToOne, </li> <li>@OneToMany,  @ManyToOne, </li> <li><code>@JoinTable and @JoinColumn()</code></li> <li><code>@OrderBy(\"colInManySide ASC\")</code> Sorting Children within Each Parent</li> <li> <p><code>@Fetch @batchSize</code> - use together in relation : 1-2-M,etc</p> </li> <li> <p>@ManyToMany : Add FK and create JoinTable bts.</p> </li> <li><code>@WhereJoinTable(clause = \"columnInJoinTable='value-1'\")</code></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#identifier","title":"identifier","text":"<ul> <li>@embeddedId</li> <li>@Id</li> <li>@GeneratedValue() <code>@TableGenerator</code>()</li> <li>@GeneratedValue() <code>@SequenceGenerator</code>()</li> <li>@GeneratedValue() <code>@GenericGenerator</code>()</li> <li>check more: 04_Hibernate-2-identifier+validator.md</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#inheritance","title":"Inheritance","text":"<ul> <li><code>@MappedSuperclass</code> on parent class</li> <li><code>@Inheritance(strategy = InheritanceType.SINGLE_TABLE)</code> : on parentClass</li> <li><code>@DiscriminatorColumn(name=\"columnName\",discriminatorType = DiscriminatorType.INTEGER)</code> : on parentClass</li> <li><code>@DiscriminatorValue(\"1\")</code> : on ChildClass</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#performance","title":"Performance","text":"<ul> <li>q.setFetchSize(10)</li> <li>@BatchSize(size = 20) at Entity level for All operations.</li> <li>custom code to achieve batch behaviour :</li> <li>for loop &gt;&gt; on iteration 20, perform flush amd clear em/session.</li> <li>Small Fetch Size: May lead to more frequent database calls, increasing network latency and overhead.</li> <li>Large Fetch Size: Reduces the number of database calls but consumes more memory as more rows are loaded into memory at once.</li> <li><code>@BatchSize</code> on Entity level</li> <li>option for relation/many-side:</li> <li> <p><code>@Fetch</code> </p> <ul> <li>(FetchMode.SELECT) : https://chatgpt.com/c/1375c062-4b67-437d-860b-e065a2980f57</li> <li>fetch associated entities lazily, to avoid loading unnecessary data upfront.</li> <li>optimizing performance when dealing with large collections.</li> <li>(FetchMode.Join) : load early</li> </ul> </li> <li> <p><code>@BatchSize</code> </p> <ul> <li>Use along with @Fetch.</li> <li>@OneToMany(mappedBy = \"order\")  @BatchSize(size = 10) private List items;  <li>optimize the loading of collections.</li> <li>instead of issuing separate SELECT queries for each item, Hibernate will fetch 10 items at a time, reducing the number of queries executed.</li> <li>but may increase memory usage, if batch size is big.</li> <li> <p>@OneToMany(<code>fetch</code> = FetchType.LAZY/EAGER), etc</p> </li> <li>@Basic(fetch=FetchType.EAGER)</li>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#convertor-rarely-used","title":"Convertor (rarely used)","text":"<ul> <li><code>@Convert (converter=abc.class)</code> </li> <li>more like binder - which jackson for JSON&lt;--&gt;Object(DTO)</li> <li>converter for DB::table&lt;--&gt;Object(Entity)</li> <li>use case : performing encryption/decryption, data transformations, that are NOT directly supported by JPA, etc</li> <li>implement AttributeConverter , override:<ul> <li>dbType convertToDatabaseColumn(entityType)</li> <li>entityType convertToEntityAttribute(dbType)</li> </ul> <li><code>@Lob</code> byte[]</li> <li><code>@Temporal(TemporalType.DATE)</code> private Date birthDate;</li> <li>temporal, meaning relating to time.</li> <li>java has seperate set of API(Java.sql.*), to deal with DB Date/time eg: connection code, etc</li> <li><code>java.util.*</code> and <code>java.time.*</code>  &lt;--convert--&gt;  <code>Java.sql.*</code></li> <li><code>@Enumerated</code>(EnumType.STRING/ORDINAL) MyEnum</li> <li>enums to their ordinal values or names</li> <li>hibernate automatically converts to enum value, if not mentioned.</li> <li>Automatic/inbuilt conversion by Hibernate :</li> <li>Boolean to int (t-1, f-0)</li> <li>Boolean to String(t-\"true\")</li> <li>java.time.LocalDate to java.sql.Date  &lt;&lt;&lt;</li> <li>java.time.LocalDateTime to java.sql.Timestamp &lt;&lt;&lt;</li> <li>enum to string/ordinal. String/int var1</li>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#other","title":"Other","text":"<ul> <li><code>@embedded and @embeddable</code></li> <li>define a class whose instances can be embedded in an entity. </li> <li>This class does not have its own table but shares the table of the owning entity.</li> <li>@Embedded @AttributeOverrides : use to override columnName whiling embedding   <pre><code>@Embedded  \n@AttributeOverrides({\n      @AttributeOverride(name = \"street\", column = @Column(name = \"home_street\")),\n      @AttributeOverride(name = \"city\", column = @Column(name = \"home_city\")), ...\n  })\n</code></pre></li> <li><code>@SqlResultSetMapping</code> : Map @NamedNativeQuery result to target(Entity/Tuple)</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-1-anno%2Bconverter/#annotation-from-sb-jpa-data-starter","title":"Annotation from SB-Jpa-Data-starter","text":"<ul> <li><code>@EnableTransactionManagement</code></li> <li><code>@Transactional</code></li> <li><code>@Query</code> + <code>@Param</code></li> <li><code>@QueryHints</code>({@QueryHint(name = \"org.hibernate.fetchSize\", value = \"10\")})</li> </ul> <ul> <li>pending</li> <li>program on inheritance</li> <li>program on relationship</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/","title":"Hibernate","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#identifier-strategies","title":"Identifier : strategies","text":"<ul> <li><code>@GeneratedValue(Strategy = GenerationType.\"XXXXX\")</code></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#auto","title":"AUTO","text":"<ul> <li>hibernate will choose automatically, based on dialect.</li> <li>Oracle, PostgreSQL    : Uses <code>SEQUENCE</code> because Oracle supports sequences.</li> <li>MySQL, SQL Server, H2 : Uses <code>IDENTITY</code> because MySQL supports auto-increment columns.</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#identity","title":"IDENTITY :","text":"<ul> <li><code>Auto-increment</code>, can apply on Number types.</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#table","title":"TABLE","text":"<ul> <li><code>@GeneratedValue () @TableGenerator()</code> </li> <li>less common, PK is generated using a \"table\" that holds a set of unique keys.   <pre><code>CREATE TABLE ID_GEN (\n    GEN_NAME VARCHAR(255) NOT NULL,\n    GEN_VALUE BIGINT NOT NULL,\n    PRIMARY KEY (GEN_NAME)\n);\n\n@Id\n@GeneratedValue(strategy = GenerationType.TABLE, generator = \"my_table_generator\")  &lt;&lt;&lt;\n@TableGenerator(\nname                = \"my_table_generator\", \ntable               = \"ID_GEN\",\npkColumnName        = \"GEN_NAME\",\nvalueColumnName     = \"GEN_VALUE\",\npkColumnValue       = \"MY_ID_GEN_1\",\nallocationSize      = 1 \n)\nprivate Long id;\n\n- SELECT GEN_VALUE FROM ID_GEN WHERE GEN_NAME = 'MY_ID_GEN_1';\n- UPDATE ID_GEN SET GEN_VALUE = GEN_VALUE + 1 WHERE GEN_NAME = 'MY_ID_GEN_1';\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#sequence","title":"SEQUENCE","text":"<ul> <li><code>@GeneratedValue @SequenceGenerator</code> :    <pre><code>CREATE SEQUENCE MY_SEQUENCE START WITH 1 INCREMENT BY 1;             &lt;&lt;&lt; \n\n@Id\n@GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"my_sequence\")\n@SequenceGenerator(name = \"my_sequence\", sequenceName = \"MY_SEQUENCE\", allocationSize = 1)\nprivate Long id;\n\nallocationSize -  number of sequence values to allocate at a time\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#generic-uuidguid","title":"GENERIC -  UUID/GUID","text":"<ul> <li><code>@GeneratedValue()  @GenericGenerator()</code> - from hibernate</li> <li>Random Sequence, avoid predictable sequences for security.</li> <li>fact:  Random values can lead to fragmented indexes, which can affect performance.</li> <li>UUID/GUID </li> <li>128 bit - globally unique</li> <li>eg: <code>550e8400-e29b-41d4-a716-446655440000</code></li> <li>32 char,string, group of 5 by Hypen.</li> <li>incorporate TimeStamp and hardware info.</li> <li>use-case : DB:Pk, DistributedSystem, registry keys, etc</li> <li>eg:</li> <li>org.hibernate.id.UUIDGenerator    <pre><code>    @GeneratedValue( generator = \"myUUID\")\n    @GenericGenerator(name = \"myUUID\", strategy = \"org.hibernate.id.UUIDGenerator\")\n</code></pre></li> <li> <p>create own:   CustomIdentifier.java <pre><code>public class CustomIdentifier implements IdentifierGenerator {\n  @Override\n  public Object generate(SharedSessionContractImplementor sharedSessionContractImplementor, Object o) {\n      return UUID.randomUUID();\n  }\n}            \n\n@Id\n@GeneratedValue(strategy = GenerationType.SEQUENCE, generator = \"generic-1\")\n@GenericGenerator(name = \"generic-1\", strategy = \"CustomIdentifier\")\nprivate Long id;\n</code></pre></p> </li> <li> <p>NanoID</p> </li> <li>unique IDs that are shorter and more URL-friendly.</li> <li> <p>eg: <code>DqQrAcB9jK</code></p> </li> <li> <p>TimestampId <pre><code>    @Override\n    public Serializable generate(SharedSessionContractImplementor session, Object object) {\n        long timestamp = System.currentTimeMillis();\n        int random = new Random().nextInt(999999);\n        return timestamp + \"-\" + random;\n    }\n</code></pre></p> </li> <li>Composite Identifiers</li> <li>https://www.baeldung.com/hibernate-identifiers</li> <li>@Embeddable Class ABC : Also public no-agr const, define equal and hashcode</li> <li>then inject <code>@EmbeddedId</code> ABC id;</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#d-validator","title":"D. Validator","text":"<ul> <li>spring-boot-starter-validation</li> <li>@Min / @Max / @DecimalMin/MAX / @Range- on numbetypes</li> <li>@Size(min = 3, max = 15) : on String</li> <li>@length(min = 3, max = 15) : on Collection</li> <li>@Null/ @NotNull / @NotEmpty / @NotBlank</li> <li>@AssertTrue / @AssertFalse</li> <li>@Pattern(regexp = \"^[0-9]{10}$\") String phoneNo</li> <li>Date:</li> <li>@Past</li> <li>@PastOrPresent</li> <li>@Future</li> <li>@FutureOrPresent</li> <li>More (H-specific) : @URL, @email, @CreditCardNumber, @Currency, @UUID</li> <li> </li> <li>create custom Annotation1 and annotate with <code>@Constraint(validatedBy = Validator1.class)</code></li> <li>class Validator1 implements <code>ConstraintValidator</code> // string:: TypeOfvalueBeingValidate  <li>Apply @Annotation1</li>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-2-identifier%2Bvalidator/#custom-validator","title":"Custom validator:","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/","title":"Hibernate Query","text":"<ul> <li>NamedQuery :https://www.baeldung.com/hibernate-named-query</li> <li>Polymorphic queries : https://chatgpt.com/c/1375c062-4b67-437d-860b-e065a2980f57</li> <li>@SqlResultSetMapping : https://chatgpt.com/c/7a6449ba-dede-478f-9778-1c7a9a5d5d9d</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#hibernate","title":"hibernate","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#a-query","title":"A. Query","text":"<ul> <li>parent class : Query <li>children     : TypeQuery, NamedQuery, NamedNativeQuery"},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#typedquery","title":"TypedQuery <ul> <li>T = ResultType</li> <li>It ensures that the query result matches a specific type, at compile time. <pre><code>TypedQuery&lt;Employee&gt; query = em.createQuery(\"SELECT e FROM Employee e WHERE e.department = :dept\", Employee.class);\nquery.setParameter(\"dept\", \"IT\");\nList&lt;Employee&gt; employees = query.getResultList();\nEmployee employee = query.getSingleResult();\n</code></pre></li> <li>never used.</li> </ul>","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#namedquery-hql-namednativequery-sql","title":"NamedQuery (hql) / NamedNativeQuery (sql) <ul> <li>SB-JPA-DATA repository uses these BTS for <code>@Query</code></li> <li>also follows result typing.</li> <li>centralized, Pre-validated queries, refer them by name and reuse it.</li> <li>use unique name in PC to avoid collision.</li> <li>prefer NamedQuery, use NamedNativeQuery only if certain feature not support by JPQL, and need DB specific optimization, etc <pre><code>#==============\n# 1 : Define\n#==============\n\n@NamedQuery(name = query-1,  query='static HQL/SQL')\n@Entity / @mappedSuperClass\nclass Entity {\n\n}\n  - more attribute:\n    - timeout = 1, \n    - fetchSize = 10, \n    - cacheable=t/f,  \n    - resultClass = Result.class\n\n#==============\n# 2 : use it\n#==============\n\nQuery&lt;Result&gt; q = session.createNamedQuery(\"query-1\", Result.class)\nq.setparameter(k,v)\n\nq.getSingleResult();\nq.getResultList()/Set();\n</code></pre></li> </ul>","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#result-to-custom-classtuple","title":"Result to custom-class/Tuple <ul> <li>reference:  https://chatgpt.com/c/7a6449ba-dede-478f-9778-1c7a9a5d5d9d</li> <li>way-1: @NamedNativeQuery(...,  resultClass = Result.class) <pre><code>@NamedNativeQuery(\n    name = \"Employee.findSummary\",\n    query = \"SELECT id, name, department FROM employee\",\n    resultClass = Result.class\n\n    # keep names in sync b/w query and result class           \n)\n\nList&lt;Employee&gt; employees = entityManager.createNamedQuery(\"Employee.findAll\", Employee.class).getResultList();\n</code></pre></li> <li>way-2: @SqlResultSetMapping (name=Mapping_1, ...) + @NamedNativeQuery(...)</li> </ul> <p><pre><code>@SqlResultSetMapping(\n    name = \"EmployeeDTOResult\",\n    classes = @ConstructorResult(\n        targetClass = EmployeeDTO.class,\n        columns = {\n            @ColumnResult(name = \"id\", type = Long.class),\n            @ColumnResult(name = \"name\", type = String.class),\n            @ColumnResult(name = \"department\", type = String.class)\n        }\n    )\n)\n\n@NamedNativeQuery(\n    name = \"Employee.findSummary\",\n    query = \"SELECT id, name, department FROM employee\",\n    resultClass = Result.class,            \n    resultSetMapping = \"Mapping_1\"         \n)\n\nList&lt;EmployeeDTO&gt; employees = entityManager.createNamedQuery(\"Employee.findSummary\").getResultList();\n</code></pre> - WAY-3 : tuple **  <pre><code>@NamedNativeQuery(\n    name = \"Employee.findSummary\",\n    query = \"SELECT id, name, department FROM employee\"\n)\n\nList&lt;Tuple&gt; results = entityManager.createNamedQuery(\"Employee.findSummary\", Tuple.class).getResultList();    &lt;&lt;&lt;\n\nfor (Tuple tuple : results) {\n    Long id = tuple.get(\"id\", Long.class);\n    String name = tuple.get(\"name\", String.class);\n    String department = tuple.get(\"department\", String.class);\n    System.out.println(\"id: \" + id + \", name: \" + name + \", department: \" + department);\n}\n</code></pre></p>","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#result-mapping-more","title":"Result mapping : more <ol> <li>Tuple (more like Object[],hetrogeneous)<ul> <li>use Tuple / List : for single ot mutlipe result <li>add javatuples<ul> <li>Im-mutable : Pair, triplet - hence maintain data integrity.</li> </ul> </li>   <li>class MyClass implements ResultTransformer :<ul> <li>First @override transformTuple(,)</li> <li>then use it on any query , q.setResultTransformer(RT rt)</li> <li>inbuilt ResultTransformer.<ul> <li>Transformers.TO_ARRAY</li> <li>Transformers.TO_LIST</li> <li>Transformers.ALIAS_TO_ENTITY_CLASS</li> </ul> </li> </ul> </li>","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#b-pagination-query-result","title":"B. Pagination (query result)","text":"<pre><code>int pageNumber = 1;\nint pageSize = 10; \nq.setFirstResult((pageNumber-1) * pageSize);  //offset \nq.setMaxResults(pageSize);                    // Limit\nq.getResultList();\n</code></pre> <ul> <li>Another way (old): get ids and then sublist ids <pre><code>    //STEP-1 : sort ids as well / gives total count.\n    Query q = entityManager.createQuery(\"Select f.id from Foo f order by f.id\");\n    List&lt;Integer&gt; ids = q.getResultList();\n\n    //STEP-2\n    Query query = entityManager.createQuery(\"Select f from Foo e where f.id in :ids\");\n    query.setParameter(\"ids\", fooIds.subList(0,10));\n    List&lt;Foo&gt; fooList = query.getResultList();\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#c-scrollableresults-query-result","title":"C. ScrollableResults (query result)","text":"<ul> <li>hibernate feature that allows iterating through query results in a memory-efficient way.</li> <li>instead of loading all rows into memory, it fetches rows in batches, making it suitable for processing large datasets.</li> <li>q.scroll() <pre><code>ScrollableResults resultScroll = query.scroll(ScrollMode.FORWARD_ONLY);\nquery.setFetchSize(10);\nwhile (scrollableResults.next()) {\n     Employee employee = (Employee) scrollableResults.get(0);\n}\n\n# more navigation method: \n\nnext(): Move the cursor to the next row.\nprevious(): Move the cursor to the previous row.\nfirst(): Move the cursor to the first row.\nlast(): Move the cursor to the last row.\nscroll(int positions): Move the cursor by a specific number of rows (positive for forward, negative for backward).\nsetRowNumber(int rowNumber): Jump to a specific row by its number\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#d-polymorphic-queries","title":"D. Polymorphic queries","text":"<ul> <li>implicitly : query for parent-entity, automatically includes ALL child records --&gt; 6 records.</li> <li>explicitly : use Treat, to change this behaviour.</li> <li>open and search : https://chatgpt.com/c/1375c062-4b67-437d-860b-e065a2980f57</li> <li>check below queries: <pre><code>List&lt;Vehicle&gt; vehicles = session.createQuery(\"FROM Vehicle\", Vehicle.class).getResultList();\n// Implicit polymorphism: vehicles list will contain instances of both Car and Bike\n\nList&lt;Car&gt; cars = session.createQuery(\"FROM Car\", Car.class).getResultList();\n// Explicit polymorphism: cars list will contain only instances of Car\n\nList&lt;Vehicle&gt; vehicles = session.createQuery(\"FROM Vehicle v WHERE TREAT(v AS Car).numberOfDoors &gt; 3\", Vehicle.class) .getResultList();  &lt;&lt;&lt;\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#e-hql","title":"E. HQL","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#joins","title":"joins <ul> <li>INNER : JOIN, </li> <li>OUTER : (LEFT JOIN / RIGHT JOIN)</li> <li>FETCH JOIN  : load associated entities eagerly</li> <li>fact: </li> <li>since relation is already defined with 121,12M, M2M, etc. FK/common col already  added. </li> <li>hence dont need to explicitly define ON-condition with Join.</li> <li><code>@Query(\"SELECT e, d FROM Employee e JOIN Department d ON e.department.id = d.id AND d.name = :departmentName\")     List&lt;Object[]&gt; findEmployeesByDepartmentName(@Param(\"departmentName\") String departmentName);</code></li> <li>https://chatgpt.com/c/1375c062-4b67-437d-860b-e065a2980f57</li> </ul>","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#static-queries","title":"STATIC queries <ul> <li>JPQL and Native-SQL</li> <li>JPQL take advantage of OOP of entity class.</li> <li>Positional parameters ?1,2,etc vs named parameters (preferred)</li> <li>Sorting :: order by  e.feild1, e.feild2</li> <li>sorting entities in a 1-2-M relation, meaning list on many side <code>@OrderBy(\"childName ASC\")</code> List children. // Parent has many Children <li>Sorting : in JPQL/HQPL itself :  NULLS LAST, NULLS FIRST at the end.</li> <li>Sorting Query Results with Spring Data : https://www.baeldung.com/spring-data-sorting#sorting-with-spring-data</li>","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#dynamic-criteria-api","title":"DYNAMIC : Criteria API <ul> <li>pending / skip</li> </ul>","text":""},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#f-batch-processing-in-progress","title":"F Batch  processing <code>in-progress</code>","text":"<ul> <li>Custom batch code. for&gt;flush/clear after 20.</li> <li><code>hibernate.jdbc.batch_size</code>=20</li> <li><code>spring.jpa.properties.hibernate.jdbc.batch_size</code>=20</li> <li>@BatchSize(size = 20) at Entity level for all Operations (CRUD)</li> <li>fact:@GeneratedValue(strategy = GenerationType.IDENTITY ) will disable batch-INSERT Silently. USE SEQUENCE.</li> </ul>"},{"location":"00_Springboot/03_data-layer/04_Hibernate-3-query/#zpending","title":"Z.Pending:","text":"<ol> <li>TransactionTemplate prg</li> <li>ScrollableResults program - when processing large dataset, (not sending large Dataset in batches to UI)</li> <li>Query Plan Cache</li> <li>@NamedQuery More attribute</li> <li>cacheMode=GET, IGNORE, NORMAL, PUT, or REFRESH</li> <li>flushMode=ALWAYS, AUTO, COMMIT, MANUAL, or PERSISTENCE_CONTEXT</li> </ol>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-1-start/","title":"SB JPA Data Part 1","text":"<ul> <li>reference:</li> <li>https://www.baeldung.com/persistence-with-spring-series</li> <li>https://www.baeldung.com/multitenancy-with-spring-data-jpa</li> <li>DB-06-SpringJpaData-1 : https://chatgpt.com/c/a874b751-9880-4225-a96c-9052773037fa</li> <li>DB-06-SpringJpaData-2 : https://chatgpt.com/c/8ace7914-f8cc-465e-873a-7b45974bb7b2</li> <li>DB-06-SpringJpaData-3 : https://chat.openai.com/c/7b6dd03e-ca98-44d5-87a6-73c23026a009</li> <li>DB-06-SpringJpaData-4 : https://chatgpt.com/c/8cdd30bb-cd6e-42dc-bb27-43e5235c8a68<ul> <li>spring-data-jpa-projections </li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-1-start/#springboot-jpa-data","title":"SpringBoot JPA Data","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-1-start/#a-intro","title":"A Intro","text":"<ul> <li>Provide Abstractions.</li> <li>@PersistenceContext - txn-scoped.</li> <li>AC - 3 bean - datasource, EMfactory/Sessionfactory, TxnManager.</li> <li>@Transactional</li> <li>Create Reliable transaction with ACID.</li> <li>provides abstraction, no to write start and commit/rollback.</li> <li>ACID (reliable transaction)</li> <li>A tomicity : SB - @Transactional</li> <li>C onsistency : underlying DB sol - constraints, Fk, etc</li> <li>I solated : underlying DB sol. <code>@Transactional(isolation=\"choose one\") / Optimistic concurrency control</code><ul> <li>RU(no concurrency - All 3 problem : dirty read, phantom, RR )</li> <li>RC (dirty fixed, but still - phantom, RR)</li> <li>Non-R (dirty fixed, non-R fixed, but still phantom)</li> <li>Serializable ( All fixed )</li> <li>D urable : underlying DB sol - permanent after commit.</li> </ul> </li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-1-start/#more","title":"more","text":"<ul> <li>spring.sql.init.mode = never</li> <li>always</li> <li>never</li> <li>fallback : Initialize the database using scripts if no schema is detected.</li> <li>enable logging:</li> <li>logging.level.org.springframework.transaction=DEBUG</li> <li>logging.level.org.springframework.orm.jpa.JpaTransactionManager=DEBUG</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-1-start/#testing","title":"testing","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-1-start/#sql","title":"@Sql","text":"<ul> <li>define SQL scripts to be executed before or after a test method.</li> <li>define at class or method level. <pre><code>@SpringBootTest\n\npublic class MyRepositoryTests {\n\n    @Autowired\n    private MyRepository myRepository;\n\n    @Test\n    @Sql({\"/schema_2.sql\", \"/dat_2.sql\"})\n    public void testFindAll() {\n        List&lt;MyEntity&gt; entities = myRepository.findAll();\n        // Assertions or other test logic\n    }\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-1-start/#sqlconfig","title":"@SqlConfig","text":"<ul> <li>used to configure the behavior of SQL scripts that are executed during integration tests using the @Sql <pre><code>@Sql({\"/schema.sql\", \"/data.sql\"})\n@SqlConfig(\n  dataSource         = \"myDataSource\", \n  transactionManager = \"myTransactionManager\")\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/","title":"persistence-with-springBoot","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#a-annotations","title":"A. Annotations","text":"<ul> <li>data.sql, schema.sql, JPA-buddy-PlugIn</li> <li><code>@EnableJpaRepositories</code>(\"example.baeldung.com.repo\")</li> <li><code>@EntityScan</code>(\"example.baeldung.com.entity\")</li> <li><code>@EnableTransactionManagement</code> </li> <li><code>@Transactional</code></li> <li><code>@Query</code> - if having indexed/named parameter then bind using <code>@Param</code> on arg.</li> <li><code>@Modifying</code></li> <li>method should run inside Transaction </li> <li>method returns - int,void</li> <li>annotation indicates that the method modifies the state of the database.</li> <li>testing : @Sql, @SqlConfig, @SqlGroup - </li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#b-multiple-datasource","title":"B. Multiple DataSource :","text":"<ul> <li>DBP_01_Multiple Data Sources : https://chatgpt.com/c/7c2da8f5-3f44-4e71-b4f9-4cdadacf0ec5</li> <li>Create 2 beans - Ds1() and Ds2(), Apply ConfigurationProperties on method -&gt; binds returnType(DataSource).</li> <li>create 2 beans - emF1 , emF2</li> <li>Create 2 beans - Txm1 , Txm2</li> <li>Create 2 sets of entities and repos:<ul> <li>package1 : entities1, repos1, : use Datasource1 </li> <li>package2 : entities2, repos2  : Use Datasource2. how, see below ?</li> </ul> </li> <li><code>@EnableJpaRepositories(        basePackages = \"dao1/repos1/*\",         entityManagerFactoryRef = \"emF1\",         transactionManagerRef = \"txn1\"     )     // same for another set</code></li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#c-spring-jpa-data","title":"C. Spring JPA Data","text":"<ul> <li>Purpose</li> <li>DAO/persistence layer usually consists of a lot of boilerplate code (CRUD methods, wire em, etc)</li> <li>SJD makes it possible to remove the DAO implementations entirely.</li> <li>find this interface and automatically create an implementation for it.</li> <li>Exception </li> <li>translation is still enabled by the use of the <code>@Repository</code>.</li> <li>All DB exception converts/translated to DataAccessException hierachy</li> <li>custom translator:   <pre><code># 1\npublic class Custom_PersistenceExceptionTranslator implements PersistenceExceptionTranslator \n{\n  @Override\n  public DataAccessException translateExceptionIfPossible(RuntimeException ex) {\n      ...\n  }\n}\n\n# 2\n@Configuration\nPublic class AppConfig {\n  @Bean\n  public PersistenceExceptionTranslator exceptionTranslator() {\n      return new Custom_PersistenceExceptionTranslator();\n  }}\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#repository","title":"Repository","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#1-crudrepositoryeid","title":"1. <code>CrudRepository&lt;E,ID&gt;</code>","text":"<ul> <li>returns <code>Iterable&lt;E&gt;</code> </li> <li>ListCrudRepository --&gt; returns <code>List&lt;E&gt;</code> <pre><code>    &lt;S extends T&gt; S save(S entity);\n    T findOne(ID primaryKey);\n    Iterable&lt;T&gt; findAll();\n    Long count();\n    void delete(T entity);\n    boolean exists(ID primaryKey);\n</code></pre>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#2-pagingandsortingrepositoryeid","title":"2. <code>PagingAndSortingRepository&lt;E,ID&gt;</code>","text":"<pre><code>     Iterable&lt;T&gt; findAll(Sort sort);\n     Page&lt;T&gt; findAll(Pageable pageable);\n</code></pre>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#3-jparepositoryeid","title":"3. <code>JpaRepository&lt;E,ID&gt;</code>","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#4-custom-repo","title":"4. Custom repo","text":"<ul> <li>own interface and impl class</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#5-composite-repo","title":"5. Composite repo","text":"<ul> <li>mix of above (each is called <code>fragments</code> then). eg: <pre><code># 1\npublic interface ProductRepository extends CrudRepository&lt;Product, Long&gt; { }\n\n# 2\npublic interface ProductPagingAndSortingRepository extends PagingAndSortingRepository&lt;Product, Long&gt; {}\n\n# 3\npublic interface CustomProductRepository {\n    List&lt;Product&gt; findByCustomCriteria(String criteria);\n}\npublic class CustomProductRepositoryImpl implements CustomProductRepository {\n    @PersistenceContext\n    private EntityManager entityManager;\n\n    @Override\n    public List&lt;Product&gt; findByCustomCriteria(String criteria) {\n        String jpql = \"SELECT p FROM Product p WHERE p.name LIKE :criteria\";\n        return entityManager.createQuery(jpql, Product.class)\n                            .setParameter(\"criteria\", \"%\" + criteria + \"%\")\n                            .getResultList();\n    }\n}\n\nCombine the base repositories and custom repository into a single repository interface.    &lt;&lt;&lt; \n\n@Repository\npublic interface CompositeProductRepository extends \n        ProductRepository, \n        ProductPagingAndSortingRepository, \n        CustomProductRepository {\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#d-queries","title":"D. Queries","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#1-derive-methods","title":"1. Derive methods","text":"<ul> <li>methodName :: <code>&lt;introducer&gt; [distinct|Top|FIRST]+ \"By\" + &lt;criteria&gt; + \"OrderBy\"+propertyName () + Desc|Asc</code></li> <li><code>introducer</code> : find, read, query, count and get</li> <li><code>Criteria</code> :: </li> <li>propertyName + <code>Is|IsNot</code> (T v)</li> <li>propertyName + <code>IsNull|IsNotNull</code> (v)</li> <li>booleanPropertyName + <code>True|False</code> ()</li> <li>propertyName + <code>StartingWith</code> (String prefix)</li> <li>propertyName + <code>EndingWith</code> (String suffix)</li> <li>propertyName + <code>NameLike</code>(String likePattern);</li> <li>propertyName + <code>LessThan | LessThanEqual | GreaterThan | GreaterThanEqual | Between</code> (int...)</li> <li>propertyName + <code>In</code> (Collection c)</li> <li>propertyName + <code>After</code> (ZonedDateTime)</li> <li>propertyName + <code>Before</code> (ZonedDateTime)</li> </ul> <pre><code>List&lt;User&gt; findByNameIs(String name);\nList&lt;User&gt; findByNameEquals(String name);\nList&lt;User&gt; findByNameIsNot(String name);\nList&lt;User&gt; findByNameIsNull();\nList&lt;User&gt; findByNameIsNotNull();\n\nList&lt;User&gt; findByNameStartingWith(String prefix);\nList&lt;User&gt; findByNameStartingWith(String prefix);\nList&lt;User&gt; findByNameEndingWith(String suffix);\nList&lt;User&gt; findByNameContaining(String infix);\n\nList&lt;User&gt; findByAgeLessThan(Integer age);\nList&lt;User&gt; findByAgeLessThanEqual(Integer age);\nList&lt;User&gt; findByAgeGreaterThan(Integer age);\nList&lt;User&gt; findByAgeGreaterThanEqual(Integer age);\nList&lt;User&gt; findByAgeBetween(Integer startAge, Integer endAge);\n\nList&lt;User&gt; findByAgeIn(Collection&lt;Integer&gt; ages);\n\nList&lt;User&gt; findByBirthDateAfter(ZonedDateTime birthDate);\nList&lt;User&gt; findByBirthDateBefore(ZonedDateTime birthDate);\n</code></pre> <ul> <li>Grouping : And or (Not fan of it.)</li> <li>eg: List <code>findByNameOrAgeAndActiveCustom</code>(String name, Integer age, Boolean active);<ul> <li>possibility-1 : (name = 'John' OR age = 30) AND active = true</li> <li>possibility-2 : name = 'John' OR (age = 30 AND active = true)</li> <li>its better to use @Query then, to take control.</li> <li><code>@Query(\"SELECT u FROM User u WHERE u.name = ?1 OR (u.age = ?2 AND u.active = ?3)\")</code></li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#2-query","title":"2. @Query","text":"<ul> <li>notice:</li> <li>Sort</li> <li>Pageable</li> <li>Page <li>PageRequest.of() <pre><code>------------------------\n// orderby / sorting\n------------------------\nsort-object-1:\n  - Sort.by(\"name\")\n  - Sort.by(\"price\").descending()\n  - Sort.by(\"price\").descending().and(Sort.by(\"name\"))\n  - Sort.by(Sort.Direction.ASC, \"name\")\n\n@Query(value = \"JPQL\", nativeQuery = f)\n- List&lt;E&gt; l = repo.findAll(sort-object-1);\n\n------------------------\n// pagination\n------------------------\nPageable p = PageRequest.of(page_no, page_size, sort-object-1); // int, int, Sort\n\n@Query(value = \"JPQL\", nativeQuery = f)\n- Page&lt;E&gt; l = repo.findAll(Pageable pageable);\n\n@Query(value = \"SQL\", nativeQuery = True, countQuery = '..count(*)..')\n- Page&lt;E&gt; l = repo.findAll(Pageable pageable);\n\nPageable sortedByName =PageRequest.of(0, 3, Sort.by(\"name\"));\nPageable sortedByPriceDesc =  PageRequest.of(0, 3, Sort.by(\"price\").descending());\nPageable sortedByPriceDescNameAsc = PageRequest.of(0, 5, Sort.by(\"price\").descending().and(Sort.by(\"name\")));\n\n@Query(value = \"SELECT u FROM User u WHERE u.name IN :names\")\nList&lt;User&gt; findUserByNameList(@Param(\"names\") Collection&lt;String&gt; names);    \n</code></pre></li> <li>sample Page after json serialization: <pre><code>{\n  \"content\": [\n    {\n      \"id\": 1,\n      \"name\": \"John\",\n      \"email\": \"john@example.com\"\n    }\n  ],\n  \"pageable\": {\n    \"pageNumber\": 0,\n    \"pageSize\": 5\n  },\n  \"totalPages\": 10,\n  \"totalElements\": 50\n}\n</code></pre>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-2/#more","title":"More","text":"<ul> <li>JPA Buddy plugin </li> <li>generation of JPA entities, Spring Data JPA repositories, DTOs,</li> <li>initialization DDL scripts,</li> <li>Flyway versioned migrations,</li> <li>provides an advanced tool for reverse engineering.</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/","title":"SB JPA Data Transactions","text":"<ul> <li>https://www.baeldung.com/transaction-configuration-with-jpa-and-spring - topics</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#hibernate-transaction-management","title":"Hibernate - Transaction management","text":"<ul> <li>add @Bean PlatformTransactionManager</li> <li>add @EnableTransactionManagement, or add spring-data-*-starter dependencies</li> <li>org.springframework.transaction = DEBUG</li> <li>fact:</li> <li>Mixing the database I/O with other types of I/O in a transactional context isn\u2019t a great idea.</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#a-transactional","title":"A. @Transactional","text":"<ul> <li>manage transaction boundaries in a declarative way.</li> <li>Spring creates proxies, to inject transactional-logic, before and after the running method.</li> <li>only public methods.</li> <li>best place apply on service method </li> <li>can also apply on repo methods</li> <li>@Transactional(attribtes=) : check below</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#propagation","title":"<code>propagation</code>","text":"<ul> <li>purpose:</li> <li>define the transactional behavior between multiple transactional methods.</li> <li>how the transaction management system handles existing and new transactions</li> <li>requires_new -&gt; AlwaysNewT </li> <li>If a transaction exists, the current method will join it</li> <li>If no transaction exists, a new one will be created.</li> <li>Required -&gt; t1 else t2new </li> <li>Suspends any existing transaction and starts a new one</li> <li>mandatory -&gt; t1 else ex </li> <li>Requires an existing transaction</li> <li> <p>If no transaction exists, an exception is thrown</p> </li> <li> <p>SUPPORTS -&gt; t1 </p> </li> <li>If a transaction exists, the method will participate in it.</li> <li>If no transaction exists, it will execute non-transactionally</li> <li>none  / NOT_SUPPORTED</li> <li>Suspends any existing transaction and executes non-transactionally.</li> <li>never -&gt;</li> <li>Must execute without a transaction</li> <li>Throws an exception if a transaction exists</li> <li>Nested</li> <li>inner txn :  independent transaction within the context of an existing/outer transaction.</li> <li>if inner transaction rolls back, it only rolls back the nested transaction, not the outer transaction.</li> <li>Not all databases and transaction managers provide full support for nested transactions.</li> <li>it uses Save points.</li> <li>enable it: <pre><code>  @Bean\n  public PlatformTransactionManager transactionManager(DataSource dataSource) \n  {\n    DataSourceTransactionManager transactionManager = new DataSourceTransactionManager(dataSource);\n    transactionManager.setNestedTransactionAllowed(true); // Enable nested transactions                   &lt;&lt;&lt; \n    return transactionManager;\n  }\n</code></pre></li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#isolation","title":"<code>isolation</code>","text":"<ul> <li>txn side effect : Dirty-read, Non-repeatable read, Phantom read.</li> <li>protection levele: READ_UNCOMMITTED, READ_COMMITTED, REPEATABLE_READ and SERIALIZABLE.</li> <li>can check: 03_ACID.md</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#timeout","title":"<code>timeout</code>","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#readonly","title":"<code>readOnly</code>","text":"<p>\u2013 t/f  - just a hint for the persistence provider that the transaction should be read only.  - optimizes performance.</p>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#rollbackfor-norollbackfor","title":"<code>rollbackFor / noRollbackFor</code>","text":"<ul> <li>@Transactional(<code>rollbackFor</code> = {Exception.class, SpecificException.class})</li> <li>@Transactional(<code>rollbackForClassName</code> = {\"java.lang.Exception\", \"com.example.SpecificException\"})</li> <li>if we don't mention any rule, rollback happens on unchecked-exceptions/RuntimeException</li> </ul>"},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#b-programmatic-txn","title":"B. programmatic txn","text":""},{"location":"00_Springboot/03_data-layer/05-SBjpaData-3-txn/#intro","title":"intro","text":"<ul> <li>check StudentServiceImpl.java</li> <li>TransactionTemplate utility provided by Spring to programmatically manage transaction</li> <li>Amix with AOP</li> <li>open and search : https://chatgpt.com/c/7b6dd03e-ca98-44d5-87a6-73c23026a009</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/","title":"OAuth 2.0","text":"<ul> <li>reference: </li> <li>okta : https://chatgpt.com/c/7db419de-fa44-4403-b587-a0e849b35ce8</li> <li> <p>my OAuth2 dev account : https://dev-16206041-admin.okta.com/admin/apps/active</p> </li> <li> <p>AWS OKTA SAML :</p> </li> <li>https://saml-doc.okta.com/SAML_Docs/How-to-Configure-SAML-2.0-for-Amazon-Web-Service</li> <li>https://help.okta.com/en-us/content/topics/deploymentguides/aws/aws-configure-aws-app.html</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#-oktaoauth2clientconfigurationjava","title":"- OktaOAuth2ClientConfiguration.java","text":""},{"location":"00_Springboot/04_security/00_OAuth_2.0/#pre-things","title":"pre-things","text":""},{"location":"00_Springboot/04_security/00_OAuth_2.0/#jwt","title":"JWT","text":"<ul> <li>body/payload : claims (statement about user and additional info)</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#application-arch","title":"Application arch","text":"<ul> <li>server-side web applications (SpringMVC, JSP) :</li> <li>browser-based applications / SPA :</li> <li>native/mobile apps :</li> <li>connected devices (M2M, lambda) :</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#openid-connect","title":"OpenId Connect","text":"<ul> <li>Token based Authentication.  <code>ID-Token</code></li> <li>extension over OAuth2.</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#oauth2","title":"OAuth2","text":""},{"location":"00_Springboot/04_security/00_OAuth_2.0/#intro","title":"Intro","text":"<ul> <li>http-redirection (header :: <code>location=url-2</code>, responseCode :: <code>302</code>)</li> <li>refer : https://auth0.com/intro-to-iam/what-is-oauth-2</li> <li> <p>Definition : OAuth standard protocol to solve <code>Delegated Authorization</code>.     &gt; - allow appl(Client) to access resources hosted by other web apps, on behalf of a user/resource-owner.     &gt; - provides consented access.     &gt; - restricts actions of what the client app can perform on resources, without sharing user credential.</p> </li> <li> <p>Token based Authorization. <code>Access-Token</code> + <code>Refresh Token</code> (long expiry )</p> </li> <li>Token based:</li> <li>format : JWT. </li> <li>token/s with multiple scope. (roles)</li> <li>received on callback URI</li> <li> <p>OAuth 2.0 doesn\u2019t define a specific format for Access Tokens</p> </li> <li> <p>client must identify/authenticate itself, when requesting an Access Token.</p> </li> <li>Resource server (spring-backend-app) </li> <li>must validate JWT </li> <li>has role-based access code.</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#key-components","title":"Key Components :","text":"<p>Eg: photoPrint-App &lt;--&gt; Google-Drive</p> <ul> <li>resource-Owner (User)</li> <li>Client</li> <li>resource-Server</li> <li>Authorization-Server</li> <li>more:</li> <li> <p>Scopes</p> <ul> <li>specify exactly the <code>reason</code>, for which access to resources may be granted.</li> <li>dependent on the Resource Server.</li> <li>while making Auth request mention <code>scopes</code>. eg: openid, profile, email, offline_access</li> <li>returned token will have <code>claims</code>.</li> </ul> </li> <li> <p>Authorization Code</p> <ul> <li>OAuth 2 Authorization server may not directly return an Access Token.</li> <li>Instead, and for better security, an Authorization Code may be returned, which is then exchanged for an Access Token.</li> </ul> </li> <li>Grant Types <ul> <li>grants are the <code>set of steps</code> a Client has to perform to get \"resource-access-authorization\".</li> <li>check below for detail.</li> </ul> </li> <li>claims<ul> <li>Registered claims:  iss (issuer), exp (expiration time), sub (subject), aud (audience),</li> <li>https://datatracker.ietf.org/doc/html/rfc7519#section-4.1</li> <li>public claims : https://www.iana.org/assignments/jwt/jwt.xhtml</li> <li>private claims :</li> </ul> </li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#grant-types-flows","title":"Grant Types (flows)","text":"<ul> <li>grants are the \"set of steps\" a Client has to perform to get \"resource-access-authorization\".</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#authorization-code-grant-withwithout-pkce","title":"<code>Authorization Code</code> Grant  with/without PKCE","text":"<ul> <li>https://developer.okta.com/docs/guides/sign-into-web-app-redirect/spring-boot/main/</li> <li>After validating client identity,</li> <li>AuthServer return single-use Authorization-Code to the Client via callback URI</li> <li>which is then exchanged for an Access Token.</li> <li>use-case : Traditional web apps where the exchange can <code>securely</code> happen on the server side. // back-channel.</li> <li>PKCE : additional steps that make it more secure for mobile/native apps and SPAs. <pre><code>    1. Client : GET /authorize?response_type=code&amp;client_id=`CLIENT_ID`&amp;redirect_uri=`REDIRECT_URI`&amp;scope=read&amp;state=xyz\n    2. OKTA : HTTP/1.1 302 Found Location: https://client-app.com/callback?code=`AUTHORIZATION_CODE`&amp;state=xyz\n    3. Client : POST /token \n       Content-Type: application/x-www-form-urlencoded\n       grant_type=authorization_code&amp;code=AUTHORIZATION_CODE&amp;redirect_uri=REDIRECT_URI&amp;client_id=CLIENT_ID&amp;client_secret=CLIENT_SECRET\n</code></pre></li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#implicit-grant","title":"<code>Implicit</code> Grant","text":"<ul> <li>A simplified flow where the Access Token is returned \"directly\" to the Client.</li> <li>use-case : SPA.</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#client-credential-grant","title":"<code>client-credential</code> Grant","text":"<ul> <li>First client acquire its own credentials(client id, client secret) from the Authorization Server,</li> <li>Access Token is returned against these credential. (basically AuthServer validate identity.)</li> <li>use-case : lambda, micro services.</li> <li>https://developer.okta.com/blog/2021/05/05/client-credentials-spring-security</li> <li>hands on:</li> <li>created app / client https://dev-16206041-admin.okta.com/admin/app/oidc_client/instance/0oaldbk7ys8px41Gy5d7/#tab-general</li> <li>created auth server: https://dev-16206041-admin.okta.com/admin/oauth2/as/ausldbxlfakbwq32P5d7#<ul> <li>add scope :  app_read_lekhraj</li> <li>add Access policy : allow above client</li> <li>DPoP : disable</li> <li>can add Trusted-servers</li> </ul> </li> <li>made postman call : https://lekhrajdinkar-postman-team.postman.co/workspace/My-Workspace~355328d1-2f75-4558-8e56-e229e284f6a3/example/5083106-53c3fa91-ef5f-4f49-899f-2b1064386242</li> <li>created GET http://localhost:8083/spring/security/getAccessToken to do same. <pre><code>    {\n  \"ver\": 1,\n  \"jti\": \"AT.-DVBDB63tr7t34AlwXR_y3zT_mHZWpGPWxholPDGLfI\",\n  \"iss\": \"https://dev-16206041.okta.com/oauth2/ausldbxlfakbwq32P5d7\",\n  \"aud\": \"0oaldbk7ys8px41Gy5d7\",\n  \"iat\": 1732406655,\n  \"exp\": 1732410255,\n  \"cid\": \"0oaldbk7ys8px41Gy5d7\",\n  \"scp\": [\n  \"app_read_lekhraj\"                         &lt;&lt;&lt;&lt;&lt;&lt;\n  ],\n  \"sub\": \"0oaldbk7ys8px41Gy5d7\"\n  }\n\ngot exception: \n  - org.springframework.security.oauth2.core.OAuth2AuthorizationException: [invalid_dpop_proof] The **DPoP proof JWT header is missing**. \n  - Demonstration of Proof of Possession\n  - provides an additional layer of security by requiring the client to prove possession of a private key associated.\n  - Disable it of Authorizarion-server \n</code></pre></li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#refresh-token-grant","title":"<code>Refresh Token</code> Grant","text":"<ul> <li>involves the exchange of a Refresh Token for a new Access Token.</li> </ul>"},{"location":"00_Springboot/04_security/00_OAuth_2.0/#screenshots","title":"screenshots:","text":""},{"location":"00_Springboot/04_security/01_sb-security-start/","title":"Spring Boot Security Start","text":"<ul> <li>link1 - https://chatgpt.com/c/67417202-5748-800d-9fc5-c032961a7c5b </li> <li>client credential api call, DPoP error fix</li> <li>multiple filters</li> </ul>"},{"location":"00_Springboot/04_security/01_sb-security-start/#concepts","title":"concepts","text":"<ul> <li>OAuth2 dependency :: spring-boot-starter-oauth2-client + spring-security-oauth2-jose</li> <li>LDAP : https://chatgpt.com/c/5865254e-a777-416f-ad16-8e40df050c04 </li> <li>DN entries</li> <li>Authentication vs Authorization</li> <li>token - JWT https://jwt.io/introduction/</li> <li>web filter</li> <li>CCGG pattern/s</li> <li>App &lt;--&gt; Authenticating users against an LDAP directory, directly. (old)</li> <li>App &lt;--&gt; OKTA &lt;--integrated--&gt; LDAP Authentication<ul> <li>okta has user Authentication rule configured with LDAP</li> <li>okta has user access config. eg: which scope can ask. </li> <li>okta has MFA enabled</li> <li>one app/atmid, 1 scope, 1 client, 1 issuer, JWT-claims::scope [role1,role2,...]</li> <li>developer has grab role and use it method level access.</li> </ul> </li> <li>Using SAML for single sign-on (SSO) with external identity providers/Okta.</li> <li>security on the fly : TLS/SSL</li> </ul>"},{"location":"00_Springboot/04_security/01_sb-security-start/#spring-boot-security","title":"Spring Boot Security","text":""},{"location":"00_Springboot/04_security/01_sb-security-start/#intro","title":"Intro","text":"<ul> <li>Authentication and access-control framework.</li> <li>use web-filter bts</li> <li>old: WebSecurityConfigurerAdapter</li> <li><code>@EnableGlobalMethodSecurity</code>(prePostEnabled = true)` c1</li> <li><code>@PreAuthorize</code>(\"hasAuthority('SCOPE_my.spring.app.scope')\") m()</li> <li><code>Disable</code> auto-config<ul> <li>@SpringBootApplication(exclude = { SecurityAutoConfiguration.class })</li> <li>spring.autoconfigure.exclude = org.springframework.boot.autoconfigure.security.SecurityAutoConfiguration</li> </ul> </li> <li><code>Enable</code> auto-config</li> <li>Add spring-boot-starter-security</li> <li>Add WebSecurityCustomizer <code>bean</code> <pre><code>  @Bean\n  public WebSecurityCustomizer webSecurityCustomizer() {\n      return (web) -&gt; web.ignoring().requestMatchers(\"/ignore1\", \"/ignore2\");\n  }\n</code></pre></li> <li>Add  SecurityFilterChain <code>bean</code> - <code>new and functional style</code>.<ul> <li>notice, injecting : HttpSecurity http</li> </ul> </li> </ul> <p><pre><code>@Configuration\n@EnableGlobalMethodSecurity`(prePostEnabled = true)\npublic class SecurityConfig \n{\n  @Bean\n  public SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception {\n      http\n          .authorizeRequests(authorize -&gt; authorize\n              .antMatchers(\"/path-read\").hasAuthority(\"SCOPE_ScopeRead\")    \n              .antMatchers(\"/path-write\").hasAuthority(\"SCOPE_ScopeWrite\") //.hasRole(\"\").hasAnyRole(\"\",\"\")\n              .anyRequest().authenticated()                         \n          )\n          .oauth2ResourceServer(oauth2 -&gt; oauth2\n              .jwt(Customizer.withDefaults()) // Validate JWT tokens\n          );\n      return http.build();\n  }\n }\n</code></pre>   - Security_01_Config.java     - webSecurityCustomizer-1 bean      - filter-1/2 bean - conditonally enable either.</p> <ul> <li>can have multiple filter beans. eg: </li> <li>filter-1 bean  @Order(1)  for url-pattern-1, do form-login</li> <li> <p>filter-2 bean  @Order(2)  for url-pattern-2, do Oauth-JWT-validation </p> <ul> <li>create more SecurityFilterChain and chain it on filter-2</li> <li>.addFilter(filter 3 bean)</li> <li>check reference link1 for code.</li> </ul> </li> <li> <p>claims (payload in JWT)     <pre><code>{\n\"sub\": \"1234567890\",\n\"name\": \"Lekhraj Dinkar\",\n\"roles\": [\"USER_ADMIN\"],                               &lt;&lt;&lt;\n\"scp\": [\"ScopeRead\", \"ScopeWrite\"],                    &lt;&lt;&lt;\n\"iat\": 1689704000,\n\"exp\": 1689707600\n}\n</code></pre></p> </li> <li>in SpEL, refer them like</li> <li>SCOPE_ ScopeRead</li> <li>ROLE_ USER_ADMIN</li> </ul>"},{"location":"00_Springboot/04_security/01_sb-security-start/#more-topic","title":"More topic","text":"<ul> <li>Cross-Origin Resource Sharing (CORS) settings</li> <li>Password Management safes: </li> <li>AWS-secret-manager </li> <li>CyberArk</li> <li>Prevent XSS and CSRF</li> <li>CSRF : enabled by default, </li> <li>create custom filter for further CSRF protection</li> </ul>"},{"location":"00_Springboot/04_security/02_Authentication/","title":"Authentication","text":""},{"location":"00_Springboot/04_security/02_Authentication/#key-term","title":"key term","text":"<ul> <li><code>UserDetail</code> (name,pass,role,etc),</li> <li><code>UserDetailsService</code></li> <li><code>Authentication</code></li> <li><code>AuthenticationManager</code> and <code>AuthenticationManagerBuilder</code></li> <li>central point for authentication logic</li> <li><code>AuthenticationProviders</code></li> <li>InMemoryUserDetailsManager : Security_01_Config.java</li> <li>Custom beans :  UserDetailsService AuthenticationProvider, Filters</li> </ul>"},{"location":"00_Springboot/04_security/02_Authentication/#ways-to-do","title":"ways to do","text":"<ol> <li><code>Form-based Authentication</code> (not for REST api) // http.loginForm()...</li> <li><code>Basic Authentication</code> / Digest Authentication (old,hashed credentials)<ul> <li>hide credential: Authorization header :: Base64-encoded string username:password.</li> <li>it\u2019s possible to hide the key using SSL.</li> </ul> </li> <li><code>LDAP</code> - springs helps to integrating with LDAP and perform authentication.</li> <li><code>OpenID Connect</code> </li> <li>springs helps to integrating with external authentication-providers(okta,google,etc)</li> <li>Identity token generate by Okta, requested by UI or consumer.</li> <li>okta:</li> <li>Multi-factor Authentication: configuring it</li> <li>SpringApp &lt;--&gt; okta &lt;--&gt; LDAP Integration, for Authentication</li> </ol>"},{"location":"00_Springboot/04_security/03_Authorization/","title":"Authorization","text":""},{"location":"00_Springboot/04_security/03_Authorization/#ways-to-do","title":"ways to do:","text":""},{"location":"00_Springboot/04_security/03_Authorization/#role-based-access-control-rbac","title":"<code>Role-based Access Control (RBAC)</code>","text":"<ul> <li>Assigning roles to users and granting access based on those roles.</li> <li>note: cg-LDAP takes care</li> </ul>"},{"location":"00_Springboot/04_security/03_Authorization/#url-based-security","title":"<code>URL-based Security</code>","text":"<ul> <li>Restricting access to web resources based on URL patterns.</li> </ul>"},{"location":"00_Springboot/04_security/03_Authorization/#token-based-oauth-20-green_circle","title":"token based : <code>OAuth 2.0</code> :green_circle:","text":"<ul> <li>springs helps to integrating with external authentication-providers(okta,google,etc)</li> <li>Access Token generate by Okta ; requested by UI.</li> <li><code>Spring &lt;--&gt; okta &lt;--&gt; LDAP Integration</code>, for Authorization</li> <li>parsing and validating JWT tokens.</li> </ul>"},{"location":"00_Springboot/04_security/03_Authorization/#method-level-security","title":"<code>Method-level Security</code>","text":"<ul> <li>https://www.baeldung.com/spring-security-method-security</li> <li>Anno:</li> <li>@PreAuthorize </li> <li>@PostAuthorize</li> <li>@Secured</li> <li>@RolesAllowed <pre><code>@RestController\npublic class LocationBasedAccessController \n{\n    @GetMapping(\"/restricted\")\n    @PreAuthorize(\"hasAuthority('ROLE_USER_ADMIN') and #jwt.claims['location'] == 'Irvine'\")   &lt;&lt;&lt;\n    public String restrictedAccess() {\n        return \"Access granted for users in Irvine!\";\n    }\n}\n\n{\n  \"sub\": \"1234567890\",\n  \"name\": \"Lekhraj Dinkar\",\n  \"roles\": [\"USER_ADMIN\"],\n  \"location\": \"Irvine\",  // Custom claim\n  \"iat\": 1689704000,\n  \"exp\": 1689707600\n}\n</code></pre></li> </ul>"},{"location":"00_Springboot/04_security/04_REST-secure/","title":"REST Security","text":""},{"location":"00_Springboot/04_security/04_REST-secure/#secure-rest","title":"Secure REST","text":"<ul> <li>REST APIs are stateless, they should not use sessions or cookies, use JWT which is also Stateless.</li> <li>HTTPS: Securing data in transit using <code>SSL/TLS</code>.</li> <li>Security headers</li> <li><code>Strict-Transport-Security</code></li> <li><code>X-Content-Type-Options</code></li> <li><code>X-Frame-Options</code></li> <li><code>Content-Security-Policy</code> </li> </ul>"},{"location":"00_Springboot/04_security/04_REST-secure/#options","title":"Options","text":""},{"location":"00_Springboot/04_security/04_REST-secure/#1-basicdigest-authentication","title":"1. basic/digest Authentication","text":"<ul> <li>Security_01_Config.java</li> <li>AuthenticationEntryPoint - Configure it differently for basic and digest.</li> </ul>"},{"location":"00_Springboot/04_security/04_REST-secure/#2-api-keys","title":"2. API Keys","text":"<ul> <li>https://www.baeldung.com/spring-boot-api-key-secret</li> <li>Some REST APIs use API keys for authentication.</li> <li>An API-key is like <code>token</code>, that identifies the - <code>API-client to the API without referencing an actual user</code>.</li> <li>API-key can be sent in the queryString or header.</li> <li>it\u2019s possible to hide the key using SSL.</li> <li>Create <code>Custom Filter</code> to Check API-Check</li> <li>eg: CCGG MuleSoft API</li> </ul>"},{"location":"00_Springboot/04_security/04_REST-secure/#3-oauth-20-jwt-authorization-green_circle","title":"3. OAuth 2.0 JWT / Authorization :green_circle:","text":"<ul> <li>auth0 : https://manage.auth0.com/dashboard/us/dev-gpg8k3i38lkcqtkw/onboarding </li> <li>signed up with Github</li> <li>dev-gpg8k3i38lkcqtkw</li> <li>00_OAuth_2.0.md</li> </ul>"},{"location":"00_Springboot/04_security/04_REST-secure/#springboot-security-code","title":"Springboot security code","text":"<pre><code>spring.security.oauth2.resourceserver.jwt.issuer-uri=https://dev-16206041.okta.com/oauth2/ausldbxlfakbwq32P5d7\n\n---\n\n@ConditionalOnProperty(havingValue = \"SecurityFilterChain_03\", name = \"sb.customize.SecurityFilterChain\")\n@Bean\npublic SecurityFilterChain filterChainToken3(HttpSecurity http) throws Exception\n{\nhttp.authorizeHttpRequests(registry -&gt; registry\n.requestMatchers(\"/swagger-ui/**\", \"/actuators/**\").permitAll()\n.anyRequest()\n.authenticated());\nhttp.oauth2ResourceServer(oAuth2 -&gt; oAuth2.jwt(Customizer.withDefaults()));\nreturn http.build();\n}\n</code></pre>"},{"location":"01_aws/00_DVA-C02/00_DVA/","title":"1. AWS Services  for DVA","text":""},{"location":"01_aws/00_DVA-C02/00_DVA/#a-reference","title":"A. Reference","text":"<ul> <li>https://aws.amazon.com/blogs/</li> <li>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#2-progress","title":"2. Progress","text":"<ul> <li>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/19771482#overview</li> <li>slides:  https://courses.datacumulus.com/downloads/certified-developer-k92/</li> <li>practice paper: https://www.udemy.com/course/aws-certified-developer-associate-practice-tests-dva-c01/</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-4-iam-green_circle","title":"Section 4 <code>IAM</code> :green_circle:","text":"<ul> <li>01_IAM.md</li> <li>Directory service:</li> <li>01_SSO+DirectoryService.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-5-ec2-green_circle","title":"Section 5 <code>EC2</code> :green_circle:","text":"<ul> <li>01_EC2.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-6-ebs_efs-green_circle","title":"Section 6  <code>EBS_EFS</code> :green_circle:","text":"<ul> <li>01_EBS_EFS.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-7-elb_asg-green_circle","title":"Section 7 : <code>ELB_ASG</code> :green_circle:","text":"<ul> <li>01_ELB_ASG.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-8-rds-aurora-elasticache-green_circle","title":"Section 8 -  <code>RDS + Aurora + ElastiCache</code> :green_circle:","text":"<ul> <li>01_RDS.md</li> <li>02_Aurora.md</li> <li>03_ElastiCache.md <pre><code>    ElastiCache Strategies\n    Amazon MemoryDB for Redis\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-9-route-53-green_circle","title":"Section 9 - <code>Route 53</code> :green_circle:","text":"<ul> <li>02_Rout53.md <pre><code>    Routing Policy - Traffic Flow &amp; Geoproximity Hands On\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-10-vpc-fundamentals-green_circle","title":"Section 10 - <code>VPC Fundamentals</code> :green_circle:","text":"<ul> <li>VPC details not needed. still can check:</li> <li>03_VPC-1.md</li> <li>03_VPC-2.md</li> <li>03_VPC-3.md</li> <li>03_VPC-4.md</li> <li>04_CloudFront_DVA.md <pre><code>    VPC Fundamentals - Section Introduction\n    VPC, Subnets, IGW and NAT\n    NACL, SG, VPC Flow Logs\n    VPC Peering, Endpoints, VPN, DX\n    VPC Cheat Sheet &amp; Closing Comments\n    Three Tier Architecture\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-12-aws-cli-sdk-green_circle","title":"Section 12 - <code>AWS CLI, SDK</code> :green_circle:","text":"<ul> <li>12_CLI_SDK_more.md <pre><code>    AWS EC2 Instance Metadata\n    AWS EC2 Instance Metadata - Hands On\n    AWS CLI Profiles\n    AWS CLI with MFA\n    AWS SDK Overview\n    Exponential Backoff &amp; Service Limit Increase\n    AWS Credentials Provider &amp; Chain\n    AWS Signature v4 Signing\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-111314-s3-green_circle","title":"Section 11,13,14 - <code>S3</code> :green_circle:","text":"<ul> <li>03_S3-1.md</li> <li>03_S3-2.md</li> <li>03_S3-3.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-15-cloudfront-green_circle","title":"Section 15 - <code>CloudFront</code> :green_circle:","text":"<ul> <li>04_CloudFront.md</li> <li>04_CloudFront_DVA.md <pre><code>    CloudFront - Caching &amp; Caching Policies\n    CloudFront - Cache Behaviors\n    CloudFront - Caching &amp; Caching Invalidations - Hands On\n    CloudFront - Signed URL / Cookies\n    CloudFront - Signed URL - Key Groups + Hands On\n    CloudFront - Advanced Concepts\n    CloudFront - Real Time Logs\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-16-ecs-ecr-fargate-green_circle","title":"Section 16 <code>ECS, ECR &amp; Fargate</code> :green_circle:","text":"<ul> <li>02_Containers_ECS.md</li> <li>02_Kubernetes_EKS.md <pre><code>    Amazon ECS - Rolling Updates\n    Amazon ECS Task Definitions - Deep Dive\n    Amazon ECS Task Definitions - Hands On\n    Amazon ECS - Task Placements\n    Amazon ECR - Hands On\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-17-beanstalk-green_circle","title":"Section 17 <code>beanstalk</code> :green_circle:","text":"<ul> <li>05_1_Beanstalk_SSA.md</li> <li>05_2_Beanstalk_DVA-deployments.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-18-cloudformation-green_circle","title":"Section 18 <code>Cloudformation</code> :green_circle:","text":"<ul> <li>18_CLOUD_FORMATION.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-19-sqssns-kds-kdf-green_circle","title":"Section 19 <code>SQS,SNS, KDS, KDF</code> :green_circle:","text":"<ul> <li>05_decoupling</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-20-monitor-green_circle","title":"Section 20 <code>Monitor</code> :green_circle:","text":"<ul> <li>01_CW-Metric.md</li> <li>02_CW-Logs.md</li> <li>03_CW-Alarms.md</li> <li>04_X-rays_DVA.md :yellow_circle:</li> <li>05_cloudTrail.md</li> <li>06_AWS_config.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-21-lambda-green_circle","title":"Section 21 : <code>lambda</code> :green_circle:","text":"<ul> <li>03_lambda-01-saa.md</li> <li>03_lambda-dva-01-CLI.md</li> <li>03_lambda-dva-02-trigger.md</li> <li>03_lambda-dva-03-context+event.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-22-dynamodb-green_circle","title":"Section 22 : <code>DynamoDB</code> :green_circle:","text":"<ul> <li>04_1_DynamoDB_SSA.md</li> <li>04_2_DynamoDB_DVA-components.md</li> <li>04_3_DynamoDB_DVA-operations.md</li> <li>04_4_DynamoDB_DVA-cli.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-23-api-gateway-green_circle","title":"Section 23 : <code>API-gateway</code> :green_circle:","text":"<ul> <li>05_1_API_gateway_SAA.md</li> <li>05_2_API_gateway_DVA.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-24-cicd-green_circle","title":"Section 24 : <code>CI/CD</code> :green_circle:","text":"<ul> <li>24_CI_CD</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-25-sam-serverless-application-model-green_circle","title":"Section 25 : <code>SAM :Serverless Application Model</code> :green_circle:","text":"<ul> <li>00_serverless_pardigm.md</li> <li>00_start.md</li> <li>SAM_project</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-26-cdk-green_circle","title":"Section 26 : <code>CDK</code> :green_circle:","text":"<ul> <li>26_CDK.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-27-cognito-green_circle","title":"Section 27 : <code>Cognito</code> :green_circle:","text":"<ul> <li>02_1_cognito_SAA.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-28-serverless-more-step-function-appsync-amplify-green_circle","title":"Section 28 : serverless more: <code>Step function, AppSync, Amplify</code> :green_circle:","text":"<ul> <li>28_1_STEP_FUNCTION.md</li> <li>28_2_AppSync.md</li> <li>28_3_Amplify.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-29-advance-iam-short-green_circle","title":"Section 29: <code>Advance IAM (short)</code> :green_circle:","text":"<ul> <li>01_IAM.md</li> <li>01_SSO+DirectoryService.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-30-security-kmsssmsecretmanager-green_circle","title":"Section 30 : <code>security: KMS,SSM,Secretmanager</code> :green_circle:","text":"<ul> <li>04_1_KMS_SSA.md</li> <li>04_2_KMS_DVA-cli.md</li> <li>04_3_KMS+HSM_DVA-more.md</li> <li>05_SSM-param-store.md</li> <li>06_secret_manager.md</li> <li>more (SSA)</li> <li>07_ACM.md</li> <li>08_WAF + FirewallManager.md</li> <li>09_sheild.md</li> <li>99_more_securiy_services_for_SSA.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#section-31-other-services-green_circle","title":"Section 31 : <code>other services</code> :green_circle:","text":""},{"location":"01_aws/00_DVA-C02/00_DVA/#dva","title":"DVA","text":"<ul> <li>03_openSearch.md</li> <li>ses: 02_SES+pinpoint.md</li> <li>01_athena_adhocSQL_serverless.md</li> <li>06_MSK.md</li> <li>07_ACM.md</li> <li>macie: 99_more.md</li> <li>06_AWS_config.md</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#saa","title":"SAA","text":"<ul> <li>97_more-services</li> <li>09_DR</li> <li>08_Analytics</li> <li>10_ML</li> <li>more:</li> <li>98_SAA_discussion</li> <li>practice-test-SAA</li> </ul>"},{"location":"01_aws/00_DVA-C02/00_DVA/#services","title":"services","text":"<pre><code>### Compute\n- Amazon EC2\n- AWS Lambda\n- AWS Elastic Beanstalk\n- Amazon ECS\n- AWS Fargate\n- Amazon Auto Scaling\n\n### Containers\n- Amazon ECS\n- Amazon ECR\n- AWS Fargate\n\n### Storage\n- Amazon S3\n- Amazon Elastic File System (EFS)\n- Amazon ElastiCache\n\n### Databases\n- Amazon RDS\n- Amazon DynamoDB\n- Amazon ElastiCache\n\n### Networking &amp; Content Delivery\n- Elastic Load Balancing\n- Amazon CloudFront\n- Amazon Route 53\n\n### Developer Tools\n- AWS CodeCommit\n- AWS CodeDeploy\n- AWS CodeBuild\n- AWS CodePipeline\n\n### Monitoring &amp; Observability\n- Amazon CloudWatch\n- AWS X-Ray\n\n### Security, Identity, and Compliance\n- AWS Identity and Access Management (IAM)\n- AWS Key Management Service (KMS)\n\n### Management &amp; Governance\n- AWS CloudFormation\n- AWS CloudTrail\n- Amazon EC2 Systems Manager\n\n### Application Integration\n- Amazon Simple Queue Service (SQS)\n- Amazon Simple Notification Service (SNS)\n- Amazon Simple Email Service (SES)\n- Amazon API Gateway\n- AWS Step Functions\n\n### Analytics\n- Amazon Kinesis\n\n### Customer Engagement\n- Amazon Cognito\n</code></pre>"},{"location":"01_aws/00_DVA-C02/00_DVA/#important-topics-of-exam","title":"Important topics of exam","text":"<pre><code>Study and practice S3, DynamoDB, SQS, KMS, Beanstalk, lambda a lot\n\nUnderstand SQS with visibility timeouts, message delivery, errors and security\n\nSQS limits and long polling\n\nPractice CloudFormation\n\nRemember CodeDeploy and CodeBuild hooks\n\nConcepts of ALB, NLB, and ASG with EC2 and Beanstalk\n\nOptimizing DynamoDB and S3 queries for performance\n\nDynamo partition keys, local/global secondary indexes\n\nUnderstand Beanstalk and it\u2019s best practices\n\nS3 CORS and encryption\n\nS3 limits and important APIs\n\nUse of Kinesis Stream and Kinesis Firehose\n\nKinesis shards and how to optimize them.\n\nIAM users, groups, roles, and inline policies\n\nDifferent methods of restricting access to resources (policies, ACLs)\n\nHTTP error codes (4xx, 5xx)\n\nWeb identity federation, User Pool, Identity Pool, and STS\n\nEncryption mechanism (SSE, KMS, Client Side Encryptions, In Flight Encryption)\n\nEBS basics\n\nUnderstand the concept of SAM (Serverless Application Model)\n\nPractice encryption with API gateway, Lambda, S3, Beanstalk, DynamoDB, EBS, SQS with the help of KMS, SSL/HTTPS\n\nRemember important API calls of S3, SQS, Beanstalk, STS, KMS, ECS\n\nRemember how to calculate read and write throughput (RCU, WCU) for DynamoDB.\n\nThat all my preparation hope this help.\n</code></pre>"},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/","title":"developer things","text":""},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#1-ec2-instant-metadata-api","title":"1 EC2 instant metadata API.","text":""},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#2-aws-profile","title":"2 aws profile","text":""},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#3-cli","title":"3 CLI","text":"<ul> <li>aws cli with MFA. : cli written in py(boto3)</li> <li>aws sts get-session-token </li> <li><code>--serial-number</code> arn-of-the-mfa-device </li> <li><code>--tokencode</code> code-from-token </li> <li><code>--duration-seconds</code> 3600</li> <li><code>--region</code> us-east-1 (default) </li> </ul>"},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#4-aws-sdk","title":"4 aws sdk","text":"<ul> <li>in-built retry mechanism (with exponential backoff)</li> <li>java py node.js</li> </ul>"},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#5-aws-limits","title":"5 Aws limits","text":""},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#on-api-call","title":"on API call.","text":"<ul> <li>ec2:describeInstance - 100/s</li> <li>s3:getObject         - 5500/s</li> </ul>"},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#on-resources","title":"on Resources","text":"<ul> <li>open ticket ?</li> <li>service Quota API</li> </ul>"},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#exponential-backoff","title":"Exponential backoff","text":"<ul> <li>while making api call, if get ThrottlingException or 5XX intermittently, use it.</li> <li>retry:1 after 1 sec</li> <li>retry:2 after 2 sec</li> <li>retry:3 after 4 sec</li> <li>retry:4 after 8 sec</li> </ul>"},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#6-aws-clisdkjava-credentials-provider-chain","title":"6 AWS CLI/SDK(java) Credentials Provider Chain","text":"<ul> <li>The CLI will look for credentials in this order:</li> <li>CLI option \u2013 --profile, or</li> <li>SDK :: Java system properties \u2013 <code>aws.accessKeyId</code> and <code>aws.secretKey</code></li> <li>Environment variables \u2013 <code>AWS_ACCESS_KEY_ID,AWS_SECRET_ACCESS_KEY,AWS_SESSION_TOKEN</code></li> <li>~/.aws/credentials </li> <li>~/.aws/config </li> <li>Container credentials \u2013 for ECS tasks</li> <li>Instance profile credentials \u2013 for EC2 Instance Profiles</li> </ul>"},{"location":"01_aws/00_DVA-C02/12_CLI_SDK_more/#7-signv4","title":"7 signV4","text":"<ul> <li>AWS SDKs and AWS CLI handle SigV4 signing automatically</li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/","title":"Cloud Formation (IAC)","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#a-intro","title":"A. Intro","text":"<ul> <li>declarative way of provisioning AWS Infrastructure</li> <li>IAC </li> <li>stack-1 (for vpc)<ul> <li>reource-1 (tags - stackid(arn), logicalId, physicalId,etc)</li> <li>rsource-2</li> <li>...</li> <li>resolves order / dependency</li> <li></li> </ul> </li> <li>stack-2 (app stack)</li> <li>...</li> <li>versioned in git</li> <li>app composer to visualize</li> <li>cost</li> <li>Each resources within the stack is tagged with an identifier so you can easily see how much a stack costs you</li> <li>estimate the costs of your resources</li> <li>schedule to destroy and re-create, to save cost.</li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#b-template","title":"B. Template","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#1-overview","title":"1. overview","text":"<pre><code>\u2022 AWSTemplateFormatVersion  \u2013 identifies the capabilities of the template \u201c2010-09-09\u201d\n\u2022 Description               \u2013 comments about the template\n\u2022 Resources (MANDATORY)     \u2013 your AWS resources declared in the template\n\u2022 Parameters                \u2013 the dynamic inputs for your template\n\u2022 Mappings                  \u2013 the static variables for your template\n\u2022 Outputs                   \u2013 references to what has been created\n\u2022 Conditionals              \u2013 list of conditions to perform resource creation\n</code></pre>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#2-resource","title":"2. resource","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#reference","title":"reference","text":"<ul> <li>check : https://docs.aws.amazon.com/AWSCloudFormation/latest/UserGuide/aws-template-resource-type-ref.html </li> <li>700+ resource with example and doc.</li> <li>will use CDK anyway.</li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#21-custom-resource","title":"2.1 Custom resource","text":"<ul> <li>certain resources not support</li> <li>use <code>CF custom resource</code> <ul> <li>backed by lambda  - serviceToken (arm od lambda)</li> <li></li> <li>usecase-1: empty s3 bucket before delete.</li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#22-delete-policy","title":"2.2 Delete Policy","text":"<ul> <li>resource-1<ul> <li>DeletePolicy=<code>Delete</code> (default)<ul> <li>for s3, bucket must be empty </li> </ul> </li> <li>DeletePolicy=<code>Retain</code></li> <li>DeletePolicy=<code>Snapshot</code><ul> <li>for EBS volume</li> <li>databases :<ul> <li>RDS</li> <li>DocumnetDB</li> <li>ElastiCache</li> <li>Neptune</li> <li>...</li> </ul> </li> </ul> </li> </ul> </li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#3-parameter-dynamic-input","title":"3. parameter (dynamic input)","text":"<ul> <li>refer/use them</li> <li>!Ref parameter1</li> <li>Fn::Ref parameter1, or resource1</li> </ul> <p><pre><code># -- parameter --\n- Type\n    \u2022 String \u2022 Number \u2022 CommaDelimitedList\n    \u2022 List&lt;Number&gt;\n    \u2022 AWS-Specific Parameter + List&lt;AWS-Specific Parameter&gt;\n    \u2022 SSM Parameter (get parameter value from SSM Parameter store)\n\n- Default \n- Description\n\n- Constarint\n    \u2022 Min/MaxLength\n    \u2022 Min/MaxValue\n    \u2022 AllowedValues (array)\n    \u2022 AllowedPattern (regex)\n    \u2022 NoEcho (Boolean) : for passowrd feild, so wont be logged/dispalyed anywhere\n</code></pre> - Pseudo parameter <pre><code>AWS::AccountId 123456789012\nAWS::Region us-east-1\nAWS::StackId arn:aws:cloudformation:us-east-1:123456789012:stack/MyStack/1c2fa620-982a-11e3-aff7-50e2416294e0\nAWS::StackName MyStack\nAWS::NotificationARNs [arn:aws:sns:us-east-1:123456789012:MyTopic]\nAWS::NoValue Doesn\u2019t return a value\n</code></pre></p>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#4-mapping-mapstringobject","title":"4. mapping : map(string,object)","text":"<ul> <li>static variable, fixed hardcoded value</li> <li>use/refer</li> <li>!FindInMap [ map-1, key, object-attribute-1]</li> <li></li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#5-output-optional","title":"5. output (optional)","text":"<ul> <li>must be unique in region</li> <li>print for console</li> <li>IAC-1 (collaboration)</li> <li>stack-1(vpc-1) : output export <code>vpc-id</code></li> <li>stack-2(app-1) : refer <code>vpc-id</code> in this stack</li> <li>eg:</li> <li></li> <li></li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#6-conditional","title":"6. Conditional","text":"<ul> <li>conditionally create resource. </li> <li>eg based on env type. <pre><code>Parameters:\n  envType:\n    Description: \"The environment type (prd or dev)\"\n    Type: \"String\"\n    AllowedValues:\n      - prd\n      - dev\n    Default: \"dev\"\n\nConditions: \n    IsProd: !Equals [!Ref envType, \"prd\"]  # True if envType is 'prd'\n    IsDev: !Equals [!Ref envType, \"dev\"]  # True if envType is 'dev'\n    IsNotProd: !Not [!Equals [!Ref envType, \"prd\"]]  # True if envType is not 'prd'\n    IsProdOrDev: !Or\n      - !Equals [!Ref envType, \"prd\"]\n      - !Equals [!Ref envType, \"dev\"]  # True if envType is 'prd' or 'dev'\n    IsNotDev: !Not [!Equals [!Ref envType, \"dev\"]]  # True if envType is not 'dev'\n    IsProdAndNotDev: !And\n      - !Equals [!Ref envType, \"prd\"]\n      - !Not [!Equals [!Ref envType, \"dev\"]]  # True if envType is 'prd' and not 'dev'\n\nResources:\n  Resource1:\n    Type: \"AWS::S3::Bucket\"\n    Condition: IsProd \n    ...\n\n  Resource2:\n    Type: \"AWS::DynamoDB::Table\"\n    Condition: !Not [IsProd]\n    ...\n\n  Resource3:\n    Type: \"AWS::Lambda::Function\"\n    Condition: IsProdOrDev \n    ...\n\n  Resource4:\n    Type: \"AWS::SNS::Topic\"\n    Condition: IsProdAndNotDev  \n    ...\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#6-intrinsic-function","title":"6. Intrinsic function","text":"<ul> <li><code>!Ref</code>  resource | parameter</li> <li>resource-1 : returns resource-1.id </li> <li>parameter-1 : returns value</li> <li><code>!GetAtt</code>  resource.attributename</li> <li>!GetAtt ec2-i1.id</li> <li>!GetAtt ec2-i1.AvialabilityZone</li> <li>...</li> <li><code>!FindInMap</code></li> <li><code>!ImportValue</code></li> <li><code>!Base64</code></li> <li>conditions :: <code>!Equals. !And !If !Not !Or</code></li> <li>...</li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#7-input-from-ssm-secretmanager","title":"7. input from SSM + secretManager","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#99-more","title":"99. more","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#stackupdate","title":"stackUpdate","text":"<ul> <li><code>success</code></li> <li><code>failed</code> (stack failure options)<ul> <li>option-1: preserve provisioned resource </li> <li>option-2 rollback to previous working stack (default)</li> <li><code>success</code></li> <li><code>fail</code>: (if some has manual interruption on resource)<ul> <li>manually fix resource</li> <li>call <code>ContinueUpdateRollback</code> from console/cli to get things in sync</li> </ul> </li> </ul> </li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#changeset","title":"changeset","text":"<ul> <li>change in template - add, modify (replacemnet=true/false), etc</li> <li></li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#stackset","title":"stackSet","text":"<ul> <li>AWS org<ul> <li>admin account</li> <li>child accounts/s</li> </ul> </li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#c-security","title":"C. Security","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#1-iam-role","title":"1. <code>IAM role</code>","text":"<ul> <li>being used for running stack</li> <li>Borad-access-role</li> <li><code>iam:PassRole</code> </li> <li><code>iam:getRole</code></li> <li><code>Cloudformation:*</code></li> <li>pipelineRole-1</li> <li> <p><code>s3:*</code></p> </li> <li> <p></p> </li> <li> <p>login in with Board-access-role</p> </li> <li>by default, it will be used for deploying stack.</li> <li>or can explicitly choose other role/s :<ul> <li>pipelineRole-1 : can create only s3, then.</li> </ul> </li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#2-stack-policy","title":"2. stack policy","text":"<ul> <li>resource policy like s3 policy,etc</li> <li>goal is to protect, resource from unintentional updates</li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#3-capability","title":"3. CAPABILITY","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#31-create-iam-role-from-stack","title":"3.1. Create iam role from stack","text":"<ul> <li>need to capability for that</li> <li>CAPABILITY_IAM</li> <li>CAPABILITY_NAMED_IAM</li> <li>else <code>InsufficientCapabilitiesException</code></li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#32-include-nested-stack","title":"3.2 Include nested-stack","text":"<ul> <li>need to capability<ul> <li>CAPABILITY_AUTO_EXPAND</li> </ul> </li> <li>else <code>InsufficientCapabilitiesException</code></li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#4-termination-protection","title":"4. termination protection","text":"<ul> <li>disable (default)</li> <li>allows to delete stack</li> <li>if enabled, then won't allow anyone to delete stack.</li> </ul>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#d-example","title":"D. Example","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#1-ec2-example-with-short-desc","title":"1. EC2 example with short desc.","text":"<pre><code>AWSTemplateFormatVersion: \"2010-09-09\"  # Identifies the capabilities of the template.\n\nDescription: \"Sample CloudFormation template for deploying a web server.\" # Comments about the template.\n\nParameters:  # Dynamic inputs for your template.\n  InstanceType:  # Logical name for the parameter.\n    Description: \"EC2 instance type\"  # Description of the parameter.\n    Type: \"String\"  # Type of the parameter (e.g., String, Number).\n    Default: \"t2.micro\"  # Default value for the parameter.\n    AllowedValues:  # Allowed values for the parameter.\n      - \"t2.micro\"\n      - \"t2.small\"\n    ConstraintDescription: \"Must be a valid EC2 instance type.\"\n\nMappings:  # Static variables for your template.\n  RegionMap:\n    us-east-1:\n      AMI: \"ami-0abcdef1234567890\"  # AMI for US East (N. Virginia).\n    us-west-1:\n      AMI: \"ami-0fedcba9876543210\"  # AMI for US West (N. California).\n\nResources:  # Contains definitions of AWS resources to be created (MANDATORY).\n  MyEC2Instance:  # Logical name for the EC2 instance.\n    Type: \"AWS::EC2::Instance\"  # Specifies the resource type (an EC2 instance in this case). # service-provider::service-name::data-type-name\n    Properties:  # Contains properties to configure the resource.\n      InstanceType: !Ref InstanceType  # Uses the parameter for instance type.\n      KeyName: \"MyKeyPair\"  # Name of the key pair for SSH access.\n      ImageId: !FindInMap [RegionMap, !Ref \"AWS::Region\", AMI]  # Uses mappings to select the AMI.\n      SecurityGroupIds:  # Specifies security groups for the instance.\n        - !Ref MySecurityGroup  # References the security group defined below.\n      Tags:  # Adds metadata to the instance.\n        - Key: \"Name\"\n          Value: \"WebServer\"\n\n  MySecurityGroup:  # Logical name for the security group.\n    Type: \"AWS::EC2::SecurityGroup\"  # Specifies the resource type (a security group in this case).\n    Properties:  # Contains properties to configure the security group.\n      GroupDescription: \"Allow HTTP and SSH access\"  # Description of the security group.\n      SecurityGroupIngress:  # Rules for inbound traffic.\n        - IpProtocol: \"tcp\"  # Protocol type (TCP).\n          FromPort: 22  # Allows SSH traffic.\n          ToPort: 22\n          CidrIp: \"0.0.0.0/0\"  # Allows traffic from all IP addresses.\n        - IpProtocol: \"tcp\"\n          FromPort: 80  # Allows HTTP traffic.\n          ToPort: 80\n          CidrIp: \"0.0.0.0/0\"\n\nConditions:  # List of conditions to perform resource creation.\n  CreateProdResources: !Equals [!Ref \"AWS::Region\", \"us-east-1\"]  # Example condition based on region.\n\nOutputs:  # References to what has been created.\n  InstanceId:  # Logical name for the output.\n    Description: \"ID of the EC2 instance\"  # Description of the output.\n    Value: !Ref MyEC2Instance  # References the EC2 instance to get its ID.\n\n  PublicIP:  # Logical name for the output.\n    Description: \"Public IP address of the EC2 instance\"  # Description of the output.\n    Value: !GetAtt MyEC2Instance.PublicIp  # Retrieves the public IP address of the EC2 instance.\n</code></pre>"},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#cli","title":"Cli","text":""},{"location":"01_aws/00_DVA-C02/18_CLOUD_FORMATION/#cfn-init","title":"cfn-init","text":"<ul> <li>helper script to initialize and configure EC2 instances. </li> <li>It reads the AWS::CloudFormation::Init metadata from a CloudFormation template </li> <li>and executes the specified configuration tasks, such as: <pre><code>Installing packages  &lt;&lt;&lt;\nConfiguring files\nRunning shell commands\nManaging services \n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/","title":"CI/CD","text":"<ul> <li>05_harness</li> <li>04_terraform</li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#a-concept","title":"A. Concept","text":"<ul> <li>CI</li> <li>CD</li> <li>pipeline</li> <li>IAC</li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#b-codepipeline","title":"B. CodePipeline","text":"<ul> <li>attach iam role with correct permission.</li> <li>stage/s</li> <li>stage:success</li> <li>stage:<code>failed</code> --&gt; eb:event --&gt; notify</li> <li>step/s<ul> <li>step:success</li> <li>step:<code>failed</code> --&gt; eb:event --&gt; notify</li> </ul> </li> <li>pipeline creates artifact in <code>s3</code>, then passed to next stage.</li> <li></li> <li></li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#0-codecommit","title":"0. codeCommit","text":"<ul> <li>VCS</li> <li>use external git: github</li> <li>service terminate in july 2024 for new customer.</li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#1-codebuild","title":"1. CodeBuild","text":"<ul> <li>can launch inside VPC-1</li> <li>set env var</li> <li>reference from SSM + secret manager</li> <li></li> <li>fully managed continuous integration (CI) service</li> <li>build project:</li> <li>add <code>buildspec.yaml</code> (root dir)<ul> <li>env</li> <li>phases</li> <li>artifact for s3</li> <li>cache </li> </ul> </li> <li>Compile source code, run tests, produce software packages</li> <li>Leverages Docker under the hood for reproducible builds <ul> <li>build container</li> <li>Use prepackaged Docker images</li> </ul> </li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#2-codedeploy","title":"2. CodeDeploy","text":"<ul> <li>deploy to ec2, lambda, ECS</li> <li>add <code>appsec.yaml</code> (root)</li> <li>CodeDeploy Agent on the target instances</li> <li>on ecs already present</li> <li>ec2/on-prem, install it.</li> <li>deployment speed:</li> <li> <pre><code>\u2022 AllAtOnce: most downtime\n\u2022 HalfAtATime: reduced capacity by 50%\n\u2022 OneAtATime: slowest, lowest availability impact\n\u2022 Custom: define your %\n</code></pre></li> <li>Deploy on ASG </li> <li>in-place deployment<ul> <li>replace old instance with new version</li> <li>downtime</li> </ul> </li> <li> <p>blue-green deployment (no downtime)</p> <ul> <li>old ASG(blue)</li> <li>create new ASG (green) : and deploy new version.</li> <li></li> <li>then use below traffic routing  strategies to shift traffic to green ASG </li> <li>Linear: grow traffic every N minutes until 100%</li> <li>Canary: try X percent then 100%</li> <li>AllAtOnce: immediate</li> <li>once all shift turn off blue ASG</li> <li></li> </ul> </li> <li> <p>Rollback</p> </li> <li>enable automatic rollback option.</li> <li>if deployment fails</li> <li>then make new deployment with last know good revision.</li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#hands-on-ecs","title":"hands on (ECS)","text":"<ul> <li>application-1</li> <li>deployment-group-1<ul> <li>role-1 (permission to access targets)</li> <li>choose cluster</li> <li>choose ALB and tg</li> <li>choose deployment type : inplace + blue/green</li> <li>traffic routing strategy (allAtOnce, linear, canary)</li> </ul> </li> <li>appsec.yaml ?</li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#hands-on-ec2","title":"hands on (EC2)","text":"<ul> <li>udemy reference video</li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#hands-on-lambda","title":"hands on (lambda)","text":""},{"location":"01_aws/00_DVA-C02/24_CI_CD/#-25_sam00_startc-hands-on","title":"- 25_SAM/00_start#c-hands-on","text":""},{"location":"01_aws/00_DVA-C02/24_CI_CD/#3-aws-codestar","title":"3. AWS CodeStar","text":"<p>\u2013 manage software development activities in one place</p>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#4-aws-codeartifact","title":"4. AWS CodeArtifact","text":"<ul> <li>repository-1</li> <li>package-1</li> <li>package-2</li> <li>...</li> <li>store, publish, and share software packages</li> <li>using nexus repo </li> <li> <p>proxy to maven, pip, Nuget, npm, yarm, Gradle</p> </li> <li> <p>security: create repo policy</p> </li> </ul> <p></p> <p></p> <p></p> <ul> <li>handon</li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#5-aws-codeguru-just-intro","title":"5. AWS CodeGuru : just intro","text":"<ul> <li>reviewer : looks for every commit and gives recommendation</li> <li>profiler : looks for dynamic metric and gives recommendation</li> <li>using synk scan </li> </ul>"},{"location":"01_aws/00_DVA-C02/24_CI_CD/#extra","title":"extra:","text":"<ul> <li>CodeGuruAgent config <pre><code>\u2022 MaxStackDepth \n\u2022 MemoryUsageLimitPercent \n\u2022 MinimumTimeForReportingInMilliseconds \n\u2022 SamplingIntervalInMilliseconds \n\u2022 MinimumTimeForReportingInMilliseconds\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/25_SAM/","title":"SAM","text":"<ul> <li>https://chatgpt.com/c/6763704a-0a24-800d-b9a2-1866b9931f4d</li> <li>https://github.com/aws/aws-sam-cli-app-templates</li> </ul>"},{"location":"01_aws/00_DVA-C02/25_SAM/#sam-serverless-application-model","title":"SAM (Serverless Application Model)","text":"<ul> <li>serverless : Lambda, API Gateway, DynamoDB, step function, eventbridge,CW, etc</li> </ul>"},{"location":"01_aws/00_DVA-C02/25_SAM/#a-intro","title":"A. Intro","text":"<p> - Framework for simplifying serverless application deployment - AWS SAM templates (YAML/JSON).   - defines resources     - <code>AWS::Serverless::Function</code>     - <code>AWS::Serverless::Api</code>     - <code>AWS::Serverless::SimpleTable</code></p>"},{"location":"01_aws/00_DVA-C02/25_SAM/#b-sam-cli","title":"B. sam cli","text":"<ul> <li>sam init</li> <li>same build</li> <li>sam package : creates cloudformation stack</li> <li><code>--template-file</code> </li> <li><code>--output-template-file</code> </li> <li> <p><code>--s3-bucket</code></p> <ul> <li>zip and upload (template and code) to s3</li> </ul> </li> <li> <p>sam deploy  : deploy cf stack</p> </li> <li> <p>use CodeDeploy to deploy Lambda functions</p> </li> <li> <p>sam sync --watch</p> </li> <li></li> </ul>"},{"location":"01_aws/00_DVA-C02/25_SAM/#c-hands-on","title":"C. Hands ON","text":""},{"location":"01_aws/00_DVA-C02/25_SAM/#1-deploy-lambda-function-v1-with-api-gateway","title":"1. Deploy lambda function-v1 with API-gateway","text":"<ul> <li>added env var from template</li> <li>added polices from template  <pre><code>AWSTemplateFormatVersion: '2010-09-09'\nTransform: AWS::Serverless-2016-10-31\nDescription: A simple AWS SAM example\n\nResources:\n  HelloWorldFunction:\n    Type: AWS::Serverless::Function\n    Properties:\n      Handler: app.lambda_handler\n      Runtime: python3.11\n      CodeUri: lambda/\n\n      # Environmnet var\n      Environment:\n        Variables:\n          # TABLE_NAME: HelloWorldTable\n          TABLE_NAME: !Ref HelloWorldTable\n          REGION_NAME: !Ref AWS::Region\n\n      # polices to perform CRUD on table    \n      Policies:\n        - DynamoDBCrudPolicy:\n            TableName: !Ref HelloWorldTable\n\n      # expose as API gateway      \n      Events:\n        HelloWorldApi:\n          Type: AWS::Serverless::Api\n          Properties:\n            Path: /hello\n            Method: get\n            StageName: prod\n            Cors:\n              AllowMethods: \"'GET,POST'\"\n              AllowHeaders: \"'Content-Type'\"\n              AllowOrigin: \"'*'\"\n</code></pre></li> </ul>"},{"location":"01_aws/00_DVA-C02/25_SAM/#2-add-dynamodb-table","title":"2. add DynamoDB table","text":"<p><pre><code>Resources:  \n  HelloWorldTable:\n    Type: AWS::DynamoDB::Table\n    Properties:\n      TableName: HelloWorldTable\n      PrimaryKey:\n        Name: id\n        Type: String\n      ProvisionedThroughput:\n        ReadCapacityUnits: 5\n        WriteCapacityUnits: 5\n</code></pre> </p>"},{"location":"01_aws/00_DVA-C02/25_SAM/#3-deploy-lambda-function-v2-using-codedeploybluegreen","title":"3. Deploy lambda function-v2 using <code>codeDeploy</code>(blue/green)","text":"<ul> <li>update lambda code</li> <li>update template   <pre><code>AutoPublishAlias: live  \nDeploymentPreference:\n    Type: Canary10Percent10Minutes # sam will use codeDeploy\n    Alarms:\n      - !Ref DeploymentFailureAlarm # configure **cloudwatch alarm**\n</code></pre></li> <li>sam build</li> <li> <p>sam deploy -guided</p> </li> <li> <p>sam will automatically update CF template with codeDeploy + CW:alarm</p> </li> <li>deployment type (quick revision again) 00_start.md<ul> <li>in-place</li> <li>blue/green </li> <li>traffic routing:<ul> <li><code>canary</code></li> <li><code>linear</code></li> <li><code>allAtOnce</code></li> </ul> </li> <li>traffic hook (optional)<ul> <li>pre-traffic hook - lambda-hook-fn-1 </li> <li>post-traffic hook - lambda-hook-fn-2</li> </ul> </li> </ul> </li> </ul> <p></p> <pre><code>  # update lamda\n  AutoPublishAlias: live  \n  DeploymentPreference:\n      Type: Canary10Percent10Minutes\n      Alarms:\n        - !Ref DeploymentFailureAlarm\n\n  # Another resource\n  DeploymentFailureAlarm:\n    Type: AWS::CloudWatch::Alarm\n    Properties:\n      AlarmName: DeploymentFailureAlarm\n      MetricName: Errors\n      Namespace: AWS/Lambda\n      Statistic: Sum\n      Period: 60\n      EvaluationPeriods: 1\n      Threshold: 1\n      ComparisonOperator: GreaterThanOrEqualToThreshold\n      Dimensions:\n        - Name: FunctionName\n          Value: !Ref HelloWorldFunction\n        - Name: Resource\n          Value: !Join [\"\", [!Ref HelloWorldFunction, \":\", \"live\"]] \n</code></pre> <p></p> <p></p>"},{"location":"01_aws/00_DVA-C02/25_SAM/#d-sam-local","title":"D. sam <code>local</code>","text":"<ul> <li>install AWSToolkit as well</li> <li>Provides a lambda-like execution environment locally</li> <li> <p>Locally build, test, and debug your serverless applications that are defined using AWS SAM templates</p> </li> <li> <p>sam local start-lambda + sam local invoke</p> </li> <li><code>sam local invoke    \u2013t MyCDKStack.template.json         myFunction-1</code></li> <li>sam local start-api</li> <li>sam local generate-event</li> </ul>"},{"location":"01_aws/00_DVA-C02/25_SAM/#d-sam-environment","title":"D. sam <code>environment</code>","text":""},{"location":"01_aws/00_DVA-C02/26_CDK/","title":"CDK","text":"<ul> <li>Cloud developmnet kit</li> </ul>"},{"location":"01_aws/00_DVA-C02/26_CDK/#a-intro","title":"A. intro","text":"<ul> <li>IaC with program language - py,java, nodejs</li> <li>compile and then generate cloudFormation template yaml.</li> <li>SAM focus on serverless. CDK is superset of SAM</li> <li>CDK construct</li> <li>level of abstraction:<ul> <li>level-1</li> <li>import { <code>CfnBucket</code> } from 'aws-cdk-lib/aws-s3';</li> <li>level-2 (simplified API)</li> <li>import { <code>Bucket</code>, BucketEncryption } from 'aws-cdk-lib/aws-s3';</li> <li>level-3 (pattern) </li> <li>import { <code>LambdaRestApi</code> } from 'aws-cdk-lib/aws-apigateway';</li> </ul> </li> </ul>"},{"location":"01_aws/00_DVA-C02/26_CDK/#b-cdk-cli","title":"B. CDK cli","text":"<ul> <li> <p>cdk bootstrap aws:/// <ul> <li>creates a stack, name :CDKtoolkit, contains<ul> <li><code>S3 Bucket</code> \u2013 to store files</li> <li><code>IAM Roles</code> \u2013 to grant permissions to perform deployments</li> </ul> </li> </ul> <li> <p>cdk init</p> </li> <li>create cdk project</li> <li>lib folder has stack</li> <li>cdk synth</li> <li>cdk deploy stack-1</li> <li>cdk diff</li> <li>cdk destroy</li>"},{"location":"01_aws/00_DVA-C02/26_CDK/#c-cdk-hands-on","title":"C. CDK hands on","text":"<ul> <li>nodejs : done</li> </ul>"},{"location":"01_aws/00_DVA-C02/26_CDK/#d-cdk-test","title":"D. CDK test","text":"<ul> <li>test frameworks</li> <li>Jest (JavaScript) </li> <li>Pytest (Python)</li> <li>import a template </li> <li>Template.fromStack(MyStack) : stack built in CDK</li> <li>Template.fromString(mystring) : stack build outside CDK</li> <li>Type of test:</li> <li>Fine-grained Assertions</li> <li>Snapshot Test</li> <li></li> </ul>"},{"location":"01_aws/00_DVA-C02/99_handson/","title":"challenges","text":""},{"location":"01_aws/00_DVA-C02/99_handson/#1-sqs-extended-library","title":"1. SQS extended library","text":"<ul> <li>https://chatgpt.com/c/8136549a-aed0-442e-93aa-e7dfe9fb2b46</li> </ul>"},{"location":"01_aws/00_DVA-C02/99_handson/#2-vpc-endpoint","title":"2. VPC endpoint","text":""},{"location":"01_aws/00_kick_off/00_global_infra/","title":"Global infra","text":""},{"location":"01_aws/00_kick_off/00_global_infra/#aws","title":"AWS","text":"<ul> <li>virtual infra, online delivery on IT, pay by use, go-global in few minutes.</li> <li>stop guessing capcity, elastic.</li> <li>manage remotely.</li> <li>AWS Quick History<ul> <li>since 2002, SQS S3 Ec2 first 3, etc.</li> </ul> </li> </ul>"},{"location":"01_aws/00_kick_off/00_global_infra/#global-infra_1","title":"Global infra :","text":""},{"location":"01_aws/00_kick_off/00_global_infra/#regions","title":"regions","text":"<ul> <li>choose region by avialiability, pricing, close to client, data governence.</li> <li>region-specific vs global-sevice(iam, r53, cloudFront/CDN)</li> </ul>"},{"location":"01_aws/00_kick_off/00_global_infra/#az","title":"az","text":"<ul> <li>isolated for DR </li> <li>datacenters connected with low letencuy n/w.</li> <li>us-west-2a / AWS-1  might not us-west-2a / AWS-2 </li> <li>To coordinate Availability Zones across accounts, you must use the AZ ID<ul> <li>usw2-az1</li> <li>usw2-az2</li> <li>...</li> </ul> </li> </ul>"},{"location":"01_aws/00_kick_off/00_global_infra/#edge-loc","title":"edge loc","text":"<ul> <li>400+</li> <li>content caching for faster delivery.</li> <li>CDN</li> <li>service : CF:distribution, Lambda@edge, DX</li> </ul>"},{"location":"01_aws/00_kick_off/00_global_infra/#aws-outpost","title":"AWS outpost","text":"<ul> <li>fully managed service that extends AWS infrastructure, services, and tools to on-premises locations</li> <li>It allows you to run AWS services locally in your data center or on-premises, </li> <li>providing a hybrid cloud solution for workloads that need to remain on-premises due to latency, data residency, or other regulatory requirements.</li> <li>fargate is not supported at OUTPOST :point-left:</li> <li>eg: ECS with ec2 launch type can run outpost, not fargate.</li> </ul>"},{"location":"01_aws/00_kick_off/00_global_infra/#side-notes","title":"Side Notes","text":"<ol> <li>All services are <code>publicly</code> accessible</li> <li>All service has <code>policy</code>. </li> <li>eg: bucket-policy, sns-policy, lambda-policy, VPC-endpoint policy, etc.</li> </ol>"},{"location":"01_aws/00_kick_off/00_serverless_pardigm/","title":"Serverless services in AWS","text":"<ul> <li>there is underlying server/ec2-i,</li> <li>but don't need to provision/manage it</li> <li>modern paradigm</li> </ul>"},{"location":"01_aws/00_kick_off/00_serverless_pardigm/#a-services","title":"A. services","text":""},{"location":"01_aws/00_kick_off/00_serverless_pardigm/#compute","title":"compute","text":"<ul> <li>AWS Lambda : 03_serverless_lambda.md</li> <li> <p>Fargate(ECS/EKS) </p> <ul> <li>02_Containers_ECS.md</li> <li>02_Kubernetes_EKS.md</li> </ul> </li> <li> <p>Step Functions 28_STEP_FUNCTION.md</p> </li> <li>App Sync 28_AppSync.md</li> </ul>"},{"location":"01_aws/00_kick_off/00_serverless_pardigm/#security","title":"security","text":"<ul> <li>AWS Cognito 02_cognito.md</li> </ul>"},{"location":"01_aws/00_kick_off/00_serverless_pardigm/#database","title":"Database","text":"<ul> <li>Aurora Serverless : 02_Aurora.md</li> <li>DynamoDB : 04_DynamoDB.md</li> </ul>"},{"location":"01_aws/00_kick_off/00_serverless_pardigm/#integrationcore","title":"integration/core","text":"<ul> <li>AWS API Gateway 05_API_gateway.md</li> <li>Amazon S3</li> <li>03_S3-1.md</li> <li>03_S3-2.md</li> <li>03_S3-3.md</li> <li>AWS SNS  02_SNS.md</li> <li>SQS 01_SQS.md</li> <li>AWS KDF 03_02_KDF_KinesisDataFirehose.md</li> </ul>"},{"location":"01_aws/00_kick_off/00_serverless_pardigm/#b-architecture-example","title":"B. Architecture example","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#revision-1","title":"revision-1","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_1","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_2","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_3","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_4","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_5","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_6","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_7","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_8","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_9","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#_10","title":"00 whiteboard","text":""},{"location":"01_aws/00_kick_off/00_whiteboard/#revision-2","title":"revision-2","text":"<ul> <li>soon</li> </ul>"},{"location":"01_aws/00_kick_off/readme/","title":"Readme","text":""},{"location":"01_aws/00_kick_off/readme/#udemy","title":"udemy","text":"<ul> <li>https://courses.datacumulus.com/downloads/certified-solutions-architect-pn9/</li> <li>https://courses.datacumulus.com/downloads/certified-solutions-architect-professional-m0v/</li> </ul>"},{"location":"01_aws/00_kick_off/readme/#certification","title":"Certification :","text":"<ul> <li>https://aws.amazon.com/certification/certified-solutions-architect-associate/</li> <li>https://d1.awsstatic.com/training-and-certification/docs-sa-assoc/AWS-Certified-Solutions-Architect-Associate_Exam-Guide.pdf</li> <li>https://cp.certmetrics.com/amazon/en/home/dashboard</li> <li><code>ldus@g | J12a</code></li> </ul>"},{"location":"01_aws/00_kick_off/readme/#training","title":"training","text":"<ul> <li>https://skillbuilder.aws/</li> <li>https://www.aws.training/Certification</li> </ul>"},{"location":"01_aws/00_kick_off/readme/#practice-paper","title":"Practice paper :","text":"<ul> <li>https://www.udemy.com/course/aws-certified-solutions-architect-associate-practice-tests-k/?couponCode=KEEPLEARNING</li> <li>https://www.udemy.com/course/aws-certified-solutions-architect-associate-amazon-practice-exams-saa-c03/?couponCode=KEEPLEARNING</li> <li>https://www.examtopics.com/exams/amazon/aws-certified-solutions-architect-associate-saa-c03/view/</li> <li>https://medium.com/swlh/how-i-passed-aws-solutions-architect-associate-saa-c02-in-2021-70ec503fa963</li> <li>https://tutorialsdojo.com/aws-certified-solutions-architect-associate-saa-c03/</li> <li>https://awscertificationpractice.benchprep.com/app/exam-prep-official-question-set-aws-certified-solutions-architect-associate-saa-c03-v2#exams</li> </ul>"},{"location":"01_aws/00_kick_off/readme/#future-explore","title":"Future explore:","text":"<ul> <li>https://aws.amazon.com/architecture/</li> <li>https://aws.amazon.com/solutions/</li> </ul>"},{"location":"01_aws/00_kick_off/readme/#white-paper","title":"white paper","text":"<ul> <li>Architecting for the cloud</li> <li>https://d1.awsstatic.com/whitepapers/AWS_Cloud_Best_Practices.pdf (Archived)</li> <li>Whitepapers related to well-architected framework are mentioned here </li> <li>https://aws.amazon.com/blogs/aws/aws-well-architected-framework-updated-white-papers-tools-and-best-practices/</li> <li>Disaster recovery whitepaper</li> <li>https://d1.awsstatic.com/whitepapers/aws-disaster-recovery.pdf (Archived)</li> <li>AWS now recommends a well-architected framework whitepaper</li> <li>https://d1.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf</li> </ul>"},{"location":"01_aws/00_kick_off/readme/#others","title":"others","text":"<ul> <li>accessCode=579-488-719</li> <li> <p>locale=en-US clickNum=637510163802698</p> </li> <li> <p>https://533267082359.signin.aws.amazon.com/console  </p> </li> <li><code>acct-ld@oJ83as + iamU-ld</code></li> <li><code>skillb+cert : ldus@gJ83a</code></li> </ul>"},{"location":"01_aws/01_compute/01_ASG/","title":"01 ASG","text":"<ul> <li>https://chatgpt.com/c/b1fe7e08-270f-4a92-a4db-b95e6beab7c7</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#asg","title":"ASG","text":"<ul> <li>performs 2 things</li> <li>scaling in/out</li> <li> <p>replacements / mask any instance failures. (after grace period, default = <code>300 s</code>): </p> <ul> <li>ec2 health check / impaired status</li> <li>Network connectivity issues.</li> <li>Exhausted instance resources (CPU, memory, or disk).</li> <li>Corrupted or inaccessible boot volume.</li> <li> <p>if instance is automatically recovered,then   </p> <ul> <li>identical to the original instance, including the instance ID, private IP addresses, Elastic IP addresses, and all instance metadata</li> <li>If instance has a public IPv4 address, it retains.</li> </ul> </li> <li> <p>alb target - health check api</p> </li> <li>by-default not configured  </li> <li>cannot define any other custom health check </li> <li>regional ( asg span over AZs)</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#-1-heath-checks","title":"-1. heath check/s","text":"<ul> <li>choose grace period</li> <li>can configure ASG health check with:</li> <li>ELB check</li> <li>ASG's EC2 check</li> <li>both<ul> <li>ELB health checks take precedence</li> <li>also, if ELB health check is not available or ASG can't reach ELB,  </li> <li>then ASG health will considered.</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#0-rebalancing-activity","title":"0. Rebalancing  Activity","text":"<ul> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/what-is-amazon-ec2-auto-scaling.html</li> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/auto-scaling-benefits.html</li> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-instance-termination.html</li> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/healthcheck.html</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#az-rebalancing","title":"AZ Rebalancing","text":"<ul> <li>Actions can lead un-balance: <pre><code>  - changing the Availability Zones (AZ) for your group \n  - or explicitly terminating/detaching instances\n  - AZ with insufficient capacity, recovered\n  - AZ with spot instance ( pricing matched :) \n</code></pre></li> <li>launches new instances, </li> <li>can go maz 10% beyond max capacity, temporly</li> <li>before terminating the old ones. () </li> <li>reverse order of regular scaling activity, which <ul> <li>first terminates unhealthy</li> <li>then launch new</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#capacity-rebalancing","title":"capacity Rebalancing","text":"<ul> <li>launch new spot instance</li> <li>terminate old spot instance which is at risk of interruption.</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#1-trigger","title":"1. Trigger","text":"<ul> <li>CloudWatch::metric --&gt; alarm --&gt; ASG :: scale in/out<ul> <li>CPU, memory, network, RequestCountPerTarget, custom-metric, etc</li> </ul> </li> <li>asg works in conjunction with <code>ELB</code><ul> <li>if ELB::health-check fails, ASG will terminate corresponding target instances.</li> <li>not scaling, but replacing unhealthy targets.</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#2-cooldown-period","title":"2. Cooldown Period","text":"<ul> <li>pausing further scaling actions for a specified amount of time, after a previous scaling activity completes.</li> <li>this allows the system to stabilize before initiating another scaling operation.</li> <li>so during this time, does not add/drop new instances.</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#3-scaling-types","title":"3. Scaling types","text":"<ul> <li>fact: Reduce scaling-out latency, use warm-pool </li> <li>pre-initialized instances</li> <li>ref:</li> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/scaling-overview.html</li> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/as-scale-based-on-demand.html</li> <li>a Dynamic: </li> <li> <p>a.1 <code>Simple scaling</code> :</p> <ul> <li>create trigger(CW:Alarm) + define :: ( single action + set cooldown-period )</li> <li>demo : created one and link with tg. count : <code>desired, min, max</code>.</li> <li>single step : cpu 70 : add 3 instance.</li> <li>before responding to additional alarms, waits for:</li> <li>the current scaling activity </li> <li>health check replacement to complete </li> <li>and the cooldown period to expire </li> </ul> </li> <li> <p>a.2 <code>Step scaling</code> </p> <ul> <li>create trigger(CW:Alarm) + define :: ( different/many fine-tuned action actions + set cooldown-period )</li> <li>if CPU utilization is slightly above the threshold, add 1 instance; </li> <li>if it is far above, add 3 more instances</li> <li>...</li> </ul> </li> <li> <p>a.3 <code>target tracking Scaling</code> recommended </p> <ul> <li>react fast </li> <li>define only target value. eg: 50% of aggregate (CPU,memory,network) utilization</li> <li>target : fleet of 10 ec2-i</li> <li>keep  aggregate cpu utilization 50%, else scale in/out </li> <li>Also remove the need to manually define </li> <li>CloudWatch alarms </li> <li>scaling adjustments</li> </ul> </li> <li> <p>b scheduled : </p> </li> <li>eg: scale up/down to max/min count on weekends.</li> <li> <p>scheduled action sets the minimum, maximum, and desired sizes </p> </li> <li> <p>c predictive : </p> </li> <li>continuously <code>forecast</code> load and schedule scaling ahead of time.</li> <li>Easy to create. once created ait for Week. </li> <li><code>ML</code> will be applied on historic data.</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#4-instance-launch-settings","title":"4. Instance launch settings","text":"<ul> <li>Launch template </li> <li>more modern and flexible way </li> <li>Editable/mutable: Launch Templates allow versioning</li> <li>EC2 details (AMI, OS, Role, tenancy, etc), </li> <li>more flexible - mix of purchasing options <ul> <li>eg: spot instance, on-demand,etc</li> </ul> </li> <li> <p>Configure <code>user data</code> for automation, during instance initialization.</p> </li> <li> <p>Launch Configurations</p> </li> <li>Immutable - replace entire template if changes needed <ul> <li>It is not possible to modify a launch configuration once it is created.</li> <li>Dont get confuse with LT</li> </ul> </li> <li>simpler but less flexible -  does not multiple instance types like od, spot, etc</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#scenario-1tenancy","title":"scenario-1(tenancy)","text":""},{"location":"01_aws/01_compute/01_ASG/#host-dedicated-default-launch-template-lt1-dedicated-tenancy-vpc-tenancy-default-launch-template-lt2-default-tenancy-vpc-tenancy-dedicated-if-either-launch-template-tenancy-or-vpc-tenancy-is-set-to-dedicated-then-the-instance-tenancy-is-also-dedicated-more-rules-vpc-tenancy-takes-precedence-cannot-downgrade-tenancy-instances-in-different-tenancy-types-shared-vs-dedicated-cannot-communicate-within-the-same-vpc-using-private-ips","title":"<pre><code> # host &gt;&gt; dedicated &gt;&gt; default\n- Launch Template LT1 (Dedicated Tenancy)\n  - VPC tenancy (default) \n- Launch Template LT2 (Default Tenancy)\n  - VPC tenancy (dedicated) \n\n&gt;&gt; If either \"Launch Template Tenancy\" or \"VPC Tenancy\" is set to dedicated, then the instance tenancy is also dedicated\n\n=== MORE RULES ===  \n\n- VPC Tenancy Takes Precedence\n- Cannot Downgrade Tenancy\n- Instances in different tenancy types (shared vs. dedicated) cannot communicate within the same VPC using private IPs\n</code></pre>","text":""},{"location":"01_aws/01_compute/01_ASG/#5-scale-down-default-termination-policy","title":"5. scale-down: <code>Default Termination Policy</code>","text":"<ul> <li>order:</li> <li>AZ with the most instances is selected for termination</li> <li>Instances in the <code>Standby</code> status</li> <li>instance launched with oldest version of launch-configuration/template.</li> <li>oldest age</li> <li>the instance(s) nearest the end of their billing hour. (like reserver period is close to end.)</li> <li>https://docs.aws.amazon.com/autoscaling/ec2/userguide/ec2-auto-scaling-termination-policies.html : check</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#6-instance-refresh-like-k8s-deploymnet","title":"6. Instance refresh (like k8s deploymnet )","text":"<ul> <li>update ec2-i with new launch template version.</li> <li>rolling Updates : Replaces instances incrementally to avoid downtime.</li> <li>desired capacity is maintained : specify minimum healthy %</li> <li>can pause, resume, or cancel an instance refresh if necessary.</li> <li>specify warm up time : wait times for instance stabilization <pre><code>aws autoscaling start-instance-refresh --auto-scaling-group-name &lt;ASG-name&gt; --preferences &lt;json&gt;\n\n{\n    \"MinHealthyPercentage\": 90,\n    \"InstanceWarmup\": 300\n}\n\n# monitor\naws autoscaling describe-instance-refreshes --auto-scaling-group-name &lt;ASG-name&gt;\n</code></pre></li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#7-maintenance","title":"7. Maintenance","text":"<ul> <li>scenario: </li> <li>some maintenance work on a specific Amazon EC2 instance that is part of an ASG</li> <li>every time the team deploys a maintenance patch<ul> <li>the instance health check status shows as out of service for a few minutes. </li> </ul> </li> <li>This causes ASG to provision another replacement instance immediately</li> <li>solution<ul> <li>Put the instance into the Standby state :point-left:</li> <li>once  patching done, put instance to in-service</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#8-asg-lifecycle-hook","title":"8. ASG  lifecycle hook","text":"<ul> <li>perform custom actions as the Auto Scaling group launches or terminates instances</li> <li>eg:</li> <li>install or configure software on newly launched instances</li> <li>download log files from an instance before it terminates</li> <li>thus, can save state of workload.</li> </ul>"},{"location":"01_aws/01_compute/01_ASG/#keys-terms","title":"keys Terms","text":""},{"location":"01_aws/01_compute/01_EC2/","title":"EC2","text":"<ul> <li>EC2_01: https://chatgpt.com/c/7ddee1bf-7240-4789-913a-72dae8438d00</li> <li>EC2_02 : https://chatgpt.com/c/636011e3-1ce6-4268-8089-47ca3b12c9b9</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#ec2-ecc-elastic-compute-cloud","title":"EC2 / ECC (elastic compute cloud)","text":""},{"location":"01_aws/01_compute/01_EC2/#1-intro","title":"1. Intro","text":"<ul> <li>IaaS</li> <li>connect from terminal (instance must have public IP)</li> <li>SSH (OS : linux,mac,W10+) <ul> <li>generate SSH key-Pair</li> </ul> </li> <li>Putty ( OS: W7,8,9) </li> <li>EC2 instance Connect (Amazon Linux 2) - browser session. <pre><code>- aws cli installed in ec2\n- run any commnd, provided IAM permission added on ec2-role\n- don't run \"aws configure\" \n</code></pre></li> <li>get Instance metadata</li> <li>http://169.254.169.254/latest/meta-data/  (169.254)</li> <li>instance ID,</li> <li>public IP, private IP, elastic IP, etc</li> <li>...</li> <li> <p>Retrieve runtime information dynamically</p> </li> <li> <p>AMI </p> </li> <li>ami accidental deledte --&gt; goes to recycle bin</li> <li>AMIs are bound to the Region they are created in. </li> <li>So, you need to copy the AMI across Regions for disaster recovery readiness.</li> <li>When the new EBS-backed AMI is copied from Region A into Region B,  <ul> <li>no charges for copying an AMI.However, standard storage and data transfer rates apply.</li> <li>it automatically creates a snapshot (root volumee) in Region B because AMIs are based on the underlying snapshots</li> <li>Region B will have :</li> <li>1 AMI </li> <li>1 snapshot (root + additional optional EBS vol)</li> <li>https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/CopyingAMIs.html</li> </ul> </li> </ul> <p><pre><code>t2.micro      1     1     EBS-Only          Low to Moderate\nt2.xlarge     4     16    EBS-Only          Moderate\nc5d.4xlarge   16    32    1 x 400 NVMe SSD  Up to 10 Gbps     \nr5.16xlarge   64    512   EBS Only          20 Gbps           \nm5.8xlarge    32    128   EBS Only          10 Gbps           \n</code></pre> - instance profile    - container for a role that can be attached to an Amazon EC2 instance when launched   - contain only one role, and that limit cannot be increased</p>"},{"location":"01_aws/01_compute/01_EC2/#2-ec2-instance-type-familygensize-yellow_circle","title":"2. ec2: Instance type (family,gen,size) :yellow_circle:","text":"<ul> <li>https://ec2instances.github.io/ </li> <li>https://instances.vantage.sh/</li> <li></li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#general-purpose","title":"general purpose :","text":"<ul> <li>balanced, </li> <li>eg: t2.micro</li> <li></li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#compute-optimized","title":"compute optimized,","text":"<ul> <li>gaming server, media, batch, ML, HPC</li> <li></li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#memory-optimized","title":"memory optimized","text":"<ul> <li>real-time system, large dataset processing, BI</li> <li></li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#storage-optimized","title":"storage optimized","text":"<ul> <li>File System, RDBMS, data-ware house, cache server, OLTP etc</li> <li></li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#3-purchase-options-yellow_circle","title":"3. Purchase options :yellow_circle:","text":""},{"location":"01_aws/01_compute/01_EC2/#31-on-demand","title":"3.1 On-Demand","text":"<ul> <li>No long-term commitment</li> <li>no upfront payment</li> <li>Flexible</li> <li>use case: short workload</li> <li>pay by </li> <li>second (after the first minute) (Window and Linux) </li> <li>hour (other OS)</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#capacity-reservations","title":"Capacity Reservations","text":"<ul> <li>Reserve On-Demand instances capacity in a specific AZ for any duration</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#32-reserved","title":"3.2 Reserved","text":"<ul> <li>1 &amp; 3 years</li> <li>fixed : InstanceType, scope:Region/AZ, Tenancy, OS </li> <li>up to 72% discount</li> <li>Payment Options \u2013 No Upfront (+), Partial Upfront (++), All Upfront (+++)</li> <li>use case: </li> <li>long workloads</li> <li>steady-state usage applications</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#convertible-reserved","title":"Convertible Reserved","text":"<ul> <li>upto 66%  discount</li> <li>flexible : Instance Type, scope:Region/AZ, Tenancy, OS</li> <li>use case: long workloads with flexible instances types</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#33-savings-plans","title":"3.3 Savings Plans","text":"<ul> <li>(1 &amp; 3 years) </li> <li>commitment to an amount of usage.</li> <li>Usage beyond EC2 Savings Plans is billed at the On-Demand price </li> <li>fixed : instance family &amp; AWS region</li> <li>Flexible : Instance Size, OS, Tenancy</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#34-spot-instances","title":"3.4 Spot Instances","text":"<ul> <li>upto 90% discount +  MOST cost-efficient</li> <li>can lose instances (less reliable), </li> <li>When we cancel an active spot request, it does not terminate the associated instance </li> <li><code>2 min</code> grace period.</li> <li>use case:</li> <li>Not suitable for critical jobs or databases</li> <li>workloads that are resilient to failure : Batch jobs, Data Analysis, Image processing, etc</li> <li>type: </li> <li>one time <ul> <li>if interrupted then terminated.</li> </ul> </li> <li>persistent<ul> <li>has to terminate instance manually </li> </ul> </li> <li> <p>provision : define launch pool     <pre><code>launch pool :\n    duration/expiry            &lt;&lt;&lt;\n    type: one-time/persistent \n    count\n    instance Types \n    cpu (min.max)    \n\n-   define **our max spot price** , else od-price\n\n        if max spot price  &lt; current Spot price \n           then use it\n        if max spot price  &gt; current Spot price\n            then stop/terminate instance\n            with 2 min grace\n</code></pre></p> </li> <li> <p>terminate:</p> </li> <li></li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#341-spot-fleet","title":"3.4.1 Spot fleet","text":"<ul> <li>collection of Spot Instances (and optionally On-Demand Instances)</li> <li>on-time Instances only</li> <li>define multiple launch pool</li> <li>thus request various instance types</li> <li>provides higher availability and fault tolerance</li> <li>if spot instance is termninated, it will match with another spot instance</li> <li>if none found then OD</li> <li> <p>thus maintain target capacity </p> </li> <li> <p>strategies: </p> </li> <li><code>lowestPrice</code>: <ul> <li>from the pool with the lowest price </li> <li>(cost optimization, short workload)</li> </ul> </li> <li><code>diversified</code>: <ul> <li>distributed across all pools </li> <li>(great for availability, long workloads)</li> </ul> </li> <li><code>capacityOptimized</code>: <ul> <li>pool with the optimal capacity for the number of instances</li> </ul> </li> <li><code>priceCapacityOptimized</code> (recommended): <ul> <li>pools with highest capacity available, </li> <li>then selectthe pool with the lowest price (best choice for most workloads)</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#341-spot-block-deprecated","title":"3.4.1 Spot block (deprecated)","text":"<ul> <li>Spot Blocks are priced at the same rate as Spot Instances</li> <li>but with the added benefit of no interruptions for the block duration (<code>1-6 hr</code>)</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#36-dedicated-instances","title":"3.6. Dedicated Instances","text":"<ul> <li>underlying h/w not shared with other account.</li> <li>May share hardware with other instances in same account</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#37-dedicated-hosts","title":"3.7 Dedicated Hosts","text":"<ul> <li>most expensive $$</li> <li>book an entire physical server/racks/building. </li> <li>for companies that have strong regulatory or compliance needs</li> <li>control over instance placement</li> <li>pay by : </li> <li>physical cores</li> <li>underlying network socket visibility.</li> <li>Purchasing Options</li> <li>On-demand \u2013 pay per second for active Dedicated Host</li> <li>Reserved - 1 or 3 years (No Upfront, Partial Upfront, All Upfront)</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#summary","title":"summary","text":""},{"location":"01_aws/01_compute/01_EC2/#_1","title":"EC2","text":""},{"location":"01_aws/01_compute/01_EC2/#4-hibernate","title":"4. hibernate","text":"<ul> <li>RAM state ( &lt; <code>150 GB</code>), gets preserved in </li> <li>EBS root volume </li> <li>with/without Encryption</li> <li>hence boot up fast. </li> <li>supported family instances : C3, C4, C5, I3, M3, M4, R3, R4, T2, T3, \u2026</li> <li><code>C**</code> </li> <li><code>M**</code> </li> <li><code>T**</code></li> <li>max for <code>60 days</code></li> <li>Also, Root Volume \u2013 must be EBS, encrypted. </li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#1-a-machine-learning-research-group-uses-a-proprietary-computer-vision-application-hosted-on-an-amazon-ec2-instance-every-time-the-instance-needs-to-be-stopped-and-started-again-the-application-takes-about-3-minutes-to-start-as-some-auxiliary-software-programs-need-to-be-executed-so-that-the-application-can-function-the-research-group-would-like-to-minimize-the-application-boostrap-time-whenever-the-system-needs-to-be-stopped-and-then-started-at-a-later-point-in-time-as-a-solutions-architect-which-of-the-following-solutions-would-you-recommend-for-this-use-case-create-an-amazon-machine-image-ami-and-launch-your-amazon-ec2-instances-from-that-use-amazon-ec2-instance-hibernate","title":"<pre><code>#1\nA Machine Learning research group uses a proprietary computer vision application hosted on an Amazon EC2 instance. \nEvery time the instance needs to be stopped and started again, the application takes about 3 minutes to start \nas some auxiliary software programs need to be executed so that the application can function. \nThe research group would like to minimize the application boostrap time whenever \nthe system needs to be stopped and then started at a later point in time.\n\nAs a solutions architect, which of the following solutions would you recommend for this use-case?\n- Create an Amazon Machine Image (AMI) and launch your Amazon EC2 instances from that\n- Use Amazon EC2 Instance Hibernate **\n</code></pre>","text":""},{"location":"01_aws/01_compute/01_EC2/#5-placement-group-yellow_circle","title":"5. Placement group :yellow_circle:","text":"<ul> <li>cluster </li> <li>low-latency group in a single AZ</li> <li>close-proximity. </li> <li>hence high n/w throughput</li> <li>usecase : HCP</li> <li> </li> <li> <p>spread</p> </li> <li>spreads instances across underlying hardware in mutli-AZ</li> <li>max : <code>7 instance/group/AZ</code></li> <li> <p></p> </li> <li> <p>partition</p> </li> <li>partition-1 in AZ-1 </li> <li>partition-2 in AZ-1</li> <li>...</li> <li>partition-3 in AZ-2</li> <li>...</li> <li>max /restriction<ul> <li><code>100 instances/group</code></li> <li><code>7 partitions/AZ</code></li> </ul> </li> <li>use case: hadoop, kafka, casandra</li> <li></li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#6-provision-instance-yellow_circle","title":"6. provision instance :yellow_circle:","text":"<ul> <li>Tenancy</li> <li>host / physical building and racks</li> <li>Dedicated / single-tenant (single aws account)</li> <li>default/shared/multi-tenant (multiple aws account, shares same hardware)</li> <li>change tenancy: </li> <li>```     dedicated &lt;==&gt; host : can change     cannot change any other, fixed once     ---     some rules to remember:<ol> <li>VPC tenancy take precidence over ASG's LT's tenancy</li> <li>host &gt; dedicated &gt; default : cannot downgrade. ```</li> </ol> </li> <li>OS / AMI </li> <li>can create AMI on ec2-i. </li> <li>OS boot volume : <code>gp* / io*</code> </li> <li>memory/RAM </li> <li>cpu architecture</li> <li><code>ARM</code> </li> <li><code>AMD</code></li> <li>user-data script </li> <li>bootstrap script  - automate boot tasks<ul> <li>install update</li> <li>install software</li> <li>...</li> </ul> </li> <li>run only once (first launch by-default)<ul> <li>can change to run everytime instance restarted </li> </ul> </li> <li> <p>run with root user permission.</p> </li> <li> <p>Storage </p> </li> <li>02_storage</li> <li>Network-attached (EBS &amp; EFS) </li> <li> <p>hardware (EC2 Instance Store)</p> </li> <li> <p>Network : </p> </li> <li>04_network</li> <li>ENI 00_eni+sg.md</li> <li> <p>sg: 00_eni+sg.md</p> </li> <li> <p>Elastic load Balancer 01_ELB.md</p> </li> <li>Auto Scaling group 01_ASG.md</li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#7-save-cost","title":"7. Save cost","text":""},{"location":"01_aws/01_compute/01_EC2/#aws-cost-explorer","title":"AWS Cost Explorer","text":"<ul> <li>helps you identify under-utilized Amazon EC2 instances.<ul> <li>that may be downsized on an instance by instance basis within the same instance family, </li> </ul> </li> <li>understand the potential impact on your AWS bill by taking these purchace option:<ul> <li>Reserved Instances </li> <li>Savings Planss</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/01_EC2/#aws-compute-optimizer","title":"AWS Compute Optimizer","text":"<ul> <li>recommends optimal AWS Compute resources for your workloads </li> <li>to reduce <code>costs</code> and improve <code>performance</code> by using machine learning <ul> <li>to analyze historical utilization metrics.</li> <li>helps you choose the optimal Amazon EC2 instance types.</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/","title":"ECS","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#a-docker","title":"A. docker","text":"<ul> <li>02_docker</li> <li>machine vs virtual machine vs container (partial virtualization : share OS, n/w)</li> <li>image --&gt; run on docker-agent --&gt; Container </li> <li>docker-demon / container-d</li> <li>ecs-agent on ec2-i</li> <li>container mgt tool in AWS : </li> <li>container orchestration : ecs and eks(k8s)</li> <li>image repo : ecr, </li> <li>launch type : fargate or ec2</li> <li></li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#b-k8s-vs-ecs","title":"B. k8s vs ECS","text":"<ul> <li>Analogy with k8s.</li> <li><code>eks cluster</code> - ecs cluster</li> <li><code>worker-node</code> -  fargate or ec2 nodes.</li> <li><code>pod</code>(c1) - task(c1) or service[task]</li> <li><code>pod/rs/deployment</code> manifest yaml - task definition   -<code>control panel/master node</code>  - ?</li> <li><code>service</code> - ALB --&gt; tg --&gt; asg [task-1]<ul> <li>desired task = 1</li> <li>max task count = 3</li> </ul> </li> <li><code>task schedular</code> - ?</li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#c-ecs-elastic-container-service","title":"C. ECS  (elastic container service)","text":"<ul> <li>For fargate launch, don't think underlying ec2-i/s</li> <li>Configure ASG to scale out the  ECS cluster when the ECS service's CPU utilization rises above a threshold </li> <li>configure a target tracking scaling policy</li> <li>metric: <code>ECSServiceAverageCPUUtilization</code></li> <li>ECS-cluster (with launch type = ec2)</li> <li>EC2-i1 (<code>docker-agent</code>) <ul> <li>task-1 (c1)</li> <li>task-2 (c2)</li> <li>...</li> </ul> </li> <li>EC2-i2 : task-11, task-22, ...</li> <li>EC2-i3 : task-111, task-222, ...</li> <li>...</li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#pricing","title":"pricing","text":"<ul> <li>Fargate launch type</li> <li>you pay for the amount of vCPU and memory resources that your containerized application requests.</li> <li>from the time your container images are pulled </li> <li>until the Amazon ECS Task terminates</li> <li> <p>rounded up to the nearest second. </p> </li> <li> <p>EC2 launch type </p> </li> <li>there is no additional charge for the EC2 launch type.</li> <li>pay for AWS resources <ul> <li>EC2 instances </li> <li>EBS volumes</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#ecs-demolaunchtype-ec2","title":"ECS Demo:(launchtype = ec2)","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#1-create-cluster-1","title":"1 create cluster-1","text":"<ul> <li>launchType : ec2 (worker nodes)</li> <li>has ECS-Cluster capacity provider </li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#2-create-task-definition-1-json-metadata","title":"2 create task-definition-1 : <code>json</code> metadata","text":"<ul> <li>resources <ul> <li>os</li> <li>cpu, ram</li> </ul> </li> <li>task-role(1) : attach to ecs-agent  (permission - ecr, cw, ecs)</li> <li>task-exec-role(each definition) : attach to task.</li> <li>container/s  : <code>max 10</code> <ul> <li><code>image uri</code></li> <li><code>port mapping</code></li> <li>container-port</li> <li>host-port: <ul> <li>for ec2 launch:: if 0, then get dynamic port and alb finds it.  </li> <li>for fargate launch :: not needed.</li> </ul> </li> <li><code>env var</code></li> <li>hardcode</li> <li>read from SSM store / secret manager</li> <li>bulk fetch env file from s3 </li> <li></li> <li><code>storage</code> : EFS or default(21GB EBS)</li> <li>ec2-i storage : bind mount to c1,c2,etc</li> <li>for fargate use ephemeral storage. ? </li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#3-run-task","title":"3 run task:","text":"<ul> <li>task (for job) directly,  </li> <li>or wrap task with service (for long-running web-app) : srv1:[t1,t2,t3]<ul> <li>service name - <code>service-1</code></li> <li>choose :  task-definition :<code>task-definition-1</code> **</li> <li>Desire capacity : 2 tasks - task-1(c1), task-2(c2)</li> <li>Define networking</li> <li>choose <code>subnet/VPC</code></li> <li>create <code>sg</code> : allow traffic http,etc --&gt; this will attach to ec2-i or <code>hidden-ec2-i/in-fargate</code></li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#4-expose-taskservice","title":"4 expose task/service","text":"<ul> <li>create ALB-1</li> <li>health check for tg</li> <li>listener(http:80)  --&gt; tg-1 --&gt; [  task-1(c1), task-2(c2) ]</li> <li>host-port : if 0, then get dynamic port and alb will find those  </li> <li></li> <li></li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#5-auto-scaling","title":"5 Auto Scaling","text":"<ul> <li>create ASG-1 to scale up/down task </li> <li>For ec2 launch</li> <li>option-1 (<code>ASG-1</code>) : CW --&gt; metric(CPU,etc) --&gt; <code>ASG</code>(task)</li> <li>option-2 (<code>ECS-Cluster capcity provider</code>): preferred to use, smart, better.</li> <li>For fargate: easy</li> <li>ECS-Cluster capacity provider : intelligent to do everything.</li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#6-task-placement-ec2-launch-type","title":"6 task placement (ec2 launch type)","text":"<ul> <li>note: ec2 instance role : add permission to pull image from ecr</li> <li></li> <li>statisfy:</li> <li>1 CPU, memory, and port requirements</li> <li>2 Task Placement Strategy<ul> <li><code>Binpack</code> : fill ec2-i1 first, then ec2-i2, etc</li> <li><code>random</code> </li> <li><code>spread</code> : </li> <li>Tasks are placed evenly based on the specified value</li> <li>eg: instanceId, az, etc</li> </ul> </li> <li>3 Task Placement Constraints<ul> <li><code>distinctInstance</code> : different EC2 instances</li> <li><code>memberOf</code> :  member Of expression (<code>CQL</code> - cluster query language - advance)   <pre><code>\"placemnetConstraints :[\n      {\n          \"type\": \"memberof\"\n          \"expression\" : \"attribute:ecs.instance-type =~ t2.*\"\n      }\n]\n</code></pre></li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#7-ecs-networking-mode","title":"7 ECS networking mode","text":"<pre><code>        #### Bridge Mode (for EC2 launch type)\n\n- Default Docker networking mode.\n- Containers share the host\u2019s network namespace but get mapped ports.\n- Good for traditional containerized apps but lacks direct IPs.\n\n        #### Host Mode (for EC2 launch type)\n\n- Containers use the host\u2019s network directly (no port mapping).\n- Lower latency but can cause port conflicts.\n\n        #### Awsvpc Mode (for both EC2 &amp; Fargate) (Recommended)\n\n- Assigns a dedicated ENI (Elastic Network Interface) to each task.\n- Provides full networking features, including security groups and VPC routing.\n- Required for Fargate tasks.\n\n        #### None Mode\n\n- Disables networking (containers have no external network access).\n- Used for isolated workloads.\n</code></pre>"},{"location":"01_aws/01_compute/02_Containers_ECS/#ready-green_circle","title":"READY :green_circle:","text":"<ul> <li>check cluster &gt; task &gt; container, logs/event,</li> <li>update service - manually update Desire capacity : 5</li> <li>in prod, service Auto Scaling (ASG, ECS-Cluster capcity provider) will do same.</li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#8-update-task","title":"8 update task","text":"<ul> <li><code>rolling update</code> </li> <li>default:<ul> <li>min healthy: 100%</li> <li>max : 200%</li> </ul> </li> <li>more example for understaning:</li> <li>min : 50% and max: 100%<ul> <li></li> </ul> </li> <li>min : 100% and max: 150%<ul> <li></li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#d-screenshot","title":"D. screenshot","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#1-launch-type","title":"1. launch type:","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#2-iam-rolespolicies","title":"2. iam roles/policies:","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#3-alb","title":"3. alb","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#4-storage","title":"4. Storage:","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#5-scale-asg-ecs-cluster-capcity-provider","title":"5 scale : ASG + Ecs-cluster capcity provider","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#e-trigger-ecs-task","title":"E. trigger ecs task","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#1-with-eventbridge-trigger","title":"1 with eventBridge ( trigger )","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#2-with-eventbridge-scheduled","title":"2 with eventBridge ( scheduled )","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#3-with-sqs-autoscale","title":"3 with SQS + autoScale","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#falerts","title":"F.alerts","text":""},{"location":"01_aws/01_compute/02_Containers_ECS/#exam-scenarios","title":"exam scenarios","text":"<ul> <li> <p>For ECS Anywhere on an on-premises Linux server, you need to install the following agents: <pre><code>SSM Agent     \u2013 Allows AWS Systems Manager to **manage** the server remotely &lt;&lt;&lt;\nECS Agent     \u2013 Connects the server to the Amazon ECS control plane for task scheduling.\nDocker Engine \u2013 Required to run containerized workloads.\n</code></pre></p> </li> <li> <p>EKS Anywhere: </p> </li> <li>Runs Kubernetes clusters on on-premises infrastructure using <code>bare-metal</code> or <code>VMware-vSphere</code>. </li> <li>It provides full lifecycle management for Kubernetes clusters.</li> <li>bare-metal, Runs directly on physical servers without a hypervisor. || best for cost and performance </li> <li>VMware-vSphere, Runs on virtualized infrastructure using ESXi hypervisor.</li> <li> <p>https://aws.amazon.com/blogs/containers/introducing-amazon-ecs-anywhere/</p> </li> <li> <p>EKS Distro (EKS-D) is </p> </li> <li>the open-source Kubernetes distribution used by Amazon EKS. </li> <li>It allows you to run self-managed Kubernetes clusters on any infrastructure, including <ul> <li>on-premises </li> <li>and other clouds </li> </ul> </li> </ul> <ul> <li>Deploy ECS on AWS outpost </li> <li>better latency and connectivity.</li> <li>supports only <code>EC2-launch-type</code>.</li> </ul>"},{"location":"01_aws/01_compute/02_Containers_ECS/#-alb-and-nlb-both-supports-dynamic-port-mapping","title":"- ALB and NLB, both supports dynamic port mapping","text":""},{"location":"01_aws/01_compute/02_Kubernetes_EKS/","title":"EKS","text":""},{"location":"01_aws/01_compute/02_Kubernetes_EKS/#k8s","title":"k8s","text":"<ul> <li>03_Kubernetes</li> <li>cloud-agnostic </li> </ul> <ul> <li>04_EKS</li> <li>pod + service </li> <li>control panel/master node </li> <li>worker-nodes</li> <li>use <code>EKS optimized AMI</code> to build container image.</li> <li> <p>Type:</p> <ul> <li>fargate</li> <li>managed : </li> <li>inbuilt <code>ASG</code> to scale nodes, register Node.</li> <li>support od or spot</li> <li>self-managed : </li> <li>register node manually</li> <li>support od or spot</li> </ul> </li> <li> <p>Addon</p> </li> <li><code>CSI</code>: Container Storage Interface :</li> <li></li> </ul>"},{"location":"01_aws/01_compute/02_Kubernetes_EKS/#hands-on","title":"hands on","text":"<ul> <li>eks::terraform <pre><code>1.  create cluster-1\n  - choose K8s version\n  - encrypt k8s secret with KMS : y/n\n  - create IAM EKS-cluster-role-1 \n    - attach inbuild \"AmazonEKSClusterPolicy\"\n    - ...\n  - n/w : \n    - vpc/subnet\n    - ceate sg for cluster\n\n2. update cluster with more detail\n  - resource tab (k8s things) :\n    - deployment object\n    - service Object\n    - pod\n    - job\n    - ...\n    - ...\n  - compute tab : \n    - Option-1 :: `Node/NodeGroup (bts: ec2-i)`\n      - add Node (single ec2-i) \n      - or, add Node-Group (multiple Ec2-i, set - min, max, desired) \n      - IAM policy for ec2-i : attach \"AmazonEKSWorkerNodePolicy\", \"AmazonEC2ContainerregistryReadOnly\"\n      - choose : AMI, ec2-i class, etc for ec2-i\n    - Option-2 :: `fargate profile`\n      - pending\n      - ...\n\n  - Add-on tab\n    -  add EBS-CSI (Container Storage Interface) drive\n    -  add VPC-CNI  \n    - ...\n    - ...\n\n  *** Note: very high level, need K8s expertise to do more    \n</code></pre></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/","title":"Lambda Intro","text":""},{"location":"01_aws/01_compute/03_lambda-01-saa/#-httpsdocsawsamazoncomlambdalatestdgwelcomehtml","title":"- https://docs.aws.amazon.com/lambda/latest/dg/welcome.html","text":""},{"location":"01_aws/01_compute/03_lambda-01-saa/#aws-lambda","title":"AWS Lambda","text":""},{"location":"01_aws/01_compute/03_lambda-01-saa/#a-lambdafunction","title":"A. Lambda:Function","text":"<ul> <li>lambda initially was <code>FaaS</code>. Now serverless : <code>provision code/function</code> </li> <li>lambda@edge - globally service. </li> <li>author: us-east-1</li> <li>replicated to edge location from author.</li> <li>invoke:</li> <li>by services(eg: s3 trigger lambda)</li> <li>by SDK/CLI<ul> <li><code>--invocation-type Event</code> for making async call from cli</li> </ul> </li> <li>Avoid using recursive code, never have a Lambda function call itself  </li> <li>can create vpce (PrivateLink)</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#1-scaling","title":"1. Scaling","text":"<ul> <li>auto-scale with load<code>(parallel Lambdas,</code>max- 1000`)</li> <li></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#2-network","title":"2. Network","text":"<ul> <li>default: run in aws owned VPC (has public internet access) </li> <li>run inside our VPC-1 and subnet</li> <li>attach ENI to lambda<ul> <li>ENI has SG</li> <li>define ingress/egress.</li> </ul> </li> <li>deployed in <code>private subnet</code> --&gt; don't have internet access</li> <li>deployed in <code>public subnet</code> (igw attached)<ul> <li>still don't have internet access by-default  </li> </ul> </li> <li>Get internet access with NAT<ul> <li></li> <li>deploy lambda in private subnet</li> <li>update rtb, to route traffic 0.0.0.0.\\0 traffic to NAT gateway</li> <li>this is the only way.</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#3-pricing","title":"3. Pricing","text":"<ul> <li>cost-efficient</li> <li>no of call: First 1M free, then <code>20cent/million req</code></li> <li>cpu usage: First 400K GB-second free, then <code>$1/600K GB-second</code></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#4-security","title":"4. Security","text":"<ul> <li>Attach IAM role with fine grain access to lambda. eg:</li> <li>cw:log-group</li> <li>sqs:poll (event source mapping)</li> <li>...</li> <li>lambda resource based policy </li> <li>who can invoke the Lambda function and under what conditions </li> <li>eg: allow S3 bucket:</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#5-programming-things","title":"5. programming things","text":""},{"location":"01_aws/01_compute/03_lambda-01-saa/#5-1-create-function","title":"5.-1. create function:","text":"<ul> <li>create function with x-ray tracing</li> <li>create from web-console, cli commands, terraform plan, cloudFormation template (upload zip to s3 (versioned))</li> <li></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#50-basic","title":"5.0. Basic","text":"<ul> <li>compute-time /timeout: </li> <li><code>0 - 15 min</code> </li> <li>or, <code>0 - 900 sec</code></li> <li> <p>default : <code>3 seconds</code></p> </li> <li> <p>handler : file.method (eg: l_function.l_handler(<code>event</code>,<code>context</code>))</p> </li> <li>context - metadata about the Lambda function execution environment.<ul> <li>re-use for multiple invocation.</li> <li>great for DB connection, Http client, etc</li> <li>cold start: first call will have latency to init context.</li> </ul> </li> <li>event - contains the input data for the Lambda function.</li> <li> <p>sample: 03_lambda-dva-03-context+event.md</p> </li> <li> <p>language/runtime : </p> </li> <li>node, py, java, Golang, C#/Ruby, <code>Custom Runtime - rust/golang</code></li> <li>java 11 or above : performance is 10x (free) - <code>SnapStart feature</code> </li> <li> <p></p> </li> <li> <p>build pkg size :</p> </li> <li><code>50 MB</code>  compressed</li> <li><code>250 MB</code> code+dependency</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#51-resource","title":"5.1 resource","text":"<ul> <li>RAM : <code>128 MB -10 GB</code><ul> <li>implicitly improves network as well</li> <li>implicitly add more CPU credit.</li> </ul> </li> <li>disk<ul> <li><code>/tmp</code>- ephemeral storage : </li> <li>space for writing temp files. </li> <li>no shared.</li> <li><code>512 MD to 10 GB</code></li> <li>if needed permanent space, use:</li> <li><code>s3</code>,</li> <li><code>EFS</code> : very fast (if running inside our vpc-1) </li> <li>can be shared among lambda/s</li> <li>programmatically encrypt /tmp using KMS keys. generate ir first. </li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#52-env-var","title":"5.2. ENV var","text":"<ul> <li><code>4 KB</code></li> <li>can encrypt them as well </li> <li>sample py code:   <pre><code>import os;\nos.getenv(\"ENV_VAR_1\")\n</code></pre></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#53-monitor","title":"5.3. Monitor","text":"<ul> <li>inbuilt metric</li> <li><code>iterator-age</code>: can check stream iterator/offset/sequence </li> <li><code>concurrent-execution</code></li> <li><code>Throttle</code></li> <li><code>Async delivery failure</code></li> <li>...</li> <li>log-group : /aws/lambda/lambda-1/</li> <li>traces </li> <li>Enable Active Tracing, to run the X-Ray daemon</li> <li>add this to Lambda-role : <code>AWSXRayDaemonWriteAccess</code></li> <li>Environment variables to communicate with X-Ray<ul> <li><code>_X_AMZN_TRACE_ID</code>: contains the tracing header</li> <li><code>AWS_XRAY_CONTEXT_MISSING</code>: by default, LOG_ERROR</li> <li><code>AWS_XRAY_DAEMON_ADDRESS</code>: the X-Ray Daemon IP_ADDRESS:PORT</li> </ul> </li> <li>Use AWS X-Ray SDK in Code<ul> <li>use these env var and write trace.</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#54-lambda-layer","title":"5.4. lambda layer","text":"<p> - 5 layer max - 250 MB total - aws-sdk dependency : no need to pkg in zip. :)</p>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#55-lambda-container-image","title":"5.5. Lambda Container Image","text":"<ul> <li>run docker image in lambda Function</li> <li><code>base image</code> : lambda runtime API</li> <li>eg: FROM amazon/aws-lambda-nodejs:12</li> <li>to run javacode, provides JVM runtime. </li> <li>similar provide <code>container-d</code> runtime.</li> <li></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#56-concurrency","title":"5.6. Concurrency","text":"<ul> <li>set reservedConcurrency</li> <li><code>max/default = 1000</code> (can be increased on request)</li> <li> <p>combined for all function/s together. </p> <ul> <li>function-1 has 500 invocation</li> <li>function-2 has 500 invocation</li> <li>function-3 will get retry first and then give ThrottleError (429)</li> </ul> </li> <li> <p></p> </li> <li>retry:</li> <li>for <code>sync</code> invocation - 2 times</li> <li> <p>for <code>a-sync</code> invocation: </p> <ul> <li>retry attempt exponentially increases from <code>1 second - 5 minutes</code></li> <li><code>max 6 hrs</code></li> </ul> </li> <li> <p>provisioned concurrency</p> </li> <li>configure it to have warm start, else cold-start.</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#57-codeguru-javapy","title":"5.7 CodeGuru  (java/py)","text":"<ul> <li>developer tool powered by machine learning (ML)</li> <li>Identifies performance bottlenecks</li> <li>Offers recommendations to optimize CPU and memory usage, helping to reduce costs</li> <li>Enforces coding standards and recommends fixes for anti-patterns</li> <li> <p>Detects common security vulnerabilities</p> </li> <li> <p>When activated, Lambda adds:</p> </li> <li>CodeGuruProfiler layer to function</li> <li>Env vars to your function</li> <li><code>AmazonCodeGuruProfilerAgentAccess</code> policy to your function</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#58-version-and-alias","title":"5.8 version and alias","text":"<ul> <li>publish function to create version 1,2... <code>immutable</code></li> <li>arn:aws:lambda:us-east-1:123456789012:function:function-1:alias/version</li> <li>current version : $LATEST - <code>mutable</code> (edit code)</li> <li>create alias to point one specfic version</li> <li>alias1 --&gt; version 1,2...</li> <li>alias1 --&gt;  --&gt; alias-2</li> <li>weight alias (<code>canary model</code>)<ul> <li>alias1 (1-2-M)</li> <li>90% --&gt; v1</li> <li>10% --&gt; v2</li> </ul> </li> <li>eg:</li> <li></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#59-integration-with-codedeploy","title":"5.9 integration with <code>codeDeploy</code>","text":""},{"location":"01_aws/01_compute/03_lambda-01-saa/#510-function-url","title":"5.10 Function URL","text":"<ul> <li>expose <code>function-1:version-1/alias</code> with Dedicated HTTP(S) endpoint.</li> <li>https://<code>&lt;url-id&gt;</code>.lambda-url..on.aws (dual-stack IPv4 &amp; IPv6) <li>Access your function URL through the public Internet only</li> <li>Doesn\u2019t support PrivateLink / vpce </li> <li>security:</li> <li>Supports Resource-based Policies</li> <li>CORS configurations</li> <li>set Throttle. eg: <code>seservedConcurrency=10</code></li> <li>AuthType== <code>NONE</code> (allow public and unauthenticated access)</li> <li>AuthType== <code>AWS_IAM</code><ul> <li></li> </ul> </li>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#b-integration-with-other-services-green_circle","title":"B. integration with other services :green_circle:","text":"<ul> <li>lambda trigger patterns:  </li> <li>Event source mapping </li> <li>Synchronous </li> <li>A-synchronous</li> <li> <p>details: 03_lambda-dva-02-trigger.md for details</p> </li> <li> <p>all common eg:</p> </li> <li>API-gateway (REST) &gt;&gt; lambda</li> <li>ALB &gt;&gt; target-group-1:lambda <ul> <li></li> </ul> </li> <li>S3:objectcreate,etc &gt;&gt; lambda </li> <li>CW:log-event||loggroup-subscription-filter &gt;&gt; lambda (log-processing)</li> <li>DynamoDB-streams &gt;&gt; lambda</li> <li>SQS/SNS:consumer &gt; Consumer/Subscriber &gt; lambda/s </li> <li>KDS:consumer &gt;&gt; Lambda/s</li> <li>web-client-req --&gt; CloudFront ( lambda@Edge :customize req+some processing ) --&gt; origin</li> <li>IAM:cognito &gt;&gt; Lambda</li> <li>other services's event &gt;&gt; eventBridge(<code>EventRule</code>/<code>cron scheduler</code>)  &gt;&gt; Lambda <ul> <li>codePipeline's in-built event, say e1 &gt; eventBridge(bus) &gt; EventRule-1 (capture e1) &gt; lambda-1 (process)</li> <li>...</li> <li>generic pattern :)</li> </ul> </li> <li></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-01-saa/#c-architecture-example","title":"C. Architecture example","text":""},{"location":"01_aws/01_compute/03_lambda-01-saa/#d-extra","title":"D. extra","text":""},{"location":"01_aws/01_compute/03_lambda-01-saa/#1-limit-summary","title":"1. limit summary","text":""},{"location":"01_aws/01_compute/03_lambda-dva-01-CLI/","title":"lambda CLI","text":""},{"location":"01_aws/01_compute/03_lambda-dva-01-CLI/#1-create-update-delete","title":"1. create, update, delete","text":"<pre><code>aws lambda delete-function \\\n    --function-name &lt;function_name&gt;\n\naws lambda create-function \\\n    --function-name &lt;function_name&gt; \\\n    --runtime &lt;runtime&gt; \\\n    --role &lt;role_arn&gt; \\\n    --handler &lt;handler_name&gt; \\\n    --zip-file fileb://&lt;path_to_deployment_package&gt;\n\naws lambda list-functions\n\n# get config\n# ==================\naws lambda get-function-configuration \\\n    --function-name &lt;function_name&gt;\n\n# update config\n# ==================    \naws lambda update-function-configuration \\\n    --function-name &lt;function_name&gt; \\\n    --runtime &lt;runtime&gt; \\\n    --role &lt;role_arn&gt; \\\n    --handler &lt;handler_name&gt; \\\n    --memory-size &lt;memory_in_mb&gt; \\\n    --timeout &lt;timeout_in_seconds&gt;\n\n# update code\n# ==================\naws lambda update-function-code \\\n    --function-name MyLambdaFunction \\\n    --zip-file fileb://function.zip\n\n# Downloads the deployment package of a Lambda function\n# ======================================================\naws lambda get-function \\\n    --function-name &lt;function_name&gt;\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-01-CLI/#2-invoke-sync-async","title":"2. invoke (sync + async)","text":"<pre><code>#  Synchronous Invocation\n# =======================\naws lambda invoke \\\n    --function-name &lt;function_name&gt; \\\n    --payload '&lt;json_payload&gt;' \\\n    &lt;output_file&gt;\n\n# Asynchronous Invocation\n# =======================\naws lambda invoke \\\n    --function-name MyLambdaFunction \\ \n    --invocation-type Event \\                          &lt;&lt;&lt;\n    --payload '{\"key\": \"value\"}' \\\n    response.json\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-01-CLI/#3-add-trigger-s3-notification","title":"3. Add trigger - S3 notification","text":"<pre><code># update lambda policy\n# ==================\naws lambda add-permission \\\n    --function-name &lt;function_name&gt; \\\n    --action \"lambda:InvokeFunction\" \\\n    --principal s3.amazonaws.com \\\n    --source-arn arn:aws:s3:::&lt;bucket_name&gt; \\\n    --statement-id &lt;unique_id&gt;\n\n# Add S3 triger\n#==============\naws s3api put-bucket-notification-configuration \\\n    --bucket &lt;bucket_name&gt; \\\n    --notification-configuration file://notification.json\n\n# notification.json    \n{\n  \"LambdaFunctionConfigurations\": [\n    {\n      \"LambdaFunctionArn\": \"arn:aws:lambda:region:account-id:function:function-name\",\n      \"Events\": [\"s3:ObjectCreated:*\"]\n    }\n  ]\n}\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-01-CLI/#4-more","title":"4. more","text":"<pre><code>aws logs filter-log-events \\\n    --log-group-name /aws/lambda/&lt;function_name&gt; \\\n    --start-time &lt;start_timestamp&gt; \\\n    --end-time &lt;end_timestamp&gt;\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/","title":"Lambda Invocations","text":""},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#a-synchronous","title":"A. <code>Synchronous</code>","text":"<ul> <li>below services make sync/blocking call:</li> <li>ALB, Amazon API Gateway, CloudFront (Lambda@Edge)</li> <li>Amazon S3-Batch</li> <li>Amazon Cognito</li> <li>AWS Step Functions</li> <li>Amazon Lex</li> <li>Amazon Alexa</li> <li>Amazon Kinesis Data Firehose</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#a1-alb","title":"A.1 ALB","text":"<ul> <li>Flow</li> <li>http/s request  comes to ELB</li> <li>elb <code>converts</code> http request into json object and pass to event arg</li> <li>call lambda-1 &gt; handler-1(event, context)</li> <li>lambda sends json object as response</li> <li>ELB <code>converts</code> lambda-response into http-response <pre><code>{\n\"statusCode\": 200,\n\"statusDescription\": \"200 OK\",\n\"isBase64Encoded\": false,\n\"headers\": {\n  \"Content-Type\": \"text/html\",\n  \"Set-Cookie\": \"cookie1=value1; Path=/; HttpOnly\",\n    \"Custom-Header\": \"value\"\n  },\n\"body\": \"&lt;html&gt;&lt;body&gt;Hello from Lambda!&lt;/body&gt;&lt;/html&gt;\"\n}\n</code></pre></li> <li>conversions:</li> <li></li> <li></li> <li>ALB Multi-Header Values : enable/disable this feature. </li> <li>notice queryparams,headers <code>array</code></li> <li></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#a2-gateway","title":"A.2 gateway","text":"<ul> <li>soon</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#-","title":"---","text":""},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#b-a-synchronous","title":"B <code>A-synchronous</code>","text":"<ul> <li>below services(event-based) make a-sync/non-blocking call:</li> <li>s3:evnetNotification</li> <li>SQS, SNS, SES(email)</li> <li>CW:log-events||subscription-filter</li> <li>more (not in scope of exam)<ul> <li>AWS codeCommit + codePiprline + cloudformation</li> <li>AWS config</li> <li>AWs IoT</li> </ul> </li> <li>internal eventQueue </li> <li>event --&gt; eventSQSQueue [e1,e2,...] --&gt; LambdaService reads event and invoke lambda functions async.</li> <li>if throttleError, LambdaService will return event back to internal eventQueue.</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#green_circle-b1-s3event-notification","title":":green_circle: B.1 S3:event notification","text":"<ul> <li>create s3 bucket &gt; properties tab &gt;&gt; create s3 notification</li> <li>set prefix +  s3:objectCreate event</li> <li>set target : lambda-1 (lambda-policy-1: allow s3)</li> <li>create DLQ or destination(OnFailure)</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#green_circle-b2-sqs","title":":green_circle: B.2 SQS","text":"<ul> <li>message dropped on SQS queue-1</li> <li>sqs-event will call lambda async does (non-blocking)</li> <li>next, lambda-1 &gt;&gt; configuration tab &gt;&gt; asynchronous invocation section. </li> <li>add <code>DLQ-1</code> on lambda(not on queue-1)</li> <li>set <code>retry attempt</code> = 0,1,2</li> <li>also, update lambda-role-1: + sqsSend permission</li> <li>if exception thrown from lambda(consumer), then lambda will retry</li> <li>keep lambda code Idempotent </li> <li>after reties goes to DLQ-1</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#green_circle-b3-event-bridge-generic-pattern","title":":green_circle: B.3 Event-bridge (generic pattern)","text":"<ul> <li>trigger:</li> <li>EventRule</li> <li>schedular</li> <li></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#c-event-source-mapping-poller-batch","title":"C. <code>Event Source Mapping</code> (Poller) + batch","text":"<ul> <li>udemy reference</li> <li>Lambda is triggered <code>synchronously</code> with <code>batch</code> </li> <li>by polling data from below 3 poll-based services </li> <li>Queue based: Queue Poller : <code>SQS</code> : ordered, if FIFO.</li> <li>streams based: Stream Poller : <code>KDS</code> : ordered  + <code>DynamoDB Streams</code></li> </ul> <p> - lambda will scale out, based on active message.</p>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#yellow_circle-c1-sqs-queue","title":":yellow_circle: C.1 SQS : Queue","text":"<ul> <li>Event Source Mapping will poll SQS (Long Polling)</li> <li>configuration:</li> <li>batch size  + batch Window</li> <li>recommended : Set the queue visibility timeout = 6x Lambda-1::timeout</li> <li>set-up DLQ-1 on the SQS queue.</li> <li>preferred way : destination (on-failure)</li> <li>more:</li> <li>For FIFO queue : lambda supports in order processing.</li> <li>lambda will delete item, after processing. </li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#yellow_circle-c2-kds-stream","title":":yellow_circle: C.2 KDS : stream","text":"<p> - parallelization: can have upto <code>10 batches</code> per shard. - in-order processing : processing for the affected shard is paused, until the error is resolved <pre><code>- shard-1\n  - poll-1 &gt; batch-1 &gt; lambda-1-instance-1\n  - poll-2 &gt; batch-2 &gt; **lambda-1-instance-2**   &lt;&lt;&lt; errored out\n  - ...\n  - ...\n  - poll-10 &gt; batch-10 &gt; lambda-1-instance-10\n\n  if lambda-1-instance-2 excution error out, entire shard-1 will be on hold/paused   &lt;&lt;&lt;\n\n  And entire batch, batch-2 will be reprocessed.                                     &lt;&lt;&lt;\n</code></pre> - Configuration:   - discard batch     - will go to Destination   - restrict the number of retries</p>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#yellow_circle-c3-dynamodb-stream","title":":yellow_circle: C.3 DynamoDB : stream","text":"<p>- soon</p>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#d-destination-2019","title":"D  Destination (2019)","text":"<ul> <li>udemy reference</li> <li>new, preferred, 4  services</li> <li>sqs</li> <li>sns</li> <li>another-lambda,</li> <li>event-bus</li> <li>in ccgg</li> <li>lambda &gt; java-rest-api &gt; programmatically writing into success fifo queue.</li> <li>so achieving same behaviour.</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#d1-async-invocation-failure","title":"D.1 Async invocation: <code>failure</code>","text":"<ul> <li>Destination  (condition: OnFailure)</li> <li>DLQ  (old, only 2 service, we did before)</li> <li>sqs</li> <li>sns</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#d2-async-invocation-success","title":"D.2 Async invocation: <code>success</code>","text":"<ul> <li>destination (condition: OnSuccess)</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-02-trigger/#d3-event-source-mapping-discard-batch","title":"D.3 Event Source mapping: <code>discard batch</code>","text":""},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/","title":"lambda function - handler(event,context)","text":""},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/#a-context","title":"A. context","text":"<ul> <li>metadata about the Lambda function execution environment. <pre><code>{\n  \"function_name\": \"MyLambdaFunction\",\n  \"function_version\": \"$LATEST\",\n  \"invoked_function_arn\": \"arn:aws:lambda:us-east-1:123456789012:function:MyLambdaFunction\",\n  \"memory_limit_in_mb\": 128,\n  \"aws_request_id\": \"1234-5678-9012\",\n  \"log_group_name\": \"/aws/lambda/MyLambdaFunction\",\n  \"log_stream_name\": \"2024/12/13/[$LATEST]abcdef1234567890\",\n  \"identity\": null,\n  \"client_context\": null\n}\n</code></pre></li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/#b-event","title":"B. event","text":"<ul> <li>contains the input data for the Lambda function.</li> </ul>"},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/#1-api-gateway","title":"1. API Gateway","text":"<pre><code>{\n  \"resource\": \"/{proxy+}\",\n  \"path\": \"/my/path\",\n  \"httpMethod\": \"GET\",\n  \"headers\": {\n    \"Accept\": \"application/json\",\n    \"Authorization\": \"Bearer abc123\",\n    \"Host\": \"example.com\"\n  },\n  \"queryStringParameters\": {\n    \"param1\": \"value1\",\n    \"param2\": \"value2\"\n  },\n  \"pathParameters\": {\n    \"proxy\": \"my/path\"\n  },\n  \"stageVariables\": {\n    \"stageVarName\": \"stageVarValue\"\n  },\n  \"body\": \"{ \\\"key\\\": \\\"value\\\" }\",\n  \"isBase64Encoded\": false\n}\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/#2-alb","title":"2. ALB","text":"<pre><code>{\n  \"requestContext\": {\n    \"elb\": {\n      \"targetGroupArn\": \"arn:aws:elasticloadbalancing:us-east-1:123456789012:targetgroup/my-target-group/6d0ecf831eec9f09\"\n    }\n  },\n  \"httpMethod\": \"GET\",\n  \"path\": \"/my/path\",\n  \"queryStringParameters\": {\n    \"param1\": \"value1\",\n    \"param2\": \"value2\"\n  },\n  \"headers\": {\n    \"accept\": \"text/html,application/xhtml+xml\",\n    \"accept-language\": \"en-US,en;q=0.9\",\n    \"host\": \"my-load-balancer-1234567890.us-east-1.elb.amazonaws.com\",\n    \"user-agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/96.0.4664.93 Safari/537.36\",\n    \"x-forwarded-for\": \"203.0.113.1\",\n    \"x-forwarded-port\": \"443\",\n    \"x-forwarded-proto\": \"https\"\n  },\n  \"body\": null,\n  \"isBase64Encoded\": false\n}\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/#3-s3-event-notification","title":"3. S3 event notification","text":"<pre><code>{\n  \"Records\": [\n    {\n      \"eventVersion\": \"2.1\",\n      \"eventSource\": \"aws:s3\",\n      \"awsRegion\": \"us-east-1\",\n      \"eventTime\": \"2024-12-13T12:00:00.000Z\",\n      \"eventName\": \"ObjectCreated:Put\",\n      \"s3\": {\n        \"bucket\": {\n          \"name\": \"my-bucket\",\n          \"arn\": \"arn:aws:s3:::my-bucket\"\n        },\n        \"object\": {\n          \"key\": \"my-folder/my-object.txt\",\n          \"size\": 12345,\n          \"eTag\": \"123456789abcdef\",\n          \"sequencer\": \"00123456789abcdef\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/#4-sqs","title":"4. SQS","text":"<pre><code>{\n  \"Records\": [\n    {\n      \"messageId\": \"1\",\n      \"receiptHandle\": \"AQEB...\",\n      \"body\": \"{\\\"key\\\": \\\"value\\\"}\",\n      \"attributes\": {\n        \"ApproximateReceiveCount\": \"1\",\n        \"SentTimestamp\": \"1609459200000\",\n        \"SenderId\": \"123456789012\",\n        \"ApproximateFirstReceiveTimestamp\": \"1609459201000\"\n      },\n      \"messageAttributes\": {},\n      \"md5OfBody\": \"e99a18c428cb38d5f260853678922e03\",\n      \"eventSource\": \"aws:sqs\",\n      \"eventSourceARN\": \"arn:aws:sqs:us-east-1:123456789012:MyQueue\",\n      \"awsRegion\": \"us-east-1\"\n    }\n  ]\n}\n</code></pre>"},{"location":"01_aws/01_compute/03_lambda-dva-03-context%2Bevent/#5-dynamo","title":"5. Dynamo","text":"<pre><code>{\n  \"Records\": [\n    {\n      \"eventID\": \"1\",\n      \"eventName\": \"INSERT\",\n      \"eventVersion\": \"1.1\",\n      \"eventSource\": \"aws:dynamodb\",\n      \"awsRegion\": \"us-east-1\",\n      \"dynamodb\": {\n        \"Keys\": {\n          \"id\": { \"S\": \"123\" }\n        },\n        \"NewImage\": {\n          \"id\": { \"S\": \"123\" },\n          \"name\": { \"S\": \"John Doe\" },\n          \"age\": { \"N\": \"30\" }\n        },\n        \"SequenceNumber\": \"111\",\n        \"SizeBytes\": 54\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"01_aws/01_compute/04_AppRunner/","title":"App Runner","text":""},{"location":"01_aws/01_compute/04_AppRunner/#intro","title":"Intro","text":"<ul> <li>Fully managed srv, handy, all in one service, saves time.</li> <li><code>Rapid deployment with best practices</code>.</li> <li>deploy <code>web app at scale</code>.</li> <li>automatic scaling</li> <li>ELB</li> <li>highly available</li> <li>encryption</li> <li>VPC support to access DB.</li> <li>good for <code>beginner</code>, deploy your code without knowing much abt of underlying infra.</li> <li>costly : <code>72 cent/hr</code></li> </ul>"},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/","title":"05 1 Beanstalk SSA","text":""},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#-httpschatgptcomc6763df4d-2998-800d-aea7-4430e4d96fc5","title":"- https://chatgpt.com/c/6763df4d-2998-800d-aea7-4430e4d96fc5","text":""},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#elastic-beanstalk","title":"Elastic Beanstalk","text":""},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#a-common-web-architecture","title":"A. Common Web Architecture","text":""},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#b-intro","title":"B. Intro","text":"<ul> <li>Managed services, deals with:</li> <li> <p>Managing infrastructure</p> <ul> <li>databases, <code>RDS</code></li> <li>load balancers, <code>ELB</code> + networking</li> <li>ELB type cannot be changed once provided </li> <li>if ALB, then cannot change to NLB.</li> <li>scaling concerns, <code>ASG</code></li> <li>Monitoring</li> <li>...</li> <li>note: create cloudFormation template bts for infra.</li> </ul> </li> <li> <p>Deploying Code</p> <ul> <li>into multiple env, </li> <li>compute: </li> <li>primarly EC2 </li> <li>ECS under the hood for container App</li> </ul> </li> <li> <p>Basically from central place, dealing with all these services, being used commonly for web development. </p> </li> <li>developer focus on code</li> <li>rest all beanStalk will do <code>infra + deploymnet</code></li> </ul>"},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#c-pricing","title":"C. pricing","text":"<ul> <li><code>Free</code> </li> <li>but pay for underlying infra.</li> </ul>"},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#d-elastic-beanstalk-application","title":"D. Elastic Beanstalk : <code>Application</code>","text":""},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#d1-environments","title":"D.1 Environment/s","text":"<ul> <li>create multiple <code>dev, prod, qa</code></li> <li>can clone env as well</li> <li>it represents infra which are running our application version.</li> <li>Type/tier:</li> <li>web-server  Environment<ul> <li>can send traffic to worker</li> </ul> </li> <li>worker Environment<ul> <li>for long-running task,jobs,scheduledJobs</li> </ul> </li> <li></li> </ul>"},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#d2-configuration-for-env","title":"D.2 configuration (for env)","text":"<ul> <li>deployment </li> <li> <p>deployment mode:</p> <ul> <li>05_2_Beanstalk_DVA-deployments.md</li> </ul> </li> <li> <p>availability:</p> <ul> <li>single instance (with/without using spot)</li> <li>High availability (with/without using spot+od)</li> <li></li> </ul> </li> <li> <p>Networking</p> </li> <li>choose VPC and subnet</li> <li>public IP for ec2.<ul> <li><code>enable</code> for single ec2</li> <li><code>disable</code> for multiple, since we wil ALB to expose.</li> </ul> </li> <li>ELB <ul> <li>can be shared with all env, to save some cost. </li> <li>security groups</li> </ul> </li> <li> <p>ASG - min, max, trigger(metric,alarm)</p> </li> <li> <p>Database</p> </li> <li>DB will get link with beanstalk env lifecycle.</li> <li> <p>if env is deleted, database will be deleted too. </p> </li> <li> <p>Monitoring</p> </li> <li>X-ray</li> <li>logs</li> <li>metrics</li> </ul>"},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#d3-application-version","title":"D.3 Application version","text":"<ul> <li>define platform </li> <li>language </li> <li>runtime : can use Docker </li> <li>upload code (<code>zip</code>)</li> <li>code, v1</li> <li>code, v2</li> <li>...</li> <li>code, <code>v1000</code> (max)</li> <li>use s3 bts for storing zip </li> <li>Application version lifecycle</li> <li>enable it, To phase out old application versions.</li> <li>Option not to delete the source bundle in S3 to prevent data loss</li> </ul>"},{"location":"01_aws/01_compute/05_1_Beanstalk_SSA/#z-hands-on","title":"Z. Hands on","text":"<pre><code>- Create Application\n  - create environment : dev\n    - choose type/tier: web | worker(job,long-running-task)\n  - choose platform : language, runtime,etc \n  - code: upload it.\n  - deployment mode:\n    - single EC2 with ASG \n    - high availabilty - multiple EC2 with ASG\n  - iam role for permission:\n      - `AWSElasticBeanStalkWebTier`,\n      - `AWSElasticBeanStalkWorkerTier`, \n      - `AWSElasticBeanStalkMultiContainerDocker`\n      - ...\n  - Skipped and using default\n    - Networking\n    - Database\n    - Monitoring\n\n# === DONE === \n\n- check cloudFormation stack (composer UI)\n\n- get domain url and use it.\n- upload new code, seamlessly.\n- check other tab : CW, monitor, mmanged updates, alarms, health, etc\n- Check `configuration` link on left\n  - show all the configs for env\n  - edit them\n</code></pre>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/","title":"A. Elastic Beanstalk : <code>deployments</code>","text":"<ul> <li>mode of deployments:</li> </ul>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#1-all-at-once","title":"1. All at once","text":"<ul> <li>fastest  deployment</li> <li>issue: has  downtime</li> <li>updates same instance </li> <li>ASG-1[ec1-i1:<code>v1</code>, ec1-i2:<code>v1</code> , ...]</li> <li>ASG-1[]</li> <li>ASG-1[ec1-i1:<code>v2</code>, ec1-i1:<code>v2</code> , ...]</li> <li></li> </ul>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#2-rolling","title":"2 Rolling","text":"<p>fixing: downtime - Long deployment - steps:   - update same instances at a time (by bucket-size),    - once the bucket is healthy, move to next bucket... -    - notice: v1 and v1 - both versions are running - issue:   - rollback takes time   - under capacity</p>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#rolling-with-additional-batches","title":"Rolling (with additional batches)","text":"<p>fixing: under capacity - same like rolling, but application is running with desired capacity   - becoz of additional batch.   - also Small additional cost for a additional batch - </p>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#3-immutable","title":"3 Immutable","text":"<p>fixing: rollback time - steps:   - spins up new instances in a new temporary ASG,    - deploys new version to these new instances,   - then swaps all the instances   - ASG-1[v1,v1,...]   - ASG-temp[v2] --&gt; check health, if ok then rest   - ASG-temp[v2,v2,...]   - swap: ASG-1[v1,v1,... v2,v2,...] &gt;&gt; [ v2,v2,... ] -  - Quick rollback</p>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#4-traffic-splitting","title":"4. Traffic Splitting","text":"<p>fixing : swapping of instance - steps   - ASG-1[v1,v1,...]   - ASG-2[v2,v2,...]   - point ALB to ASG-2 eventually after testing small traffic - very quick automated rollback - - </p>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#99-blue-green-not-direct-feature","title":"99. Blue Green (not direct feature)","text":"<ul> <li>steps:</li> <li>manually create/clone a new beanstalk stage <code>environment</code> (green)</li> <li>deploy new version into green using any of above types(4).</li> <li>Traffic Splitting using <code>R53</code> (dns change)<ul> <li>send a small % of traffic to new deployment</li> </ul> </li> <li>switch over when ready</li> <li></li> <li></li> </ul>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#summary","title":"summary","text":""},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#b-elastic-beanstalk-cli","title":"B. Elastic Beanstalk : <code>CLI</code>","text":"<ul> <li>not in scope of DVA</li> <li>install and gives handy commands <pre><code>\u2022 eb create\n\u2022 eb status\n\u2022 eb health\n\u2022 eb events\n\u2022 eb logs\n\u2022 eb open\n\u2022 eb deploy\n\u2022 eb config\n\u2022 eb terminate\n</code></pre></li> </ul>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#c-elastic-beanstalk-extension","title":"C. Elastic Beanstalk : <code>Extension</code>","text":"<ul> <li>project-root-dir/</li> <li>.ebextensions/<ul> <li>yaml-json-content.config. <code>purpose</code>:</li> <li>modify default config</li> <li>add other resource (under the hood use Cloudformation)  <ul> <li>RDS, </li> <li>DynamoDB, </li> <li>ElastiCache</li> <li>...</li> </ul> </li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#example-set-environment-var","title":"example - set Environment var","text":""},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#e-elastic-beanstalk-migration-manual","title":"E. Elastic Beanstalk : <code>Migration</code> (manual)","text":""},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#example1-migrate-clb-to-alb","title":"example1: migrate CLB to ALB","text":"<p>fact: ELB type cannnot be change once env is created.  - migration step:   - create new environment with ALB, manually   - deploy code again    - DNS swapping to new environment   - delete old env - nothing fancy, but that's the only way. - </p>"},{"location":"01_aws/01_compute/05_2_Beanstalk_DVA-deployments/#example2-decouple-rds","title":"example2: Decouple RDS","text":"<ul> <li>migration step:</li> <li>create new environment</li> <li>deploy code again </li> <li>DNS swapping to new environment</li> <li>delete old env <ul> <li>RDS wont be deleted, since delete protection enabled) </li> </ul> </li> <li>again same step, nothing fancy, </li> <li></li> <li></li> </ul>"},{"location":"01_aws/01_compute/06_ECR/","title":"06 ECR","text":""},{"location":"01_aws/01_compute/06_ECR/#command","title":"command","text":"<p>aws ecr get-login-password --region region |    - docker login    - --username AWS   - --password-stdin <code>aws_account_id.dkr.ecr.region.amazonaws.com</code> - docker push <code>aws_account_id.dkr.ecr.region.amazonaws.com</code>/app-name:latest - docker pull <code>aws_account_id.dkr.ecr.region.amazonaws.com</code>/app-name:latest</p>"},{"location":"01_aws/01_compute/06_ECR/#action","title":"action","text":"<ul> <li><code>ecr:BatchCheckLayerAvailability</code>: </li> <li>Allows the task to check the availability of image layers in an Amazon ECR repository to determine if they already exist.</li> <li><code>ecr:GetDownloadUrlForLayer</code>: </li> <li>Provides the ability to get a pre-signed URL for downloading image layers from Amazon ECR.</li> <li><code>ecr:BatchGetImage</code>: </li> <li>Grants permission to pull images by retrieving metadata and image layers from an Amazon ECR repository.</li> <li><code>ecr:GetAuthorizationToken</code>: </li> <li>Enables the retrieval of an authorization token used to authenticate to an Amazon ECR registry for Docker CLI and other client pull/push operations.</li> </ul>"},{"location":"01_aws/01_compute/07_copilot/","title":"07 copilot","text":""},{"location":"01_aws/01_compute/07_copilot/#-httpsawsgithubiocopilot-cli","title":"- https://aws.github.io/copilot-cli/","text":""},{"location":"01_aws/01_compute/07_copilot/#aws-copilot","title":"AWS copilot","text":""},{"location":"01_aws/01_compute/07_copilot/#intro","title":"intro","text":"<ul> <li>CLI tool for production-ready containerized app to:</li> <li>build </li> <li>release </li> <li> <p>operate  </p> </li> <li> <p>Provisions all required infrastructure for containerized apps (ECS, VPC, ELB, ECR\u2026)</p> </li> <li>cloudformation stack.</li> <li>Automated deployments with one command using CodePipeline</li> <li>Deploy to multiple environments</li> <li>Troubleshooting, logs, health status\u2026</li> </ul>"},{"location":"01_aws/01_compute/07_copilot/#hands-on","title":"hands-on","text":"<ul> <li>check : https://github.com/aws-samples/aws-copilot-sample-service</li> <li>deploy: <pre><code>copilot init --app demo \\\n  --name api \\\n  --type \"Load Balanced Web Service\" \\\n  --dockerfile \"./Dockerfile\" \\\n  --deploy\n</code></pre></li> <li>more commands <pre><code>- copilot init\n- copilot svc init \n- copilot job init \n- copilot pipeline init \n- copilot env init\n</code></pre> <pre><code>- copilot/**service-1**/manifest.yml\n- copilot/**job-1**&gt;/manifest.yml\n- copilot/**environment-1**/manifest.yml\n</code></pre></li> </ul>"},{"location":"01_aws/01_compute/08_AWS_AppConfig%2BCW-evidently_DVA/","title":"AppConfig","text":""},{"location":"01_aws/01_compute/08_AWS_AppConfig%2BCW-evidently_DVA/#intro","title":"Intro","text":"<ul> <li>deploy dynamic configurations independently of any code deployments</li> <li>EC2 instances, Lambda, ECS, EKS\u2026</li> <li>don\u2019t need to restart the application </li> <li>Validate configuration changes before deployment using:</li> <li>JSON Schema (syntactic check) or</li> <li>Lambda Function \u2013 run code to perform validation</li> <li>if failed then  rollback</li> </ul>"},{"location":"01_aws/01_compute/08_AWS_AppConfig%2BCW-evidently_DVA/#cloudwatch-evidently","title":"Cloudwatch Evidently","text":""},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/","title":"Step Function (serverless)","text":"<ul> <li>https://aws.amazon.com/step-functions/</li> </ul>"},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#0-intro","title":"0. intro","text":"<ul> <li>function orchestrator that makes it easy to sequence AWS Lambda functions and multiple AWS services into business-critical applications</li> <li>can create and run a series of checkpointed and event-driven workflows</li> <li>output of one step acts as an input to the next</li> <li>visual workflows</li> <li>Improve resiliency</li> <li>manages state, checkpoints and restarts for you to make sure that your application executes in order and as expected.</li> <li>Built-in try/catch, retry and rollback capabilities deal with errors and exceptions automatically</li> </ul>"},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#1-state-machine","title":"1. State machine","text":"<ul> <li>model workflow as state-machine</li> <li>from workflow studio / console UI</li> <li>create <code>ASL</code> (Amazon State lamguage), json.</li> <li>has states to do some work, like</li> <li></li> <li> </li> <li> <p>type: </p> </li> <li>standard </li> <li>express</li> </ul> <p></p>"},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#2-state","title":"2. state","text":"<ul> <li>type</li> <li><code>pass</code></li> <li><code>choice</code></li> <li><code>wait</code></li> <li><code>parallel</code></li> <li><code>fail</code></li> <li>Activity task <ul> <li>have poll mechanism.</li> <li>activity worker (lambda, ec2, ecs) polls for task (taskToken-1)</li> <li>API : getActivityTask</li> <li>send back : </li> <li>API : sendTaskSuccess / SendTaskfailure<ul> <li>output/error</li> <li>taskToken-1</li> </ul> </li> <li>waits for worker, options:</li> <li>option-1: worker-1, periodically send heardbeat, API: SendtaskHeartBeat<ul> <li>upto 1 year </li> </ul> </li> <li>option-2 : configure <code>TimeOutSecond</code></li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#3-wait-for-task-token","title":"3. wait for task Token","text":"<ul> <li>similar to activity task</li> <li>task --&gt; depend on 3rd app response</li> </ul>"},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#4-error-handing","title":"4. Error handing","text":"<ul> <li>can handle in Application code</li> <li>can handle in state machine using retry and  catch</li> <li>udemy Video ref</li> </ul>"},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#retry","title":"Retry","text":""},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#catch","title":"Catch","text":"<ul> <li>error/exception</li> <li>note: <code>CustomError</code> in screenshot : coming from Application/lambda code <pre><code>\u2022 States.ALL        : matches any error name\n\u2022 States.Timeout    : Task ran longer than TimeoutSeconds or no heartbeat received\n\u2022 States.TaskFailed : execution failure\n\u2022 States.Permissions: insufficient privileges to execute code\n</code></pre></li> <li> </li> <li> <p>resultpath : input to next state</p> </li> <li></li> </ul>"},{"location":"01_aws/01_compute/28_1_STEP_FUNCTION_DVA/#5-security","title":"5. security","text":""},{"location":"01_aws/01_compute/28_2_AppSync_DVA/","title":"AppSync (serverless) : Intro","text":"<ul> <li>overview hands on</li> <li>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/19732102#overview</li> <li>upload GraphQL schema</li> <li>backed by dynamoDB</li> </ul>"},{"location":"01_aws/01_compute/28_2_AppSync_DVA/#use-case","title":"use case","text":"<ul> <li>Retrieve data in real-time with <code>WebSocket</code>  / <code>MQTT on WebSocket</code></li> <li>GraphQL</li> <li>source<ul> <li>NoSQL data stores, </li> <li>Relational databases, </li> <li>HTTP APIs</li> <li>OpenSearch </li> <li>lambda</li> </ul> </li> </ul>"},{"location":"01_aws/01_compute/28_3_Amplify_DVA/","title":"Amplify (serverless)","text":""},{"location":"01_aws/01_compute/28_3_Amplify_DVA/#intro","title":"Intro","text":"<ul> <li>set of tools, for creating :</li> <li>mobile App</li> <li> <p>web application</p> </li> <li> <p>has integrations with :</p> </li> <li><code>storage</code> : dynamoDB, S3</li> <li><code>security</code> : cognito</li> <li><code>API</code> : appsync (GraphQL)</li> <li><code>UI</code> : frontend lib</li> <li><code>ML</code></li> <li><code>Hosting</code> : cloudfront</li> <li><code>testing</code> : Cypress testing framework</li> <li>note: use cloudFormation for provision resource.</li> <li></li> </ul>"},{"location":"01_aws/01_compute/28_3_Amplify_DVA/#amplify-studiovisual-cli","title":"Amplify studio(visual) + CLI","text":"<ul> <li>amplify init</li> <li>amplify add auth</li> <li>amplify add api</li> <li>amplify add hosting</li> </ul>"},{"location":"01_aws/01_compute/28_3_Amplify_DVA/#screenshot","title":"screenshot","text":""},{"location":"01_aws/01_compute/99-Lambda-question/","title":"AWS Lambda Exam Questions","text":""},{"location":"01_aws/01_compute/99-Lambda-question/#multiple-choice-questions","title":"Multiple-Choice Questions","text":"<ol> <li> <p>Which of the following statements about AWS Lambda is true?</p> <ul> <li>A) You must provision EC2 instances to run Lambda functions.</li> <li>B) AWS Lambda scales automatically based on the number of events triggered.</li> <li>C) You are charged for Lambda functions even when they are not in use.</li> <li>D) Lambda functions can only be triggered by S3 events.</li> </ul> </li> <li> <p>What is the maximum execution time for an AWS Lambda function?</p> <ul> <li>A) 5 minutes</li> <li>B) 10 minutes</li> <li>C) 15 minutes</li> <li>D) Unlimited</li> </ul> </li> <li> <p>Which of the following services can trigger an AWS Lambda function? (Select TWO)</p> <ul> <li>A) Amazon S3</li> <li>B) AWS CloudFormation</li> <li>C) Amazon DynamoDB Streams</li> <li>D) Amazon RDS</li> </ul> </li> <li> <p>Which AWS service is best suited to monitor and log AWS Lambda function executions?</p> <ul> <li>A) Amazon CloudFront</li> <li>B) Amazon CloudWatch</li> <li>C) AWS Config</li> <li>D) AWS Inspector</li> </ul> </li> <li> <p>How does AWS Lambda handle scaling?</p> <ul> <li>A) It creates more EC2 instances based on the load.</li> <li>B) It automatically provisions additional Lambda functions as demand increases.</li> <li>C) It requires manual intervention to scale.</li> <li>D) It uses Elastic Load Balancers to distribute requests.</li> </ul> </li> </ol>"},{"location":"01_aws/01_compute/99-Lambda-question/#scenario-based-questions","title":"Scenario-Based Questions","text":"<ol> <li> <p>A company wants to process uploaded images in an Amazon S3 bucket automatically. The images must be resized and saved back to another S3 bucket. Which combination of AWS services should be used?</p> <ul> <li>A) Amazon EC2, Amazon S3, and AWS CLI</li> <li>B) Amazon S3, AWS Lambda, and Amazon CloudWatch</li> <li>C) AWS Lambda, Amazon DynamoDB, and Amazon RDS</li> <li>D) Amazon S3, Amazon Kinesis, and AWS Lambda</li> </ul> </li> <li> <p>You are designing a serverless web application. The application must invoke a backend service using AWS Lambda when API requests are received. Which service would you use to expose the API to clients?</p> <ul> <li>A) Amazon SQS</li> <li>B) Amazon API Gateway</li> <li>C) Amazon SNS</li> <li>D) AWS CloudFormation</li> </ul> </li> <li> <p>A Lambda function has intermittent high latencies when processing requests. What should you check to optimize its performance? (Select TWO)</p> <ul> <li>A) Ensure the function is stateless.</li> <li>B) Increase the memory allocation for the Lambda function.</li> <li>C) Use AWS Step Functions to divide tasks.</li> <li>D) Reduce the number of concurrent executions.</li> </ul> </li> <li> <p>Which AWS Lambda feature allows you to set the amount of memory allocated to a function and automatically allocates proportional CPU power?</p> <ul> <li>A) Memory Tiers</li> <li>B) Execution Tiers</li> <li>C) Provisioned Concurrency</li> <li>D) Memory Allocation Setting</li> </ul> </li> <li> <p>Which of the following best describes AWS Lambda\u2019s pricing model?</p> <ul> <li>A) Fixed monthly fee for unlimited execution</li> <li>B) Pay-per-execution and duration of execution</li> <li>C) Based on the number of EC2 instances provisioned</li> <li>D) Based on storage used in Amazon S3</li> </ul> </li> </ol>"},{"location":"01_aws/01_compute/99-Lambda-question/#truefalse-questions","title":"True/False Questions","text":"<ol> <li> <p>AWS Lambda requires you to manually manage server scaling. True/False</p> </li> <li> <p>You can set environment variables in AWS Lambda to store sensitive information securely. True/False</p> </li> <li> <p>Lambda functions are always stateful and maintain context between invocations. True/False</p> </li> </ol>"},{"location":"01_aws/01_compute/99-Lambda-question/#correct-answers","title":"Correct Answers","text":""},{"location":"01_aws/01_compute/99-Lambda-question/#multiple-choice-questions_1","title":"Multiple-Choice Questions","text":"<ol> <li>B</li> <li>C</li> <li>A, C</li> <li>B</li> <li>B</li> </ol>"},{"location":"01_aws/01_compute/99-Lambda-question/#scenario-based-questions_1","title":"Scenario-Based Questions","text":"<ol> <li>B</li> <li>B</li> <li>A, B</li> <li>D</li> <li>B</li> </ol>"},{"location":"01_aws/01_compute/99-Lambda-question/#truefalse-questions_1","title":"True/False Questions","text":"<ol> <li>False</li> <li>True</li> <li>False</li> </ol> <pre><code>A company uses AWS Lambda for processing data streams from Amazon Kinesis. \nOccasionally, processing times exceed the maximum Lambda execution duration. \nWhat should the company do to handle this?\n\nA) Increase Lambda memory allocation.\nB) Use AWS Step Functions to orchestrate workflows.\nC) Split the stream into smaller shards.\nD) Enable Provisioned Concurrency for Lambda.\n(Answer: B)\n---\nYou need to design a solution where AWS Lambda must securely connect to an \nAmazon RDS instance without hardcoding credentials. What should you use?\n\nA) Store credentials in Lambda environment variables.\nB) Use AWS Secrets Manager to retrieve database credentials at runtime.\nC) Embed credentials in the Lambda function code.\nD) Attach an IAM role to Lambda with database access policies.\n(Answer: B or D, depending on the detailed context.)\n---\nA Lambda function invoked through Amazon API Gateway is experiencing \nhigh latencies due to cold starts. How can you minimize these latencies?\n\nA) Increase the timeout limit for API Gateway.\nB) Use AWS X-Ray to trace cold starts.\nC) Enable Provisioned Concurrency for the Lambda function. **\nD) Increase the function\u2019s memory allocation.\n\nC Provisioned Concurrency ensures that a specific number of execution environments are pre-warmed and ready to process requests.\n</code></pre>"},{"location":"01_aws/02_storage/01_EBS_EFS/","title":"EBS & EFS","text":"<ul> <li>https://chatgpt.com/c/677dbc0a-3414-800d-8960-b0d969c9ffda</li> <li>ebs,efs,Fxs,snowball</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#storage","title":"Storage","text":"<ul> <li>check these 3 aspects:</li> <li><code>size</code> (capacity)</li> <li><code>iops</code> <ul> <li>read iops</li> <li>write iops</li> </ul> </li> <li><code>throughput</code> (MB/s)</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#a-ec2-instant-store-block-storage","title":"A. EC2 instant-store (block-storage)","text":""},{"location":"01_aws/02_storage/01_EBS_EFS/#intro","title":"Intro","text":"<ul> <li>better Read/write iops </li> <li>high-performance hardware disk</li> <li>depends on ec2-i family type.</li> <li></li> <li>risk of data loss if h/w fails </li> <li>manual backup</li> <li>volume size is fixed </li> <li>determined by the EC2 instance type.</li> <li>so dont have option to choose custom instant store </li> <li>fact : AMIs do not preserve instance store data </li> <li>fixed to host machine</li> <li>cannot be detached or reattached</li> <li>can be used as boot volume  not preferred</li> <li>AMI does NOT preserve instance store volumes. </li> <li>only EBS backed AMI </li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#b-ebs","title":"B. EBS","text":""},{"location":"01_aws/02_storage/01_EBS_EFS/#1-intro","title":"1. Intro","text":"<ul> <li>AZ bounded </li> <li>Have volumes</li> <li>network drive (bit latency, same az) + limited performance</li> <li>can be attach/dettach to ec2-i</li> <li>persist data, even after their termination</li> <li>only be mounted to one instance at a time. multiple volumes can be attached. <code>1-2-M</code></li> <li>deleteOnTermination </li> <li>root volume - <code>true</code><ul> <li>if disable it on running app - how ? console or api/cli**</li> </ul> </li> <li>additional ebs volume - <code>false</code></li> <li>use <code>e2label</code> command to change label name</li> <li>scenario:   <pre><code>  - ec2-1 root volume &gt; snapshot-1 &gt; created volume-2 &gt; attached to ec2-2 as additional volume \n  - vol-1 is root vol for ec2-2\n  - re-b0ot ec2-2, it will boot from volume-2, rather than vol-1\n</code></pre></li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#2-ebs-snapshot","title":"2. EBS: snapshot","text":"<ul> <li>Snapshots are incremental backups </li> <li>which means that only the blocks on the device that have changed after your most recent snapshot are saved.</li> <li><code>point in time</code> snapshot.</li> <li>no need to detach volumn while taking snapshot, but recommended.</li> <li>cross az/region restore </li> <li></li> <li> <p>Build an AMI, will also create EBS snapshots </p> </li> <li> <p>store snapshot to archive tier</p> </li> <li>75% cheaper, save cost</li> <li>but restore time 24-72 hrs </li> <li> <p></p> </li> <li> <p>accidental delete </p> </li> <li>setup recycle bin with retention policy (1 day to 1 year)</li> <li> <p></p> </li> <li> <p>Fast Snapshot Restore (FSR)  </p> </li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#3-security","title":"3. Security","text":"<ul> <li>encrypt at rest, both - volume and snapshot using KMS</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#4-types","title":"4. Types","text":"<ul> <li>General Purpose SSD</li> <li>gp2 <ul> <li>size defines iops --&gt; <code>3 iops / GB</code> </li> <li>max --&gt;  <code>16TB | 3K iops | 125 MB/s</code></li> </ul> </li> <li> <p>gp3 </p> <ul> <li>max --&gt;  <code>16TB | 16k iops | 1000 MB/s</code></li> <li>System boot volumes, Virtual desktops, Development and test environments</li> <li>Balanced price/performance for a wide variety of workloads</li> </ul> </li> <li> <p>Provisioned IOPS SSD</p> </li> <li>io1 <ul> <li>max --&gt;  <code>16TB | 64k iops | 1000 MB/s</code></li> </ul> </li> <li> <p>io2 </p> <ul> <li>max --&gt;  <code>64TB | 256k iops | 4000 MB/s</code></li> <li>supports multi attach </li> <li>max - 16 ec2-i</li> <li>databases workloads</li> </ul> </li> <li> <p>HDD</p> </li> <li>dont use as boot volume </li> <li> <p>HDD  / Throughput Optimized HDD / <code>st1</code></p> <ul> <li>max --&gt;  <code>? | 500 iops | max-500 MB/s</code></li> <li>Big Data, Data Warehouses, Log Processing</li> <li></li> </ul> </li> <li> <p>cold HDD  / <code>sc1</code></p> <ul> <li>max --&gt; <code>? | 250 iops | max-250 MB/s</code></li> <li>data that is infrequently accessed</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#general-purpose-ssd-gp3-iops-up-to-16000-iops-throughput-up-to-1000-mbs-use-case-balanced-priceperformance-for-a-wide-variety-of-workloads-provisioned-iops-ssd-io2io2-block-express-iops-up-to-64000-iops-io2-up-to-256000-iops-io2-block-express-throughput-up-to-1000-mbs-io2-up-to-4000-mbs-io2-block-express-use-case-critical-applications-requiring-high-performance-and-reliability-throughput-optimized-hdd-st1-iops-up-to-500-iops-throughput-up-to-500-mbs-use-case-big-data-data-warehouses-and-log-processing-cold-hdd-sc1-iops-up-to-250-iops-throughput-up-to-250-mbs-use-case-infrequently-accessed-data-with-lower-cost-requirements","title":"<pre><code>General Purpose SSD (gp3):\n- IOPS: Up to 16,000 IOPS.\n- Throughput: Up to 1,000 MB/s.\n- Use Case: Balanced price/performance for a wide variety of workloads.\n\nProvisioned IOPS SSD (io2/io2 Block Express):\n- IOPS: Up to 64,000 IOPS (io2), up to 256,000 IOPS (io2 Block Express).\n- Throughput: Up to 1,000 MB/s (io2), up to 4,000 MB/s (io2 Block Express).\n- Use Case: Critical applications requiring high performance and reliability.\n\nThroughput Optimized HDD (st1):\n- IOPS: Up to 500 IOPS.\n- Throughput: Up to 500 MB/s.\n- Use Case: Big data, data warehouses, and log processing.\n\nCold HDD (sc1):\n- IOPS: Up to 250 IOPS.\n- Throughput: Up to 250 MB/s.\n- Use Case: Infrequently accessed data with lower cost requirements.\n</code></pre>","text":""},{"location":"01_aws/02_storage/01_EBS_EFS/#c-efs-regional","title":"C. EFS (regional)","text":""},{"location":"01_aws/02_storage/01_EBS_EFS/#intro_1","title":"Intro","text":"<ul> <li>distributed across an unconstrained number of storage servers.</li> <li>grow elastically to petabyte scale.</li> <li>high availability Managed NFS (network file system)</li> <li>protocol    : NFSv4</li> <li>file system : POXIS-complaint</li> <li>3x times expensive than EBS(gp2), because:</li> <li>no capacity planning<ul> <li>auto-Scale in Size(PB) </li> <li>auto/manual adjust performance.</li> </ul> </li> <li>supports <ul> <li>multi-AZ (Regional)  </li> <li>single AZ</li> <li></li> <li>attach to multiple EC2 ( Linux based AMI only) </li> </ul> </li> <li> <p>high performance </p> <ul> <li>Read - <code>3 GB / s</code></li> <li>Write - <code>1 GB / s</code></li> </ul> </li> <li> <p>use case</p> </li> <li>content management, web serving, data sharing, Wordpress, big data, media processing.</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#storage-class","title":"storage class","text":"<ul> <li>lifecycle policy to move between </li> <li>standard (with One-Zone option as well)</li> <li>Infrequent-Access (with One-Zone option as well) </li> <li>Archive 50% low cost</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#target-mount","title":"Target Mount","text":"<ul> <li>Allows EC2 instances in a VPC to access an EFS file system</li> <li>not needed for lambda.</li> <li>not needed for on-prem  ( if DX/VPN, is setup)</li> <li>configure:</li> <li>Subnet ID</li> <li>Security Groups</li> <li>EFS mount targets are:</li> <li>created per AZ, not per subnet.</li> <li>EFS is not multi-VPC, use VPC peering </li> <li>eg:    ```text<ul> <li>tm-1 create for az-1, and for VPC-1</li> <li>VPC-1 has 3 subnets for az-1  </li> <li>VPC-2 has 3 subnets for az-1</li> <li>Next, VPC-1 --- peer --- VPC-2</li> <li>update security group</li> <li>then can mount EFS on ec2 intance of VPC-2    ```</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#efs-throughput-modes","title":"EFS Throughput Modes","text":"<ul> <li>Bursting Throughput ( default)</li> <li> <p>throughput scales with file system size</p> </li> <li> <p>elastic Throughput</p> </li> <li>throughput scale regardless of size</li> <li> <p>auto-scale with the best performance. (R/recommended)</p> </li> <li> <p>provisioned Throughput</p> </li> <li>manually configure throughput.</li> <li>If your workloads require even higher and consistent throughput</li> <li>allows you to specify the throughput you need, independent of the amount of data stored.</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#efs-performance-mode","title":"EFS Performance Mode","text":"<ul> <li>general-purpose ( default)</li> <li>low-latency operations :)</li> <li>lower throughput</li> <li> <p>and is not ideal for highly parallelized/concurrent big data processing tasks.</p> </li> <li> <p>max I/O </p> </li> <li>Highly <code>parallelized</code> applications and big data workloads that require higher throughput.</li> <li>supports thousands of <code>concurrent</code> connections and higher I/O operations.</li> <li>higher latencies</li> <li>higher throughput</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#summary","title":"Summary","text":"Category Option Description Best For Performance Modes General Purpose Low latency, limited concurrency, fixed throughput per client. Latency-sensitive workloads. Max I/O Higher latency, massive concurrency, elastic throughput scaling. High-concurrency workloads. Throughput Modes Bursting Throughput Default mode; scales with file system size. Variable workloads with spiky demand. Provisioned Fixed throughput, independent of file system size. Consistent high-throughput workloads. Elastic Throughput Automatically scales throughput to match workload needs (Enhanced Mode). Unpredictable or spiky workloads."},{"location":"01_aws/02_storage/01_EBS_EFS/#security","title":"Security","text":"<ul> <li>choose VPC/subnet &gt;  add security group.</li> <li>Encryption at rest using <code>KMS</code> + enable/disable automatic backup</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#dr","title":"DR","text":"<ul> <li>EFS cross region replication : enable. <code>preferrered</code> </li> <li>DataSync also, as alternative.</li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#hands-on","title":"hands on","text":""},{"location":"01_aws/02_storage/01_EBS_EFS/#-create-efs-efs-1-efs-sg-1-ec2-i1-and-i2-launch-instance-attach-efs-1-choose-mount-location-mntefsfs1-aws-automatically-adds-sg-ec2-i1-sg-inbound-rule-typenfs-protocoltcp-port2049-sourceefs-sg-1-similary-outbound-rule-ssh-to-ec2-i1-and-echo-hello-mntefsfs1hellotxt-ssh-to-ec2-i2-and-cat-mntefsfs1hellotxt","title":"<pre><code>- Create EFS `efs-1` + efs-sg-1\n- Ec2-i1 and i2 : launch instance &gt; attach efs-1\n- choose mount location : /mnt/efs/fs1\n- aws automatically adds sg\n    - ec2-i1-sg : inbound rule : Type:NFS, protocol:TCP, port:2049, source:efs-sg-1\n    - similary outbound rule.\n- ssh to ec2-i1 and echo \"hello\" &gt;  /mnt/efs/fs1/hello.txt\n- ssh to ec2-i2 and cat  /mnt/efs/fs1/hello.txt\n</code></pre>","text":""},{"location":"01_aws/02_storage/01_EBS_EFS/#extra","title":"Extra","text":"<ul> <li> <p>price compare <pre><code>Storage Class               Price (per GB)  \n\nEBS General Purpose (gp3)   $0.08\nEBS General Purpose (gp2)   $0.10\nEBS Provisioned IOPS (io1)  $0.125\nEBS Provisioned IOPS (io2)  $0.125\nEBS Magnetic (standard)     $0.05\n\n=== SSD 12 cent , for HDD 5 cent\n\nEFS Standard                $0.30\nEFS Standard-IA             $0.025\nEFS One Zone                $0.16\nEFS One Zone-IA             $0.0133\n\n=== standard 30 cent , IA - 2 cent\n</code></pre></p> </li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#exam","title":"Exam","text":"<ul> <li>EFS with Provisioned Throughput mode <ul> <li>supports concurrent access </li> <li>Provisioned Throughput, Ensures consistent performance for high I/O workloads</li> </ul> </li> <li> <p>DynamoDB </p> <ul> <li>Not optimized for large file storage &amp; high-frequency writes.</li> </ul> </li> <li> </li> <li>every 12 hr screenshot</li> <li>delete older screenshot</li> <li>options:<ul> <li>use event rule schedular &gt; lambda &gt; ...</li> <li>use Amazon Data Lifecycle manager **</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/01_EBS_EFS/#1-need-high-frequency-reading-and-writing-20-mb-file-max-1-tb-total-size","title":"1 need high-frequency reading and writing (20 MB file) max 1 TB total size.","text":""},{"location":"01_aws/02_storage/01_EBS_EFS/#2-ebs-volume-automate","title":"2 EBS volume : automate:","text":""},{"location":"01_aws/02_storage/02_FSx_serverless-FS/","title":"FSx","text":""},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#amazon-fxs-serverless","title":"Amazon FXs (serverless)","text":""},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#1-fxx-intro","title":"1. FXx : Intro","text":"<ul> <li>serverless fileSystem + fully managed</li> <li>high performance FS. </li> <li>multi-AZ  (regional)</li> <li>mount on:</li> <li>on-prem ( for networking : <code>vpn</code> or <code>directConnect</code>)  </li> <li>ec2-instance</li> <li>KMS encrypted.</li> <li>automated backup to S3 </li> </ul>"},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#2-file-system-type-protocol-types","title":"2. File System type +  protocol types","text":"<ul> <li>File System type (4):  Windows File System, Lustre (linux + cluster), ONTAP, OpenZFS</li> <li>protocol types : protocol for communication</li> <li> <p>SMB </p> <ul> <li>Server Message Block</li> <li>network file-sharing protocol</li> <li>read, write, and manage files over a network</li> <li>primarily used in Windows</li> </ul> </li> <li> <p>NTFS</p> <ul> <li>file system developed by Microsoft for the Windows OS</li> </ul> </li> <li> <p>NFS </p> <ul> <li>Network File System </li> <li>distributed file system protocol</li> <li>primarily used in unix/linux</li> <li>Allows multiple clients to access shared directories</li> <li>version</li> <li>NFSv3 Stateless</li> <li>NFSv4 Stateful</li> </ul> </li> <li> <p>Lustre Protocol </p> </li> <li> <p>iSCSI</p> <ul> <li>Internet Small Computer Systems Interface</li> <li>transfer TCP/IP n/w</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#3-fxs-types-4","title":"3. Fxs : Types (4)","text":""},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#fxs-for-windows-file-system","title":"Fxs for <code>Windows File System</code>","text":"<ul> <li>mount on :</li> <li>ec2-i (windows  OS)</li> <li>ec2-i (Unix/Linux OS) </li> <li>supported protocol : <code>SMB</code> , <code>NTFS</code> </li> <li>supported storage option : <code>SSD</code>,  <code>HDD</code></li> <li>support Microsoft\u2019s Distributed File System (DFS) </li> <li> <p>size: <code>100s PB</code> |  iops : <code>in millions</code>   | throughput <code>10 GB/s</code></p> </li> <li> <p>more</p> </li> <li>DR :  <ul> <li>fully managed backups</li> <li>availability : offers single-AZ and <code>multi-AZ</code> deployment options</li> </ul> </li> <li>integrate with <ul> <li>ms AD - self or AWS managed ms AD.</li> <li>ACLs</li> <li>ms DFS : group multiple FS </li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#fxs-for-luster-fs","title":"Fxs for <code>Luster FS</code>","text":"<ul> <li>mount on :<ul> <li>ec2-i (Unix/Linux OS) </li> </ul> </li> <li>supported storage option : <code>SSD</code> , <code>HDD</code></li> <li>supported protocol : <code>Lustre Protocol</code>, <code>POXIS-compliant</code></li> <li> <p>size: <code>100s PB</code> |  iops : <code>in millions</code>   | throughput <code>100s of GB/s with large clister</code></p> </li> <li> <p>More</p> </li> <li>integrate with S3 <ul> <li>transparently presents <code>S3 objects as files</code> and allows you to write changed data back to S3</li> <li>ability to both process the </li> <li>hot data in a parallel and distributed fashion.</li> <li>cold data on Amazon S3</li> </ul> </li> <li>use case <ul> <li>HPC, ||, ML, Modeling</li> </ul> </li> <li>deployment option <ul> <li>scratch : short term storage, 6x faster, <code>no data replication</code></li> <li>persistent : Long term storage: data replication in same AZ</li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#fxs-for-netapp-ontap","title":"Fxs for <code>NetApp ONTAP</code>","text":"<ul> <li>protocol : <code>NFS, SMB, iSCSI</code> </li> <li>OS : W | mac | Linux </li> <li>compression</li> <li>Point-in-time instantaneous cloning</li> <li>compatible with lots of system.</li> <li></li> </ul>"},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#fxs-for-openzfs","title":"Fxs for <code>OpenZFS</code>","text":"<ul> <li>protocol : <code>NFS</code> </li> <li>OS : W | mac | Linux </li> <li>compression.</li> <li>Point-in-time instantaneous cloning</li> <li><code>compatible</code> with lots of system. </li> <li>same as netApp ontap FS.</li> </ul>"},{"location":"01_aws/02_storage/02_FSx_serverless-FS/#exam","title":"Exam","text":"<ul> <li>Check this for comparison: https://aws.amazon.com/fsx/when-to-choose-fsx/ </li> <li></li> <li>FSx :: ontap | ZFS | windows | Luster </li> <li></li> </ul> <p>```text  1.  Amazon FSx for Windows File Server Supported OS: Windows, Linux (via SMB client) Protocols: SMB (2.0, 2.1, 3.0, 3.1.1)</p> <ol> <li> <p>Amazon FSx for Lustre Supported OS: Linux Protocols: Lustre, POSIX-compliant</p> </li> <li> <p>Amazon FSx for NetApp ONTAP Supported OS: Windows, Linux, macOS Protocols: NFS (v3, v4.0, v4.1), SMB (2.0-3.1.1), iSCSI</p> </li> <li> <p>Amazon FSx for OpenZFS Supported OS: Linux, Windows, macOS Protocols: NFS (v3, v4, v4.1) </p> </li> </ol>"},{"location":"01_aws/02_storage/02_snow-family/","title":"AWS snow family","text":""},{"location":"01_aws/02_storage/02_snow-family/#a-snowball-data-migration","title":"A. snowball : Data Migration","text":""},{"location":"01_aws/02_storage/02_snow-family/#a1-snowball-edge-offline","title":"A.1 Snowball <code>Edge</code> (offline)","text":"<ul> <li>Use cases</li> <li>large data cloud migrations, </li> <li>DC decommission, </li> <li> <p>disaster recovery</p> </li> <li> <p>Snowball devices (offline portable devices), max:</p> </li> <li>Snowball Edge Storage Optimized : <code>80 TB | 80  GB RAM | 40 cpu</code></li> <li>Snowball Edge Compute Optimized : <code>42 TB | 416 GB RAM | 104 cpu</code><ul> <li>an optional GPU for use cases such as advanced machine learning and full-motion video analysis.</li> <li>These devices may also be rack mounted and clustered together to build larger, temporary installations </li> <li>can run lambda@edge </li> </ul> </li> <li>post device </li> <li>send/upload to/from:<ul> <li>block volume / EBS</li> <li>object storage / S3 / but not glacier storage class </li> <li></li> </ul> </li> <li>next, transfer over the stable directconnect network to destination acct's s3 / ebs</li> </ul> <p></p>"},{"location":"01_aws/02_storage/02_snow-family/#a2-snowball-cone-offline-online","title":"A.2 Snowball <code>Cone</code> (offline + online)","text":"<ul> <li>Small, portable, light (2 kg) devices</li> <li>type:</li> <li>Snowcone \u2013  <code>8 TB HDD</code>  | <code>4 GB RAM, 2cpu</code></li> <li>Snowcone SSD \u2013 <code>14 TB SSD</code> | <code>4 GB RAM, 2cpu</code></li> <li>send option</li> <li>post device (offline)</li> <li>AWS DataSync (online)<ul> <li>to send/upload data to/from:</li> <li>AWS EBS only </li> <li>not s3  </li> <li>AWS DataSync agent is pre-installed</li> <li>more</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/02_snow-family/#a3-snowball-mobile-offline","title":"A.3 Snowball <code>mobile</code> (offline)","text":"<ul> <li>100 PB + 100 PB + ...  === upto <code>1 exabyte</code> (1 Million TB)</li> <li>driven back to an AWS Region where the data is loaded into  S3 </li> <li>does not offer a storage Clustering option  <pre><code>  - 1024 TB = 1 PB \n  - 1024 PB = 1 exabyte \n  - so it `1000,000 TB` or 1 Million TB\n</code></pre></li> <li>truck with </li> <li>GPS</li> <li>24/7 video surveillance</li> </ul>"},{"location":"01_aws/02_storage/02_snow-family/#summary","title":"summary","text":""},{"location":"01_aws/02_storage/02_snow-family/#b-snow-edge-computing","title":"B. SNOW : Edge computing","text":"<ul> <li>edge : location which can produce data, but limited/no internet connectivity, so cannot compute.</li> <li></li> <li>same device as above.</li> <li>run ec2 + lambda</li> <li>long term deployment +  1 / 3 year saving</li> <li>interact with <code>aws-cli</code> or <code>AWS OpsHub</code>(ui)</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/","title":"S3 Basics","text":""},{"location":"01_aws/02_storage/03_S3-1/#-httpschatgptcomc677dffc9-dd0c-800d-93c3-3b72503bf82e","title":"- https://chatgpt.com/c/677dffc9-dd0c-800d-93c3-3b72503bf82e","text":""},{"location":"01_aws/02_storage/03_S3-1/#sss-simple-storage-service-s3-regional","title":"SSS - Simple storage service / S3 (Regional)","text":""},{"location":"01_aws/02_storage/03_S3-1/#1-s3-intro","title":"1. S3: Intro","text":"<ul> <li>by default, the AWS S3 bucket owner has <code>full access</code> to the bucket and all objects within it </li> <li>infinitely scaling  + highly durable + highly available </li> <li>always return latest version object </li> <li>Also foundation service</li> <li>other services use S3 as an integration </li> <li> <p>main building blocks of AWS</p> </li> <li> <p>bucket-naming convention </p> </li> <li>No uppercase, No underscore</li> <li>3-63 characters long</li> <li>Not an IP</li> <li>Must start with lowercase letter or number</li> <li>Must NOT start with the prefix xn--</li> <li> <p>Must NOT end with the suffix -s3alias</p> </li> <li> <p>performance:</p> </li> <li>latency (low) : <code>100-200 ms</code> </li> <li> <p>throughput : <code>3500-5500 request/sec/prefix</code>  (notice per prefix)</p> </li> <li> <p>upload option</p> </li> <li>S3 directly - slow/internet</li> <li>CF-distribution ==&gt; origin:s3 </li> <li>S3 transfer Acceleration (S3TA) - <code>to/from</code> <ul> <li>Amazon\u2019s high-speed backbone network</li> <li>directs traffic to the nearest edge location</li> <li>don't need to pay, S3TA failed. (which is additional <code>4 cent/GB</code> )</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#2-s3-usecase","title":"2. S3: Usecase","text":"<ul> <li>Hybrid-Cloud-storage </li> <li>Archival</li> <li>Backup (eg: snapshot : ebs,efs,db )</li> <li>...</li> <li>hosting</li> <li>Media,</li> <li>Static website </li> <li>Application/Software delivery</li> <li>DR </li> <li>cross-region-replication, </li> <li>move data from region/az to another then restore.</li> <li>BigData Analytics</li> <li>run Data lakes in s3 </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#3-s3-bucket","title":"3. S3: Bucket","text":"<ul> <li>s3://my-bucket/prefix-1/<code>my_file.txt</code></li> <li> <p>looks like directory but no-concept-of-directory</p> </li> <li> <p>bucket type</p> </li> <li>general-purpose **</li> <li> <p>Directory (New)</p> </li> <li> <p>s3-bucket-1 &gt; properties &gt; access log  --&gt; choose <code>another bucket-2</code> and log-format(default)  </p> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#31-object","title":"3.1. Object","text":"<ul> <li>max size :<code>5TB</code></li> <li>can enable version + replication</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#access-endpoint","title":"access endpoint","text":"<ul> <li>expose s3 object as public access endpoint</li> <li>attach access point policy</li> <li>select object by prefix</li> <li>creates dns entry </li> <li>VPC-endpoint --&gt; s3:access-point --&gt; bucket:selected-object<ul> <li></li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#access-endpoint-with-lambda","title":"access endpoint (with lambda )","text":"<ul> <li>once object is fetch want to run some operation on object using lambda.</li> <li>kind of ETL::transform</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#pre-signed-url","title":"pre-signed URL","text":"<ul> <li>temp access on object</li> <li>generated from UI/cli a Pre-signed URL and share it</li> <li> <p>can set expiry</p> </li> <li> <p></p> </li> <li> <p> </p> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#32-object-storage-classes-green_circle","title":"3.2. Object: Storage Classes :green_circle:","text":""},{"location":"01_aws/02_storage/03_S3-1/#amazon-s3-standard-frequent","title":"Amazon S3 Standard / frequent","text":"<ul> <li>General Purpose </li> <li>highly durable/available.</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#infrequent-access-ia","title":"Infrequent Access (IA)","text":"<ul> <li>low cost</li> <li>usecase - DR-backup/recovery</li> <li>min storage duration : <code>30 days</code></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#one-zone-infrequent-access","title":"One Zone-Infrequent Access","text":"<ul> <li>single-AZ,  low ava</li> <li>min storage duration : <code>30 days</code></li> <li>use case - data which can recreate.</li> <li><code>20% less</code> than S3 Standard-IA.</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#amazon-s3-glacier","title":"Amazon S3 Glacier","text":"<ul> <li>99.999999999% durability</li> <li>low storage cost, but : </li> <li>has longer  - min storage duration</li> <li>plus retrival fee</li> <li>check below</li> <li>retrieval mode</li> <li>Instant Retrieval : <ul> <li>in ms </li> <li>same throughput as in Standard-IA storage classes</li> <li>but, min storage duration : <code>90 days</code></li> </ul> </li> <li>Flexible Retrieval <ul> <li>1-5 min</li> <li>3-5 hr </li> <li>5-12 hr <code>free</code></li> <li>min storage duration : <code>90 days</code></li> </ul> </li> <li> <p>Deep Archive </p> <ul> <li>12-48 hr <code>free</code></li> <li>min storage duration : <code>180 days</code></li> </ul> </li> <li> <p>retrieval policy in aws s3 glacier class for regular and randon retrieval, to save cost ?</p> </li> <li>No retrieval limit : unlimited, costly</li> <li>max retrieval limit : set daily limit in GB</li> <li>free tier : 10% free retrival per month </li> <li>standard : takes3-5 hours, balanced cost and speed</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#amazon-s3-intelligent-tiering","title":"Amazon S3 Intelligent Tiering","text":"<ul> <li>move object b/w tier based on (usage + config)</li> <li>mix of above classes into single</li> <li>can set up an expiration action (to delete) + transitional actions </li> <li>tiers</li> <li><code>Frequent Access</code> tier (automatic): default tier</li> <li><code>Infrequent Access</code> tier (automatic): objects not accessed for 30 days</li> <li><code>Archive Instant Access</code> tier (automatic): objects not accessed for 90 days</li> <li><code>Archive Access tier</code> (optional): configurable from 90 days to 700+ days</li> <li><code>Deep-Archive Access</code> tier (optional): config. from 180 days to 700+ days</li> <li>more</li> <li>on bucketObject (standard GP / Standard IA) --&gt; run s3 analytics --&gt; take 24/28 hrs --&gt; CSV report</li> <li>report gives recommendation <ul> <li>Standard --&gt;  Standard IA </li> <li>observes the infrequent access patterns</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#comparison","title":"comparison","text":"<pre><code>Storage Class                   Price (per GB) === 2 cent\n\nS3 Standard                     $0.023  \nS3 Standard-IA                  $0.0125\nS3 One Zone-IA                  $0.010\nS3 Glacier Instant Retrieval    $0.004\nS3 Glacier Flexible Retrieval   $0.00385\nS3 Glacier Deep Archive         $0.00099\n</code></pre>"},{"location":"01_aws/02_storage/03_S3-1/#zero-day-lifecycle-policy","title":"zero-day lifecycle policy","text":"<ul> <li>AWS recommends using a zero-day lifecycle policy for cases where you want to move objects to a different storage class </li> <li>immediately after they are uploaded to standard-s3.</li> <li>ideal for scenarios like archival storage </li> <li>will be charged for glacier, not standard-s3</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#4-s3-bucket-versioning-green_circle","title":"4. S3 bucket: versioning :green_circle:","text":"<ul> <li>enable for each bucket + UI:showVersion.</li> <li>can roll back to previous version/s</li> <li>protect again un-intended delete.</li> <li>delete:</li> <li><code>delete</code> : adds delete marker.</li> <li><code>delete marker</code> : undo delete.</li> <li>UI: show-version &gt; select version &gt; <code>delete the version</code> : permanent deletes.</li> <li>Once you version-enable a bucket, </li> <li>it can never return to an unversioned state. (disable) </li> <li>but can suspend</li> <li>can apply a retention period to an object version explicitly </li> <li>specify a Retain Until Date for the object version.</li> <li>Different versions of a single object can have different retention modes and periods</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#5-s3-bucket-replication-green_circle","title":"5. S3 bucket: Replication  :green_circle:","text":"<ul> <li>async  </li> <li>enable versioning </li> <li>create replication rule</li> <li>replicate object </li> <li>replicate delete marker(y/n)</li> <li>...</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#facts","title":"facts","text":"<ul> <li>only new object will be replicated.</li> <li>for existing old objects , use S3 Batch replication separately.</li> <li>No chaining</li> <li>having b1 --&gt; b2 | b2 --&gt; b3</li> <li>if obj-1 added in b1, it will be replicated to b2 only.</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#type","title":"Type","text":"<ul> <li>SRR (same region replication)</li> <li>CRR (Cross region replication)</li> <li> <p>single region keys keys) </p> <ul> <li><code>un-encrypted object</code> --&gt; Replicated to region-2</li> <li><code>encrypted object</code> (sse-s3, sse-c) --&gt; Replicated to region-2</li> <li><code>encrypted object</code> (sse-kms) : </li> <li>decrypt with key-region-1</li> <li>Re-encrypt with key-region-2<ul> <li>update  custom policy for your specific access.</li> <li>if using default policy : access already given to all principle in same account.</li> </ul> </li> </ul> </li> <li> <p>keys multi-region kms key</p> <ul> <li><code>un-encrypted object</code> --&gt; Replicated to region-2 : same as abv</li> <li><code>encrypted object</code> (sse-s3, sse-c) --&gt; Replicated to region-2  : same as abv</li> <li><code>encrypted object</code> (sse-kms) </li> <li>same key-1 is present in region-1 and region-2</li> <li>but s3 will treat then as diff keys </li> <li>and, perform <code>decryption and rn-encryption</code> again  </li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#6-s3-jobbatch-yellow_circle","title":"6. S3: Job/batch :yellow_circle:","text":"<ul> <li>Perform bulk operations on existing S3 objects with a single request.</li> <li>Modify object/s metadata, properties, tags, etc</li> <li>manual object/s replication </li> <li>Encrypt un-encrypted objects</li> <li>Modify object ACLs</li> <li>Restore objects from S3 Glacier</li> <li>Invoke Lambda function to perform custom action on each object</li> <li>S3:job</li> <li>Define list of Objects</li> <li>action</li> <li>optional param</li> <li>Flow</li> <li><code>s3:Inventory</code> &gt; <code>s3:Select</code> &gt; <code>S3:Job</code>  &gt; process each object</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#7-s3-event-notification-yellow_circle","title":"7. S3: Event Notification :yellow_circle:","text":"<ul> <li>sends event to target :</li> <li>s3:event --&gt; <code>sns</code></li> <li>s3:event --&gt; <code>Lambda</code> </li> <li>s3:event --&gt; <code>SQS :: Standard-queue</code> (standard only, not fifo)  </li> <li>...</li> <li>s3:event --&gt; EventBridge (filtering) --&gt; target(18+ services)  <ul> <li>archive event</li> <li>replay event</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#8-s3-security","title":"8. S3: Security","text":"<ul> <li>At account level can enable/disable public flag</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#s3-policies","title":"S3 policies","text":"<ul> <li>offer more granular and advanced control for access to both buckets and objects.</li> <li>cross Account access</li> <li>grant users </li> <li>within your AWS Account </li> <li>other AWS Accounts </li> <li>further restrict access to specific resources based on certain condition</li> <li>request time (Date Condition),</li> <li>whether the request was sent using SSL (Boolean Conditions), </li> <li>a requester\u2019s IP address (IP Address Condition), </li> <li>...</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#s3-acls","title":"S3 ACLs","text":"<ul> <li>simpler/basic permissions(R/W/Full) typically on individual objects </li> <li>cross Account access</li> <li>grant users</li> <li>within your AWS Account</li> <li>other AWS Accounts - NO </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#comparison_1","title":"comparison","text":""},{"location":"01_aws/02_storage/03_S3-1/#1-encryption","title":"1. encryption","text":""},{"location":"01_aws/02_storage/03_S3-1/#at-rest","title":"At REST","text":"<ul> <li>server side</li> <li> <p>sse-s3 (default) : </p> <ul> <li>encryption-key provided/owner by <code>aws:s3</code> , </li> <li>http header : \"x-amz-server-side-encryption\": <code>AES-256</code></li> </ul> </li> <li> <p>sse-kms </p> <ul> <li>encryption-key comes from <code>kms</code> </li> <li>http header : \"x-amz-server-side-encryption\": <code>aws:kms</code></li> <li>client create kms-key before.</li> </ul> </li> <li> <p>dsse-kms  2023</p> </li> <li> <p>sse-c : customer provide key (outside aws)</p> <ul> <li>client upload encrypted key</li> </ul> </li> <li> <p></p> </li> <li></li> <li> <p></p> </li> <li> <p>client side encryption</p> </li> <li>outside AWS</li> <li> <p>object enc/decr at client end.</p> </li> <li> <p></p> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#at-transit-tlcssl","title":"At transit (TLC/SSL)","text":"<ul> <li><code>https</code> endpoint --&gt; update bucket policy : deny <code>http</code></li> <li>add s3 bucket policy</li> <li>allow/deny : putObject on bucket-1,  <code>condition: secureTransport=true</code></li> <li></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#2-iam-policy","title":"2. IAM policy","text":""},{"location":"01_aws/02_storage/03_S3-1/#21-user-based-iam-polices","title":"2.1  User-Based IAM polices","text":"<ul> <li>eg:</li> <li>lambda role-1 - add permission for s3:*</li> <li>IAM user - add permission for s3:*</li> <li></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#22-resource-based","title":"2.2 Resource-Based","text":"<ul> <li>S3 Bucket Policies</li> <li>bucket wide rules : effect,principal,Action,resource</li> <li> <p>eg:</p> <ul> <li>allow public access</li> <li>allow cross account access</li> <li>Force objects encryption at upload</li> <li>allow/deny : putObject on bucket-1,  <code>condition : sse-kms=true</code></li> <li>allow/deny : putObject on bucket-1,  <code>condition: secureTransport=true</code></li> <li>...</li> </ul> </li> <li> <p></p> </li> <li> <p></p> </li> <li> <p>ACL</p> </li> <li>03_S3-3-ACL.md</li> <li>Object ACL</li> <li>Bucket ACL</li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#3-s3-mfa-delete","title":"3. S3: MFA-delete","text":"<ul> <li>with root account enable/disable MFA delete <pre><code>aws s3api put-bucket-versioning \n    --bucket &lt;bucket-name&gt; \n    --versioning-configuration Status=Enabled,MFADelete=Enabled    # disabled \n    --mfa \"arn:aws:iam::&lt;account-id&gt;:mfa/&lt;mfa-device&gt; &lt;mfa-code&gt;\"\n</code></pre></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#9-s3-more","title":"9. S3: More","text":""},{"location":"01_aws/02_storage/03_S3-1/#91-s3-transfer-acceleration-s3ta","title":"9.1 S3 Transfer Acceleration (S3TA)","text":"<ul> <li>speed up content transfers to and from Amazon S3 by as much as 50-500% </li> <li>for long-distance transfer of larger objects </li> <li>10 GB+ object up/down globally</li> <li>internally uses:</li> <li>fast AWS private global network/edge-locations</li> <li>CloudFront\u2019s globally distributed Edge Locations and over AWS backbone networks,</li> <li>upload in multipart <ul> <li>if 100MB+ use it,  recommended for 5GB+</li> <li>delete incomplete multi-part</li> </ul> </li> <li></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#92-byte-range-fetch-down","title":"9.2 byte-range fetch (DOWN)","text":"<ul> <li>parallelize GETS to speed up download. can configure how many <code>bytes</code> to read.</li> <li></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#93-server-side-filtering","title":"9.3 server side filtering","text":"<ul> <li>use S3-select + Glacier-Select</li> <li>maximum length of sql query is <code>256 KB</code> </li> <li>filters csv row and column, more like SQL queries. </li> <li></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#94-requester-pay","title":"9.4 requester pay","text":"<ul> <li>network cost on requester</li> <li></li> </ul>"},{"location":"01_aws/02_storage/03_S3-1/#10-s3-static-website-cors","title":"10. S3: static website : <code>CORS</code>","text":"<pre><code>// SPA\n- server-1(ng:SPA) + server-2(api)\n- browser --&gt; server-1\n- browser(ng)--&gt; server-2(api) --&gt; response:header:access-control-allow-Origin=server-1\n\n// S3 static website\n- bucket-1(index.html) + bucket-2(images, other resource, page-1.html)\n   - update bucket policies:  getObject for all * prinicple.\n- browser --&gt; bucket-1\n- browser(index.html) --&gt; ajax::fetch(bucket-2/page-1.html) --&gt; bucket-2 --&gt; will work, only CORS is enabled to bucket-1 as origin \n- bucket-2 &gt; permission tab &gt; edit CORS &gt; add json:origin-bucket-1\n</code></pre>"},{"location":"01_aws/02_storage/03_S3-1/#99-s3-hands-on","title":"99. S3: hands on","text":"<pre><code>  - create bucket - bucket-1-us-west-2, will be created in all AZ.\n  - disable : ACL, , versioning\n  - enable : public access + attach BUCKET POLICIES (read from any principle, resource:*)\n  - encryption: SSE-S3 *, SSE-KMS, DSSE-KMS\n  - upload png file\n  - https://bucket-1-us-west-2.s3.us-west-2.amazonaws.com/Screenshot+2024-07-16+002401.png\n  - inspect : \n      - Open link --&gt; `s3 pre-signed url`, credential-info are encode in url.\n      - access with public-url :  failed | ok after making public.\n  - static website hoisting : enable on bucket + index.html\n    - endpoints: https://bucket-1.s3-website.region.amazon.com\n\n  // Replication\n  - create another  buvket-2-us-west-1\n  - create replication rule:\n    - add target bucket : bucket-1-us-west-2\n    - enable versionsing\n    - craete new IAM\n\n  // storage classes:\n  - bucket-1 &gt; mgt &gt; create Life Cycle rule\n    - select object: ALL /  by-prefix/suffix / by-tag\n    - create transistion Rule/s\n      - rule-1 : move from class1 to clas2 after xxdays\n      - ...\n      - ... \n    - -create deletion Rule/s\n      - delete old version/s\n      - delete all version/s\n      - mark for delete\n</code></pre>"},{"location":"01_aws/02_storage/03_S3-2-more/","title":"S3 continue...","text":""},{"location":"01_aws/02_storage/03_S3-2-more/#1-s3-glacier-object-vault-lock-yellow_circle","title":"1. S3 Glacier object : Vault lock :yellow_circle:","text":"<ul> <li>WORM policy : write once, read many.</li> <li>set <code>retention period</code>, can be extend.</li> <li>set (optional) <code>legal hold</code> : lock indefinitely. (irrespective of retention-period)</li> <li><code>usecase</code>: data retention. and compliance</li> <li><code>lock</code> object in glacier storage class.</li> <li>retention mode:</li> <li><code>compliance</code> --&gt; no longer be deleted/updated in the future, not even by root.</li> </ul>"},{"location":"01_aws/02_storage/03_S3-2-more/#2-s3-object-lock","title":"2. S3 object lock","text":"<ul> <li>WORM policy.</li> <li>set <code>retention period</code>, can be extend.</li> <li>set (optional) <code>legal hold</code> : lock indefinitely. (irrespective of retention-period)</li> <li>retention mode:</li> <li><code>compliance</code> --&gt; no longer be deleted/updated in the future, not even by root.<ul> <li>only way to delete, delete account itself. </li> </ul> </li> <li><code>Governance</code> --&gt; root user can update/delete.</li> </ul>"},{"location":"01_aws/02_storage/03_S3-2-more/#3-storage-lens-service-yellow_circle","title":"3. Storage lens service  :yellow_circle:","text":"<ul> <li>Understand, analyze, and <code>optimize</code> storage across entire <code>AWS Organization</code> (acct &gt; region &gt; bucket)</li> <li><code>dashboard</code> : enable by default/cant delete.</li> <li>aggregated reports/csv gernerted by specific metric --&gt; can publish to CW for free.</li> <li><code>advance</code> metric (available for 15 month), paid</li> <li><code>free</code> metric (available for 14 day, once generated)</li> <li> <p>metric/s :</p> <ul> <li><code>summary</code> metric : insight to object -size, count, fastest growing bucket, etc</li> <li><code>cost-optimization</code> metric : insight to non-current, incomplete multiparts, etc</li> <li><code>Data protection</code> metric: count of encrypted Bucket, replication rule</li> <li><code>Access-mgt</code> : object owner</li> <li><code>event</code> metric : s3-eventNotification count, etc</li> <li><code>Activity</code> + <code>statusCode</code> : GET, POST, etc +   count of 200, 404, etc</li> <li><code>performance</code> : s3 transfer acce enable count</li> </ul> </li> <li> <p></p> </li> </ul>"},{"location":"01_aws/02_storage/03_S3-2-more/#4-cli","title":"4. CLI","text":""},{"location":"01_aws/02_storage/03_S3-2-more/#s3-sync-command","title":"S3 sync command","text":"<ul> <li>one-time copy of data </li> <li>uses the CopyObject APIs to copy objects between Amazon S3 buckets. </li> <li>lists the source and target buckets to identifies:</li> <li>missing objects.</li> <li>objects that have different LastModified dates </li> <li>The sync command on a versioned bucket copies </li> <li>only the current version of the object </li> <li>previous versions aren't copied.</li> <li>By default, this preserves object metadata, NOT ACL </li> <li>but the access control lists (ACLs) are set to FULL_CONTROL for your AWS account,</li> <li>which removes any additional ACLs. </li> <li>If the operation fails, you can run the sync command again without duplicating previously copied objects.</li> <li><code>aws s3 sync s3://DOC-EXAMPLE-BUCKET-SOURCE s3://DOC-EXAMPLE-BUCKET-TARGET</code></li> </ul>"},{"location":"01_aws/02_storage/03_S3-2-more/#putobject","title":"PutObject","text":"<ul> <li>include header : <code>x-amz-server-side-encryption : AES256|aws:kms</code>  to encrypt.</li> <li>include header : <code>aws:SecureTransport</code> : allow HTTPS  , not HTTP</li> </ul>"},{"location":"01_aws/02_storage/03_S3-2-more/#5-static-website","title":"5. static website","text":"<ul> <li>url format: </li> <li>http://bucket-name.s3-website.Region.amazonaws.com</li> <li>http://bucket-name.s3-website-Region.amazonaws.com<ul> <li>notice <code>http</code>. dont support <code>https</code> directly.</li> <li>Alternative: CF:distribution with ACM and s3 website as origin</li> </ul> </li> <li>Direct R53 Alias to S3 Website Endpoint--&gt; \u274c Not possible</li> <li>S3 website endpoints are not AWS resources</li> <li>Instead, use a CNAME record pointing to the S3 website endpoint. </li> </ul>"},{"location":"01_aws/02_storage/03_S3-2-more/#6-searchlist-s3-onject-fast","title":"6. search/list s3 onject fast","text":""},{"location":"01_aws/02_storage/04_Storage_gateway/","title":"Storage Gateway","text":""},{"location":"01_aws/02_storage/04_Storage_gateway/#1-intro","title":"1. Intro","text":"<ul> <li>provides local cache </li> <li>high throughput </li> <li>low latency </li> <li>purpose </li> <li>hybrid storage </li> <li>migration </li> <li>DR and backup</li> <li>gateway is supposed to be installed on on-prem datacenter </li> <li>order gateway Hardware appliance</li> <li>it has required CPU, memory, n/w, etc</li> </ul>"},{"location":"01_aws/02_storage/04_Storage_gateway/#2-type-3","title":"2. Type (3)","text":""},{"location":"01_aws/02_storage/04_Storage_gateway/#21-file-gateway","title":"2.1 File gateway","text":"<ul> <li>NFS or SMB </li> <li><code>s3</code>(1 cent /per, cheap) and <code>FSx for windows</code> (70 cent / hr) </li> <li></li> <li></li> </ul>"},{"location":"01_aws/02_storage/04_Storage_gateway/#22-volume-gateway","title":"2.2 Volume gateway","text":"<ul> <li>iSCSI</li> <li>Types:</li> <li><code>Gateway-Cached Volumes</code>: Primary data storage is in Amazon S3, with frequently accessed data cached locally.</li> <li><code>Gateway-Stored Volumes</code>: Primary data storage is on-premises, with cloud-based backup.</li> <li></li> </ul>"},{"location":"01_aws/02_storage/04_Storage_gateway/#23-tap-gateway","title":"2.3  Tap gateway","text":"<ul> <li>tap : physical tapes, drive</li> <li>enables to replace using physical tapes on-premises with virtual tapes in AWS without changing existing backup workflows.</li> <li>encrypts data + compress data.</li> <li>iSCSI VTL ( virtual tap library)</li> <li></li> </ul>"},{"location":"01_aws/02_storage/04_Storage_gateway/#exam-scenario","title":"Exam scenario","text":"<ul> <li>gateway vs Datasync</li> <li></li> <li> </li> <li> <p>comparison: <pre><code>DMS:               Best for live database migrations with minimal downtime.\nDataSync:          Used for file-based data transfers, not databases.\nStorage Gateway:  For hybrid cloud storage, not database migrations.\n</code></pre></p> </li> </ul>"},{"location":"01_aws/02_storage/05_transferFamily%2BDataSync/","title":"05 transferFamily+DataSync","text":""},{"location":"01_aws/02_storage/05_transferFamily%2BDataSync/#a-ftp-aws-transfer-family3","title":"A. FTP : AWS Transfer Family(3)","text":"<ul> <li>SFTP / FTPS (outside AWS) </li> <li>FTP with in AWS/VPC</li> <li>expose s3/EFS over FTP protocol </li> </ul>"},{"location":"01_aws/02_storage/05_transferFamily%2BDataSync/#b-aws-datasync","title":"B. AWS DataSync","text":"<ul> <li>scheduled continuous data sync</li> <li>hourly</li> <li>daily </li> <li>weekly </li> <li>...</li> <li>can create in opposite direction as well  </li> <li>Move large amount of data/files to and from </li> <li>On-prem(install datasync-agent) and aws <ul> <li>10 Gbps</li> <li>use multiple agent for more speed</li> <li></li> </ul> </li> <li> <p>AWS to AWS (no agent)</p> <ul> <li></li> </ul> </li> <li> <p>target NO EBS </p> </li> <li> <p>more:</p> </li> <li>File permissions and metadata are <code>preserved</code></li> <li>protocol: NFS and SMB </li> <li>TLS</li> <li> <p>save n/w cost with snowcone</p> </li> <li> <p>Network perspective </p> </li> <li>Direct Connect \u2705 \u2013 Supported. DataSync can transfer data over AWS Direct Connect for faster, private transfers.</li> <li>Site-to-Site VPN \u2705 \u2013 Supported. DataSync can run over a VPN tunnel for secure data transfers between on-prem and AWS.</li> <li> <p>Internet \u2705 \u2013 Supported. By default, DataSync uses the public internet with encryption for transfers between on-prem storage and AWS.</p> </li> <li> <p>fact:</p> </li> <li>cannot open locked file</li> <li>file is opened and modified, while sysnc<ul> <li>it will detect Data inconsistency during VERFYING stage.</li> </ul> </li> <li>above 2 files will be skipped/ found missing then </li> </ul>"},{"location":"01_aws/02_storage/06_AppFlow/","title":"06 AppFlow","text":""},{"location":"01_aws/02_storage/06_AppFlow/#aws-appflow","title":"AWS AppFlow","text":"<ul> <li>securely transfer data between SaaS applications (like Salesforce, SAP, Slack) and AWS services (S3, Redshift, etc.) without writing custom code.</li> <li>Schedule or trigger data flows without manual intervention.</li> <li>Process and transform data  using :<ul> <li>Lambda</li> <li>custom mappings</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/06_AppFlow/#use-case","title":"use case","text":"<ul> <li> <p>SaaS to AWS    \u2013 Sync data from Salesforce, Google Analytics, Zendesk, etc., to S3, Redshift, or EventBridge.</p> </li> <li> <p>AWS to SaaS    \u2013 Push data from S3 or DynamoDB to applications like Salesforce.</p> </li> <li> <p>When NOT  to Use :</p> <ul> <li>For large-scale ETL pipelines \u2192 Use AWS Glue or Step Functions.</li> <li>For real-time streaming \u2192 Use Kinesis or EventBridge instead.</li> </ul> </li> </ul>"},{"location":"01_aws/02_storage/99_summary/","title":"Quick Summary on All storage options","text":"<ul> <li><code>S3</code>: Object Storage</li> <li><code>S3 Glacier</code>: Object Archival</li> <li><code>EBS volumes</code>: Network storage for one EC2 instance at a time</li> <li><code>EC2 Instance Storage</code>: Physical storage for your EC2 instance (high IOPS)</li> <li><code>EFS</code>: Network File System for Linux instances, POSIX filesystem</li> <li><code>FSx</code><ul> <li>FSx for Windows: Network File System for Windows servers</li> <li>FSx for Lustre: High Performance Computing Linux file system</li> <li>FSx for NetApp ONTAP: High OS Compatibility</li> <li>FSx for OpenZFS: Managed ZFS file system</li> </ul> </li> <li><code>Storage Gateway</code>: S3 &amp; FSx File Gateway, Volume Gateway (<code>cache &amp; stored</code>), Tape Gateway</li> <li><code>Transfer Family</code>: FTP, FTPS, SFTP interface on top of Amazon S3 or Amazon EFS</li> <li><code>DataSync</code>: Schedule data sync from on-premises to AWS, or AWS to AWS</li> <li><code>Snowcone / Snowball / Snowmobile</code>: to move large amount of data to</li> <li><code>Database</code>: for specific workloads, usually with <code>indexing and querying</code></li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/","title":"00 quickOverview","text":"<ul> <li>reference:</li> <li>https://chatgpt.com/c/675945a8-f8b8-800d-a789-e07e6db38e8d</li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#a-choosing-right-database","title":"A. Choosing Right database","text":""},{"location":"01_aws/03_database/00_quickOverview/#data-model","title":"<code>Data model</code>","text":"<ul> <li>RDBMS / NoSQL</li> <li>Joins? Structured? Semi-Structured?</li> <li>Strong schema? More flexibility?</li> <li>Reporting? Search?</li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#performance","title":"performance","text":"<ul> <li>Throughput, </li> <li>Read-heavy, write-heavy, balanced workload</li> <li>Latency requirements</li> <li>Concurrent users?</li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#size","title":"Size","text":"<ul> <li>How much data to store and for how long? </li> <li>Will it grow? </li> <li>Average object size?</li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#availability-global-db","title":"availability (global DB)","text":"<ul> <li>replicate</li> <li>DR Support</li> <li>backup/recovery</li> <li>Aurora and DynamoDB are global database</li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#security","title":"Security","text":"<ul> <li>MySQL + Postgres has IAM role based security</li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#cost","title":"cost","text":""},{"location":"01_aws/03_database/00_quickOverview/#-","title":"-","text":""},{"location":"01_aws/03_database/00_quickOverview/#b-aws-database-offerings","title":"B. AWS Database Offerings","text":""},{"location":"01_aws/03_database/00_quickOverview/#b1-relational-databases","title":"B.1 Relational Databases","text":"<p>Relational databases are designed to handle structured data with predefined schemas and support SQL queries.</p>"},{"location":"01_aws/03_database/00_quickOverview/#1-amazon-rds-relational-database-service","title":"1. Amazon RDS (Relational Database Service)","text":"<ul> <li>Fully managed relational database service.</li> <li>Supports multiple database engines:<ul> <li>MySQL</li> <li>PostgreSQL</li> <li>MariaDB</li> <li>Oracle</li> <li>Microsoft SQL Server</li> </ul> </li> <li>Features:<ul> <li>Automated backups and snapshots.</li> <li>High availability with Multi-AZ deployments.</li> <li>Read replicas for scalability.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#2-amazon-aurora","title":"2. Amazon Aurora","text":"<ul> <li>High-performance, fully managed relational database service.</li> <li>Compatible with:<ul> <li>MySQL</li> <li>PostgreSQL</li> </ul> </li> <li>Features:<ul> <li>Up to 5x performance of standard MySQL and 3x performance of standard PostgreSQL.</li> <li>Automatic scaling.</li> <li>Fault-tolerant and self-healing</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#b2-non-relational-databases","title":"B.2 Non-Relational Databases","text":"<p>Non-relational databases are designed for unstructured or semi-structured data and support a variety of access patterns.</p>"},{"location":"01_aws/03_database/00_quickOverview/#1-amazon-dynamodb","title":"1. Amazon DynamoDB","text":"<ul> <li>Fully managed NoSQL database service.</li> <li>Key-value and document database.</li> <li>Features:<ul> <li>Single-digit millisecond performance.</li> <li>Serverless with auto-scaling.</li> <li>Integrated with DynamoDB Streams for event-driven architecture.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#2-amazon-elasticache","title":"2. Amazon ElastiCache","text":"<ul> <li>Fully managed in-memory data store.</li> <li>Supports:<ul> <li>Redis</li> <li>Memcached</li> </ul> </li> <li>Features:<ul> <li>Ultra-low latency.</li> <li>Ideal for caching, session management, and real-time analytics.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#3-amazon-neptune","title":"3. Amazon <code>Neptune</code>","text":"<ul> <li>Fully managed graph database service.</li> <li>relation b/w dataset</li> <li>optimized for:<ul> <li>storing billions of relationships</li> <li>querying the graph with milliseconds latency</li> </ul> </li> <li>Supports:<ul> <li>Property Graph</li> <li>RDF (Resource Description Framework)</li> </ul> </li> <li>more:<ul> <li>High performance and scalability.</li> <li>Neptune is secure with support for HTTPS encrypted client connections </li> <li>highly available, with read replicas, point-in-time recovery, continuous backup to Amazon S3, and replication across AZ.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#4-amazon-documentdb-with-mongodb-compatibility","title":"4. Amazon <code>DocumentDB</code> (with MongoDB compatibility)","text":"<ul> <li>Fully managed document database service.</li> <li>store, query, and index JSON data</li> <li>it does not have an in-memory caching layer </li> <li>Compatible with MongoDB.</li> <li>Features:<ul> <li>Purpose-built for JSON workloads.</li> <li>High availability and durability.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#5-amazon-keyspaces-for-apache-cassandra","title":"5. Amazon <code>Keyspaces</code> (for Apache Cassandra)","text":"<ul> <li>Fully managed Cassandra-compatible database service.</li> <li>Features:<ul> <li>Serverless.</li> <li>Handles large-scale, time-series data.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#6-amazon-timestream","title":"6. Amazon <code>Timestream</code>","text":"<ul> <li>Fully managed time-series database service.</li> <li>serverless</li> <li>store trillions of records</li> <li>faster and cost-effective compare to RDBMS </li> <li>integrated with :</li> <li>Data collection service: <code>KDS</code>, <code>MSK</code>, opensource tools, et</li> <li><code>Sagemaker</code>.</li> <li>Features:<ul> <li>Optimized for IoT and operational applications.</li> <li>Query and analyze time-series data efficiently.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#7-amazon-qldb-quantum-ledger-database","title":"7. Amazon <code>QLDB</code> (Quantum Ledger Database)","text":"<ul> <li>Fully managed ledger database.</li> <li>Features:<ul> <li>Immutable and cryptographically verifiable transaction logs.</li> <li>Ideal for applications requiring an authoritative data source.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#b3-hybrid-solutions","title":"B.3 Hybrid Solutions","text":""},{"location":"01_aws/03_database/00_quickOverview/#1-aws-database-migration-service-dms","title":"1. AWS Database Migration Service (DMS)","text":"<ul> <li>seamlessly migrate data <code>from</code> supported sources <code>to</code> :</li> <li>relational databases,</li> <li>data warehouses,</li> <li>streaming platforms (KDS,MSK)  </li> <li>and other data stores in AWS cloud.</li> <li>more:</li> <li>Continuous Data Replication</li> <li>Supports migrations between relational and non-relational databases. </li> <li>source database remains fully operational during the migration</li> <li>minimizing downtime to applications that rely on the database.</li> <li>sources:</li> <li>relational/non-relational databases</li> <li>S3</li> <li>...</li> <li>usecase </li> <li>S3 --&gt; DMS --&gt; KDS,MSK </li> </ul>"},{"location":"01_aws/03_database/00_quickOverview/#summary-table","title":"Summary Table","text":"Database Service Type Use Case Amazon RDS Relational General-purpose SQL workloads Amazon Aurora Relational High-performance SQL workloads Amazon DynamoDB Non-Relational Key-value and document storage Amazon ElastiCache Non-Relational Caching and session management Amazon Neptune Non-Relational Graph-based queries Amazon DocumentDB Non-Relational JSON document storage Amazon Keyspaces Non-Relational Cassandra-compatible workloads Amazon Timestream Non-Relational Time-series data Amazon QLDB Non-Relational Ledger use cases <p>This document outlines the core relational and non-relational database offerings from AWS, highlighting their use cases and features.</p> <p></p>"},{"location":"01_aws/03_database/01_RDS/","title":"RDS","text":""},{"location":"01_aws/03_database/01_RDS/#-httpschatgptcomc675945a8-f8b8-800d-a789-e07e6db38e8d","title":"- https://chatgpt.com/c/675945a8-f8b8-800d-a789-e07e6db38e8d","text":"<ul> <li>AWS RDBMS offering </li> <li>Option-1 : <code>on EC2</code><ul> <li>Provision Ec2</li> <li>install RDBMS and maintain it (os patching, security update, etc)</li> </ul> </li> <li>Option-2 : AWS <code>Aurora</code></li> <li>Option-3 : AWS <code>RDS</code> </li> </ul>"},{"location":"01_aws/03_database/01_RDS/#rds","title":"RDS","text":""},{"location":"01_aws/03_database/01_RDS/#intro","title":"Intro","text":"<ul> <li>not serverless</li> <li>regional</li> <li>RDBMS | OLTP</li> <li>migrate to Aurora </li> <li>involves significant systems administration effort</li> <li>2 options: custom + fully manages</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#rds-custom-yellow_circle","title":"RDS :: custom :yellow_circle:","text":"<ul> <li>RDS does not allow you to access the host OS of the database</li> <li>use RDS custom </li> <li>allow some customization capabilities of underlying DB and OS (limited)  </li> <li>only for <code>SQL server</code> and <code>oracle</code> DB.</li> <li>First disable automation mode, take snapshot, then access it.</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#rds-fully-managed-green_circle","title":"RDS :: fully managed :green_circle:","text":"<ul> <li>Automates  below administrative tasks :</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#1-hardware-provisioning","title":"1. hardware provisioning","text":"<ul> <li>choose EBS volume type:</li> <li><code>gp2</code></li> <li><code>io1</code></li> <li>choose RDS ec2 instance s : </li> <li>compute family size</li> <li>no access/ssh</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#2-database-setup","title":"2. database setup","text":"<ul> <li>choose Supported engine:</li> <li>Postgres, MySQL, MariaDB, Oracle, Microsoft SQL Server, IBM DB2</li> <li>Aurora (AWS Proprietary database, not open source)</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#3-high-availability","title":"3. High Availability","text":"<ul> <li>choose availability</li> <li>setup single-AZ (default) </li> <li>setup mutli-AZ<ul> <li>fault tolerance</li> <li>SYNC replication b/w instance in diff AZ. </li> </ul> </li> <li>fact: Multi-AZ keeps the same connection endpoint url for all instance in AZ  </li> <li>easily switch from Single-AZ to multi-AZ  </li> </ul>"},{"location":"01_aws/03_database/01_RDS/#4-patching","title":"4. patching","text":"<ul> <li> <p>Auto OS patching :: in maintenance window. <pre><code>- Scenario : in Mutli-AZ setup :dart:\n  - a. primary and standby, both will upgrade at same time with downtime ? ****\n  - b. first primary, then standby. no downtime ?\n  - c. first standby, then primary. no downtime ?\n</code></pre></p> </li> <li> <p>Running a DB instance as a Multi-AZ deployment can further reduce the impact of a maintenance <pre><code>- Perform maintenance on the standby.\n- Promote the standby to primary.\n- Perform maintenance on the old primary, which becomes the new standby.\n</code></pre></p> </li> </ul>"},{"location":"01_aws/03_database/01_RDS/#5-scalability","title":"5. Scalability","text":""},{"location":"01_aws/03_database/01_RDS/#instancescale-vertical","title":"instance::scale (vertical)","text":"<ul> <li>Scaling involves resizing instances</li> <li>which may require downtime.</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#instancescale-horizontal-read-replica","title":"instance::scale (horizontal) - read replica","text":"<ul> <li>Not built-in scaling </li> <li>but can manually create - <code>ASG</code> and <code>CW:alarm</code> on these <code>metric</code>:<ul> <li>connection count </li> <li>cpu utilization</li> <li>READ/WRITE traffic</li> <li>...</li> </ul> </li> <li> <p>or, manually create read replication anytime.</p> </li> <li> <p>READ replica</p> </li> <li>each Read Replicas add new endpoints URL, with their own DNS name <ul> <li>use case: </li> <li>analytics application</li> <li>can run Analytics</li> </ul> </li> <li>each Read Replica is associated with a priority tier (0-15).  <ul> <li>In the event of a failover, Amazon Aurora will promote the Read Replica that has the highest priority.</li> <li>If two or more Aurora Replicas share the same priority, then Amazon RDS promotes the replica that is largest in size</li> <li>eg:  tier-1 (16 terabytes), tier-1 (32 terabytes), tier-10 (16 terabytes), tier-15 (16 terabytes), tier-15 (32 terabytes)</li> </ul> </li> <li>Also, can promote as primary in DR, if stand-by not provisioned.</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#underlying-storage","title":"Underlying Storage","text":"<ul> <li>define: </li> <li>threshold ( maz-size in GB ) </li> <li>trigger  eg: free space &lt; 10%, space runs last 5min, etc.</li> <li>good for unpredictable workloads</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#6-dr-support","title":"6. DR support","text":""},{"location":"01_aws/03_database/01_RDS/#option-1-pitr","title":"option-1: PITR","text":"<ul> <li>Point in Time Restore </li> <li>Continuous backups happens and goes to s3</li> <li>can retore these backup to new database instance.</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#option-2-stand-by-replica","title":"option-2: Stand-by replica","text":"<ul> <li>manually enable Multi AZ-setup for DR. </li> <li>master-writer-DB (az-1) --&gt; <code>SYNC replica/free</code> --&gt; Stand-by-DB (az-2)</li> <li>Automatic fail-over from master to standby in DR situation. :dart</li> <li>R53 CNAME record will be updated to point to the standby database.  <pre><code>  - R53 failover-record for RDS url1. \n    - url1 -x-&gt; primary/active\n    - url1 --active--&gt; secondary/passive \n</code></pre></li> </ul>"},{"location":"01_aws/03_database/01_RDS/#option-3-promote-read-replica","title":"option-3: Promote Read replica","text":"<ul> <li>cross-region-read replicas, is also possible : paid</li> <li>promote any READ replica as main DB later based on priority and size</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#7-security","title":"7. Security","text":""},{"location":"01_aws/03_database/01_RDS/#encryption","title":"Encryption","text":"<ul> <li><code>At-rest</code> encryption:</li> <li>Database master &amp; replicas encryption using AWS KMS</li> <li>If the master is not encrypted, the read replicas cannot be encrypted</li> <li>To encrypt an un-encrypted database, go through a DB snapshot &amp; restore as encrypted</li> <li>can only enable encryption for an Amazon RDS DB instance when you create it, not after the DB instance is created </li> <li><code>In-flight</code> encryption: </li> <li>TLS-ready by default, use the <code>AWS TLS root certificates</code> client-side.</li> <li>use the same <code>domain-name-1</code> for both the certificate and the CNAME record in Route 53.</li> <li>Export cert in ACM </li> <li>when create/modify RDS instance, configure it use custom  cname <code>domain-name-1</code>.</li> <li>RDS support TDE (transparent Data encryption) with Oracle  and SQL </li> <li>integrated with CloudHSM (store keys in single tenant hardware module.) 10_HSM_DVA.md</li> <li>key managed by AWS</li> <li>automatic Encryption/decry..</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#iam-authentication","title":"IAM Authentication","text":"<ul> <li>works with MySQL and PostgreSQL </li> <li>token has a lifetime of <code>15 minutes</code></li> <li>can use <code>IAM roles</code> to ec2-i, to connect to your database (instead of username/pw). eg:<ul> <li>ecs (role-1) --&gt; rds</li> <li>lambda (role-1) --&gt; rds</li> </ul> </li> <li>or, create one time <code>password/token</code> after cluster creation</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#security-groups","title":"Security Groups","text":"<ul> <li>Control Network access to your RDS / Aurora DB</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#8-db-backup","title":"8 DB backup","text":"<ul> <li>for automatic bkp , retention 1 to 35</li> <li>for manual, retention - as long we want for maul backup.</li> <li>on-prem MySQL/postgres DB --&gt; create db-dumps( <code>Percona XtraBackup</code>) --&gt; place in S3 --&gt; then restore.</li> <li>with automated backups, I/O activity is no longer suspended, since backups are taken from the standby </li> </ul>"},{"location":"01_aws/03_database/01_RDS/#9-cloning","title":"9 cloning","text":"<ul> <li>faster than backup &gt; restore</li> <li>uses <code>copy-on-write</code> - use same volume + for new changes additional storage allocated and data copied to it.</li> <li>use case: create test env from prod instance.</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#4-more","title":"4. more","text":""},{"location":"01_aws/03_database/01_RDS/#41-rds-proxy","title":"4.1 RDS proxy","text":"<ul> <li>pools open connections.</li> <li>reduces fail-over time by 66%</li> <li>access privatey only</li> <li>client --&gt; RDS proxy --&gt; RDs instance</li> <li></li> </ul>"},{"location":"01_aws/03_database/01_RDS/#42-performance","title":"4.2 performance","text":"<ul> <li>Uses SSD-based storage.</li> <li><code>write instance DB</code> + <code>Read replica/s</code> for improved read performance.</li> <li>Up to 15 READ replica/s</li> <li>within AZ, or</li> <li>cross-AZ, or</li> <li>cross-region (paid replication)</li> <li>main-DB --&gt; <code>A-SYNC replication (free within region)</code> --&gt; Read Replicas</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#43-rdspricing","title":"4.3 RDS::pricing","text":"<ul> <li>Charged based on instance class and storage used.</li> <li>standby instance</li> <li>read replica</li> <li>inbound data transfer is free.</li> <li>Outbound data transfer is charged based on the volume of data transferred outside of AWS</li> <li> <p>replication charge: <code>cross-region only</code> </p> </li> <li> <p>Cost Optimization Tips</p> </li> <li>Use Reserved Instances: Commit to a 1 or 3-year term for discounts</li> <li>Enable Auto-Scaling.</li> <li>Choose the Right Storage.</li> <li>take snapshot and delete db if you dont need. later on restore from snapshot. this will save money.</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#44-integration-with-aws-ecosystem","title":"4.4 Integration with AWS Ecosystem","text":"<ul> <li>IAM, Lambda, CloudWatch, and Elastic Beanstalk.</li> <li>Simplifies building serverless or event-driven architectures</li> </ul>"},{"location":"01_aws/03_database/01_RDS/#5-demo","title":"5. demo","text":""},{"location":"01_aws/03_database/01_RDS/#-create-single-db-rdb-in-region-1-choose-underlying-ec2-type-memory-optimzed-ebs-volume-db-admin-password-db-name-backupscreenshot-enable-retention-policy-upto-35-days-backup-window-preferrence-enable-storage-autoscaling-give-maz-size-100-gb-connectivity-option-1-add-specified-ec2-i-will-automatically-configure-things-good-for-beginner-option-2-dont-connect-to-ec2-i-define-vpc-subnet-allow-public-access-choose-sg-port-authentication-db-password-or-iam-monitoring-enable-backup-window-pr-miantaincence-window-enable-deletion-prevention-ready-to-use-check-monitoring-dashboard-cpu-moemory-connections-etc-action-create-read-replica-take-snapshot-migrate-snapshot-restore-to-point-create-read-replica","title":"<pre><code>- create single DB RDB in region-1\n- choose underlying ec2 type (memory optimzed), EBS volume\n- DB admin + password + DB name\n- backup/screenshot : \n  - enable + retention policy upto 35 days\n  - backup window preferrence.\n- enable STORAGE autoscaling, give maz size : 100 GB\n- Connectivity : \n  - option-1: add \"specified ec2-i\", will automatically configure things (good for beginner)\n  - option-2: Dont connect to Ec2-i\n    - define VPC, subnet\n    - allow public access\n    - choose SG\n    - port \n- Authentication : DB password or IAM\n- Monitoring : Enable\n- backup window pr\n- Miantaincence window\n- Enable deletion prevention \n\n === READY to USE ===\n\n- Check monitoring dashboard : CPU, Moemory, Connections, etc\n- action:\n  - create read replica\n  - take Snapshot + migrate Snapshot + restore to point.\n  - create read replica.\n</code></pre>","text":""},{"location":"01_aws/03_database/01_RDS/#99-for-dva","title":"99. for DVA","text":""},{"location":"01_aws/03_database/01_RDS/#100-exam","title":"100. exam","text":"<ul> <li>un-encrypted RDS, encrypt it:</li> <li>take screenshot &gt;&gt; encrypted snapshot &gt;&gt; restore it as new DB : correct</li> <li> <p>take screesnhot &gt;&gt; encrypted while restoring </p> </li> <li> <p>PITR more</p> </li> <li>Takes an automatic daily snapshot (called a daily backup).</li> <li>Continuously backs up transaction logs every <code>5 minutes</code> to allow point-in-time recovery within the backup retention period.</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/","title":"Amazon RDS :: Aurora provisioned","text":"<ul> <li>optimal read : upto ram 1024 GB,  40,000 mbps</li> <li>burstable : 2 Gb ram , 4 cpu unit</li> <li>Memory optimized  -- SSD, eni-speed-high</li> <li>single, multi-az mode</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#aurora-rds-serverless-v2","title":"Aurora RDS :: serverless v2","text":""},{"location":"01_aws/03_database/02_RDS_Aurora/#a-intro","title":"A. Intro","text":"<ul> <li>engine : <code>Postgres</code> 3x  and <code>MySQL</code> 5x</li> <li>serverless v2 improvement : instant auto-scaling with no warm-up time.</li> <li>forwarding writes from secondary to primary region. developer dont nned to write logic.</li> <li>no capacity planning : configure min/max ACU  (1acu === 2 gb ram , equ n/w and cpu)</li> <li>scale to 128TB per db instance </li> <li>OLTP | rdbms</li> <li>cluster design, fault tolerance by design:</li> <li>cluster spans multiple AZ in region.</li> <li>1 primary + ( 5-16 )read replica(assign priority, can change at any time.)</li> <li>if no reader, the primary itself re-created.</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#b-dr","title":"B. DR","text":"<ul> <li>RPO : <code>1 sec</code> | RTP <code>&lt; 1 min</code> </li> <li>aurora has no stand-by instance thing </li> <li>has read replicas only in Aurora cluster, only replica can promote as primary, during DR.</li> <li>read replica has 2 purpose : reader endpoint + availability</li> <li>self-healing,</li> <li>continuous s3 backup,</li> <li>PITR</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#c-advantages","title":"C. Advantages","text":"<ul> <li>include RDS adv.</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#1-global-aurora-database","title":"1 Global Aurora database","text":"<ul> <li>cross <code>region</code> replicas in <code>less than a sec</code>. | single Database spans over multiple region.</li> <li>1 Primary Region (read / write)</li> <li>Up to 5 secondary (read-only) in each region, <code>replication</code> lag is less than <code>1 second</code> </li> <li>Up to 16 Read Replicas per secondary region</li> <li>RPO: less than second</li> <li>RTO: less than a minute</li> <li></li> <li>provides more comprehensive failover capabilities </li> <li>Managed planned failover</li> <li>Unplanned failover (\"detach and promote\") </li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#2-integration-ml-service","title":"2 integration ML service","text":"<ul> <li><code>SageMaker</code> and <code>Comprehend</code></li> <li>fraud detection, ads targeting, sentiment analysis, product recommendations</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#3-auto-scaling-storage-and-compute-are-separate","title":"3 Auto-scaling (storage and compute are separate)","text":"<ul> <li><code>storage</code> scaling :: EBS volume - <code>10 GB to 128 TB</code> . /64TB?</li> <li><code>compute</code> Instance :: type( eg: d.r3.large,etc), --RAM++, --cpu++.</li> <li><code>Read replicas</code>:  (built-in, dont need to create CW + ASG, auto happens bts)</li> <li>can add, CW metric --&gt; triggers --&gt; auto up/down read replicas</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#4-performance","title":"4 performance","text":"<ul> <li>AWS cloud optimized and claim <code>3x</code> Performance improvement (on Postgres)</li> <li>master + <code>6-15</code> Read Replica, with fast replication</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#5-availability-cluster-arch","title":"5 Availability (cluster arch)","text":"<ul> <li><code>6 copies</code> for data access 3 AZ : <code>cluster</code> ( with reader and writer endpoint)</li> <li>instant fail-over (&lt;30s) + <code>self healing</code> from peer2peer replication.</li> <li></li> <li></li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#6-backtracking","title":"6 backtracking","text":"<ul> <li>rewind the DB cluster to any time you specify</li> <li>faster compared to restoring a DB cluster via  PITR or snapshot</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#7-cloning","title":"7 cloning","text":"<ul> <li>usecase : create test env from prod.</li> <li>faster than backup</li> <li>restore uses <code>copy-on-write</code> </li> <li>use same volume </li> <li>for new changes additional storage allocated and data copied to it.</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#8-more","title":"8 more","text":"<ul> <li>Isolation and <code>security</code></li> <li><code>Industry compliance</code></li> <li>Push-button <code>scaling</code> </li> <li>Advanced Monitoring</li> <li>Routine <code>Maintenance</code> + Automated <code>Patching</code> with Zero Downtime</li> <li>Backtrack: <code>restore</code> data at any point of time without using backups. (earliest :<code>5 mim ago</code>)</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#b-pricing","title":"B pricing","text":"<ul> <li>20% extra cost than RDS.</li> </ul>"},{"location":"01_aws/03_database/02_RDS_Aurora/#c-demo","title":"C. demo","text":"<pre><code>- select engine\n- select versions (so many available)\n- template - prod (allow to configure everything)\n    - admis + password\n    - max i/o or standard\n    - ec2 instance or serverless\n    - choose : avialability - replica,etc\n    - vpc, subnet, Ibv4\n    - public access\n    - sg\n    - port\n    - authentication\n    - db name\n    - ...\n\n=== READY ====\n\n- add more read replica\n- add cross az replica \n- add region (global database)\n- horizontal scaling policy (trigger : metric -CPU usage)\n    - max 15 and min 1\n</code></pre>"},{"location":"01_aws/03_database/03_ElastiCache/","title":"03 ElastiCache","text":""},{"location":"01_aws/03_database/03_ElastiCache/#-httpsawsamazoncomcachingimplementationconsiderations","title":"- https://aws.amazon.com/caching/implementationconsiderations/","text":""},{"location":"01_aws/03_database/03_ElastiCache/#elasticache","title":"ElastiCache","text":"<ul> <li>key-value</li> <li>if data changing slowly, then have it. eg:</li> <li><code>key-value</code> caching</li> <li><code>aggregations-results</code> caching</li> <li>...</li> <li>AWS offering :  </li> <li><code>Redis</code>,</li> <li><code>MemCache</code></li> <li><code>MemoryDB</code> has Redis like api.</li> <li>advantages:</li> <li>sub ms latency.</li> <li>negative side</li> <li>need application code changes.</li> <li>Data may be out of date, eventually consistent.</li> <li> <p>not suited for un-structured  data.</p> </li> <li> <p>usecase: to significantly improve latency and throughput for: </p> </li> <li>read-heavy application workloads <ul> <li>(such as social networking, gaming, media sharing, leaderboard, and Q&amp;A portals) </li> </ul> </li> <li>compute-intensive workloads</li> </ul>"},{"location":"01_aws/03_database/03_ElastiCache/#a-cache-use-cases","title":"A cache use-cases","text":""},{"location":"01_aws/03_database/03_ElastiCache/#database-read","title":"Database Read","text":"<ul> <li>prg &lt;--- DB (state)</li> <li>prg (<code>code</code> changes to use cache ) &lt;--- <code>Cache</code> &lt;--- DB(Data) : for stateless Application<ul> <li><code>low latency</code></li> <li><code>high performance</code></li> <li><code>reduce load</code> off of databases for read intensive workloads</li> <li></li> <li>lazy loading(stale read) and write-through(sync cache with DB)</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/03_ElastiCache/#maintain-user-session","title":"Maintain user Session","text":""},{"location":"01_aws/03_database/03_ElastiCache/#b-type","title":"B Type","text":""},{"location":"01_aws/03_database/03_ElastiCache/#1-redis","title":"1 <code>Redis</code>","text":"<ul> <li>think of RDS, similar </li> <li>supports advance data structure. </li> <li>internal: </li> <li>uses <code>Sets</code>(uniqness) and <code>SortedSets</code> (uniqueness + ordering)</li> <li><code>cluster</code> &gt; <code>shard</code>(node group) &gt; <code>node</code>(cache)</li> <li>One primary Node (choose: ec2 intance type)</li> <li>select upto 5 Read Replicas to scale reads and have high availability <ul> <li>Read replica-1 --&gt; az-1</li> <li>Read replica-2 --&gt; az-2, etc</li> <li>...</li> </ul> </li> <li> <p>enable/disable: <code>Multi AZ</code> with Auto-Failover, more cost.</p> <ul> <li>stand-by replica-1 --&gt; az-1</li> <li>stand-by replica-2 --&gt; az-2, etc</li> </ul> </li> <li> <p>use case </p> </li> <li><code>millions of requests / second</code> for real-time applications <ul> <li>in Gaming, Ad-Tech, Financial Services, Healthcare, and IoT. </li> </ul> </li> <li>popular choice for :<ul> <li>caching, </li> <li>session management, </li> <li>gaming, leaderboards, </li> <li>real-time analytics, </li> <li>geospatial, </li> <li>purpose-built commands for working with real-time geospatial data at scale.</li> <li>operations like finding the distance between two elements (for example people or places)</li> <li>GEOADD, GEORADIUS, GEODIST</li> <li>chat/messaging, </li> <li>media streaming, </li> <li>and pub/sub apps.</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/03_ElastiCache/#redisdemo","title":"Redis::Demo","text":""},{"location":"01_aws/03_database/03_ElastiCache/#-create-redis-rdb-file-choose-design-youe-own-cache-method-easy-cluster-cache-restorefrom-rdb-cluster-name-password-port-maintenece-window-security-encryption-rest-fly-enable-logs-tags-vpcsubnet-redis-engine-vesrion-ec2-instance-type-count-of-read-replica-ready-primary-end-point-reader-end-point-backuprestore","title":"<pre><code>- Create REDIS (.rdb file)\n- Choose : Design youe own cache\n    - method : Easy, cluster cache ** , restore(from .rdb)\n    - cluster name, password, port\n    - maintenece window\n    - security : encryption (rest /fly)\n    - enable logs\n    - tags\n    - VPC/subnet\n    - redis Engine : vesrion, ec2 instance type, count of Read replica\n\n    === READY ===\n\n    - primary end point\n    - reader end point\n    - backup/restore\n</code></pre>","text":""},{"location":"01_aws/03_database/03_ElastiCache/#2-memcache","title":"2 <code>MemCache</code>","text":"<ul> <li>No high availability (replication)</li> <li><code>Non persistent</code> </li> <li>No backup/restore</li> <li>Security: <code>SASL</code> (more advance)</li> <li>Multi-threaded architecture ?</li> <li>Multi-node for partitioning of data (sharding) ?</li> <li>Memcached does NOT offer support for geospatial data.  </li> </ul>"},{"location":"01_aws/03_database/03_ElastiCache/#comparison","title":"Comparison","text":""},{"location":"01_aws/03_database/03_ElastiCache/#3-memory-db-for-redis-intro","title":"3 <code>Memory DB for redis</code> : intro","text":"<p> - Ultra-fast performance with over <code>160 millions requests/second</code>  - Durable in-memory data storage    - with Multi-AZ, hundreds of nodes   - Scale seamlessly from <code>10s GBs</code> &gt;&gt;&gt; <code>100s TBs</code> of storage - Use cases:    - web and mobile apps,    - online gaming,    - media streaming,   - \u2026</p>"},{"location":"01_aws/03_database/03_ElastiCache/#c-strategies-caching-design-pattern","title":"C strategies ( caching design pattern )","text":""},{"location":"01_aws/03_database/03_ElastiCache/#1-lazy-loading-or-population-cache-aside","title":"1. Lazy Loading or Population / Cache-Aside","text":"<p> - flow for understanding:   - hit-1: read from cache : found ok   - not found, hit-2: read from db   - hit-3: set cache   - next:     - <code>case:1</code>  Data update on some other api       - cache will become stale / inconsistent.       - this is drawback.        - write-through strategy solves it. next     - <code>case:2</code> new data-1 wrote on DB, by some other api       - read data-1 from cache will miss       - since cache was updated after write.       - write-through strategy solves it. next</p> <ul> <li>sample psuedo code for understanding:</li> <li></li> </ul>"},{"location":"01_aws/03_database/03_ElastiCache/#2-write-through","title":"2. write-through","text":"<p> - each write on DB, requires 2 hit:   - hit-1: write on DB   - hit-2: write on cache   - pseudo code:   -  - drawback:   - cache churn: writing lot n lot of data in cache, which will be never read.   - cache-eviction and TTL resolves it. next</p>"},{"location":"01_aws/03_database/03_ElastiCache/#3-cache-eviction","title":"3. cache-eviction","text":"<ul> <li>set eviction policy by</li> <li>LRU (least recently used)</li> <li>TTL (sec, min, hr, days)</li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/","title":"DynamoDB SSA","text":""},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#-httpschatgptcomc675f4a6d-26b8-800d-b73e-a01c28a386b2","title":"- https://chatgpt.com/c/675f4a6d-26b8-800d-b73e-a01c28a386b2","text":""},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#dynamodb-serverless","title":"DynamoDB (serverless)","text":""},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#a-intro","title":"A. Intro","text":"<ul> <li>No Sql </li> <li>unstructured</li> <li>rapidly evolve schemas</li> <li>All the data that is needed for a query is present in one row</li> <li>don\u2019t perform aggregations such as \u201cSUM\u201d, \u201cAVG\u201d, \u2026</li> <li> <p>scale horizontally </p> </li> <li> <p>Fully managed </p> </li> <li>no maintenance/patching</li> <li>no db admin</li> <li> <p>no provisioning db</p> </li> <li> <p>high consistent performance DISTRIBUTED database </p> </li> <li><code>single-digit millisecond performance</code>, at any scale </li> <li><code>Millions of requests</code> per seconds</li> <li><code>trillions of row</code></li> <li><code>100s of TB</code> of storage</li> <li>Scales to <code>massive workloads</code></li> <li> <p>It provides both provisioned (specify RCU &amp; WCU) and on-demand (pay for what you use) capacity modes.</p> </li> <li> <p>Allows event driven programming with DynamoDB Streams </p> </li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#b-distributed-db-highly-available","title":"B. Distributed DB (highly available)","text":""},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#traditional-relational-db","title":"Traditional relational DB:","text":"<ul> <li>Vertical scaling (getting a more powerful CPU / RAM / IO)</li> <li><code>limited</code> Horizontal scaling </li> <li>increasing Read Replicas.</li> <li>but limited. eg max 16 read replica/s.</li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#1-dynamodb-single-region-table","title":"1. DynamoDB: <code>Single-region</code> Table","text":"<ul> <li>table data stored in multiple partitions.</li> <li>hashing algorithm( on PartitionKey) ==&gt; decides which partition  to go.</li> <li>partitionKey</li> <li><code>unique</code></li> <li><code>diverse</code>, to distribute data evenly on partition.  <ul> <li>add suffix to partition key to make it more n more diverse.</li> <li>this is called write sharding.</li> <li>so use random. calculated suffix.</li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#partition","title":"Partition","text":"<ul> <li>dynamoDB</li> <li> <p>table-1</p> <ul> <li>partitions-1 (node-1 in different az/s) &lt;--&gt; 2-way replication b/w AZ/s &lt;--&gt; partitions-1(node-2)</li> <li>both can Read and Write</li> <li>no leader/primary concept.</li> <li>partitions-2</li> <li>...</li> <li>...</li> <li>scale out more partition/s</li> </ul> </li> <li> <p>Number of partitions</p> </li> <li></li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#2-dynamodb-global-table","title":"2. DynamoDB: <code>Global</code> Table","text":"<ul> <li>table-1 (R/W) is <code>region-1</code></li> <li>table-1 (R/W) is <code>region-2</code></li> <li>2-way replication b/w region/s.</li> <li></li> <li>Enable DynamoDB Streams </li> <li>helps to replicate data across replica tables in other AWS Regions</li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#c-dynamodb-streams","title":"C. DynamoDB streams","text":"<ul> <li>udemy reference</li> <li>enable it explicitly and select one of below kind: <pre><code>\u2022 KEYS_ONLY           \u2013 only the key attributes of the modified item\n\u2022 NEW_IMAGE           \u2013 the entire item, as it appears after it was modified\n\u2022 OLD_IMAGE           \u2013 the entire item, as it appeared before it was modified\n\u2022 NEW_AND_OLD_IMAGES  \u2013 both the new and the old images of the item\n</code></pre></li> <li>internally has same concept of shards, same like in KDS </li> <li>we don\u2019t provision shards, this is automated by AWS</li> <li> <p>03_01_KDS_KinesisDataStream.md</p> </li> <li> <p>Ordered stream of item-level modifications (create/update/delete) in a table.</p> </li> <li> <p>has 24 hrs retention, so process it or send it somewhere in that window , if needed.</p> </li> <li>read and process by directly <code>Lambda fn</code><ul> <li>Define event source mapping 03_lambda-dva-02-trigger.md</li> </ul> </li> <li> <p>send to <code>KDS</code> using kinesis-connectors</p> <ul> <li>custom app ( aws-sdk or KCL) - read and process</li> <li>KDA</li> <li>KDF &gt;&gt; redshift / s3 / opensearch </li> <li>lambda fn</li> </ul> </li> <li> <p>stream <code>Use cases</code></p> </li> <li>react to changes in real-time (welcome email to users)</li> <li>Analytics</li> <li>Insert into derivative tables</li> <li>Insert into OpenSearch Service</li> <li> <p>cross-region replication </p> <ul> <li>if not using global dynamoDB</li> </ul> </li> <li> <p>common architecture</p> </li> <li></li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#d-storage","title":"D. Storage","text":"<ul> <li>max item size : <code>400 KB</code></li> <li>storage classes ( like in s3 ): </li> <li>Standard</li> <li>Infrequent Access (IA) <ul> <li>to save more cost</li> </ul> </li> <li>storing large object in dynamoDB.</li> <li>use s3 to storage</li> <li>in table store s3 metadata.</li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#e-security","title":"E. Security","text":"<ul> <li>encryption at rest/fly by KMS/TLS</li> <li>Resource-based policy for table.</li> <li>keep traffic inside vpc</li> <li>create vpce / gateway (privateLink)</li> <li>Integrated with IAM</li> <li>use Identity provider </li> <li>federated user</li> <li>Assign an IAM Role to federated user with a Condition:<ul> <li>to limit their API access to DynamoDB</li> <li>dynamodb:<code>LeadingKeys</code> == partition_key or partition_key_prefix</li> <li>row level access. </li> <li>user can access row with that partition_key</li> <li>dynamodb:<code>Attributes</code> <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"dynamodb:GetItem\",\n            \"dynamodb:Query\"\n        ],\n        \"Resource\": \"arn:aws:dynamodb:us-west-2:123456789012:table/YourTableName\",\n        \"Condition\": {\n            \"ForAllValues:StringEquals\": {\n                \"dynamodb:Attributes\": [\"name\", \"email\"]\n            }\n        }\n    },\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": \"dynamodb:UpdateItem\",\n        \"Resource\": \"arn:aws:dynamodb:us-west-2:123456789012:table/YourTableName\",\n        \"Condition\": {\n            \"ForAllValues:StringEquals\": {\n                \"dynamodb:Attributes\": [\"status\"]\n            }\n        }\n    },\n\n\n    {\n        \"Effect\": \"Allow\",\n        \"Action\": [\n            \"dynamodb:GetItem\",\n            \"dynamodb:Query\",\n            \"dynamodb:PutItem\",\n            \"dynamodb:UpdateItem\",\n            \"dynamodb:DeleteItem\"\n        ],\n        \"Resource\": \"arn:aws:dynamodb:us-west-2:123456789012:table/YourTableName\",\n        \"Condition\": {\n            \"ForAllValues:StringEquals\": {\n                \"dynamodb:LeadingKeys\": \"${aws:userid}\"\n                //\"dynamodb:LeadingKeys\": \"${aws:departid}_*\"\n            }\n        }\n    }\n]\n}\n</code></pre> </li> </ul> </li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#f-dr","title":"F. DR","text":"<ul> <li>Automatic backup for last <code>35 days</code>. </li> <li>take ondemand backup for longer retention.</li> <li>Enable Cross-region copy. no performace impact/ downtime.</li> <li>PITR - point in time recovery</li> <li><code>export</code> (json,ion) data --&gt; S3.</li> <li><code>import</code> (json,csv,ion) --&gt; Dynamo DB</li> <li></li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#g-copying-dynamodb-table-into-s3","title":"G. Copying DynamoDB Table (into s3)","text":""},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#1-aws-data-pipeline-fast","title":"1 AWS Data pipeline (fast)","text":"<ul> <li>launches EMR bts. <pre><code>\"EMR\" is a cloud-based big data platform that \nsimplifies the process of running large-scale distributed data processing frameworks like \n  - Apache Hadoop\n  - Apache Spark \n  - ...\n</code></pre> </li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#2-backup-and-restore","title":"2 backup and restore","text":"<ul> <li>takes time</li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#3-api-call","title":"3 API call","text":"<ul> <li>scan + putItem</li> <li>BatchWriteItem</li> <li>not recommended, but can do for small table.</li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#h-migration","title":"H. Migration","text":"<ul> <li>use AWS DMS to dynamoDB from:</li> <li>MongoDB</li> <li>SQL database : MySQL,Oracle, etc<ul> <li>de-normalize</li> <li>convert to item</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/04_1_DynamoDB_SSA/#i-architecture-example","title":"I. Architecture example:","text":"<ul> <li>use dynamoDB for indexing S3 metadata.</li> <li></li> <li></li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/","title":"A. DynamoDB - <code>components</code>","text":""},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#0-table","title":"0. Table","text":"<ul> <li>PK : partitionKey , or</li> <li>PK : partitionKey + Sortkey</li> <li></li> <li>Also, define mode for read/write operation:</li> <li><code>provisioned</code> - define capacity <code>RCU / WCU</code></li> <li><code>onDemand</code> - uses <code>RRU / WRU</code> requests, internally. 2.5 times expensive.</li> <li>can switch b/w modes, at any time </li> <li>created : https://us-west-2.console.aws.amazon.com/dynamodbv2/home?region=us-west-2#table?name=ps-games</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#1-record","title":"1. Record","text":"<ul> <li>or Item</li> <li>has attributes (<code>400 KB max</code>)</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#2-datatype","title":"2. Datatype","text":"<ul> <li>Scalar Types \u2013 String, Number, Binary, Boolean, Null</li> <li>Document Types \u2013 List, Map</li> <li>Set Types \u2013 String Set, Number Set, Binary Set</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#3-ttl","title":"3. TTL","text":"<ul> <li>set expiration for record / item</li> <li>it will auto-delete and send event stream</li> <li>eg: </li> <li>enable TTL setting and give attribute name : <code>my_expire_on</code></li> <li>add attribute : <code>my_expire_on ==  &lt;timeinMillisecond&gt;</code></li> <li>expired after 2 hr</li> <li>and deleted from index - LSI and GSL </li> <li>and after <code>48 hrs</code>, permanently deleted from main table also. (for recovery purpose)</li> <li>eg: webUser --&gt; session 2 hr --&gt; session logout --&gt; expire his/her data after 2 hr.</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#4-write-capacity-units-wcu","title":"4. Write Capacity Units (WCU)","text":"<ul> <li><code>1 WCU</code> == write <code>1 item</code>(<code>upto 1 KB</code>)/<code>sec</code></li> <li></li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#5-read-capacity-units-rcu","title":"5. Read Capacity Units (RCU)","text":"<ul> <li>2 types of read</li> <li>ConsistentRead == True<ul> <li>1 RCU ==  1 <code>Strongly</code> Consistent Read of 1 item(<code>upto 4 KB</code>)</li> </ul> </li> <li>ConsistentRead == false (default)<ul> <li>1/2 RCU ==  <code>Eventually</code> Consistent Read of 1 item(<code>upto 4 KB</code>)</li> </ul> </li> <li></li> <li>because of replication lag, can be Strongly or Eventually consistent</li> <li></li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#6-define-throughput-for-each-table","title":"6. Define throughput for each table","text":""},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#61-on-demand-mode","title":"6.1. On-Demand Mode","text":"<ul> <li>read/write operation, automatically scale up/down upto its max, with growing workloads</li> <li>Read Request Units (RRU)</li> <li>Write Request Units (WRU)</li> <li>for un-predictable workload.</li> <li>simplified billing but <code>2.5 times expensive</code></li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#62-provisioned-mode-default","title":"6.2. Provisioned Mode (default)","text":"<ul> <li>for predicated workload</li> <li>can optionally, enable auto-scaling of WCU/RCU</li> <li>so we define capacity : RCU and WCU</li> <li></li> <li></li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#63-throttleerror","title":"6.3. ThrottleError","text":"<ul> <li>if capacity exceeded then <code>ProvisionedThroughputExceededException</code></li> <li>RCUs and WCUs are spread across all the table's partitions </li> <li>reason</li> <li><code>Hot Keys</code>\u2013 one partition key is being read too many times (e.g., popular item)</li> <li><code>Hot Partitions</code></li> <li><code>Very large items</code>, remember RCU and WCU depends on size of items</li> <li>Solutions:</li> <li>retry with Exponential backoff when exception is encountered (already in SDK)</li> <li>configure autoscale of WCU/RCU - [ min,max,desired ]</li> <li>Distribute partition keys as much as possible</li> <li>If RCU issue, we can use DAX</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#7-partiql","title":"7. PartiQL","text":"<ul> <li>SQL-compatible query language for DynamoDB - CRUD</li> <li>no joins</li> <li>Run PartiQL queries from:</li> <li>web Console</li> <li>NoSQL Workbench for DynamoDB</li> <li>CLI/SDK</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#8-secondary-index","title":"8. Secondary Index","text":"<ul> <li>udemy reference</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#81-lsi-local-secondary-index","title":"8.1. <code>LSI</code> - Local Secondary Index","text":"<ul> <li>index for : query by </li> <li><code>same</code> PartitionKey</li> <li><code>Alternative</code> SortKey</li> <li>restriction: </li> <li><code>5 max</code></li> <li>Must be defined at table creation time </li> <li>Attribute Projections :  KEYS_ONLY, INCLUDE, ALL</li> <li>Uses the WCUs and RCUs of the main table</li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#82-gsi-global-secondary-index","title":"8.2. <code>GSI</code> - Global Secondary Index","text":"<ul> <li>index for : query by</li> <li><code>Alternative</code> PartitionKey</li> <li><code>Alternative</code> SortKey</li> <li>Speed up queries on non-key attributes</li> <li>Can be added/modified after table creation</li> <li> <p>Attribute Projections :  KEYS_ONLY, INCLUDE, ALL</p> </li> <li> <p>provision new WCU and RCU</p> </li> <li>If the writes are throttled on the GSI,</li> <li>then the main table will be throttled!  </li> </ul> <p></p>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#9-transaction","title":"9. transaction","text":"<ul> <li>DynamoDB supports transactions but </li> <li>only for up to <code>25 items</code></li> <li>or <code>4 MB</code> in total size</li> <li>ACID</li> <li>Read Modes (query/scan)</li> <li>Eventual Consistency 1/2 RCU</li> <li>Strong Consistency  1 RCU</li> <li><code>Transactional</code><ul> <li>Consumes 2x RCUs </li> <li><code>TransactGetItems</code></li> </ul> </li> <li>Write Modes  ((add/update/delete))</li> <li>Standard </li> <li><code>Transactional</code> <ul> <li>Consumes 2x WCUs</li> <li><code>TransactWriteItems</code></li> </ul> </li> </ul>"},{"location":"01_aws/03_database/04_2_DynamoDB_DVA-components/#10-store-session-states","title":"10. store session states","text":"<ul> <li>It\u2019s common to use DynamoDB to store session states</li> <li>compare with other cache option/s</li> <li>vs. ElastiCache<ul> <li>ElastiCache is <code>in-memory</code>, but DynamoDB is <code>serverless</code></li> <li>Both are key/value stores</li> </ul> </li> <li>vs. EFS<ul> <li>EFS must be attached to EC2 instances as a network drive</li> </ul> </li> <li>vs. EBS &amp; Instance Store<ul> <li>EBS &amp; Instance Store can only be used for local caching, not shared caching</li> </ul> </li> <li>vs. S3<ul> <li>S3 is higher latency, and not meant for small objects</li> </ul> </li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/","title":"A. DynamoDB - <code>Simple Operations</code>","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#1-read","title":"1. Read","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#11-getitem","title":"1.1. GetItem","text":"<ul> <li>Read based on Primary key</li> <li>Primary Key can be HASH or HASH+RANGE</li> <li>Eventually Consistent Read (default)</li> <li>Option to use Strongly Consistent Reads (more RCU - might take longer)</li> <li>ProjectionExpression </li> <li>to retrieve only certain attributes</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#12-scan","title":"1.2. Scan","text":"<ul> <li>Scan the entire table and then filter out data</li> <li>ProjectionExpression</li> <li>FilterExpression</li> <li>Consumes a lot of RCU</li> <li>For faster performance, use Parallel Scan</li> <li>can use limit and pagination.</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#2-write","title":"2. Write","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#21-putitem","title":"2.1 PutItem","text":"<ul> <li>Creates a new item </li> <li>or fully replace an old item (same Primary Key)</li> <li>Consumes WCUs</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#22-updateitem","title":"2.2 UpdateItem","text":"<ul> <li>Edits an existing item\u2019s attributes </li> <li>or adds a new item if it doesn\u2019t exist</li> <li>use Atomic Counters</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#3-query","title":"3. Query","text":"<ul> <li>returns Item/s based on below expression:</li> <li>KeyCondition : <ul> <li>on partitionKey</li> <li>on sortKey</li> </ul> </li> <li>Filter <ul> <li>addition filter on other attributes.</li> </ul> </li> <li>set limit</li> <li>no of item</li> <li>size. eg : 1 MB data.</li> <li>perform pagination</li> <li>index ?</li> <li>local secondary ?</li> <li>Global Secondary ?</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#4-delete","title":"4. Delete","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#41-deleteitem","title":"4.1 DeleteItem","text":"<ul> <li>delete an individual item</li> <li>Ability to perform a conditional delete</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#42-deletetable","title":"4.2 DeleteTable","text":"<ul> <li>Delete a whole table and all its items</li> <li>Much quicker deletion than calling DeleteItem on all items</li> <li>table cleanup</li> <li>option-1: DeleteTable and recreate it.  <code>fast, cheap</code></li> <li>option-2: scan and delete individual item. <code>slow, consumes RCU/WCU</code></li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#b-dynamodb-batch-operations","title":"B. DynamoDB - <code>Batch Operations</code>","text":"<ul> <li>reducing the number of API calls</li> <li>done in parallel for better efficiency</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#1-batchwriteitem","title":"1. BatchWriteItem","text":"<ul> <li>Up to <code>25</code> PutItem and/or DeleteItem in one call</li> <li>Up to <code>16 MB</code> of data written, up to <code>400 KB</code> of data per item</li> <li>Can\u2019t update items (use UpdateItem)</li> <li>error: UnprocessedItems for failed write operations </li> <li>exponential backoff </li> <li>add WCU</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#2-batchgetitem","title":"2. BatchGetItem","text":"<ul> <li>Return items from one or more tables</li> <li>Up to <code>100 items</code>, up to <code>16 MB</code> of data</li> <li>Items are retrieved in parallel to minimize latency</li> <li>error: UnprocessedKeys for failed read operations </li> <li>exponential backoff </li> <li>add RCU</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#c-types-of-write-4","title":"C. Types  of write (4)","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#1-concurrent-write","title":"1. concurrent write","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#2-atomic-write","title":"2. Atomic write","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#3-batch-write","title":"3. batch Write","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#4-conditional-write-optimistic-locking","title":"4. conditional Write (optimistic locking)","text":"<ul> <li>Accept a <code>write/update/delete</code> only</li> <li>if conditions are met,</li> <li>otherwise returns an error</li> <li>Helps with concurrent access to items</li> <li>No performance impact</li> <li>use these function in conditional expression</li> <li><code>attribute_exists()</code></li> <li><code>attribute_not_exists()</code></li> <li><code>attribute_type()</code></li> <li><code>contains()</code> (for string)</li> <li><code>begins_with()</code> (for string)</li> <li>ProductCategory <code>IN</code> (:cat1, :cat2) and Price <code>between</code> :low and :high</li> <li><code>size()</code> (string length)</li> </ul>"},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#program","title":"program","text":""},{"location":"01_aws/03_database/04_3_DynamoDB_DVA-operations/#1-py-conditional-write-optimistic-locking","title":"1. py : conditional write ( optimistic locking)","text":"<ul> <li>https://us-west-2.console.aws.amazon.com/lambda/home?region=us-west-2#/functions/dynamodb-ps-games-operation?tab=code</li> <li>https://us-west-2.console.aws.amazon.com/dynamodbv2/home?region=us-west-2#item-explorer?operation=SCAN&amp;table=ps-games</li> </ul> <p><pre><code>{\n  \"id\": { \"N\": \"101\" },\n  \"name\": { \"S\": \"The Last of Us Part II\" },\n  \"release_year\": { \"N\": \"2020\" },\n  \"genre\": { \"S\": \"Action-Adventure\" },\n  \"developer\": { \"S\": \"Naughty Dog\" },\n  \"rating\": { \"N\": \"9.5\" },\n  \"platforms\": { \"SS\": [\"PS4\", \"PS5\"] },\n  \"multiplayer\": { \"BOOL\": false },\n  \"file_size\": { \"N\": \"80\" },\n  \"version\" : { \"N\", \"1\"}\n}\n</code></pre> <pre><code>import boto3\nfrom decimal import Decimal\n\ndynamodb = boto3.resource('dynamodb')\ntable = dynamodb.Table('playstation-games')\n\n# Use Decimal for numeric values\ntry:\n    table.update_item(\n        Key={\"id\": 101, \"name\": \"The Last of Us Part II\"},\n        UpdateExpression=\"SET rating = :new_rating, version = version + :incr\",\n        ConditionExpression=\"version = :expected_version\",\n        ExpressionAttributeValues={\n            \":new_rating\": Decimal('9.6'),  # Use Decimal instead of float\n            \":expected_version\": Decimal('1'),\n            \":incr\": Decimal('1')\n        }\n    )\n    print(\"Update successful!\")\nexcept dynamodb.meta.client.exceptions.ConditionalCheckFailedException:\n    print(\"Version mismatch! Item was updated by another process.\")\n</code></pre> <pre><code>aws dynamodb update-item \\\n  --table-name ps-games \\\n  --key '{\n      \"id\": {\"N\": \"101\"},\n      \"name\": {\"S\": \"The Last of Us Part II\"}\n  }' \\\n  --update-expression \"SET rating = :new_rating, version = version + :incr\" \\\n  --condition-expression \"version = :expected_version\" \\\n  --expression-attribute-values '{\n      \":new_rating\": {\"N\": \"9.6\"},\n      \":expected_version\": {\"N\": \"1\"},\n      \":incr\": {\"N\": \"1\"}\n  }' \\\n  --region us-west-2\n</code></pre></p>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/","title":"DynamoDB AWS CLI Commands","text":"<p>This document provides a comprehensive guide to DynamoDB AWS CLI commands, including all common options available for various operations.</p>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#table-information","title":"Table Information","text":"<ul> <li>Table Name: <code>ps-games</code></li> <li>Primary Key:<ul> <li>Partition Key: <code>id</code> (Number)</li> <li>Sort Key: <code>name</code> (String) <pre><code>[\n    {\n        \"AttributeName\": \"id\",\n        \"KeyType\": \"HASH\"\n    },\n    {\n        \"AttributeName\": \"name\",\n        \"KeyType\": \"RANGE\"\n    }\n]\n</code></pre></li> </ul> </li> </ul>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#common-options-for-dynamodb-cli-commands","title":"Common Options for DynamoDB CLI Commands","text":"Option Purpose <code>--page-size</code> Reduces the number of items fetched per API request to improve performance and avoid timeouts or excessive memory use. scan and query <code>--max-items</code> <code>--table-name</code> Specifies the table name for the operation. <code>--key</code> Defines the primary key of the item for operations like <code>GetItem</code>, <code>UpdateItem</code>, <code>DeleteItem</code>. <code>--item</code> Provides the item attributes for <code>PutItem</code>. <code>--update-expression</code> Specifies how to update attributes in <code>UpdateItem</code>. <code>--condition-expression</code> Adds conditions for operations like <code>PutItem</code>, <code>UpdateItem</code>, and <code>DeleteItem</code>. <code>--filter-expression</code> Filters results during <code>Scan</code> or <code>Query</code> based on attribute values. <code>--key-condition-expression</code> Specifies conditions for <code>Query</code> to fetch items based on partition/sort key. <code>--projection-expression</code> Limits the attributes returned by operations like <code>Query</code> or <code>Scan</code>. <code>--expression-attribute-values</code> Maps placeholders to actual values used in expressions. <code>--expression-attribute-names</code> Maps placeholders to actual attribute names to avoid reserved words. <code>--return-values</code> Specifies what is returned after <code>PutItem</code>, <code>UpdateItem</code>, or <code>DeleteItem</code>. Values: <code>NONE</code>, <code>ALL_OLD</code>, <code>UPDATED_OLD</code>, <code>ALL_NEW</code>, <code>UPDATED_NEW</code>. <code>--select</code> Used in <code>Query</code> or <code>Scan</code> to specify the returned data (<code>ALL_ATTRIBUTES</code>, <code>COUNT</code>, <code>SPECIFIC_ATTRIBUTES</code>). <code>--consistent-read</code> Ensures strongly consistent reads for <code>GetItem</code>, <code>Query</code>, or <code>Scan</code>. Default: eventually consistent. <code>--region</code> Specifies the AWS region for the DynamoDB operation. <code>--return-consumed-capacity</code> Shows read/write capacity units consumed by the operation. Options: <code>INDEXES</code>, <code>TOTAL</code>, <code>NONE</code>. <code>--limit</code> Restricts the number of items returned by <code>Query</code> or <code>Scan</code>. <code>--exclusive-start-key</code> Specifies the starting point for <code>Query</code> or <code>Scan</code> to continue from the last response. <code>--index-name</code> Specifies a secondary index for <code>Query</code> or <code>Scan</code>. <code>--segment</code> and <code>--total-segments</code> Divides a <code>Scan</code> into parallel operations for faster processing."},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#1-put-item-insert-a-new-item","title":"1. Put Item (Insert a New Item)","text":"<pre><code>aws dynamodb put-item \\\n  --table-name ps-games \\\n  --item '{\n      \"id\": {\"N\": \"102\"},\n      \"name\": {\"S\": \"God of War Ragnarok\"},\n      \"release_year\": {\"N\": \"2022\"},\n      \"genre\": {\"S\": \"Action-Adventure\"},\n      \"rating\": {\"N\": \"9.8\"},\n      \"platforms\": {\"SS\": [\"PS5\", \"PS4\"]},\n      \"multiplayer\": {\"BOOL\": false},\n      \"version\": {\"N\": \"1\"}\n  }' \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#2-get-item-retrieve-a-specific-item","title":"2. Get Item (Retrieve a Specific Item)","text":"<pre><code>aws dynamodb get-item \\\n  --table-name ps-games \\\n  --key '{\n      \"id\": {\"N\": \"102\"},\n      \"name\": {\"S\": \"God of War Ragnarok\"}\n  }' \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#3-query-fetch-items-based-on-partition-key","title":"3. Query (Fetch Items Based on Partition Key)","text":"<pre><code>aws dynamodb query \\\n  --table-name ps-games \\\n  --key-condition-expression \"id = :id\" \\\n  --expression-attribute-values '{\n      \":id\": {\"N\": \"102\"}\n  }' \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#4-scan-retrieve-all-items-in-a-table","title":"4. Scan (Retrieve All Items in a Table)","text":"<pre><code>aws dynamodb scan \\\n  --table-name ps-games \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#5-delete-item-remove-an-item","title":"5. Delete Item (Remove an Item)","text":"<pre><code>aws dynamodb delete-item \\\n  --table-name ps-games \\\n  --key '{\n      \"id\": {\"N\": \"102\"},\n      \"name\": {\"S\": \"God of War Ragnarok\"}\n  }' \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#6-update-item-modify-existing-attributes","title":"6. Update Item (Modify Existing Attributes)","text":"<pre><code>aws dynamodb update-item \\\n  --table-name ps-games \\\n  --key '{\n      \"id\": {\"N\": \"102\"},\n      \"name\": {\"S\": \"God of War Ragnarok\"}\n  }' \\\n  --update-expression \"SET rating = :new_rating, genre = :new_genre\" \\\n  --expression-attribute-values '{\n      \":new_rating\": {\"N\": \"9.9\"},\n      \":new_genre\": {\"S\": \"Adventure\"}\n  }' \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#7-add-a-new-attribute-using-updateitem","title":"7. Add a New Attribute (Using UpdateItem)","text":"<pre><code>aws dynamodb update-item \\\n  --table-name ps-games \\\n  --key '{\n      \"id\": {\"N\": \"102\"},\n      \"name\": {\"S\": \"God of War Ragnarok\"}\n  }' \\\n  --update-expression \"SET file_size = :size\" \\\n  --expression-attribute-values '{\n      \":size\": {\"N\": \"85\"}\n  }' \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#8-conditional-update-prevent-overwrites","title":"8. Conditional Update (Prevent Overwrites)","text":"<pre><code>aws dynamodb update-item \\\n  --table-name ps-games \\\n  --key '{\n      \"id\": {\"N\": \"102\"},\n      \"name\": {\"S\": \"God of War Ragnarok\"}\n  }' \\\n  --update-expression \"SET rating = :new_rating\" \\\n  --condition-expression \"rating &lt; :current_rating\" \\\n  --expression-attribute-values '{\n      \":new_rating\": {\"N\": \"9.7\"},\n      \":current_rating\": {\"N\": \"9.9\"}\n  }' \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#9-list-all-tables-in-your-aws-account","title":"9. List All Tables (In Your AWS Account)","text":"<pre><code>aws dynamodb list-tables --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#10-describe-table-view-table-structure-and-capacity","title":"10. Describe Table (View Table Structure and Capacity)","text":"<pre><code>aws dynamodb describe-table \\\n  --table-name ps-games \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#11-delete-table-clean-up-table","title":"11. Delete Table (Clean Up Table)","text":"<pre><code>aws dynamodb delete-table \\\n  --table-name ps-games \\\n  --region us-west-2\n</code></pre>"},{"location":"01_aws/03_database/04_4_DynamoDB_DVA-cli/#notes","title":"Notes:","text":"<ul> <li>Replace attribute values as needed for your use case.</li> <li>Ensure proper IAM permissions are configured before running commands.</li> <li>Use these commands responsibly in your AWS environment!</li> </ul>"},{"location":"01_aws/03_database/05_DAX/","title":"DAX (DynamoDB Accelerator)","text":""},{"location":"01_aws/03_database/05_DAX/#intro","title":"Intro","text":"<ul> <li>in memory cache for DynamoDB</li> <li>It caches the most frequently used data,</li> <li>thus offloading the heavy reads on hot keys of your DynamoDB table, </li> <li>hence preventing the <code>ProvisionedThroughputExceededException</code> exception.</li> <li><code>10x performance</code> improvement.</li> <li>micro sec latency </li> <li>fully secured</li> <li>DAX is compatible with DynamoDB API call</li> <li>hence won't require an application refactoring</li> </ul>"},{"location":"01_aws/03_database/05_DAX/#provision-dax-cluster","title":"provision DAX cluster","text":"<ul> <li>udemy reference</li> <li></li> <li>node size : min <code>3 nodes</code> recommended in prod.</li> <li>can add more later.</li> <li>node family : r-type / t-type</li> <li>can't change later</li> <li>network setup</li> <li>VPC-1</li> <li>subnets-1/2/3</li> <li>sg-1<ul> <li>allow inbound from port <code>9111</code> or <code>8111</code> in  the sg of application (elb, ec2, etc) </li> </ul> </li> <li>spread nodes in multi-AZ</li> <li>IAM role</li> <li>access to dynamoDB</li> <li>...</li> <li>setup parameter group</li> <li>TTL (item)</li> <li>DONE, get cluster URL and use in app.</li> </ul>"},{"location":"01_aws/03_database/05_DAX/#use-case","title":"use case","text":"<ul> <li>to fix hot key problem</li> <li>specific key read too many time, giving throttleError</li> <li>then cache that item in DAX</li> <li>cache has TTL (<code>5 min</code> default)</li> <li>millions of requests per second to DynamoDB, causing performance issue.</li> <li>Add DAX on front.</li> </ul>"},{"location":"01_aws/03_database/05_DAX/#architecture-example","title":"Architecture example","text":"<ul> <li>usinf DAX and ElasticCache, both.</li> </ul>"},{"location":"01_aws/04_network/00_eni%2BsecurityGroup/","title":"Network","text":""},{"location":"01_aws/04_network/00_eni%2BsecurityGroup/#eni-elastic-network-card","title":"ENI (elastic network card)","text":"<ul> <li>AZ bound </li> <li>create ENI independently and attach them on the fly to EC2,ALB,DB,etc</li> <li>flexible</li> <li>if ec2-1 is down/failed </li> <li>then launch new ec2-2 </li> <li> <p>attach same ENI from old instance to new</p> </li> <li> <p>eni Defines:</p> </li> <li>up/down speed</li> <li>VPC</li> <li>subnet</li> <li>one IP public <ul> <li>machine restarted, then it gets changed</li> <li>use elastic IP then.</li> </ul> </li> <li>one MAC address.</li> <li>one private (primary) + many secondary private IP</li> <li>elastic IP<ul> <li>only have <code>5 Elastic IP</code> in your account</li> <li>try to avoid using Elastic IP</li> <li>alternative : random Public IP + DNS entry</li> </ul> </li> <li>Security groups.</li> </ul>"},{"location":"01_aws/04_network/00_eni%2BsecurityGroup/#ec2-network-security-group-regional","title":"EC2: Network: Security group (regional)","text":"<ul> <li>virtual firewalls / traffic rules(60 max) - eg: allow incoming http, SSH traffic.</li> <li>inbound: all traffic blocked by default.</li> <li> <p>outbound : all traffic allow by default</p> </li> <li> <p><code>M2M</code> : apply multiple(max 5) sg on an ec2 instance, apply same sg2 to multipe ec2 insatnces.</p> </li> <li>EC2 instance-1 has sg-1, sg2,etc</li> <li> <p>EC2 instance-2 has sg-1, sg3,etc</p> </li> <li> <p><code>Stateful</code></p> </li> <li>if inbound allows request is allowed, then response is allowed too with further checking rule.</li> <li> <p>unlike ACL (staeless):  inbound rule is checked &gt; req allowed &gt; response came &gt; outbound rule is checked.</p> </li> <li> <p>TIP : always create new SG for <code>SSH</code> (22)</p> </li> <li>ssh -i \"path/to/your-key-file.pem\" -p 22 ec2-user@your-ec2-public-dns</li> <li> <p>use keypair over password</p> </li> <li> <p>Inbound / Outbound RULES</p> </li> <li>Protocol (TCP, UDP, RDP etc)</li> <li><code>Source</code> IP range/CIDR + <code>another SG</code><ul> <li>203.0.113.1/32 (specfic IP)</li> <li>0.0.0.0/0 (anywhere)</li> </ul> </li> <li><code>port</code> / single range (target machine which is ec2)<ul> <li>classic port: 21,22,80,443, 3389</li> <li>ICMP (Ping)  doesn't use ports</li> <li>range (from_port=80, to_port=80 ) --&gt; it will set single port.</li> <li>range (from_port=1, to_port=10 ) --&gt; it will 10 ports.</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/00_eni%2BsecurityGroup/#extra","title":"Extra","text":""},{"location":"01_aws/04_network/00_eni%2BsecurityGroup/#classic-ports","title":"classic ports","text":"<pre><code>\u2022 22 = SSH (Secure Shell) - log into a Linux instance\n\u2022 21 = FTP (File Transfer Protocol) \u2013 upload files into a file share\n\u2022 22 = SFTP (Secure File Transfer Protocol) \u2013 upload files using SSH\n\u2022 80 = HTTP \u2013 access unsecured websites\n\u2022 443 = HTTPS \u2013 access secured websites\n\u2022 3389 = RDP (Remote Desktop Protocol) \u2013 log into a Windows instance\n</code></pre>"},{"location":"01_aws/04_network/01_ELB/","title":"ELB (regional)","text":"<ul> <li>DNS name : <code>XXXX.region.elb.amazonaws.com</code> </li> <li>public IP might change </li> <li>https://docs.aws.amazon.com/elasticloadbalancing/latest/application/introduction.html</li> <li>SSl/TLS</li> <li><code>X.502</code> === TLS certificate (private key, bodt, chain)</li> <li>SNI (Server Name Indication)<ul> <li>resolves multiple certificate load problem.</li> <li>allows to expose multiple HTTPS applications each with its own SSL certificate on the same listener.</li> </ul> </li> <li>cpmplex service, AWS manages its underlying infrastructure outside your VPC.  </li> </ul>"},{"location":"01_aws/04_network/01_ELB/#1-proxy-server-with-additional-feature","title":"1. Proxy server with additional feature","text":"<ul> <li> <p>sits b/w client and backend-server. hides the backend server's IP address.</p> </li> <li> <p>forwards client requests to the appropriate backend server based on configured rules in <code>balanced distribution way</code>.</p> </li> <li>Content-Based Routing (url, queryparam,etc)</li> <li>gateway : offers a synchronous decoupling of applications</li> <li>client Session Stickiness</li> <li>Enforce stickiness with cookies</li> <li>integrated with ACM, WAF to add security. </li> <li>Termination of SSL/TLS at the ELB level</li> <li>allowing it to decrypt and inspect incoming traffic before forwarding it to the backend instances.</li> <li>separate <code>public-traffic</code> and <code>private-traffic</code></li> <li>also act as reverse-proxy</li> <li>it forwards client requests to backend servers and sends responses from those servers back to the clients.</li> </ul>"},{"location":"01_aws/04_network/01_ELB/#2-cross-zone-load-balancing","title":"2. Cross-Zone Load Balancing","text":"<ul> <li><code>mutli-AZ</code>(span over AZs), forwards traffic to multiple ec2 in different AZs.</li> <li>if az-1 has more instances running, most traffic must forward to az-1</li> <li></li> </ul>"},{"location":"01_aws/04_network/01_ELB/#3-health-check","title":"3. health-check","text":"<ul> <li>At tg-level. forwards traffic to healthy tg.</li> <li>Grace Period : helps to avoid premature health check failures.</li> <li>impaired status of EC2 </li> <li>OS check, n/w status failed on Ec2 - failed</li> <li>ASG marks unhealthy, replace it.</li> </ul>"},{"location":"01_aws/04_network/01_ELB/#5-integration","title":"5. integration","text":"<ul> <li>WAF </li> <li>ACM </li> <li>cert-1 for domain-1</li> <li>cert-2 for domain-2, </li> <li>...  </li> <li>SNI helps to load single Cert.</li> <li>route-53 (internet) + Global-Accelerator (aws private n/w) </li> <li>Cloudwatch</li> </ul>"},{"location":"01_aws/04_network/01_ELB/#6client-stickiness-with-cookies","title":"6.Client Stickiness with cookies","text":"<ul> <li>storing session data on ec2-i/tg</li> <li>may create imbalance </li> <li></li> <li>alternative approach</li> <li>use stores session data on elastiCache with TTL. </li> <li>03_ElastiCache.md</li> <li>cookies:</li> <li>ELB generated :<code>AWSALB, AWSALBAPP, AWSALBTG</code></li> <li>Application based : MY_TG_1_COOKIE, etc</li> </ul>"},{"location":"01_aws/04_network/01_ELB/#7types-3","title":"7.Types (3)","text":"<ul> <li>Classic LB (deprecated) </li> <li>ALB </li> <li>operate at <code>layer 7 : HTTP,HTTPS, websocket</code></li> <li>network LB </li> <li>operate at <code>layer 4 : TCP, UDP, TLS</code> </li> <li>very low latency, fast</li> <li>million of request</li> <li>gaming</li> <li>gateway LB (in 2020) </li> <li>provides advance security</li> <li>check more detail below:</li> </ul>"},{"location":"01_aws/04_network/01_ELB/#71-elb-alb-application-lb-layer-7","title":"7.1 ELB : ALB - Application LB (<code>layer 7</code>)","text":"<ul> <li>example flow:</li> <li><code>HTTP/S</code> request comes client with IP-1 to ELB</li> <li>ELB has integration ACM, WAF, etc</li> <li>adds extra header in http : <code>X-forwarded-for</code> : client ip</li> <li>rewrites the destination IP address </li> <li> <p>forward <code>HTTP</code> to </p> <ul> <li>target-group (one or many)</li> <li>redirect</li> <li>fixed-http-response</li> </ul> </li> <li> <p>target-group</p> <ul> <li>LB &gt;&gt; tg [EC2-I1, EC2-I3,...] : <code>VM</code></li> <li>LB &gt;&gt; tg [VM-1 [docker-1, docker-2, ...]] : <code>containers</code></li> <li>LB &gt;&gt; tg [lambda-1, lambda-2]</li> <li>LB &gt;&gt; tg [ip address] : <code>on-prem server IPs</code></li> </ul> </li> </ul>"},{"location":"01_aws/04_network/01_ELB/#listeners-with-content-based-routing","title":"Listeners with <code>content-based routing</code>","text":"<ul> <li>listens incoming traffic and appli forwarding rule and forward to tg</li> <li> <p>content-based routing </p> <ul> <li>path based </li> <li>route/path/url-1 --&gt; tg-1</li> <li>route/path/url-2 --&gt; tg-2</li> <li>...</li> <li>query-param </li> <li>/url-1?<code>plateform=mobile</code> --&gt; tg-1</li> <li>/url-1?<code>plateform=desktop</code> --&gt; tg-2</li> <li>...</li> <li>host based</li> <li>*.mycorp.com --&gt; tg0</li> <li>subdomain-1.mycorp.com --&gt; tg1</li> <li>subdomain-2.mycorp.com --&gt; tg2</li> <li>...</li> <li>HTTP header-based routing</li> <li>HTTP method-based routing</li> <li>Source IP  CIDR-based routing</li> </ul> </li> <li> <p>Cross-Zone Load Balancing : <code>free</code>, enable for ALB</p> </li> </ul>"},{"location":"01_aws/04_network/01_ELB/#registration-delay","title":"registration delay","text":"<ul> <li>(old name : Connection Draining)</li> <li>feature of load balancers that ensures active requests are completed before instances are deregistered / terminated</li> <li>prevents disrupting in-flight requests and ensures a smooth user experience</li> <li>default : <code>300 sec / 5 min</code> : allow 5 min to drains</li> <li>max : <code>3600 sec</code> / 1 hr</li> <li>make <code>0 to disable</code></li> <li> <p>if low like 5 sec, then:</p> <ul> <li>ec2-i will terminate fast, and all active clients session might lost,</li> <li>and assign to new instance on subsequent req.</li> </ul> </li> <li> <p>Security group</p> </li> <li>2 level of SG:<ul> <li>sg-elb-1</li> <li>sg-ec2-i1</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/01_ELB/#72-elb-nlb-network-lb-layer-4","title":"7.2 ELB : NLB - Network LB (<code>layer 4</code>)","text":"<ul> <li>fast: handles millionsOfReq/Second.</li> <li>ultra-low latencies</li> <li>automatically scales to handle the vast amounts of incoming traffic</li> <li>operates at <code>layer 4</code> </li> <li><code>TCP</code>, UDP, TLS </li> <li>cannot facilitate content-based routing like in ALB </li> <li>health-check support multiple-protocol : <code>http, https, TCP</code></li> <li>expose a fixed IP to the public web </li> <li>Security group NO  </li> <li> <p>alternatives:</p> <ul> <li>so add sg to EC2-i or tg</li> <li>or add network access control lists (NACLs)</li> </ul> </li> <li> <p>use-case</p> </li> <li>applications that need fixed IP addresses. <code>AWS assign static-IP to ALB, one for each AZ</code>.</li> <li>ideal for TCP/UDP Applications.</li> <li>microservices architectures.</li> <li> <p>gaming and streaming services.</p> </li> <li> <p>NLB target group</p> </li> <li>ELB/ALB </li> <li>EC2 instances</li> <li> <p>IP Addresses</p> </li> <li> <p>Cross-Zone Load Balancing : disable by default, <code>paid</code> </p> </li> <li>scenario #1 :highly available architecture for a ASG [ bastion hosts ec2-i  ]</li> </ul>"},{"location":"01_aws/04_network/01_ELB/#73-elb-gwlb-gateway-lb-layer-3","title":"7.3  ELB : GWLB - gateway LB (<code>layer 3</code>)","text":"<ul> <li>(layer 3 of OSI) IP packets.</li> <li>3rd party security instance:</li> <li>Deep packet inspection</li> <li>payload manipulate</li> <li>...</li> <li>uses protocol-GENEVE, port-6081 </li> <li>Cross-Zone Load Balancing : disable by default, <code>paid</code> </li> <li></li> </ul>"},{"location":"01_aws/04_network/01_ELB/#hands-on","title":"hands on","text":""},{"location":"01_aws/04_network/01_ELB/#alb","title":"ALB","text":"<pre><code>    - Launch `ec2-i1` and `ec2-i2`, add sg-1 to both.\n      - sg-1 : allow traffic ONLY from below `elb-sg-1` \n    - create target group - `tg-1` + /health/ + http:80\n    - Creat ELB - elb-1, elb-dns-1\n      - choose AZs\n      - add `elb-sg-1` : all public traffic\n      - add Listener &amp; Routing :  \n        - Listener-1::No-contion : outside traffic on http:80  --&gt; forward to --&gt; `tg-1` \n        - Listener-1::consition-1 (priority-100) : path, header, queryparam, etc. [TRY] --&gt; tg-x\n        - Listener-2::No-Condition (priority-200)  on https:443 --&gt; forward to --&gt; tg-2 + make sure ACM has Cert for tg-dns name.\n        - ...\n        - ...  \n        - Note:rule with higestest priorty win  \n      - hit dns-1\n      - terminate ec2-i1 and hit elb-dns-1 again.\n</code></pre>"},{"location":"01_aws/04_network/02_Rout53/","title":"Route 53","text":"<ul> <li>only service provide : <code>100% availability</code></li> <li>fact:: <code>53</code> is reference <code>tradition DNS port</code></li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#a-key-concept","title":"A. Key concept","text":""},{"location":"01_aws/04_network/02_Rout53/#dns","title":"DNS","text":"<ul> <li>registrar : dns record stores in zone file</li> <li>Naming Server : resolve dns queries<ul> <li></li> </ul> </li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#ttl","title":"TTL","text":"<ul> <li>client cache the result from DNS server, for that that period locally.</li> <li>hence wont query again till TTl expire.</li> <li>eg: 24 hr, 60 sec</li> <li>Domain/subdomain Name (example.com) + value (11.22.33.44)</li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#namespace","title":"namespace:","text":"<ul> <li>root domain <code>.</code> </li> <li>top level domain TLD</li> <li>second level domain SLD</li> <li>sub domain </li> <li>FQDN </li> <li>URL <ul> <li></li> <li>SLD/TLD === zone apex (eg: covid19survey.com)</li> <li>cannot create CNAME for covid19survey.com </li> </ul> </li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#dns-records","title":"DNS Records","text":"<ul> <li><code>A : domain -&gt; IPv4</code></li> <li><code>AAAA : domain -&gt; Ipv6</code></li> <li><code>CNAME : domain -&gt; doanother Domain (except root/TLD)</code></li> <li>eg: xxxx.us-east-1.alb.com --&gt; my-elb.com</li> <li><code>NS : domain -&gt; Name Server</code></li> <li><code>Alias</code> (AWS specific) </li> <li>benefit : free + native health-check</li> <li>eg:<ul> <li>domain --&gt; aws resources </li> <li>domain --&gt; root domain + TLD (works)</li> <li>domain --&gt; another record in same hosted zone</li> <li>domain --&gt; CAN NOT : ec2-instance-DN </li> <li>domain --&gt; CAN NOT :www.google.com (not aws resource) </li> </ul> </li> <li>Configuring TTL not allowed, set bt R53 </li> <li>Alias === [ A or AAAA + flag:alias=True ]</li> <li></li> <li><code>advanced</code>:   [ CAA / DS / MX / NAPTR / PTR / SOA / TXT / SPF / SRV ] - skip</li> <li>PTR: resolves IP address to FQDN</li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#aws-hosted-zone","title":"AWS :: Hosted Zone","text":"<ul> <li>cost : .50/m</li> <li>Container for DNS Record/s</li> <li>define traffic routing for its domain, its sub-domains </li> <li>Type</li> <li>public <ul> <li>internet traffic, resolves to public IP</li> </ul> </li> <li> <p>private  ( domainName eg: <code>internal.example.com</code>) </p> <ul> <li>internal traffic within VPC, resolves to private IP</li> <li>internal DNS management, secured, scalable.</li> <li>if associated (1-2-M) it with non-default VPC/s, then need to enable (disabled by default): </li> <li>DNS hostnames  / enable DnsHostnames</li> <li>DNS resolution / enable DnsSupport </li> </ul> </li> <li> <p></p> </li> <li></li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#c-r53routing-policy","title":"C. R53::<code>Routing policy</code>","text":"<ul> <li><code>simple</code> : domain -&gt; [ip-1, domain-2, ...] multiple target, </li> <li>randomly choose 1 </li> <li> <p>irrespective of health </p> </li> <li> <p><code>weighted</code> : domain -&gt; [ip-1::Weight10, domain-2::Weight70, ...]</p> </li> <li> <p>choose by weight</p> </li> <li> <p><code>Latency</code> : domain -&gt; [ip-1::region-1, domain-2:region-2, ...] multiple target, </p> </li> <li>AWS will look for latency and pick one with low value.</li> <li> <p></p> </li> <li> <p><code>failover</code> : domain -&gt; [ip-1::Primary, domain-2::Seconday, ...] multiple target, </p> </li> <li> <p>primary until healthy, else secondary.</p> </li> <li> <p><code>Geolocation</code> :  domain -&gt; [ip-1::Country-1, domain-2::Country-2, domain-3::default,...] multiple target, </p> </li> <li> <p>from client get Country.</p> </li> <li> <p><code>Geo-proximity</code> : domain -&gt; [ip-1::bais-0, domain-2::bais-50, ...] multiple target, </p> </li> <li>shift more traffic to domain-2</li> <li>Route traffic to your resources based on the geographic location of users and resources</li> <li></li> <li>create with UI for better visuality.</li> <li> <p>baise: -99 to 99</p> </li> <li> <p><code>IP based</code> : domain -&gt; [ip-1::Client-IP-range/CIDR-1, domain-2::Client-IP-range/CIDR-2, ...]</p> </li> <li> <p>choose by client_IP</p> </li> <li> <p><code>Multi value</code> : domain -&gt; [ip-1, domain-2, ...] multiple target, randomly choose 1 (<code>healthy</code>) </p> </li> <li>similar to <code>simple</code>.</li> <li> <p>randomly choose 1 but healthy only </p> </li> <li> <p>3rd party:  route by <code>goDaddy</code> policy.</p> </li> <li>link goDaddy with R53, </li> <li>just by updating  NS record in R53 hosted-zone(public),  with goDaddy DNs.</li> <li>can use R53 then.</li> <li></li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#hands-on","title":"hands on","text":"<ul> <li>https://us-east-1.console.aws.amazon.com/route53/trafficflow/home?region=us-east-2#/</li> <li>create from UI, :) <pre><code>- launch Ec2-i1, i2, and i3  (in az1, az2,az3), with simple webapp\n- create ALB\n    - `alb-1-dns` : hostname/domainname\n    - choose az1, az2, az3\n    - create TG (tg-1)\n        - sg : allow all HTTPs traffic\n        - AZ1, az2, az3\n        - regsister Ec2-i1, i2, and i3\n    - routing and filter: \n        - Listener-1::No-contion : outside traffic on `http:80`  --&gt; forward to --&gt; `tg-1` \n\n- create hosted Zone  [Zone : hz.com ]\n  - NS hz.com -&gt; *****, ****, ****, **** some entry comes automatically once HZ created : alrady present\n  - A + alias:F, ec2-1.com -&gt;   ec2-1 public IP  \n  - A + alias:F, ec2-2.com -&gt;   ec2-2 public IP  \n  - A + alias:F, ec2-3.com -&gt;   ec2-3 public IP  \n  - CNAME        abl.com --&gt; alb-1-dns\n  - A + alias:T, abl-alias.com --&gt; now can provide another domain --&gt; alb-1-dns ; FREE\n  - CNAME        hz.com --&gt;   alb-1-dns : ERROR\n  - A + alias:T, hz.com --&gt; alb-1-dns : WORKS\n\n  // Rourting policies\n  // SIMPLE\n  -  record-id-1, A + alias:F, webapp1.com -&gt;   ec2-1 public IP  SIMPLE \n  -  record-id-2, A + alias:F, webapp1.com -&gt;   ec2-2 public IP  SIMPLE \n  -  record-id-3, A + alias:F, webapp1.com -&gt;   ec2-3 public IP  SIMPLE\n  // WEIGHTED\n  -  record-id-11, A + alias:F, webapp2.com -&gt;   ec2-1 public IP  WEIGHTED 10\n  -  record-id-21, A + alias:F, webapp2.com -&gt;   ec2-2 public IP  WEIGHTED 20\n  -  record-id-33, A + alias:F, webapp2.com -&gt;   ec2-3 public IP  WEIGHTED 70\n  // LATENCY\n  -  record-id-111, A + alias:F, webapp3.com -&gt;   ec2-1 public IP  LATENCY us-east-1\n  -  record-id-222, A + alias:F, webapp3.com -&gt;   ec2-2 public IP  LATENCY us-east-1\n  -  record-id-333, A + alias:F, webapp3.com -&gt;   ec2-3 public IP  LATENCY us-west-2\n  // failover\n  -  record-id-1111, A + alias:F, webapp4.com -&gt;   ec2-1 public IP  failover \"primary\",  R53:healthCheck-1\n  -  record-id-2222, A + alias:F, webapp4.com -&gt;   ec2-2 public IP  failover \"seconday\", R53:healthCheck-2 (optional)\n  // Geolocation\n  -  record-id-1111, A + alias:F, webapp5.com -&gt;   ec2-1 public IP  Geolocation \"ASIA\",  \n  -  record-id-2222, A + alias:F, webapp5.com -&gt;   ec2-2 public IP  Geolocation \"EUROPE\"\n  // Geo-proximity\n  -  record-id-1111, A + alias:F, webapp6.com -&gt;   ec2-1 public IP  Geo-proximity Bias-10  \n  -  record-id-2222, A + alias:F, webapp6.com -&gt;   ec2-2 public IP  Geo-proximity Bias-50\n  // Multi-value\n  -  record-id-1111, A + alias:F, webapp7.com -&gt;   ec2-1 public IP Multi-value  R53:healthCheck-1 \n  -  record-id-2222, A + alias:F, webapp7.com -&gt;   ec2-2 public IP Multi-value  R53:healthCheck-1\n\n- acess webapp:\n  - diectly from ec2-i public IPS\n  - add (A + alias:F) record and access\n  - via ELB \n    - alb-1-dns\n    - abl-alias.com\n  - hz.com\n  - Rourting policies demo : webapp[1,2,3,...7].com\n</code></pre></li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#d-r53-health-check","title":"D. R53 :: <code>health Check</code>","text":"<ul> <li>create health heck and use in DNS entries.</li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#a-health-checker-endpoint","title":"a. health checker : <code>Endpoint</code>","text":"<ul> <li>update sg to allow: runs outside private VPC</li> <li>provide health endpoints.</li> <li>set interval : 10 sec or 30 sec</li> <li></li> <li>eg: R53 alais record</li> <li>point to ALB</li> <li>health check point to ALB (Evaluated Health Check = True) </li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#b-health-checker-caculated","title":"b. health checker : <code>Caculated</code>","text":"<ul> <li>choose : state of other health checks</li> <li>AND OR NOT, etc. mix amd match.</li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#c-health-checker-cw-alarm-state","title":"c. health checker : <code>CW Alarm state</code>","text":"<ul> <li>create CW alarm, first.</li> <li> <p>select it. while creating R53 health check</p> </li> <li> <p></p> </li> <li></li> <li></li> </ul>"},{"location":"01_aws/04_network/02_Rout53/#e-scenario","title":"E. Scenario","text":""},{"location":"01_aws/04_network/02_Rout53/#1-resolve-outside-aws-dns","title":"1. resolve Outside AWS dns","text":"<ul> <li>A retail company has connected its on-premises data center to the AWS Cloud  via AWS Direct Connect. </li> <li>The company wants to be able to resolve DNS queries </li> <li>for any resources in the <code>on-premises</code> from the <code>AWS VPC</code> </li> <li>for any resources in the <code>AWS VPC</code> from the <code>on-premises</code></li> <li>solution:</li> <li>Create an outbound endpoint on  Route 53 Resolver <ul> <li>and then <code>Amazon Route 53 Resolver</code> </li> <li>can conditionally forward DNS queries to <code>on-premises resolvers</code>, via this endpoint.</li> </ul> </li> <li>Create an inbound endpoint on  Route 53 Resolver <ul> <li>and then <code>on-premises DNS resolvers</code> </li> <li>can conditionally forward DNS queries to  <code>Route 53 Resolver</code>, via this endpoint.</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/","title":"A  network fundamental","text":""},{"location":"01_aws/04_network/03_VPC-1-start/#1-cidr","title":"1 cidr","text":"<ul> <li>CIDR/IP-range : base-IP/fixed-bit (0-32)</li> <li>0.0.0.0/0  or ::0 -  Any traffic in internet.</li> <li>Private IP</li> <li>10.0.0.0 \u2013 10.255.255.255 <ul> <li>10.0.0.0/8 : in big networks, </li> <li>10.0.0.0/28 - will use </li> <li>10.0.0.0/16 - will use</li> </ul> </li> <li>172.16.0.0 \u2013 172.31.255.255 <ul> <li>(172.16.0.0/12)  AWS default VPC uses this.</li> </ul> </li> <li>192.168.0.0 \u2013 192.168.255.255 <ul> <li>192.168.0.0/16: Home n/w</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#2-ephemeral-port","title":"2 ephemeral port","text":"<ul> <li>ephemeral port </li> <li>random port client open, to receive response on that port from server. </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#b-vpc-regional","title":"B. VPC ( Regional)","text":""},{"location":"01_aws/04_network/03_VPC-1-start/#1-fact","title":"1. fact","text":"<ul> <li>ec2&gt;eni&gt;sg === ec2&gt;sg</li> <li>s3 upload : ingress traffic</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#2-intro","title":"2. Intro","text":"<ul> <li>max: <code>5-VPC</code> in  a region with non-overlapping CIDR.</li> <li>single VPC can have max <code>5-CIDR</code></li> <li>CIDR min **/28 = 32-28 = 4 --&gt; 2^4 = <code>16</code></li> <li>CIDR max **/16 = 32-16 = 16 --&gt; 2^16 = <code>65,536</code></li> <li>private resource : referring only private IPs ranges.</li> <li>route table <code>rtb</code> vs security group <code>sg</code></li> <li>sg allow/deny traffic</li> <li>rtb helps in forwarding , routing allowed traffic.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#3-default-vpc-walkthrough","title":"3. Default VPC : walkthrough","text":""},{"location":"01_aws/04_network/03_VPC-1-start/#30-tenancy-for-ec2","title":"3.0 <code>tenancy</code> for EC2","text":"<ul> <li>console &gt;&gt; VPC Settings &gt;&gt; Tenancy dropdown &gt;&gt;</li> <li>Default  **</li> <li>Dedicated</li> <li>tenancy(in VPC) sets the baseline, and tenancy (in LT) cannot downgrade it.  <ul> <li><code>host &gt;&gt; dedicated &gt;&gt; default</code></li> </ul> </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#31-cidr","title":"3.1 CIDR","text":"<ul> <li>CIDR-1 : <code>172.32.0.0/16</code></li> <li>CIDR-2,3,4,5 </li> <li>Add these once IPs are exhausted in your VPC.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#32-subnet-found-4","title":"3.2 subnet (found 4)","text":"<ul> <li>4 az === 4 subnets </li> <li>each has it own IP CIDR.</li> <li>first 4 and last IP  are reserved (<code>5-resevered in each subnet</code>) </li> <li>first: network address</li> <li>2:reserved - VPC router</li> <li>3:reserved - DNS</li> <li>4:reserved - future use</li> <li>last:reserved - network broadcast address, (not supported currently)</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#33-route-table","title":"3.3 Route table","text":"<ul> <li>vpc - associated with main-rtb</li> <li>subnet-1 : associate with main-rtb, or create new rtb</li> <li>subnet-2</li> <li>...</li> <li> <p>1-2-1 mapping </p> </li> <li> <p>destination</p> </li> <li>0.0.0.0/0(internet),</li> <li>subnet-CIDR</li> <li>vpc-CIDR</li> <li>custom-cidr</li> <li>...</li> <li>target</li> <li><code>igw</code>, <code>nat-g/i</code>, <code>local</code>, <code>vpc-peer</code>, <code>vgc</code>, <code>cgw</code>, <code>dxg</code>, <code>transient-gateway</code></li> <li> <p><code>VPC-endpoint</code>, <code>s3-gateway</code>, <code>dynamoDb-gateway</code></p> </li> <li> <p>IPv6 routing</p> </li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#34-network-acl-nacl","title":"3.4 Network ACL (NACL)","text":"<ul> <li>similar to SG/Firewall, another layer of traffic check at subnet level</li> <li> <p>Inbound + outbound rule (with weight/priority) for allow/deny traffic</p> </li> <li> <p>stateless</p> </li> <li>inbound rule is checked &gt;  allow/deny </li> <li>if allowed &gt; response came &gt; outbound rule is checked &gt;  allow/deny</li> <li></li> <li>ACL rules</li> <li>1-32,766 (high to low precedence), use increment of 100.</li> <li>first matching rule, drive decision.</li> <li><code>*</code> last rule, denies a request.</li> <li>thus, Does not execute all rule, once executed a matching high priority rule, it stops.</li> <li>default rule</li> <li>allows everything in/out </li> <li>don't change it, rather create new ACL and associate with your subnet.</li> <li></li> <li><code>subnet</code> 1-2-1 <code>ACL</code></li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#sg-vs-acl","title":"sg vs ACL","text":"<ul> <li>Operates at the instance level | subnet level</li> <li>Stateful| Stateless: return traffic must be explicitly allowed by rules (think of ephemeral ports)</li> <li><code>allow</code> rules only |  <code>allow/deny</code> rules</li> <li><code>All</code> rules are evaluated | Rules are evaluated <code>in order</code> (lowest to highest) and <code>first match wins</code>.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#nacl-with-ephemeral-port-range","title":"NACL with  ephemeral port range","text":""},{"location":"01_aws/04_network/03_VPC-1-start/#4-igw","title":"4. IGW","text":""},{"location":"01_aws/04_network/03_VPC-1-start/#5-nat","title":"5. NAT","text":"<ul> <li>03_VPC-2-NAT.md</li> <li>Bastian host</li> <li>NAT instance (outdated after 2020) </li> <li>NAT gateway</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#6-dual-stack-mode-vpc","title":"6. Dual-stack mode VPC","text":"<ul> <li>can not disable Ipv4, but enable Ipv6 ( for all public in AWS) <code>3.8*10^38</code></li> <li>ec2-i will have both:</li> <li>private IPv4 </li> <li>public IPv6 </li> <li>so if IPv4 is exhausted, even though soo many IPv6 available, will still get exhausted error. </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#7-egress-only-internet-gateway","title":"7. Egress-Only Internet gateway","text":"<ul> <li>used only for Ipv6</li> <li>note: update rtb ::0 | Egress-IGW</li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#8-vpc-flow-logs","title":"8. VPC Flow Logs","text":"<ul> <li>log level : VPC | Subnet | ENI </li> <li>destination :</li> <li>S3  &gt;&gt; athena<ul> <li>CloudWatch </li> <li>CW::metric &gt;&gt; CW::alarm &gt;&gt; sns</li> <li>KDF (collect data stream)  , not KDS</li> <li>...</li> </ul> </li> <li></li> <li></li> <li> </li> <li> <p>hands on: <pre><code>- create flow log -1 and give it S3\n- choose type of traffic : ALL, allow, deny\n- to : s3 (bucket-name-1)\n- choose format :keep default\n- role-1 : give s3 permission\n- check logs (perform complex analysis &gt; give it athena)\n  -eni-1.log \n  -eni-2.log. ...\n  - Attena:\n    - choose query result loc: bucket-name-1-result\n    - ...\n\n- create flow log -2 and give it CW\n- choose type of traffic : ALL, allow, deny\n- to : cloudwatch (log-group-1)\n- choose format :keep default\n- role-2 : give CW permission\n- check logs --&gt; create metric &gt; alarm &gt; SNS\n</code></pre></p> </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#9-pricing-per-gb","title":"9. pricing (per GB)","text":"<ul> <li>if 2 DB are in same AZ, replication cost will be less, but availability will be less.</li> <li>refer VPC-endpoint(s3-gateway) <code>1 cent</code></li> <li>ingress - free</li> <li> <p>choose AWS direct location, close/same as your location/region-AZ</p> </li> <li> <p></p> </li> <li></li> <li></li> <li></li> </ul> Service/Feature Pricing VPC Peering Intra-region: $0.01/GB, Inter-region: $0.02\u2013$0.09/GB AWS Transit Gateway (TGW) $0.36/hour per attachment, $0.02\u2013$0.05/GB data transfer NAT Gateway $0.045/hour, $0.045/GB for outbound data Elastic IP (EIP) Free for 1 associated IP; additional/unused: $0.005/hour VPN Connections $0.05/hour per VPN connection, standard data transfer rates apply Traffic Mirroring $0.015/GB Endpoints (PrivateLink) Interface Endpoints: $0.01/hour + $0.01/GB, Gateway LB Endpoints: $0.0035/GB Data Transfer Intra-AZ: Free, Inter-AZ: $0.01/GB, Inter-region: $0.02\u2013$0.09/GB Interface Endpoints $0.01/hour per endpoint + $0.01/GB Gateway Endpoints Free --- ## 10. Traffic Mirroring - Steps/use-case: - capture traffic (from Specific <code>source ENIs</code>) - route/send to <code>ELB/NLB</code> or <code>target ENI</code> - ec2-i(security appliance) - perform inspection (threat monitoring, etc) -"},{"location":"01_aws/04_network/03_VPC-1-start/#11-topolgies","title":"11. topolgies","text":"<ul> <li>03_VPC-4-tolologies.md</li> <li>on-prem VPN<ul> <li>client gateway</li> </ul> </li> <li>aws vpc<ul> <li>virtual gateway</li> <li>Dx gateway</li> <li>Transient gateway</li> </ul> </li> <li>s2s + cloudHub</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#99-handson-create-new-vpc","title":"99. handson: create new VPC","text":"<ul> <li>region - us-west-2</li> <li>vpc-1 : https://us-west-2.console.aws.amazon.com/vpcconsole/home?region=us-west-2#VpcDetails:VpcId=vpc-04ce2894d2f99bbb8 <pre><code>- edit CIDR : add IPv6 cide.\n- For Internet access:\n  - create `igw-1` (igw-0ee888f95b632848e, internet gateway) to vpc-1 and `attach` to vpc-1\n  - create `nat-ec2-i1` (NAT - network access translation)\n  - create `ngw-1` ( NAT gateway) : pending\n- route table:\n  - `rtb-main` : gets created automatically with vpc.\n    - will automatically get associated underlying subnet/s, if not attached to any explicit rtb.\n  - `rtb-explicit/s` : can create and association to subnet.\n      - create `rtb-explicit-1-private-vpc1` , routes:\n        - destination: internet(0.0.0.0/0) --&gt; nat-instance-1 [nat-i](03_VPC-2.md) ==&gt; give internet access (without exposing ec2-i)\n      - create `rtb-explicit-2-public-vpc1` , routes: \n        - destination: internet(0.0.0.0/0)  --&gt; igw-1 ==&gt; give internet access.\n        - VPC private CIDR --&gt; local (within VPC)\n        - ![img.png](../99_img/vpc-1/img.png)\n  - `relation`:\n    - VPC &lt;--1-to-1--&gt; rtb-main\n    - underlying subnet/s &lt;--1-to-1--&gt; rtb-explicit/s or rtb-main:default\n  - ![img_1.png](../99_img/vpc-1/img_1.png)\n\n- add `subnet`\n  - az-1 (us-west-2a)\n    - vpc-1-subnet-`private`-1-us-west-2a\n      - link with rtb-explicit-2-private-vpc1.\n    - vpc-1-subnet-`public`-1-us-west-2a\n      - link with rtb-explicit-2-public-vpc1.\n      - contains: `ACL`+ Ec2-i1(public IP-1)\n      - edit CIDR : add `IPv6` CIDR block + enable: assigning IPv6.\n        - update `sg/acl` rule for IPv6\n        - update `rtb` with ::0 (IPv6 anywhere)\n  - az-2 (us-west-2b)\n    - vpc-1-subnet-`private`-2-us-west-2b\n      - link with rtb-explicit-2-private-vpc1\n    - vpc-1-subnet-`public`-2-us-west-2b\n      - link with rtb-explicit-2-public-vpc1\n</code></pre></li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#100-summary","title":"100. Summary","text":"<ul> <li><code>CIDR</code> \u2013 IP Range</li> <li><code>VPC</code> \u2013 Virtual Private Cloud =&gt; we define a list of IPv4 &amp; IPv6 CIDR</li> <li><code>Subnets</code> \u2013 tied to an AZ, we define a CIDR</li> <li><code>Internet Gateway</code> \u2013 at the VPC level, provide IPv4 &amp; IPv6 Internet Access</li> <li><code>Route Tables</code> \u2013 must be edited to add routes from subnets to the IGW, VPC Peering Connections, VPC Endpoints, \u2026</li> <li><code>Bastion Host</code> \u2013 public EC2 instance to SSH into, that has SSH connectivity to EC2 instances in private subnets</li> <li><code>NAT Instances</code> \u2013 gives Internet access to EC2 instances in private subnets. Old, must be setup in a public subnet, disable Source / Destination check flag</li> <li><code>NAT Gateway</code> \u2013 managed by AWS, provides scalable Internet access to private EC2 instances, when the target is an IPv4 address</li> <li><code>NACL</code> \u2013 stateless, subnet rules for inbound and outbound, don\u2019t forget Ephemeral Ports</li> <li><code>Security Groups</code> \u2013 stateful, operate at the EC2 instance level</li> <li><code>VPC Peering</code>\u2013 connect two VPCs with non overlapping CIDR, non-transitive</li> <li><code>VPC Endpoints</code> \u2013 provide private access to AWS Services (S3, DynamoDB, CloudFormation, SSM) within a VPC</li> <li><code>VPC Flow Logs</code> \u2013 can be setup at the VPC / Subnet / ENI Level, for ACCEPT and REJECT traffic, helps identifying attacks, analyze using Athena or CloudWatch Logs Insights</li> <li><code>Site-to-Site VPN</code> \u2013 setup a Customer Gateway on DC, a Virtual Private Gateway on VPC, and site-to-site VPN over public Internet</li> <li><code>AWS VPN CloudHub</code> \u2013 hub-and-spoke VPN model to connect your sites Direct Connect \u2013 setup a Virtual Private Gateway on VPC, and establish a direct private connection to an AWS Direct Connect Location</li> <li><code>Direct Connect Gateway</code> \u2013 setup a Direct Connect to many VPCs in different AWS regions</li> <li><code>AWS PrivateLink</code> / VPC Endpoint Services:</li> <li>Connect services privately from your service VPC to customers VPC</li> <li>Doesn\u2019t need VPC Peering, public Internet, NAT Gateway, Route Tables</li> <li>Must be used with Network Load Balancer &amp; ENI</li> <li><code>ClassicLink</code> \u2013 connect EC2-Classic EC2 instances privately to your VPC</li> <li><code>Transit Gateway</code> \u2013 transitive peering connections for VPC, VPN &amp; DX</li> <li><code>Traffic Mirroring</code> \u2013 copy network traffic from ENIs for further analysis</li> <li><code>Egress-only Internet Gateway</code> \u2013 like a NAT Gateway, but for IPv6 targets</li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#c-vpc-firewall","title":"C. VPC firewall","text":"<ul> <li>managed service</li> <li>inspect all traffic to/from:</li> <li>internet</li> <li>peered VPC</li> <li>Data-center/customer (DX oe S2S)</li> <li>...</li> <li></li> <li>firewall use gateway Load Balancer </li> <li>layer 3 to 7 protection</li> <li>tg ec2-i : security applicance running<ul> <li>rules - filter ip, port, protocol, domain level(*.abc.com), regex</li> <li>action : allow, drop, alert</li> </ul> </li> <li>more:</li> <li>can be used to manage multiple aws account</li> <li>analysis:<ul> <li>send logs to s3, CW, KDF</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#d-extra-ssa","title":"D. Extra : SSA","text":""},{"location":"01_aws/04_network/03_VPC-1-start/#1-shared-service-vpc","title":"1. <code>shared service VPC</code>","text":"<ul> <li>VPC-1/2/3... all connected with transient gateway</li> <li>inside VPC-1 </li> <li>create service-1 - eni:vpce-1</li> <li>create service-2 - eni:vpce-2</li> <li>...</li> <li>provides access to services-1/2/..., required by workloads in each of the VPCs</li> <li>share service-1/2/... with VPC-2,3,... using VPC endpoint/s</li> <li>VPC-1 will become shared VPC, since its sharing resources to other VPC <pre><code>#1\nAn e-commerce company operates multiple AWS accounts and has interconnected these accounts in a hub-and-spoke style\nusing the AWS Transit Gateway. Amazon Virtual Private Cloud (Amazon VPCs) have been provisioned across these AWS accounts \nto facilitate network isolation.\n\nWhich of the following solutions would reduce both the administrative overhead and the costs while providing shared access \nto services required by workloads in each of the VPCs?\n\n- Build a shared services Amazon Virtual Private Cloud (Amazon VPC)\n</code></pre> </li> </ul>"},{"location":"01_aws/04_network/03_VPC-1-start/#2-transit-vpc","title":"2. Transit VPC","text":"<ul> <li>Transit VPC uses customer-managed EC2 instances in a dedicated transit VP with an Internet gateway</li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-2-NAT/","title":"VPC-2","text":""},{"location":"01_aws/04_network/03_VPC-2-NAT/#1-bastion-host","title":"1. bastion host","text":"<ul> <li>Access(perform SSH) ec2-i in private subnet from internet  ( via bastion host)</li> <li>SSH protocol, which is a TCP based protocol on port 22. </li> <li>just update SGs:</li> <li>sg-bastion : <ul> <li>allow inbound traffic 0.0.0.0/0  on port 22(SSH)</li> </ul> </li> <li>sg-ec2-i : <ul> <li>allow inbound traffic from  sg-bastion, on port 22(SSH) </li> <li></li> </ul> </li> <li>bastion host is not typically used to manage all <code>outgoing traffic</code> from the private network to the internet.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-2-NAT/#2-nat-instance","title":"2. NAT instance","text":"<ul> <li>can be used as a bastion server </li> <li>outdated after 2020 </li> <li>NAT instances are not a managed service, it has to be managed and maintained by the customer.</li> <li>Alternative : NAT gateway </li> <li>need internet  access for ec2-i running on private subnet. how ?</li> <li> <p>route internet traffic to IGW via through NAT-instance.</p> <ul> <li>deploy NAT-instance in public subnet</li> <li>create ec2-i, from PreConfigured Linux AMI, <code>amzn-ami-vpc-nat-&lt;year&gt;.xxxxxxx-&lt;cpu-arch&gt;</code></li> <li>disable source/destination IP check, so that it will re-write <code>src</code> and <code>dest</code> IPs </li> <li></li> <li>update rtb of private subnet</li> <li>0.0.0.0/0  ::  NAT-instance</li> <li>update NAT-instance sg</li> <li>update sg of private ec2-i, to allow traffic from  NAT-instance-sg</li> <li>assign elastic-IP</li> </ul> </li> <li> <p>it supports port forwarding </p> </li> <li>by modifying the instance's iptables rules. </li> <li> <p>to forward traffic </p> <ul> <li>from : specific port on the NAT Instance </li> <li>to : port on a private EC2 instance.</li> </ul> </li> <li> <p></p> </li> <li>https://app.diagrams.net/#Hlekhrajdinkar%2F02-spring%2Fmain%2Faws%2FVPC-1.drawio</li> <li>types and use case: private and public</li> <li></li> <li>private NAT-g: use to route traffic from VPC-1 to VPC-2, having overllaping CIDR.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-2-NAT/#3-nat-gateway","title":"3. NAT Gateway","text":"<ul> <li>Can\u2019t be used by EC2 instance in the same subnet, where NAT gateway is present   </li> <li></li> <li>NAT gateway cannot be used as a bastion server </li> <li> <p>does  not support port forwarding </p> </li> <li> <p>primary task:</p> </li> <li>enable instances in a private subnet to connect to the internet or other AWS services</li> <li> <p>but prevent the internet from initiating a connection with those instances.</p> </li> <li> <p>AZ bounded </p> </li> <li>AWS-managed</li> <li>no administration </li> <li> <p>No Security Groups to manage</p> <ul> <li>alternative: attach ACL on subnet</li> </ul> </li> <li> <p>higher bandwidth supports bandwidth : <code>5 - 45 Gbps</code>.</p> </li> <li> <p>provision </p> </li> <li>create one with <code>in each AZ</code></li> <li>assign elastic-IP </li> <li>choose public subnet (having IGW)</li> <li> <p>update route table of each private subnet.</p> <ul> <li>if destination is <code>0.0.0.0/0</code>  ::  then route to <code>NAT-gateway-az-1</code></li> <li>if destination is <code>0.0.0.0/0</code>  ::  then route to <code>NAT-gateway-az-2</code></li> <li>...</li> </ul> </li> <li> <p>more</p> </li> <li>supported protocols: TCP, UDP, and ICMP.</li> <li>support up to <code>55,000</code> simultaneous connections, to each unique destination.</li> <li>primarily for outbound-only traffic from private subnets</li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/","title":"1. VPC peering","text":""},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#intro","title":"intro","text":"<ul> <li>establishes a direct network connection between two VPCs</li> <li>enabling traffic to be routed between them using private IP addresses.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#scenario","title":"scenario","text":"<p><pre><code>- within the same account \n  - same region\n  - cross region\n- across different accounts\n  -  same region\n  - cross region\n- or even AWS Organizations.\n</code></pre> - Same AWS Account   - Aws1::VPC-1  &lt;--- VPC peer---&gt; Aws1::VPC-2 - Cross Account   - Aws1::VPC-1  &lt;--- VPC peer---&gt; Aws2::VPC-1</p>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#more","title":"more","text":"<ul> <li>NOT Transitive </li> <li>VPC-1  &lt;--&gt; VPC-2 &lt;--&gt; VPC-3 </li> <li>this does not mean VPC-1 can connect VPC-3</li> <li>create dedicated connections.</li> <li> <p>or use transitive gateway, for connecting mutliple VPC/s</p> <ul> <li>$0.05 per GB for inter-VPC data transfer.</li> <li>$0.36 per hour per attached VPC.</li> </ul> </li> <li> <p>no overlapping CIDR</p> </li> <li>operates over the AWS backbone network, ensuring</li> <li>low latency </li> <li> <p>high throughput</p> </li> <li> <p>Limited by the number of peering connections per VPC (up to 125 by default).</p> </li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#hands-on","title":"hands on:","text":"<pre><code>#1. connecting ec2-i on vpc-1 to ==&gt; ec2-i on default-vpc, in same AWS account\n- having VPC-1 (cidr1) + default-VPC(cidr2) \n- create `VPC-peer-1` : select vpcs -&gt; ( VPC-1 + default-VPC )\n- update main-rtb of both VPC with VPC-peer-1\n  - vpc-1-main-rtb       : [ destinition:cidr2 =&gt; VPC-peer-1 ]\n  - default-vpc-main-rtb : [ destinition:cidr1 =&gt; VPC-peer-1 ]\n- Now route going both ways :) \n</code></pre>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#2-vpc-endpoint","title":"2. VPC Endpoint","text":"<ul> <li>AWS PrivateLink</li> <li>provides private connectivity between VPCs (Virtual Private Clouds) and AWS services or on-premises networks via private IP addresses,</li> <li>ensuring that traffic does not traverse the public internet.</li> <li>Uses Elastic Network Interfaces (ENIs) with private IPs.</li> <li>Traffic stays within the AWS network, for higher security and reduced latency.</li> <li>use case: Expose your service to other VPCs in the same region or across regions.</li> <li>VPC Endpoint (Interface Endpoint) </li> <li>connects service swith in same regions, privately. Not suitable for inter region comm. </li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#intro_1","title":"intro","text":"<ul> <li>highly available</li> <li>scales horizontally</li> <li><code>service-1</code> aws-?:region-? --&gt; AWS PrivateLink (No internet) --&gt;  <code>service-2</code> aws-?:region-?</li> <li>Works within the AWS network, allowing secure access to services via private IPs</li> <li>in ccgg:mapss. everything in one region.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#scenarios-for-understanding","title":"scenarios (for understanding)","text":"<ul> <li>ECS-1:TASK-1 (region-1,VPC-1) ==&gt; SEND TO SNS (region-2,VPC-2)</li> <li>option-1 : VPC1 &gt; NGW &gt; IWG &gt; internet &gt; VPC2</li> <li>using internet</li> <li> </li> <li> <p>option-2 : VPC1 &gt; VPC-endpoint &gt; aws-private-network/link &gt; VPC2 : </p> </li> <li>better: remains on VPC/s, no internet</li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#type","title":"Type","text":""},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#interface","title":"interface : $","text":"<ul> <li>use with ALL services</li> <li>AWS use PrivateLink to comm.</li> <li>attach ENI to aws resource + update private DNS for subnet/vpc</li> <li>update security group as per this ENI.</li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#gateway-free","title":"Gateway : free","text":"<ul> <li>Avialable for  S3 and DynamoDB , only </li> <li>s3-gateway : aws create special gateway to access global s3 services.</li> <li>DynamoDB-gateway :  aws create special gateway to access global Dynamo DB.</li> <li>just update rtb with these gateway/s, like wwe did for igw,nat,etc.</li> <li>Destination: prefix_list_id</li> <li>target : gateway_endpoint_id</li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#hands-on_1","title":"hands on","text":""},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#-vpc-1-public-subnet-1-ec2-i1-rtb-igw-1-was-present-connectssh-to-ec2-i1-aws-ls-s3-works-becuase-of-igw-1-remove-igw-1-from-rtb-aws-ls-s3-no-response-fix-with-vpc-endpoint-a-create-interface-name-vpc-endpoint-interface-1-select-service-to-select-vpc-from-select-az-subnet-where-these-will-be-deployed-update-sg-rules-remember-ec2enisg-ec2sg-b-s3-gateway-select-vpc-select-rtb-to-be-updated-aws-ls-s3-works-now-because-of-s3-gateway-recommended-to-use-s3-private-link","title":"<pre><code>- vpc-1 &gt;  public-subnet-1 (ec2-i1) &gt; rtb: igw-1 (was present)\n- connect,SSh to ec2-i1 &gt; aws ls s3 : works becuase of igw-1\n- remove igw-1 from rtb\n- aws ls s3 - no response\n- Fix with VPC-endpoint:\n  - a.  create interface : \n    - name: vpc-endpoint-interface-1\n    - select service (to)\n    - select vpc  (from)\n    - select AZ + subnet, where these will be deployed.\n    - update sg rules. (remember : ec2&gt;eni&gt;sg === ec2&gt;sg)\n  - b. s3 gateway:\n    - select vpc\n    - select rtb, to be updated.\n- aws ls s3 : works now, because of s3-gateway (recommended to use) / s3-private-Link\n</code></pre>","text":""},{"location":"01_aws/04_network/03_VPC-3-vpcPeer%2Bvpce/#3-vpc-sharing","title":"3. VPC Sharing","text":"<ul> <li>Resource R1,R2,etc provisioned within the VPC-b(middle) of Account B</li> <li>create vpce1 foe R1, etc </li> <li>transient gatewat connected already Account A (vpc A), Account b (vpc b ), Account c (vpc c)</li> <li>hence can communicate with each other over <code>private IP</code> without additional configuration.</li> <li>Since all resources are within the same VPC, there are no additional data transfer costs. </li> <li>no data going out of AWS.</li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/","title":"03 VPC 4 tolologies","text":"<pre><code>  - network:0 - AWS VPC-1 (vpc)\n  - network:1 - internet (public internet)\n  - network:2 - Corporate Network (VPN)\n\n  - vgw == `Vitual-private GateWay` \n  - cgw == `Customer gateway` / software+hardware, running on customer side / attached `NAT-device`(public-IP-1)\n</code></pre>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#network-topologies","title":"Network topologies","text":""},{"location":"01_aws/04_network/03_VPC-4-tolologies/#a-awsvpc-awsvpc","title":"A. AWS::VPC &lt;==&gt; AWS::VPC","text":""},{"location":"01_aws/04_network/03_VPC-4-tolologies/#a1-awsvpc-1-to-internet","title":"A.1. <code>AWS::VPC-1</code> to <code>internet</code>","text":"<p><pre><code>network:0,AWS VPC-1 (`rtb-main`) --&gt; `igw`  --&gt; network:1 : \n</code></pre> - create igw-1 - update rtb-main with igw-1 entry.</p>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#a2-vpc-peering-awsvpc-1-to-awsvpc-2","title":"A.2. VPC peering :: <code>AWS::VPC-1</code> to <code>AWS::VPC-2</code>","text":"<ul> <li>03_VPC-3-vpcPeer+vpce.md <pre><code>all vpc in same/cross region &lt;&lt;&lt;\n\neg : with same region: \n `Aws1::VPC-1` (CIDR-1)  &lt;--- VPC peer ---&gt; `Aws1::VPC-2` \n `Aws1::VPC-2` (CIDR-2)  &lt;--- VPC peer ---&gt; `Aws1::VPC-3` \n `Aws1::VPC-3` (CIDR-3)  &lt;--- VPC peer ---&gt; `Aws1::VPC-1` \n\n # No \"overlapping\" CIDR among them.\n # not transitive\n</code></pre></li> </ul>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#b-awsvpc-internet-clientvpn","title":"B AWS::VPC &lt;INTERNET&gt; client::VPN","text":""},{"location":"01_aws/04_network/03_VPC-4-tolologies/#b1-aws-site-2-site-vpn","title":"B.1. AWS Site-2-site VPN","text":"<ul> <li><code>AWS::VPC-1</code> to <code>Client-VPN-1</code></li> <li>also known as IPsec VPN connection</li> <li> <pre><code>- connect AWS::VPC-1 to Client-VPN-1\n\nhow:\nAWS VPC-1 (rtb-main:vgw-1) &lt;==&gt; [ vgw-1 &lt;---Site-2-site VPN(uses:internet)---&gt; cgw-1 ] &lt;==&gt; network:2(customer-1) \n- this connection are `encrypted` by default.\n- uses:internet\n</code></pre></li> <li>Step-1: create virtual gateway <code>vgw-1</code>, and attached on AWS VPC-1 </li> <li>does not Support ECMP </li> <li>Step-2: create client gateway <code>cgw-1</code>, with customer details like - public-IP, etc</li> <li>Step-3: create Site2Site VPN to connect <code>cgw-1</code> with <code>vgw-1</code>.</li> <li>tunnels<ul> <li><code>tunnel-1</code> forward</li> <li><code>tunnel-2</code> backward</li> <li>tunnel 1/2 == used for single connection</li> <li><code>1.25gbps</code></li> </ul> </li> <li>Step-4: update <code>rtb-main</code> with vgw-1 : for traffic forwarding between networks.</li> <li>optional steps :</li> <li>update sg on ec2.</li> <li>update ACL on subnet.</li> <li></li> <li></li> <li>slow, then :  Transit Gateway with equal cost multipath routing and add additional VPN tunnels</li> </ul>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#b2-aws-vpn-cloudhub","title":"B.2. AWS VPN cloudHub","text":"<ul> <li><code>AWS::VPC-1</code> to [ <code>Client-VPN-1</code>, <code>Client-VPN-2</code>, ... ] <pre><code>- connect **AWS::VPC-1** to **many Client-VPN/s**\n  - Client-VPN-1\n  - Client-VPN-2\n  - ...\n\n # solution-1 - create Site-2-site VPN for each client. not managable for 100 of cleint/s.\n # solution-2 - VPN cloudhub    \n    - uses:internet\n</code></pre></li> <li>Step-1: create <code>vgw-1</code>, and attached on AWS VPC-1</li> <li>Step-2: create <code>cgw-1,2,3..</code>, with customer details</li> <li>Step-3: create <code>AWS VPN cloudHub(uses:internet)</code> - link <code>cgw-1,2,3,...</code> with <code>vgw-1</code>.</li> <li>rest of the step same as above.</li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#c-awsvpc-dx-clientvpn","title":"C AWS::VPC &lt;DX&gt; client::VPN","text":""},{"location":"01_aws/04_network/03_VPC-4-tolologies/#c1-dx-direct-connect","title":"C.1. DX (Direct Connect)","text":"<p> <pre><code># scenario\n - customer-1 is connected to DX-1::endpoint\n - AWS:VPC-1 wants to connect to same DX-1::endpoint\n\n flow:\n AWS VPC-1  (rtb-main:vgw-1) --&gt; [ vgw-1 &lt;--aws-direct-Location,DX::endpoint --&gt; cgw-1 ] --&gt; network:2(customer-1)\n</code></pre> - AWS-Direct-location, between on-premises and AWS, Bypasses the public internet.   - key-highlight     - dedicated physical connection     - private      - high-bandwidth / fast     - low-latency      - consistent/stable connection.     - no encryption by default, can add but bit complex     - fact:there is lead/wait time to setup new connection, around a month    - Types:     - Dedicated : wire ethernet, <code>1,10,100 Gbps</code>, fastest     - hosted    : via DX-partner <code>50 500 Mbps</code>, <code>1 2 5 10 Gbps</code>, slow   - resiliency :      - add more connection/s.     -      - or, create primary:DX + Secondary:Site2SiteVPN     - </p> <ul> <li>Steps:</li> <li>Step-1: create <code>vgw-1</code>, and attached on AWS VPC-1</li> <li>Step-2: create <code>cgw-1</code>, with customer details</li> <li> <p>Step-3: create <code>DX-1::endpoint</code></p> <ul> <li>connect vgw-1 to DX-1::endpoint</li> <li>connect cgw-1 to DX-1::endpoint</li> </ul> </li> <li> <p></p> </li> </ul>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#c2-dx-gateway","title":"C.2 DX gateway","text":"<p><pre><code># scenario\n  - customer is connected to DX-1::endpoint\n  - 2 or more AWS VPC wants to connect to same DX-1::endpoint\n    - AWS::VPC-1 --&gt; DX-1::endpoint\n    - AWS::VPC-2 --&gt; DX-1::endpoint\n    - ...\n    - ...\n</code></pre> - way-1    - for AWS::VPC-1      - create <code>vgw-1</code>      - connect <code>vgw-1</code>to DX-1::endpoint     - AWS::VPC-1 (update rtb:vgw-1)    - for AWS::VPC-2     - create <code>vgw-1</code> for AWS::VPC-1     - connect <code>vgw-1</code>to DX-1::endpoint     - AWS::VPC-1 (update rtb:vgw-1)   - ...   - ...</p> <ul> <li>way-2 : </li> <li>create DX-gateway  <code>dxg-1</code></li> <li>connect  <code>dxg-1</code> to DX-1::endpoint</li> <li>AWS::VPC-1(update rtb:<code>dxg-1</code>) </li> <li>AWS::VPC-2(update rtb:<code>dxg-1</code>) </li> <li>...</li> <li>...</li> <li></li> </ul>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#transient-gateway","title":"transient Gateway","text":"<ul> <li>NOT tied to a specific VPC, Account level services : point_left:</li> <li>network topologies can be complicated, transient Gateway, simplify above topologies</li> <li>define everything at single place : rtb of transient gateway</li> <li>supports <code>IP-multicast</code> ?</li> <li></li> <li>create multiple tunnels in <code>AWS Site-2-site VPN</code> : <code>ECMP routing</code></li> <li></li> <li>shared with multiple aws account **</li> <li>AWS Transit Gateway with <code>Resource Access Manager</code> (RAM)</li> <li>can scale the  VPN throughput </li> <li>with <code>equal cost multi-path</code> (ECMP) routing support over multiple VPN tunnels. </li> <li>A single VPN tunnel still has a maximum throughput of 1.25 Gbps. </li> <li>If you establish multiple VPN tunnels to an ECMP-enabled transit gateway, it can scale beyond the default maximum limit of 1.25 Gbps. </li> <li>You also must enable the dynamic routing option on your transit gateway to be able to take advantage of ECMP for scalability.</li> </ul>"},{"location":"01_aws/04_network/03_VPC-4-tolologies/#exam-scenarios","title":"Exam scenarios:","text":""},{"location":"01_aws/04_network/03_VPC-4-tolologies/#_1","title":"03 VPC 4 tolologies","text":"<ul> <li>critical production workloads that require maximum resiliency</li> <li>AWS Direct Connect connections with speeds greater than 1 Gbps.</li> <li>correct</li> <li></li> <li>incorrect</li> <li></li> <li></li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/","title":"AWS cloudFront (global)","text":""},{"location":"01_aws/04_network/04_CloudFront/#pictorial-description","title":"Pictorial description","text":"<ul> <li>1-2-M</li> <li>one distribution - multiple origins</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#key-point","title":"key point","text":"<ul> <li>protocol : HTTP/RTMP </li> <li>CDN content delivery network, cache data all around the world/countries</li> <li><code>allow-list</code> countries</li> <li><code>black-list</code> countries.</li> <li>static-content cached for TTL (eg : a day), thus low latency.</li> <li>Also can invalidate cache at any time</li> <li>security: </li> <li>can integrate with WAF 08_WAF+FirewallManager.md</li> <li> <p>integrated with AWS-shield (firewall) 09_sheild.md</p> </li> <li> <p>bypass the regional edge cache, and go directly to the origin </p> </li> <li>Proxy methods PUT/POST/PATCH/OPTIONS/DELETE go</li> <li>Dynamic content, as determined at request time</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#a-distribution-regional-cache","title":"A. Distribution (regional cache)","text":""},{"location":"01_aws/04_network/04_CloudFront/#1-origin","title":"1. origin","text":"<ul> <li>source (3):</li> <li>s3 bucket<code>or</code>s3(static Web), </li> <li>Any http backend</li> <li>ALB only (not other ELB)</li> <li>remember : NO Lambda  exam confuse with lambda alot.</li> <li>distribution(edge-location) ---&gt; <code>privatelink</code> physical connection ---&gt; origin(eg:alb on us-east-1)<ul> <li>cf also needs access-policy to access origin</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#2-origin-access","title":"2. origin access","text":"<ul> <li>make origin <code>publicly</code> accessible.</li> <li>get list of Public IPs of all 400+ edge location</li> <li>add app level security to allow access only to above IPs.</li> <li>update sg to allow traffic.</li> <li>OAC - Origin access control </li> <li>policy allow CF to connect/access origin.</li> <li></li> </ul> <pre><code>1. OAI (Origin Access Identity) - Legacy Method\n- A special CloudFront IAM identity used to access an S3 bucket.\n- Requires updating the S3 bucket policy to allow access from CloudFront.\n- Limitations: Works only for S3 origins and lacks fine-grained permissions.\n\n2. OAC (Origin Access Control) - Newer &amp; Recommended   &lt;&lt;&lt;&lt;&lt;\n- Uses IAM-based authorization instead of S3 bucket policies.\n- Supports both S3 origins and custom origins (e.g., EC2, ALB).\n- Provides granular permissions via IAM roles.\n- More secure and flexible than OAI.\n\nabove example:\n- principal : cf service\n- condition : distribution arn\n</code></pre>"},{"location":"01_aws/04_network/04_CloudFront/#3-origin-failover","title":"3. origin failover","text":"<ul> <li>to help support your <code>data resiliency</code> needs.</li> <li>origin group with </li> <li>primary and secondary origins</li> <li>to configure Amazon CloudFront for high-availability and failover</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#4-security-feild-level-encryption","title":"4. security: feild level encryption","text":"<ul> <li>distribute content only to its service-subscribers / bona fide end users </li> <li>Use Amazon CloudFront signed cookies</li> <li>Use Amazon CloudFront signed URLs</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#5-cloudfront-function","title":"5. CloudFront Function","text":"<ul> <li>purpose:</li> <li>Website Security and Privacy</li> <li>Dynamic Web Application at the Edge</li> <li>Search Engine Optimization (SEO)</li> <li>Intelligently Route Across Origins and Data Centers</li> <li>Bot Mitigation at the Edge</li> <li>Real-time Image Transformation</li> <li>A/B Testing</li> <li>User Authentication and Authorization</li> <li>User Prioritization</li> <li>User Tracking and Analytics</li> <li>Type:</li> <li>lambda@Edge</li> <li>CloudFront-Function</li> <li> </li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#a-lambdaedge","title":"a. lambda@Edge","text":"<ul> <li><code>nodeJs</code> or <code>Py</code></li> <li>lambda is heavy</li> <li>scale to <code>1000s of request/sec</code></li> <li>execution time : 5-10 sec</li> <li>globally service. </li> <li>author: us-east-1</li> <li>replicated to edge location from author.</li> <li></li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#b-cloudfront-function","title":"b. CloudFront-Function","text":"<ul> <li><code>js</code></li> <li>very light weight </li> <li>10 KB pkg</li> <li>Max 2Mb ram</li> <li>scale to <code>million of Req/sec</code></li> <li>pricing: 1/6 time cheaper than lambda.</li> <li></li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#-","title":"-","text":""},{"location":"01_aws/04_network/04_CloudFront/#b-demo","title":"B. Demo","text":""},{"location":"01_aws/04_network/04_CloudFront/#1-s3-as-origin","title":"1. s3 as origin","text":"<pre><code>  - create CF &gt; distribution-1\n    - choose default object (optional) : index.html\n    - choose `origin` : add s3-bucket-1 + upload index.html\n        - choose `origin-access` (s3 access ways) :\n            - public, or\n            - OAC **\n                - create OAC-1 and attach to distribution-1\n                - Copy OAC-1:policy\n                - so we don't need to make s3-bucket-1 public\n\n  - update s3-bucket-1 policy with `OAC-1:policy`.\n    - this will allow distribution-1 to access s3.\n\n  - Copy public-url and hit it\n    - public-url --&gt; redirect to --&gt; public-url/index.html.\n\n  - Now upload abc.png in bucket\n  - hit - blic-url/abc.hit\n  - this comes from distributio, not directly from s3.\n\n   - Now upload sub-folder/abc.png in bucket\n  - hit - public-url/sub-folder/abc.hit\n  - ...\n  - so on\n</code></pre>"},{"location":"01_aws/04_network/04_CloudFront/#2-alb-as-origin","title":"2. ALB as origin","text":""},{"location":"01_aws/04_network/04_CloudFront/#c-pricing","title":"C. Pricing","text":"<p> - price class   - <code>100</code> - usa, europe, etc   - <code>200</code> - africa, asia, etc   - <code>ALL</code> - </p>"},{"location":"01_aws/04_network/04_CloudFront/#d-signed-url-cookies","title":"D. signed URl / cookies","text":"<ul> <li>CloudFront supports two types of signers for creating signed URLs or cookies:</li> <li><code>Trusted AWS Account Signers</code></li> <li><code>Key Pair Signers</code> (deprecated) <ul> <li>key pairs associated with the root AWS account</li> </ul> </li> <li><code>CloudFront key groups</code><ul> <li>public key is added to the key group in the CloudFront distribution settings</li> <li>The corresponding private key is securely stored by the developer or application creating signed URLs.</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#exam","title":"exam","text":""},{"location":"01_aws/04_network/04_CloudFront/#1","title":"1","text":"<ul> <li>Choosing Between ElastiCache and CloudFront</li> <li>If your goal is  (<code>ElastiCache</code>)<ul> <li>to improve the performance of database queries </li> <li>store session data in memory, use Amazon . </li> </ul> </li> <li>If your goal is  (<code>CloudFront</code>)<ul> <li>to deliver content quickly to users across the globe, </li> <li>reduce latency for static and dynamic content</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#2","title":"2","text":"<ul> <li>cannot directly integrate Cognito User Pools with CloudFront distribution</li> <li>via AWS <code>Lambda@Edge function</code> can accomplish </li> <li>but requires additional development</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#3","title":"3","text":"<ul> <li>If you have objects that are smaller than <code>1GB</code>,</li> <li>you should consider using Amazon CloudFront's PUT/POST commands for optimal performance. </li> </ul>"},{"location":"01_aws/04_network/04_CloudFront/#4","title":"4","text":"<ul> <li>send custom error if origin server is down.</li> <li>upload/host error on s3</li> <li>configure 4xx and 5xx</li> <li>under error-page tab on console.</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront_DVA/","title":"CloudFront ( for DVA)","text":""},{"location":"01_aws/04_network/04_CloudFront_DVA/#a-cache","title":"A Cache","text":"<ul> <li>Demo : https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/36528154#overview</li> <li>objects with CacheKey</li> <li>default cachekey </li> <li></li> <li>hostname + resourcePortion</li> <li>while hitting origin, it will drop query param as shown.</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront_DVA/#1-cache-policy","title":"1. Cache Policy","text":"<ul> <li>to set TTL</li> <li>to refine caching key and object. </li> <li>while hitting origin, include below which are coming in request.</li> <li>HTTP Headers: None \u2013 Whitelist</li> <li>Cookies: None \u2013 Whitelist \u2013 Include All-Except \u2013 All</li> <li>Query Strings: None \u2013 Whitelist \u2013 Include All-Except \u2013 All</li> <li>further enhance it before forwarding to origin.</li> <li>use Origin request policy. next</li> </ul>"},{"location":"01_aws/04_network/04_CloudFront_DVA/#2-origin-request-policy","title":"2. Origin-request policy","text":"<ul> <li>before hitting origin, can modify http request. </li> <li>eg add additional : (not come as part of original req)</li> <li>HTTP Headers</li> <li>Cookies</li> <li>Query Strings</li> <li>Note: but cacheKey will be remain as per Cache Policy, (NOt on Origin request policy) </li> </ul>"},{"location":"01_aws/04_network/04_CloudFront_DVA/#b-cache-behavior","title":"B. Cache behavior","text":"<ul> <li>behaviour-1 for path pattern : /s3/*     ==&gt; origin-1 (s3) : cache-policy-1, Origin-request-policy-1, ...</li> <li>behaviour-2 for path pattern : /alb-1/*  ==&gt; origin-2 (alb): cache-policy-2, Origin-request-policy-2, ...</li> <li>behaviour-default for path pattern : /*  ==&gt; origin-1/2 (?): cache-policy-3, Origin-request-policy-3, ...</li> <li>...</li> <li></li> </ul>"},{"location":"01_aws/04_network/04_CloudFront_DVA/#c-invalidate-cache","title":"C. Invalidate cache","text":"<ul> <li>distribution &gt; invalidation tab</li> <li>create invalidation<ul> <li>define key</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/04_global_Acceleartor/","title":"AWS Global accelerator (global)","text":""},{"location":"01_aws/04_network/04_global_Acceleartor/#0-network-problems","title":"0. network problems","text":""},{"location":"01_aws/04_network/04_global_Acceleartor/#latency","title":"latency","text":"<ul> <li>alb-1(api-1) is running on region-1 mumbai</li> <li>alb-2(api-2) is running on region-2 europe</li> <li>client in USA connects: </li> <li>to region-1 (high latency) - path-1</li> <li>to region-2 (low latency)  - path-2</li> <li>can optimize path to use path-2 (intelligent-routing) </li> <li>to reach out closest target server</li> </ul>"},{"location":"01_aws/04_network/04_global_Acceleartor/#server-hopping","title":"server hopping","text":"<ul> <li>alb-1(api-1) is running on region-1 mumbai</li> <li>client: <ul> <li>USA --&gt; hops overs multiple server/s s1 &gt; s2 &gt; s3 &gt; s4 &gt; s4 --&gt; to reach alb-1</li> <li>europe --&gt; hops overs multiple server/s s1 &gt; s2 &gt; s3 --&gt; to reach alb-1</li> <li>nepal --&gt; hops overs few server/s &gt; s1 --&gt; to reach alb-1</li> </ul> </li> <li>this creates risk of loss of network and data packet. </li> <li> </li> <li> <p>can prevent hopping by using stable AWS global privatelink</p> </li> <li></li> </ul>"},{"location":"01_aws/04_network/04_global_Acceleartor/#1-intro","title":"1. Intro","text":"<ul> <li>directs traffic to optimal endpoints over </li> <li>the AWS global network</li> <li>NOT internet</li> <li>improving your \"internet-user performance\" by up to <code>60%</code>.</li> <li>supports both TCP and UDP protocols </li> <li>gaming, live video streaming, and other real-time communication applications</li> <li>integrated with AWS-sheild </li> <li>thus provides DDoS protection </li> <li>uses AWS global network infrastructure of AWS / privateLink / edge location</li> <li>performance 60% </li> <li>reduce latency</li> <li>fast failover</li> <li> <p>optimizes the path to your application to prevent packet loss and reduce latency .</p> </li> <li> <p>provides 2 static anycast IP addresses that act as a fixed entry point to your application endpoint/s.   <pre><code>- The two IP addresses are mapped to multiple AWS edge locations globally. \n- If one IP address or its associated edge location experiences an issue, \n- the other IP address automatically takes over, ensuring uninterrupted traffic flow.\n</code></pre></p> </li> <li>configure these IP addresses in DNS records, </li> <li>providing a single point of reference for global traffic distribution</li> <li>eliminating the need to update DNS frequently <pre><code>- Uni-cast IP\n  - one ip assigned to one server\n\n- Any-cast IP\n  - same ip assigned to multiple server\n  - fixed IP,  does not support dynamic IP addresses.\n</code></pre></li> </ul>"},{"location":"01_aws/04_network/04_global_Acceleartor/#2-provision-listener","title":"2. Provision <code>listener</code>","text":"<ul> <li>create <code>accelerator</code> for our Application Endpoint <pre><code>####  our Application Endpoint\n- launch ec2-1 in region-1 (us-east-1)\n- launch ec2-2 in region-2 (us-west-1)\n- launch alb-1 in region-2 with ec2-3\n\n####  accelerator (INTELLIGENT ROUTING on global network)\n- create accelerator-1 : has dn-1               &lt;&lt;&lt;&lt; \n- create Listener/s :\n    - listener-1 : \n        - TCP:80\n        - endpoint-group -1 (weight - w1 ):     &lt;&lt;&lt;&lt; \n            - endpoint-1 : ec2-1 \n            - endpoint-2 : ec2-2\n            - endpoint-3 : alb-2\n            - endpoint-4 : static-ip \n        - endpoint-group -2 (weight - w2 ):  \n          - ...\n          - ...\n        - setup health as well, for each endpoint.\n    - listener-2 :\n        ...\n\n- hit dn-1 url:\n    - goes to us-east-1, ec2-2 everytime, since iam in CA,USA\n\n#### failover\n- make ec2-1 fail, update sg : deny traffic.\n- -hit dn-1 url\n  - goes to us-east-1,ec2-1 now\n</code></pre></li> </ul>"},{"location":"01_aws/04_network/04_global_Acceleartor/#3-pricing-extra","title":"3. pricing (extra)","text":"<ul> <li><code>$0.025 / accelerator / hour</code>.</li> <li><code>$0.02\u2013$0.07 / GB</code> </li> <li>varies by AWS region pair</li> </ul>"},{"location":"01_aws/04_network/04_global_Acceleartor/#99-scenario","title":"99. scenario","text":"<p><pre><code>#1\nA gaming company is looking at improving the availability and performance of its \"global\" flagship application \nwhich utilizes User Datagram Protocol and needs to support fast regional failover in case an AWS Region goes down. \nThe company wants to continue using its own custom Domain Name System (DNS) service.\n\n---\n\n#2\nA retail company wants to rollout and test a blue-green deployment for its \"global\" application in the next 48 hours. \nMost of the customers use mobile phones which are prone to Domain Name System (DNS) caching. \nThe company has only two days left for the annual Thanksgiving sale to commence.\n\nAs a Solutions Architect, which of the following options would you recommend to test the deployment \non as many users as possible in the given time frame?\n\na. Use AWS Global Accelerator to distribute a portion of traffic to a particular deployment **\nb. Use Amazon Route 53 weighted routing to spread traffic across different deployments\n\n &gt;&gt; Use AWS Global Accelerator to distribute traffic to the blue and green deployments efficiently and avoid delays caused by DNS caching\n\n ---\n\n #3\n A gaming company uses ALB in front of Amazon EC2 instances for different services and microservices.\n The architecture has now become complex with too many ALB in multiple AWS Regions. \n Security updates, firewall configurations, and traffic routing logic have become complex with \"too many IP addresses\" and configurations.\n\n The company is looking at an easy and effective way to \"bring down the number of IP addresses\" allowed by the firewall\n and easily manage the entire network infrastructure. Which of these options represents an appropriate solution for this requirement?\n\n a. Launch AWS Global Accelerator and create endpoints for all the Regions. \n     Register the ALB of each Region to the corresponding endpoints ** 2 anycast IPs :)\n\n b. Set up a NLB with elastic IP address. Register the private IPs of all \n    the ALB as targets of this Network Load Balancer --&gt; again regional, soo many IPs\n</code></pre> </p>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/","title":"05 1 API gateway SAA","text":""},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#-httpschatgptcomc6761df7b-aa90-800d-b11f-c0e411c511fe","title":"- https://chatgpt.com/c/6761df7b-aa90-800d-b11f-c0e411c511fe","text":""},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#api-gateway-serverless","title":"API gateway (Serverless)","text":""},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#a-intro","title":"A. Intro","text":"<ul> <li>API ( <code>REST API</code>** , <code>http API</code> ,<code>websocket API</code>), with other benefit:</li> <li>caching</li> <li>API versioning : enable</li> <li>API documentation : enable SDK/doc generation</li> <li>interceptor : <code>mapping template</code> to transform req/resp (json/xml only)</li> <li>more:<ul> <li>No infrastructure to manage. :)</li> <li>create environment  - dev,qa,prod</li> <li>throttling - rate limiting</li> <li>has default setting to prevent from DDoS </li> <li>security - check below.</li> <li>import</li> <li>already have pre-define API</li> <li>from Swagger/OpenAPI</li> <li>req/resp body schema validation</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b-api-gateway-integration","title":"B. API gateway: integration","text":""},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b1-backend","title":"B.1. Backend","text":"<ul> <li>can have multiple backend and create forwarding/transformation rule at api-gateway level as well. </li> <li>use it gateway for microservice</li> <li>API-g &gt;&gt; PROXY &gt;&gt;lambda (event,context)</li> <li>pure serverless</li> <li>most common</li> <li>default/max timeout : <code>29 sec</code> </li> <li> <p>use AWS_PROXY</p> </li> <li> <p>API-g &gt;&gt; PROXY &gt;&gt; Any HTTP backend</p> </li> <li>API-g &gt;&gt; on-prem-API<ul> <li>DX or S2S connection.</li> </ul> </li> <li> <p>API-g &gt;&gt; ALB</p> <ul> <li>expose ALB public directly. happening in ccgg.</li> <li>expose API-g &gt;&gt; ALB &gt; tg [ecs/eks - <code>container</code> - ec2/fargate]</li> </ul> </li> <li> <p>API-g &gt;&gt; PROXY &gt;&gt; <code>Any</code> AWS service API call. </p> </li> <li>s3:*</li> <li>sqs:getMessage</li> <li>kds:* </li> <li>...</li> <li>note: setup mapping template </li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b2-proxy","title":"B.2. Proxy","text":"<ul> <li>there are 3 proxy options. choose either.</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b21-aws_proxy","title":"B.2.1. AWS_PROXY","text":"<ul> <li>NO mapping template</li> <li>request/response object uses inbuilt aws-template</li> <li>eg: API-g &lt;&gt;    <code>AWS_PROXY</code>  &lt;&gt; lambda</li> <li></li> <li>Note: </li> <li>ALB &lt;&gt;         <code>AWS_PROXY</code> &lt;&gt; tg:lambda</li> <li>use same template, remember</li> <li>01_ELB_ASG.md</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b22-http_proxy","title":"B.2.2. HTTP_PROXY","text":"<ul> <li>NO mapping template</li> <li>eg: API-g &lt;&gt;  AWS_PROXY  &lt;&gt; http-backend (<code>ALB</code>)</li> <li></li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b23-no-proxy-for-http-aws","title":"B.2.3. NO PROXY for (HTTP / AWS)","text":"<ul> <li>set up mapping template</li> <li>Content-Type must be == application/json/xml</li> <li></li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b24-mock","title":"B.2.4. MOCK","text":"<ul> <li>for dev/testing purpose</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b3-mapping-template","title":"B.3.  Mapping Template","text":"<ul> <li>response from lambda</li> <li></li> <li>create template</li> <li></li> <li>check final response</li> <li></li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#use-cases","title":"Use-cases","text":"<ul> <li>use-case-1: transform SOAP response</li> <li></li> <li>use-case-2: tranform query param</li> <li></li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#c-endpoint-type","title":"C. Endpoint type","text":"<ul> <li>by Deployment model </li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#1-regional","title":"1 <code>regional</code>","text":"<ul> <li>deployed in single region eg: us-west-1</li> <li>for users in one region</li> <li>can have regional with CloudFont eg:</li> <li>set-1: for us-west-1</li> <li>UNION</li> <li>Set-2 : create CF distribution-1 (CF) : whiteList - europe user + india user</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#2-edge-optimized-default","title":"2 <code>edge-optimized</code> (default)","text":"<ul> <li>deployed/lives in one region, but configure to</li> <li>route request through CF many edge location/s</li> <li>backed by : cloudFront distribution</li> <li>for global user</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#3-private","title":"3 <code>private</code>","text":"<ul> <li>with private VPC</li> <li>API-g &gt;&gt; VPC endPoint</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#b-security-rest-api-gateway","title":"B. Security : REST API-gateway","text":"<ul> <li>no native support for openIDConnect/OAuth - <code>REST API-gateway</code></li> <li>but <code>Http API-gateway</code> has it.</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#1-authentication","title":"1. Authentication","text":""},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#11-api-keys","title":"1.1. API keys","text":"<ul> <li>Authentication</li> <li>pass<code>x-api-key</code> header</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#12-iam","title":"1.2 IAM","text":"<ul> <li>for IAM user / roles</li> <li>IAM-based SigV4 signing </li> <li>AWS SDKs and AWS CLI handle SignatureV4 signing automatically.</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#13-cognito","title":"1.3 Cognito","text":"<ul> <li>for global user</li> <li>integrate with 3rd party ID provider.</li> <li></li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#14-lambda-authorizer","title":"1.4 Lambda Authorizer","text":"<p> - Great for 3rd party tokens - Handle Authentication verification + Authorization in the Lambda function</p>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#2-ssl","title":"2 SSL","text":"<ul> <li>export certificate to ACM</li> <li>create R53 entry (cname/alias)</li> <li>integrated with ACM</li> <li>keep certificate it <code>us-east-1</code> for edge-optimized endpoint.</li> <li>certificate with backend server domain name.</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#3-cors","title":"3 CORS","text":"<ul> <li>CORS can be enabled on api gateway</li> <li></li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#4-authorization","title":"4 Authorization","text":"<ul> <li>API-gateway resource iam policy, <ul> <li>not exist by default. have to create one </li> </ul> </li> <li>principle/who:<ul> <li>use for cross account id</li> <li>...</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#5-throttle-setting-for-stage","title":"5 <code>throttle</code> setting for stage","text":"<ul> <li>set rate (no.of req per seconds make be made)</li> <li><code>10000 rps</code>across all APIs </li> <li>set limit for stage. </li> <li>else one api/stage will consume all and impact other</li> <li>set burst (no of concurrent request)</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#6-firewall-setting-for-stage","title":"6 <code>firewall</code> setting for stage","text":"<ul> <li>set WAF</li> <li>set certificate</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#7-create-usage-plan","title":"7. create usage plan","text":"<ul> <li>first create API key</li> </ul>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#c-pricing","title":"C. pricing","text":"<pre><code>REST API\n    $3.50 per million requests (first 300M, then $1.51 per million).\n    Data transfer &amp; caching costs extra.\n\nHTTP API (Cheaper than REST API)\n    $1.00 per million requests for first 300M, \n    then $0.90 per million\n\nWebSocket API\n    $1.00 per million messages \n     connection minutes cost.\n</code></pre>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#y-hands-on","title":"Y. hands on","text":"<pre><code>- create (4 Type) : api-gateway-1\n    - HTTP API  &gt;&gt; lambda, http backend\n    - REST API | REST API (Private,vpc-1) &gt;&gt; lambda, http backend, awsServices\n    - Web-scoketAPI  &gt;&gt; lambda, http backend, + awsServices\n\n  - choose - REST API\n  - API details:  \n        - create new **\n        - import frpm OPen/AI swagger\n        - clone API\n  - deplomnet model : regional \n        - region : us-east-1\n  - integration Type: lambda\n        - choose method: lambda-fn-1\n\n  - set timeout : default 30 s\n\n  - check lambda &gt; permission &gt; \"resource based policy statemnet\" \n    - allow invoke for agi-g          &lt;&lt;&lt;&lt;\n\n  - proxy integration : enabled       &lt;&lt;&lt;&lt;                \n    - if not enabled\n    - then create mapping template\n\n  - invoke from aws webcosole\n\n  - Deploy API\n      - choose stage - dev,qa, prod\n      - will get invoke URL\n      - try on BROWSER\n</code></pre>"},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#z-architecture-example","title":"Z. Architecture Example","text":""},{"location":"01_aws/04_network/05_1_API_gateway_SAA/#microservice-gateway","title":"microservice (gateway)","text":""},{"location":"01_aws/04_network/05_2_API_gateway_DVA/","title":"A. API-gateway - Stage","text":"<ul> <li>url has API ID and stage name</li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#1-intro","title":"1. Intro","text":"<p> - once created API-g, need to deploy it on stages   - give stage a name -dev,qa,prod,whatever   - stages has deployment history      - stage can be rollback.     - so think of <code>deploymnet object in k8s</code>   - has stage variable, for dynamic configuration for stages. eg:     - lambda-arn     - http-endpoint-uri     - ...     - note: passed to context object. =&gt; lambda.handler(event,<code>context</code>)      - format ${stageVariables.<code>var-1</code>}</p>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#2-example","title":"2. example","text":"<pre><code>    - api-gateway-1:\n      - integrated with lambda-1 arn ==&gt; xxxx:${stageVariables.`lambda-alias`} \n        - created one stage variable\n        - similarly create more stage variable.\n      - set value of stageVariable \"lambda-alias\" in all stages, then\n      - stages:\n        - dev-1\n          - set lambda-alias: dev\n          - dev is point to $LATEST\n        - qa-1\n          - set lambda-alias: v10\n</code></pre>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#3-cache-setting","title":"3. <code>cache</code> setting","text":"<ul> <li>cache request/response</li> <li>define at stage level</li> <li>provision size : <code>0.5 GB</code> to <code>237 GB</code></li> <li>set cache object TTL</li> <li>default: <code>5 min / 300 sec</code></li> <li>max: <code>1 hr / 3600 sec</code></li> <li>optionally encrypt</li> <li></li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#cache-invalidation","title":"cache Invalidation","text":"<ul> <li>from console</li> <li>any client without/with iam:permission can do it</li> <li>header: cache-control:max-age = 0</li> <li>iam permission : execute-api:InvalidateCache</li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#4-canary-deployment","title":"4. canary deployment","text":"<p> - api-gateway-1     - stage-1 (<code>95 %</code> traffic) : monitor-1     - stage-2 ( <code>5 %</code> traffic) : monitor-2 - console &gt;&gt;  canary tab     - set above configuration.</p>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#5-supports-openapi","title":"5. supports <code>OpenAPI</code>","text":"<ul> <li>export:</li> <li></li> <li>this is API document which client can refer.</li> <li>generate SDK</li> <li>for client to consume API</li> <li>api-gateway-open-api-1.json</li> <li>Replace <code>{region}</code> with your AWS region</li> <li>Replace <code>{lambda-arn}</code> with the ARN of the Lambda function handling the request.</li> <li>check schema. </li> <li>import this into api-gateway</li> <li>schema validation</li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#5-monitor","title":"5. Monitor","text":""},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#cwlogs","title":"<code>CW:logs</code> :","text":"<ul> <li>enable/disable</li> <li>set log level</li> <li>error only</li> <li>error + info</li> <li>full req + response log</li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#cwx-rays","title":"<code>CW:x-rays</code>","text":"<ul> <li>enable/disable</li> <li>give full picture</li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#cwmetric","title":"<code>CW:metric</code>","text":"<ul> <li>enable/disable below metrics</li> <li>CacheHitCount </li> <li>CacheMissCount: efficiency of the cache</li> <li>IntegrationLatency (backend latency, latency from lambda)</li> <li>latency (overall : backenf + gateway itself)</li> <li>4XXError (client-side) <ul> <li><code>429</code> throttleError</li> </ul> </li> <li>5XXError (server-side)<ul> <li>504 server timeout</li> <li>503 service not available</li> <li>502 bad gateway</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#b-api-gateway-api-key","title":"B. API-gateway : API key","text":"<ul> <li>purpose:</li> <li>authentication </li> <li>usage tracking</li> <li>create API keys to identify API clients/customer<ul> <li>Ex: WBjHxNtoAb4WPKBC7cGm64CBibIb24b4jt8jJHo9</li> <li>httpheader: x-api-key=your-api-key</li> </ul> </li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#c-api-gateway-usage-plan","title":"C. API-gateway : usage plan","text":"<ul> <li>create plan at API key level.</li> <li>eg: set:</li> <li>Throttling limits </li> <li>Quotas limits is the overall number of maximum requests</li> <li>associate stages and methods</li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#d-other-2-api-gateway","title":"D. Other 2 API gateway","text":"<ul> <li>so far working on REST API</li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#d1-http-gateway","title":"D.1. HTTP gateway","text":"<ul> <li><code>low-latency | cost-effective</code> just more simple</li> <li>native support for OIDC and OAuth 2.0 + CORS</li> <li>Always proxy</li> <li>HTTP proxy</li> <li>Lambda proxy</li> <li>NO_PROXY <ul> <li>hence cannot define any mapping template</li> </ul> </li> <li>usage-plans and API-keys </li> </ul>"},{"location":"01_aws/04_network/05_2_API_gateway_DVA/#d2-websocket-gateway","title":"D.2. websocket gateway","text":"<ul> <li>websocket</li> <li>Two-way interactive communication between a user\u2019s browser and a server : persistent connection<ul> <li>Server can push information to the client</li> <li>This enables stateful application use cases</li> </ul> </li> <li> <p>use-case : realtime applications</p> <ul> <li>chat applications, </li> <li>collaboration platforms,</li> <li>multiplayer games,</li> <li>financial trading platforms.</li> <li>...</li> </ul> </li> <li> <p>WebSocket URL</p> </li> <li>wss://[some-uniqueid].execute-api.[region].amazonaws.com/[stage-name]</li> <li>Communication (<code>connection-id</code> reused)</li> <li>client ==&gt; server<ul> <li></li> </ul> </li> <li> <p>server ==&gt; client</p> <ul> <li></li> <li>operations by server on client:</li> <li>POST : Sends a message from the Server to the connected WS Client </li> <li>GET : Gets the latest connection status of the connected WS Client</li> <li>DELETE : Disconnect the connected Client from the WS connection</li> </ul> </li> <li> <p>websocket gateway : backend:</p> </li> <li><code>lambda</code></li> <li><code>DynamoDB</code></li> <li><code>Any Http backend</code></li> </ul>"},{"location":"01_aws/04_network/06_RAM/","title":"RAM (Resource access manager)","text":"<ul> <li>https://aws.amazon.com/ram/</li> </ul>"},{"location":"01_aws/04_network/06_RAM/#intro","title":"Intro","text":"<p><pre><code>- AWS org\n  - mgt acct\n  - OU-1\n    - member-acct-1\n    - member-acct-2\n    - ...\n</code></pre> - It simplifies resource sharing    - eliminates the need to duplicate resources across multiple accounts in aws Org   - seamlessly share resources as your organization grows</p>"},{"location":"01_aws/04_network/06_RAM/#supported-services","title":"Supported services","text":"<ul> <li>VPC Subnets (not vpc itself)</li> <li>Amazon Aurora and RDS Clusters</li> <li>Route 53 </li> <li>Share resolver rules for DNS queries.</li> <li>AWS Transit Gateways</li> <li>Share transit gateways for network connectivity.</li> <li>more:</li> <li>AWS Backup Vaults: Share backup vaults across accounts.</li> <li>License Manager Configurations: Share license configurations.</li> </ul>"},{"location":"01_aws/04_network/06_RAM/#vpc-sharing-part-of-resource-access-manager","title":"VPC sharing (part of Resource Access Manager)","text":"<p><pre><code># scenario\n- AWS org\n  - mgt acct (VPC-1 subnet-1/2/3/...)\n  - OU-1 \n    - member-acct-1  (subnet-1 shared)\n    - member-acct-2   (subnet-2 shared)\n    - ...\n</code></pre> - share subnet/s (not VPC) with member-account - member-account can view, create, modify, and delete their application resources in the subnets shared with them only </p>"},{"location":"01_aws/04_network/99_Questions-1/","title":"99 Questions 1","text":""},{"location":"01_aws/04_network/99_Questions-1/#1","title":"1","text":"<p>You have multiple AWS accounts within a single AWS Region managed  by AWS Organizations and you would like to ensure all Amazon EC2  instances in all these accounts can communicate privately.  Which of the following solutions provides the capability at the <code>CHEAPEST</code> cost </p> <ul> <li>VPC peering</li> <li>only pay for the data transfer. CHEAPEST </li> <li>AWS Transit Gateway</li> <li>pay for the data transfer</li> <li>incur costs for each attachment (VPC, VPN, etc.)</li> <li>AWS PrivateLink</li> <li>high costs associated with endpoint services and data processing</li> <li>VPN Connections</li> <li>VPN gateway attach to each VPC.</li> <li>Site2Site connection</li> <li>VPN gateway charges and data transfer costs</li> </ul> <pre><code>Cost Comparison:\n\nVPC Peering \u2192 Only pay for data transfer (cheapest option). \u2705\nAWS Transit Gateway \u2192 Data transfer + per VPC attachment fees (costly). \u274c\nAWS PrivateLink \u2192 High costs for endpoint services &amp; processing (most expensive). \u274c\nVPN Connections \u2192 VPN gateway charges + data transfer (not cost-effective for intra-region). \u274c\n\n\ud83d\udd39 VPC Peering is the cheapest because it only charges for data transfer without extra attachment fees. \ud83d\ude80\n</code></pre>"},{"location":"01_aws/04_network/99_Questions-1/#2-communication-between-two-vpcs-with-overlapping-cidr","title":"2  Communication Between Two VPCs with Overlapping CIDR","text":"<p><pre><code>How to Enable Communication Between Two VPCs with Overlapping CIDR?\nSince VPC Peering and Transit Gateway do NOT support overlapping CIDRs, you must use NAT or VPN-based solutions.\n\n\u2705 Solution 1: NAT Gateway (Most Common)\nVPC-1 (CIDR: 10.0.0.0/16) \u2192 Use Private NAT Gateway.\nVPC-2 (CIDR: 10.0.0.0/16) \u2192 Use another Private NAT Gateway.\nAssign non-overlapping Elastic IPs or secondary CIDRs for NAT translation.\nRoute traffic via NAT Gateway instead of direct peering.\n\n\u2705 Solution 2: AWS Transit Gateway with NAT\nUse Transit Gateway (TGW) with NAT for IP translation between VPCs.\nRequires custom route tables to avoid conflicts.\n</code></pre> </p>"},{"location":"01_aws/04_network/99_Questions-1/#3-dx-and-bgp-border-gateway-protocol","title":"3 Dx and BGP (Border gateway protocol)","text":""},{"location":"01_aws/04_network/99_Questions-1/#4-vpc-connectivity-with-vpce","title":"4 VPC connectivity with vpce","text":"<ul> <li>region-1 :VPC-1/2/....</li> <li>connect VPCs - already know VPC peering and transient gateway</li> <li>another way: vpce</li> <li>eg: vpce for NLB</li> <li></li> </ul>"},{"location":"01_aws/04_network/99_Questions-1/#5","title":"5","text":""},{"location":"01_aws/05_decoupling/01_SQS/","title":"SQS","text":"<ul> <li>oldest &amp; Fully managed  </li> <li>auto-scale</li> <li>unlimited throughput,  </li> <li>low latency (&lt; 10ms), </li> <li>max msg size : 256KB </li> <li>use extended-SQS, backed by s3.</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#a-de-couple-models-in-aws","title":"A. De-couple Models in AWS","text":"<ul> <li><code>queue</code> :  SQS <ul> <li>coupled app (sync) </li> <li>de-couple app (Async)</li> </ul> </li> <li><code>pub/sub</code> : SNS</li> <li><code>real time data-stream</code> : kinese Firehose</li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#b-types","title":"B. Types","text":""},{"location":"01_aws/05_decoupling/01_SQS/#1-standard","title":"1. Standard","text":"<ul> <li>multiple producer p1,p2,p3, ...  ---&gt; [queue:message-1(with Attribites)] ---&gt; multiple consumers (C1,C2,C3, lambda-Consumer, ... )</li> <li>can purge </li> <li>at least once delivery </li> <li>multiple consumer can receive same message.</li> <li>consumer handle duplicate message, has to delete message.</li> <li>idempotent consumer, if needed.</li> <li>best effect ordering : order not guaranteed.</li> <li>msg retention: </li> <li>max     : <code>14 days</code> </li> <li>default :  <code>4 days</code></li> <li>visibility timeout </li> <li><code>0-12 hr</code></li> <li>consumer could call this api to get more time.</li> <li></li> <li> <p>if too low, then may get duplicate.</p> </li> <li> <p>Polling Type (2)</p> </li> <li>short polling (default)<ul> <li>SQS sends the response right away, even if the query found no messages</li> </ul> </li> <li> <p>Long polling </p> <ul> <li>Consumer can optionally \u201cwait\u201d for messages to arrive, if there are none in the queue </li> <li>set <code>message receive wait time</code> : (1-20 sec)</li> <li>pattern : poll-1 API -- wait 10 sec -- poll-1 API -- wait 10 sec ...</li> <li>long poll preferred : </li> <li>more gap in poll api calls, but increase latency</li> <li>Amazon SQS sends an empty response only, if the polling wait time expires</li> <li>save cpu cycle, save money $$ </li> </ul> </li> <li> <p>DLQ must also be a standard queue</p> </li> <li>Delivery delay</li> <li>Throughput : virtually unlimited messages per second. :point-left:</li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#2-fifo","title":"2. FIFO","text":"<ul> <li>DLQ must also be a FIFO queue</li> <li>S3:event notification target --&gt; only standard, not fifo </li> <li>Exactly-once processing </li> <li>name : has suffix <code>.fifo</code></li> <li>no duplicate. </li> <li><code>content-based-de-duplication</code> : enable it</li> <li><code>de-duplication interval</code> : say 5 min<ul> <li>duplicate messages are for 5 min, will get refused.</li> </ul> </li> <li>how to check duplicate:<ul> <li><code>de-duplication_ID</code> along with message</li> <li><code>SHA-246 hash of message body</code></li> <li></li> </ul> </li> <li>Limited throughput: </li> <li>default (batch size = 1) : <code>300 msg/s</code></li> <li>batch size =  2, 600 msg/s</li> <li>...</li> <li> <p><code>max batch size =  10</code>, this max <code>3000 msg/s</code> </p> </li> <li> <p>ordered</p> </li> <li>within group.</li> <li> <p>not across groups</p> </li> <li> <p>multiple consumer </p> </li> <li>use grouped messages: MessageGroupingId (like in kafka)</li> <li>group-1 ( msg1, msg-2, ...) --&gt; consumer-1 (ordered in group-1)</li> <li>group-2 ( msg1, msg-2, ...) --&gt; consumer-2 (ordered in group-1)</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#3-ephemeral-queue","title":"3. Ephemeral queue","text":"<ul> <li>Amazon SQS Temporary Queues </li> <li>cannot be created directly from the AWS Management Console.</li> <li>They must be created programmatically using the AWS SDK or CLI.</li> <li><code>CreateQueue</code> API , attributes:<ul> <li>FifoQueue </li> <li>ExpiresAfter</li> </ul> </li> <li>short-lived, designed for temporary message passing</li> <li>Auto-delete after inactivity.</li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#b-dlq","title":"B. DLQ","text":"<ul> <li>If a consumer fails to process a message within the Visibility Timeout or Exception from Consumer code.</li> <li>then. message goes back to the queue and consume received again.</li> <li>After the MaximumReceives threshold (say 3) is exceeded,</li> <li>message goes into a <code>Dead Letter Queue</code>(DLQ)</li> <li>Good to set a retention of 14 days in the DLQ</li> <li>re-drive </li> <li>push messages from the DLQ back into the <code>source queue / any other queue</code></li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#c-security","title":"C. Security","text":""},{"location":"01_aws/05_decoupling/01_SQS/#general","title":"general","text":"<ul> <li>attach iam:sqs-policy.</li> <li>cross account access</li> <li>allow other service: <ul> <li>eg: S3 Event Notifications To SQS Queue</li> </ul> </li> <li>In-flight encryption </li> <li><code>HTTPS</code> (with TLS)</li> <li>At-rest encryption </li> <li>KMS keys (<code>sse-sqs</code>, <code>sse-kms</code>, <code>sse-c</code>)</li> <li>Client-side encryption :  if the client wants to perform encryption/decryption itself.</li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#d-price-cheap","title":"D. price (cheap)","text":"<ul> <li>number of requests </li> <li>Standard Queue : <code>$0.40 / million requests</code>.</li> <li>FIFO Queue : <code>$0.50 /  million requests</code>.</li> <li>data transfer</li> <li>inbound data is free</li> <li>outbound traffic paid. ?</li> <li>Long Polling: No extra cost for long polling.</li> <li>save cost, because it reduces the number of empty receives </li> </ul>"},{"location":"01_aws/05_decoupling/01_SQS/#e-hands-on","title":"E. hands on","text":"<p><pre><code>- create queue : queue-1\n- Type : standard ** + FIFO\n- configuration:\n  - `visibility timeout` : 30\n  - `delivery delay`\n  - `receive message weight time`\n-  encrytion : sse-sqs\n- policies:\n    - SQS access policy : json\n    - Redrive allow policy : pending\n- Dead-letter queue\n- tags\n\n// READY\n- send : hellow world\n- receive : poll messages + delete\n- purge : delete all message.\n</code></pre> - </p>"},{"location":"01_aws/05_decoupling/01_SQS/#f-api-must-know-for-dva","title":"F. API must know (for DVA)","text":""},{"location":"01_aws/05_decoupling/01_SQS/#g-use-case-arch-eg","title":"G. use-case / arch eg","text":"<ol> <li>flow</li> <li>frontend request going to sqs</li> <li>SQS logs &gt;&gt; CW &gt;&gt; custom-metric::ApproximateNumberOfmessageVisible  &gt;&gt; alarm </li> <li>SQS:inbuilt-metric::ApproximateNumberOfmessageVisible  &gt;&gt; alarm</li> <li>ASG [ ... multiple consumers ec2-i... ] --&gt; in/out</li> <li> </li> <li> <p>ASG [ FE-1, FE-2, ... ] ---&gt; stage all request in Queue --- &gt; ASG [ BE-1, BE-2, ...]</p> </li> <li> <p></p> </li> <li> <p>Overloaded DB request:</p> </li> <li>ASG [ FE-1,...] --&gt; Queue-1(Stage client request) --&gt; ASG [BE-1,...] --&gt; store to DB, OVERR-LOADED --&gt; <code>lose some insert</code></li> <li>ASG [ FE-1,...] --&gt; Queue-1(<code>Stage client request</code>) --&gt; ASG [BE-1,...] --&gt; Queue-2(<code>stage-DB-request</code>) --&gt;  ASG [BE-repo-1,...]</li> <li></li> <li></li> </ol>"},{"location":"01_aws/05_decoupling/02_SNS/","title":"SNS","text":""},{"location":"01_aws/05_decoupling/02_SNS/#a-key-point","title":"A. key point","text":"<ul> <li>pub-sub model</li> <li></li> <li><code>100k</code> topics, per account, can be extended.</li> <li>type</li> <li>Standard </li> <li>FIFO</li> <li>subscription</li> <li>max: 12 million</li> <li>subscription with filter policy <ul> <li>filter message by message attribute</li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/05_decoupling/02_SNS/#b-subscribers","title":"B. Subscriber/s","text":"<ul> <li>KDF</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/02_SNS/#c-publishers","title":"C. publisher/s","text":""},{"location":"01_aws/05_decoupling/02_SNS/#d-security","title":"D. Security","text":""},{"location":"01_aws/05_decoupling/02_SNS/#general","title":"general","text":"<ul> <li>attach iam:sns-policy.</li> <li>cross account access</li> <li>allow other service</li> <li>In-flight encryption</li> <li><code>HTTPS</code> (with TLS)</li> <li>At-rest encryption</li> <li>KMS keys (<code>sse-sqs</code>, <code>sse-kms</code>, <code>sse-c</code>)</li> <li>Client-side encryption :  if the client wants to perform encryption/decryption itself.</li> </ul>"},{"location":"01_aws/05_decoupling/02_SNS/#e-use-case","title":"E. use case","text":"<ul> <li>SQS + SNS fan out pattern</li> <li></li> <li></li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/","title":"03 01 KDS KinesisDataStream","text":"<ul> <li>real-time stream. eg:</li> <li>app log</li> <li>CW metric</li> <li>web activity</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#a-kinesis-data-stream-kds-serverless","title":"A. Kinesis Data Stream <code>KDS</code> (serverless)","text":"<ul> <li> <p>think of kakfa</p> </li> <li> <p>serverless</p> </li> <li>manages the infrastructure</li> <li>storage</li> <li>networking,</li> <li>configuration needed to stream data.</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#1-key-feature","title":"1. key feature","text":"<ul> <li>RealTime (~200 ms latency)</li> <li>ingest data at scale </li> <li>processing</li> <li>supports replay</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#2-capacity-planning-streamshard","title":"2. Capacity planning (stream&gt;shard)","text":""},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#provisioned","title":"provisioned","text":"<ul> <li>choose shard count needed.</li> <li>cost - hourly <code>/shard</code> : 0.015</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#on-demand-new","title":"on-demand new","text":"<ul> <li>default capacity of stream : <code>4000 record/sec + 4 MB/sec</code></li> <li>meaning - 4 shards</li> <li>auto-scale shards based on last 30 throughput peek history</li> <li>max: <code>200k record/sec + 200 MB/sec</code></li> <li>cost</li> <li>hourly <code>/stream</code> </li> <li>data in/out GB</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#3-component","title":"3. component","text":""},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#a-kineses-stream-topic","title":"A kineses stream  === <code>topic</code>","text":"<ul> <li>retention : <code>1(24 hrs) - 365 days (8760 hrs)</code> </li> <li>default retention : <code>24 hours</code> </li> <li>immutable</li> <li>can replay</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#b-shards-partition","title":"B shards === <code>partition</code>","text":"<ul> <li>shard-1, shard-2, ...</li> <li>shard count decides. write eg:</li> <li>message/record throughput :<code>1000 record/sec/shard</code> : if 6 shards =&gt; 6000 message/sec</li> <li>produce speed : <code>1 MB/sec/shard</code> : if 6 shards =&gt; 6MB/s</li> <li>consume speed : <code>2 MB/sec/shard</code>  : if 6 shards =&gt; 12MB/s</li> <li>order : data in each shared is ordered.</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#c-record-message","title":"C record === message","text":"<ul> <li>shard#,</li> <li><code>Blob</code>(data) 1MB-max</li> <li><code>partition-key</code> : msg with same key goes to same shard.<ul> <li>use highly distribute key, else imbalance and ProvisionThroughputExceeded error </li> <li>fixes:</li> <li>a. do retry with exponential backoff. (short term + as soon as the request rate increases, again issue)</li> <li>b. scale out shards. (short term + increase cost)</li> <li>c. batch messages <ul> <li>PutRecord API action  in a loop is inadequate.</li> <li>application must batch records, optimally using the shards in long term.</li> </ul> </li> <li></li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#-","title":"-","text":""},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#d-producer","title":"D producer","text":"<pre><code>- DynamoDb stream --&gt; k-agent --&gt; KDS\n- s3 --&gt; DMS --&gt; KDS\n</code></pre>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#producer-1-app","title":"producer-1: app","text":"<ul> <li>aws SDK (for simple producer)</li> <li>KPL - kineses producer lib <ul> <li>for adv usecase : <code>compression</code>, <code>batch</code>, etc. </li> </ul> </li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#producer-2-kineses-agent","title":"producer-2: kineses-Agent","text":"<ul> <li>stand-alone java programs</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#e-consumer","title":"E consumer","text":"<ul> <li>fanout consumer/s - ( multiple ) </li> <li><code>classic</code> fan out consumer/s (pull):<ul> <li>3 consumer on shard-1, then throughput will 2MB/sec/3 == 666KB/sec each</li> <li>getRecord API</li> </ul> </li> <li><code>enhanced</code> fanout consumer/s (push using HTTP/2)<ul> <li>subscribe API</li> <li>sift limit of 5 consumer per stream.</li> </ul> </li> <li></li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#consumer-1-appaws-sdk","title":"consumer-1: app(<code>aws-sdk</code>)","text":"<ul> <li>support shared + enhanced</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#consumer-2-appkcl","title":"consumer-2: app(<code>KCL</code>)","text":"<ul> <li>Kineses Client libray, (java lib)</li> <li>read progress is tracked in dynamoDB. so add IAM role. </li> <li>max one KCL consumer per shard only </li> <li></li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#consumer-3-lambda","title":"consumer-3: lambda","text":"<ul> <li>supports both mode </li> <li>classic </li> <li>enhanced</li> <li>configure these : <code>batch size</code> and <code>batch window</code>.</li> <li>eg: serverless flow</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#consumer-4-kdf-firehose","title":"consumer-4: kDF (firehose)","text":"<ul> <li>03_02_KDF_KinesisDataFirehose.md</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#consumer-5-kda-analytics","title":"consumer-5: KDA (analytics)","text":"<ul> <li>03_03_KDA_KinesisDataAnalytics.md</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#4-security","title":"4. security","text":"<ul> <li>authorization: IAM polices</li> <li>encryption : at fly and at rest</li> <li>monitor API call with cloudTrail</li> <li>vpc endpoint for private connection.</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#6-scaling","title":"6. scaling","text":""},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#61-shard-splitting","title":"6.1 shard <code>splitting</code>","text":"<ul> <li>The old shard is closed and will be deleted once the data is expired</li> <li>use new shard/s</li> <li>split into 2 only in single operation.</li> <li>so more recursive splitting for more.</li> <li>increase cost.</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#62-shard-merging","title":"6.2 shard <code>merging</code>","text":"<ul> <li>low traffic on shard-1 and shard-2. </li> <li>merge them, saves cost.</li> <li>merge only 2 in single operation.</li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#7-more","title":"7. more","text":"<ul> <li>S3 --&gt; <code>DMS</code> --&gt; kinesis</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/03_01_KDS_KinesisDataStream/#8-hands-on","title":"8 hands on","text":"<ul> <li>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/26101790#overview <pre><code>aws kinesis create-stream \\\n    --stream-name &lt;stream_name&gt; \\\n    --shard-count &lt;number_of_shards&gt;\n\naws kinesis list-streams\n\naws kinesis describe-stream \\\n    --stream-name &lt;stream_name&gt;\n\naws kinesis delete-stream \\\n    --stream-name &lt;stream_name&gt;\n\naws kinesis put-record \\\n    --stream-name &lt;stream_name&gt; \\\n    --partition-key &lt;partition_key&gt; \\\n    --data &lt;base64_encoded_data&gt;\n\naws kinesis put-records \\\n    --stream-name &lt;stream_name&gt; \\\n    --records '[{\"Data\":\"&lt;base64_encoded_data&gt;\",\"PartitionKey\":\"&lt;partition_key&gt;\"}, {...}]'\n\naws kinesis get-shard-iterator \\\n    --stream-name &lt;stream_name&gt; \\\n    --shard-id &lt;shard_id&gt; \\\n    --shard-iterator-type &lt;type&gt;\n\nLATEST                : Most recent data.                         &lt;&lt;&lt;&lt;\nTRIM_HORIZON          : Oldest data.\nAT_TIMESTAMP          : Specific time.\nAFTER_SEQUENCE_NUMBER : After a sequence number.\n\naws kinesis get-records \\\n    --shard-iterator &lt;shard_iterator&gt;\n</code></pre></li> </ul>"},{"location":"01_aws/05_decoupling/03_02_KDF_KinesisDataFirehose/","title":"B. Kinesis Data Firehose <code>KDF</code>","text":""},{"location":"01_aws/05_decoupling/03_02_KDF_KinesisDataFirehose/#1-intro","title":"1 Intro","text":"<ul> <li>easiest way to load streaming data into data stores and analytics tools.</li> <li><code>capture</code>, </li> <li><code>transform</code>, </li> <li><code>load streaming data</code></li> <li>also : batch, compress, and encrypt </li> <li>NearRealTime <code>Data Delivery streams</code></li> <li>set buffer-interval <code>0-900 Sec</code><ul> <li>if buffer-interval == 0 --&gt; <code>real time</code></li> <li>if buffer-interval == 1 to 900 sec --&gt; <code>Near real time</code></li> </ul> </li> <li> <p>set buffer-size</p> <ul> <li>min : 1 MB</li> <li>default : 5 min</li> <li>KDF only buffers data, does not have any its own permanent storage.</li> <li>no replay capbilty,</li> </ul> </li> <li> <p>serverless</p> </li> <li>fully managed, </li> <li>no administration <ul> <li>unlike KDS where we provision no. of shards.</li> </ul> </li> <li>auto scale</li> </ul>"},{"location":"01_aws/05_decoupling/03_02_KDF_KinesisDataFirehose/#2-source-and-destinations","title":"2 Source and Destinations","text":"<ul> <li>source: KDS, KCL/SDK, K-agent, AWS IoT </li> <li>destination ( only 3 in aws side): <code>s3</code>, <code>redshift</code>/OLAP DB, <code>openSearch</code></li> <li>CANNOT set up multiple consumers gor KDF-streams, as it can dump data in a single data repository at a time </li> <li>fact to remember  </li> <li> <p>When KDS is configured as the source of a KDF stream, then:</p> <ul> <li>Firehose\u2019s PutRecord and PutRecordBatch operations are disabled </li> <li>thus, Kinesis-Agent cannot write to KDF Stream directly.</li> </ul> </li> <li> <p></p> </li> <li>optional lambda transformation + convert format to parquet+ORC</li> <li>can put failed item into s3</li> <li>write data in batches</li> </ul>"},{"location":"01_aws/05_decoupling/03_02_KDF_KinesisDataFirehose/#extra","title":"extra","text":""},{"location":"01_aws/05_decoupling/04_active_MQ/","title":"Amazon MQ","text":"<ul> <li>SQS, SNS are \u201ccloud-native\u201d services</li> <li>Traditional applications on-premises may use open protocols : MQTT, AMQP, STOMP</li> <li>migrate cloud</li> <li>option-1 : re-engineer to SQS/SNS</li> <li>option-2 : Use Amazon MQ to run rabbitMQ (AMQP)</li> <li>benefit: High avaliability:</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/05_eventBridge/","title":"Eventbridge","text":"<ul> <li>aws1:custom-bus-1 (access policy) --&gt; allow cross account access.</li> <li>archive event &gt; replay event</li> </ul>"},{"location":"01_aws/05_decoupling/05_eventBridge/#architecture","title":"Architecture","text":""},{"location":"01_aws/05_decoupling/05_eventBridge/#central-event-bus","title":"central event bus:","text":"<ul> <li>AWS org (main account)</li> <li>child aws will publish event to this bus</li> <li>update IAM policy of bus, for cross acct access.</li> <li></li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/06_MSK/","title":"MSK","text":""},{"location":"01_aws/05_decoupling/06_MSK/#a-intro","title":"A. Intro","text":"<ul> <li>Alternative to Amazon KDS.</li> <li>Fully managed Apache Kafka on AWS.</li> </ul>"},{"location":"01_aws/05_decoupling/06_MSK/#b-provision","title":"B. provision","text":""},{"location":"01_aws/05_decoupling/06_MSK/#b1-serverless","title":"B.1 serverless:","text":"<ul> <li>Don't provision cluster capacity, </li> <li>resource, </li> <li>compute, </li> <li>storage,etc</li> </ul>"},{"location":"01_aws/05_decoupling/06_MSK/#b2-msk-regular-we-provision","title":"B.2 MSK-regular, we provision:","text":"<ul> <li>Cluster</li> <li>Kafka <code>brokers nodes</code> </li> <li><code>Zookeeper</code> nodes</li> <li>deploy in <code>Multi-AZ</code></li> <li>Data stored in <code>EBS</code> (as long as paying for volume)</li> <li><code>recovery</code> from failure</li> </ul>"},{"location":"01_aws/05_decoupling/06_MSK/#c-consumer","title":"C. Consumer","text":"<ul> <li>managed Service for Apache Flink</li> <li>Glue</li> <li>lambda </li> <li>custom app</li> <li>ecs,eks,etc</li> <li></li> </ul>"},{"location":"01_aws/05_decoupling/06_MSK/#d-comparison-with-kafka","title":"D. comparison with kafka","text":""},{"location":"01_aws/06_Security/01_IAM/","title":"IAM","text":""},{"location":"01_aws/06_Security/01_IAM/#-iam_01-httpschatgptcomc3bfd592e-3ccc-403f-a61c-8e6ab72eacf5","title":"- IAM_01 https://chatgpt.com/c/3bfd592e-3ccc-403f-a61c-8e6ab72eacf5","text":""},{"location":"01_aws/06_Security/01_IAM/#a-iam","title":"A. IAM","text":""},{"location":"01_aws/06_Security/01_IAM/#1-intro","title":"1. intro","text":"<ul> <li>AWS CLI / SDK</li> <li>signed API call with SigV4</li> <li>Access keys ID + secret Access key</li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#user-group","title":"User / group","text":"<ul> <li>IAM user </li> <li>federated user </li> <li>outside AWS user</li> <li>authenticated by an external identity provider (okta,google,fb) using SAML,OIDC, OAUTH2.0</li> <li>external identity provider, is register with AWS account</li> <li>IAM Group</li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#policies","title":"policies","text":"<ul> <li>permission, JSON document </li> <li>leverage special policy variable eg: ${aws:username}</li> <li>attach to many principle: IAM user, IAM group, IAM role</li> <li>Type: </li> <li><code>AWS managed policies</code> (fullSQSaccess, fulls3access, etc)</li> <li><code>customer managed polices</code><ul> <li>Version Controlled </li> <li>rollback</li> <li>attach to many principle: IAM user, IAM group, IAM role</li> </ul> </li> <li><code>inline polices</code> **<ul> <li>attach to single principle: IAM user, IAM group, IAM role</li> <li>1-2-1</li> <li>delete principle, also delete inline policy.</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#iampassrole-and-iamgetrole","title":"Iam:PassRole and iam:GetRole","text":"<ul> <li>Broad-access-role / pipeline role has these action on all resource(role type)</li> <li>that's why Broad-access-role, able to add any-role on lambda,ecs,etc</li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#audit","title":"Audit","text":"<ul> <li>check below Reports</li> <li>user level : access advisor, etc</li> <li>account level : credential report, etc</li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#good-practice","title":"good practice","text":"<ul> <li>Monitor API calls made by a user in CloudTrail</li> <li>root user + MFA</li> <li>Grant Least Privilege</li> <li>don't store IAM key credentials on EC2</li> <li>On premise server must call STS to obtain temporary security credentials.</li> <li>dont reuse role, create separate.</li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#2-iam-role-green_circle","title":"2. IAM role :green_circle:","text":"<ul> <li>service role is pre-defined for AWS services  </li> <li>AWS Lambda execution role, EC2 Auto Scaling role, RDS service role</li> <li> <p>so, automatically add current-service as trusted entity. no need to add again.</p> </li> <li> <p>Designed to provide temporary security credentials by trusted entities/principle :</p> </li> <li>other aws-service - ec2, s3,etc</li> <li>cross account service/user </li> <li>has 2 things:</li> <li>permission policy<ul> <li>[ effect, action, resource, condition ]</li> </ul> </li> <li>trusted entities (role trust policy)<ul> <li>which principals (trusted entities) are allowed to assume the role.</li> </ul> </li> <li>use case</li> <li>service to service communication.</li> <li>lambda role --&gt; s3,sqs,ec2,etc</li> <li>ecs/eks --&gt; s3,sqs,etc</li> <li>federated user, assumes role - Broad-access-role</li> <li>service account in k8s assumes role (IRSA)</li> <li>cross account access<ul> <li>create role for other account-2 to assume role and access rsource on account-1</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#3-resource-policy-green_circle","title":"3. Resource Policy :green_circle:","text":"<ul> <li>has principle</li> <li>who amd what are allowed to access </li> <li>eg:</li> <li>s3 policy</li> <li>sqs policy</li> <li>API gateway policy</li> <li>...</li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#4-permission-boundary-green_circle","title":"4. Permission Boundary :green_circle:","text":"<ul> <li>principle-1</li> <li>attach <code>IA-policy-1</code></li> <li>attach <code>Permission-Boundary-policy-1</code></li> <li>intersection of both will be effective</li> <li> </li> <li> <p>apply on: </p> </li> <li>IAM <code>roles</code> </li> <li>IAM <code>users</code></li> <li>IAM groups - N0  </li> </ul> <pre><code>// example:\nboundary-1 : allow  `ecs,lambda,s3` only\n  - attach to iam-user-1\n  - iam-user-1 --&gt; attach iam-policy(`sqs` access) \n  - iam-user-1 cannot access sqs, since its outside boundary. \n</code></pre>"},{"location":"01_aws/06_Security/01_IAM/#5-sts-secure-token-service","title":"5. STS : secure token service","text":""},{"location":"01_aws/06_Security/01_IAM/#stsassumerole","title":"sts:<code>assumeRole</code>","text":"<ul> <li>provides temporary security credentials(Access key + secret) + token(expiry)</li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#stsassumerolewithsaml","title":"sts:<code>assumeRoleWithSAML</code>","text":""},{"location":"01_aws/06_Security/01_IAM/#stsgetsessiontoken","title":"sts:<code>getSessionToken</code>","text":"<ul> <li>equivalent to gimme-aws-creds</li> <li>get aws accessID,key,token,etc with MFA token</li> <li>add condition -&gt; <code>aws:MultiFactorAuthPresent:true</code></li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#6-scenarios","title":"6. scenarios","text":""},{"location":"01_aws/06_Security/01_IAM/#61-cross-account-access","title":"6.1. cross account access","text":"<ul> <li> <p><code>AWS-1(user-11)</code> --&gt; has to access --&gt;  <code>AWS-2(resource : R1)</code> </p> </li> <li> <p>option-1 : <code>ResourceBasedPolicy</code>)</p> </li> <li>R1:Policy &gt; update/add &gt; allow AWS-1(user-11) </li> <li> <p> For S3,SQS,SNS,Lambda - use resource-based-Policy</p> </li> <li> <p>option-2 : <code>IAM policy</code></p> </li> <li>First, inside AWS-2 <ul> <li>create <code>role-1</code> &gt;  allow AWS-1(user-11) to R1.</li> <li>create <code>policy-1</code> : allow user-11 to assume <code>role-1</code></li> </ul> </li> <li>Next, user-11 <code>assume role-1</code> and access it, but<ul> <li>user-11 will first <code>give up</code> all the original permission.</li> <li>then assume/get role-1 permissions.</li> </ul> </li> <li>for Kinesis Db - use iam role  </li> </ul> <p></p>"},{"location":"01_aws/06_Security/01_IAM/#7-evaluation-logic-yellow_circle","title":"7. Evaluation logic :yellow_circle:","text":"<ul> <li>order: <ul> <li>explicit deny</li> <li>allow</li> <li>SCP</li> <li>resource policy</li> <li>principal's IAM policy</li> <li>permission boundary</li> <li>AWS CloudFormation a global service (temp access)</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#8-advance-polices-example","title":"8. Advance Polices example","text":""},{"location":"01_aws/06_Security/01_IAM/#conditions","title":"Conditions","text":"<ul> <li> <p>eg-1 Allow Access Based on IP Address <pre><code>        {\n            \"Effect\": \"Allow\",\n            \"Action\": \"s3:*\",\n            \"Resource\": \"arn:aws:s3:::example-bucket/*\",\n            \"Condition\": {\n                \"IpAddress\": {\n                    \"aws:SourceIp\": \"203.0.113.0/24\"\n                },\n                // always AND\n                \"StringEquals\": {\n                        \"aws:SourceVpc\": \"vpc-12345678\"\n                }\n            }\n        }\n</code></pre></p> </li> <li> <p>eg-2 Allow Access During Specific Time Period <pre><code>            \"Condition\": {\n                \"DateGreaterThan\": {\n                    \"aws:CurrentTime\": \"2024-07-19T09:00:00Z\"\n                },\n                \"DateLessThan\": {\n                    \"aws:CurrentTime\": \"2024-07-19T17:00:00Z\"\n                }\n            }\n</code></pre></p> </li> <li> <p>eg-3 Allow Access Based on MFA Authentication <pre><code>            \"Condition\": {\n                \"Bool\" / \"BoolIfExist\": {\n                    \"aws:MultiFactorAuthPresent\": \"true\"\n                }\n            }\n</code></pre></p> </li> <li> <p>eg-4 tag <pre><code>\"Condition\": {\n                \"StringNotEquals\" / \"StringEquals\": {\n                    \"ec2:ResourceTag/Environment\": \"Production\",\n                    \"aws:principleTag/Departmnet\": \"d1\"\n                }\n            }\n</code></pre></p> </li> <li>eg-5 <pre><code>#  Users belonging to the IAM user group can terminate an Amazon EC2 instance in the **us-west-1** region \n#  when the user's source IP in 10.200.200.0/24\n{\n    \"Version\":\"2012-10-17\",\n    \"Id\":\"EC2TerminationPolicy\",\n    \"Statement\":[\n        {\n            \"Effect\":\"Deny\",\n            \"Action\":\"ec2:*\",\n            \"Resource\":\"*\",\n            \"Condition\":{\n                \"StringNotEquals\":{\n                    \"ec2:Region\":\"us-west-1\"\n                }\n            }\n        },\n        {\n            \"Effect\":\"Allow\",\n            \"Action\":\"ec2:TerminateInstances\",\n            \"Resource\":\"*\",\n            \"Condition\":{\n                \"IpAddress\":{\n                    \"aws:SourceIp\":\"10.200.200.0/24\"\n                }\n            }\n        }\n    ]\n}\n</code></pre></li> <li>more eg :</li> <li>\"aws:RequestedRegion\": \"eu-west-1\" :  allow running Amazon EC2 instances only in the eu-west-1 region </li> <li>\"aws:priciplaOrgId\": \"0-xxxxxxxxx\"</li> <li></li> </ul>"},{"location":"01_aws/06_Security/01_IAM/#9-principals","title":"9. principals","text":""},{"location":"01_aws/06_Security/01_SSO%2BDirectoryService/","title":"A. Directory Service","text":""},{"location":"01_aws/06_Security/01_SSO%2BDirectoryService/#1-simple-ad","title":"1. Simple AD","text":"<p> - aws managed AD, users present only in this AD - least expensive option  - your best choice if you have <code>5,000 or fewer users</code></p>"},{"location":"01_aws/06_Security/01_SSO%2BDirectoryService/#2-ad-connector","title":"2. AD Connector","text":"<p> - users present in on-prem AD, only - <code>proxy</code> help to connect it.</p>"},{"location":"01_aws/06_Security/01_SSO%2BDirectoryService/#3-aws-managed-ad","title":"3. AWS managed AD","text":"<p> - hybrid kind : user present in both : <code>AWS AD</code> + <code>on-prem AD</code> - best choice if you have more than 5,000 users - <code>AWS AD</code> create trust with <code>on-prem AD</code></p>"},{"location":"01_aws/06_Security/01_SSO%2BDirectoryService/#b-iamsso-or-iamidentity-provider","title":"B. IAM:SSO or IAM:Identity provider","text":"<ul> <li>use case:<ul> <li>sso for all account in aws org</li> <li>sso for all ec2 instance in an aws account</li> </ul> </li> <li> <p>IP has :</p> <ul> <li><code>AD : Active directory</code>  + integrate to <code>3rd party IP (OKta)</code><ul> <li>check here</li> </ul> </li> <li><code>permission set</code> : which user has access to what: <code>fine grained permission and assginmnet</code><ul> <li>lek role-1(full-access) on  member-account-1</li> <li>lek role-2(read-access) on  member-account-1</li> <li>lek role-3(write-access) on  member-account-1</li> <li>lek role-1(write-access) on  member-account-2</li> </ul> </li> </ul> </li> <li> <p>Flow:</p> <ul> <li>lek -&gt; okta home  --&gt; aws-mgt-acct:<code>AWS IP/SSO with permission-Set</code> --&gt; <code>Okta SSO</code><ul> <li>member-account-1 &gt; assume role-1, role-2, role-3</li> <li>member-account-2 &gt; assume role-1</li> <li>how and where SAML fits ?</li> </ul> </li> </ul> </li> <li> <p></p> </li> <li></li> <li></li> </ul>"},{"location":"01_aws/06_Security/01_SSO%2BDirectoryService/#summary","title":"Summary","text":"<ul> <li>check eveything in diagram:</li> <li></li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/","title":"A. CUP : Cognito user pool (Serverless)","text":"<ul> <li>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/19731934#notes</li> <li>Complicated service, Need to have high level idea for SAA/DVA</li> <li>https://chatgpt.com/c/676b51a6-3388-800d-a754-f5872af7a68a</li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/#1-intro","title":"1. Intro","text":"<ul> <li>sign-in functionality for global user (web/mobile)</li> <li>simple login:<ul> <li>userid, password, custom feild, email/phone verification.</li> <li>password-reset, acct recovery</li> <li>enable MFA</li> <li>send email to user. SES</li> <li>JWT token</li> <li>Authenticate through:</li> <li>integration with federated Identity provide - Okta,fb,google (social login)</li> <li>SAML (corporate login)</li> <li>OIDC</li> <li>Microsoft AD , LDAP</li> <li>own serverless database of user/s</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/#2-hosted-ui","title":"2. hosted UI","text":"<ul> <li>set domain</li> <li>aws provided</li> <li>custom<ul> <li>must create ACM cert in us-east-1 </li> </ul> </li> <li>customize UI </li> <li>CSS </li> <li>logo</li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/#3-lambda-trigger","title":"3. lambda trigger","text":"<ul> <li>on user pool event</li> <li></li> <li></li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/#4-adaptive-authentication","title":"4. Adaptive Authentication","text":"<ul> <li>risk score for every login activity</li> <li>if it looks suspicious, then prompted for MFA</li> <li>in case of compromised credential, takeover to email/phone confirmation</li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/#5-integration-example","title":"5. Integration example","text":""},{"location":"01_aws/06_Security/02_1_cognito_SAA/#1-api-gateway","title":"1 API-gateway","text":""},{"location":"01_aws/06_Security/02_1_cognito_SAA/#21-alb-high-level","title":"2.1 ALB (high level)","text":""},{"location":"01_aws/06_Security/02_1_cognito_SAA/#22-alb-with-oidc","title":"2.2 ALB (with OIDC)","text":""},{"location":"01_aws/06_Security/02_1_cognito_SAA/#b-cognito-identity-pool","title":"B. Cognito Identity pool","text":"<ul> <li>authorization.</li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/#1-intro_1","title":"1 Intro","text":"<ul> <li>once user is authenticated with any of these,</li> <li>then can get temp AWS credential by assuming IAM role, to access aws resource.</li> <li>role has trust policy. <pre><code>\u2022 Public Providers (Login with Amazon, Facebook, Google, Apple)\n\u2022 Users in an Amazon Cognito user pool\n\u2022 OpenID Connect Providers &amp; SAML Identity Providers\n\u2022 Developer Authenticated Identities (custom login server)\n\u2022 Cognito Identity Pools allow for unauthenticated (guest) access\n</code></pre></li> <li></li> </ul>"},{"location":"01_aws/06_Security/02_1_cognito_SAA/#2-iam-policy-example","title":"2 IAM policy example","text":""},{"location":"01_aws/06_Security/02_1_cognito_SAA/#access-s3","title":"access s3","text":""},{"location":"01_aws/06_Security/02_1_cognito_SAA/#access-dynamodb","title":"access dynamoDB","text":""},{"location":"01_aws/06_Security/02_1_cognito_SAA/#3-hands-on","title":"3 hands on","text":"<ul> <li>configure permission (create IAM role/s - 1, 2,3 ...)</li> <li></li> <li>connect to user pool (ID provider)</li> <li></li> <li>create rule to choose role, based on :</li> <li>claims in token </li> <li>user-attribute set is user pool</li> <li>next, use SDK check doc.</li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/","title":"A. AWS Organisation (global srv)","text":""},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#1-key-term","title":"1. key term","text":"<ul> <li><code>organisation unit, OU</code> : Applied one policy(scp) : <code>AWSFULLAccess</code></li> <li><code>OU (root)</code> :  <ul> <li><code>Management-account</code> (main) : <ul> <li>Don't apply SCP, have full access already.</li> <li>even if we apply, no impact.</li> </ul> </li> <li><code>member-account</code>-1</li> <li>member-account-2</li> <li><code>ou (dev)</code>  : <code>SCP-2</code>, <code>SCP-3</code><ul> <li>dev-account-1</li> <li>dev-account-2</li> <li>...</li> </ul> </li> <li><code>ou (prod)</code><ul> <li>dev-account-1</li> <li>dev-account-2</li> <li>...</li> </ul> </li> <li>...</li> <li>can have nesting &gt; nesting&gt; ...</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#2-organizational-policies","title":"2. organizational policies","text":""},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#scp-service-control-policies","title":"SCP (Service Control Policies)","text":"<ul> <li>SCPs DONT retroactively affect existing resources </li> <li>permission/policies  </li> <li>by default, allow NOTHING</li> <li>applies to member-acct <ul> <li>member-acct's :: [ root account , IAM user, IAM group, IAM role ]  root as well</li> <li>does not affect service-linked role (AWS managed roles)</li> </ul> </li> <li>applies to OU<ul> <li>applies to member-acct-OU-1</li> <li>applies to member-acct-OU-2</li> <li>...</li> </ul> </li> <li>child OU inherit SCP from parent OU</li> <li>strategies</li> <li><code>AllowedList</code> : deny all first, then start adding allowed items.</li> <li><code>Blocklist</code> : allow all first, then start adding blocks.</li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#tag-policies","title":"tag policies","text":"<ul> <li>create tags and create polices around it. </li> <li>eg : ccgg has tag on attmid</li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#backup-polices","title":"backup polices","text":"<ul> <li>org wide backup plan.</li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#3-benefit-purpose","title":"3. benefit / purpose","text":"<ul> <li><code>hierarchical structure of OUs</code></li> <li>API to create member-acct and organize them.</li> <li> <p>ou by business unit, ou by project, ou by env</p> </li> <li> <p><code>Cost</code></p> </li> <li>Aggr all usage and give more <code>saving</code></li> <li> <p><code>consolidated</code> billing.</p> </li> <li> <p><code>security</code></p> </li> <li>Configure <code>AWS SSO</code>/ <code>Identity Center</code> for centralized access management<ul> <li>create <code>cross account role</code> in permission-Set of IP</li> </ul> </li> <li>centrally manage and govern multiple AWS accounts.</li> <li> <p>policies</p> </li> <li> <p><code>centralized log</code> : Send CloudWatch Logs to central account\\</p> </li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#5-deploy-iac-stackset","title":"5. deploy IAC : <code>StackSet</code>","text":"<ul> <li>Stacks are ideal for single-region deployments</li> <li>StackSet Manages Centralized deployment of resources across </li> <li>multiple regions </li> <li>multiple accounts </li> <li>in AWS org</li> <li></li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#98-screenshot","title":"98. Screenshot","text":""},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#99-exam-scenario","title":"99. Exam scenario","text":"<pre><code>Scenario #1\nYou would like to migrate an AWS account from an AWS Organization A to an AWS Organization B. \nWhat are the steps do to it:\n  - Remove the member account from the old organization. first\n  - Send an invite to the member account from the new Organization. \n  - Accept the invite to the new organization from the member account\n\n===  \nScenario #2\n- AWS Org, member account MA-1 has NAT-gatway-1\n- later on SCP-1 attached to  deny attaching new NAT gateway.\nwhat will happen to new and existing NAT gateway ?\n\nSolution:\n- Existing NAT Gateway (NAT-Gateway-1) in MA-1 \u2192 \u2705 Will continue to work because SCPs do not retroactively affect existing resources.\n- New NAT Gateway Creation in MA-1 \u2192 \u274c Will be denied due to SCP-1 restricting new NAT gateway creation.\n</code></pre>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#b-aws-control-tower","title":"B. AWS Control tower","text":""},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#intro","title":"Intro","text":"<ul> <li>Another service on top of AWS org </li> <li>to set-up new, secure, and compliant multi-account AWS environmnet, </li> <li>reducing the time and complexity involved.</li> <li>provides interactive dashboard to see:</li> <li>compliance in all acct/s in org.</li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#guardrails","title":"guardrails","text":"<ul> <li>Automate on-going policy management using guardrails</li> <li>Detect policy violations - built-in governance and compliance </li> <li> <p>remediate them</p> </li> <li> <p>Type:</p> </li> <li>Preventive guardrails <ul> <li>restrict, using SCP</li> </ul> </li> <li>detective guardrails <ul> <li>notify non-compliance using AWS config </li> </ul> </li> <li></li> <li></li> </ul>"},{"location":"01_aws/06_Security/03_AWS_org%2Bcontrol-tower/#c-more","title":"C. more","text":"<ul> <li>AWS licence manager</li> <li>https://docs.aws.amazon.com/license-manager/latest/userguide/license-manager.html</li> <li>for both Aws manager and 3rd part licence.</li> <li>intergated with AWS marketplace</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/","title":"Encryption","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#1-encryption-at-fly","title":"1. Encryption at <code>Fly</code>","text":"<ul> <li>TLS / SSL certificate / HTTPS</li> <li>prevent from MITM</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#2-encryption-at-rest","title":"2. Encryption at <code>Rest</code>","text":"<ul> <li>encryption/decryption happens at server.</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#3-client-side-encryption","title":"3. Client side encryption","text":"<ul> <li>Don't trust server</li> <li>cant make KMS api call</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#-symmetricaes-256-generate-single-key-private-aws-service-integrated-with-kms-uses-it-a-symmetric-rsa-generate-2-keys-public-for-encrypt-access-it-download-it-share-with-client-private-for-decrypt-for-client-server-comm-used-for-digital-signature","title":"<pre><code># --- symmetric(AES-256) ---\n- generate single key\n  - private\n\n- aws-service integrated with kms, uses it.   &lt;&lt;&lt;\n\n# ---  A-symmetric (RSA) ---\n- generate 2 keys\n  - public ( for encrypt)\n     - access it, download it.\n     - share with client\n  - private ( for decrypt)\n\n- for client-server comm                       &lt;&lt;&lt;\n- used for digital signature.\n</code></pre>","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#kms","title":"KMS","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#a-kms-key-types","title":"A. KMS: key types","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#1-aws-owned","title":"1. AWS owned","text":"<ul> <li>keys already created for services. </li> <li>key is <code>FREE</code> + API call is <code>FREE</code></li> <li>eg</li> <li>sse-s3</li> <li>sse-sns</li> <li>...</li> <li>sse-s3</li> <li>Fully managed by S3<ul> <li>Key rotation is not applicable for us.</li> <li>Minimal key management overhead</li> </ul> </li> <li>access control via S3 bucket policies</li> <li>No specific key tracking (basic S3 logs)</li> <li>No additional cost for encryption</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#2-aws-managed-key","title":"2. AWS managed key","text":"<ul> <li>request key from kms (sse-kms), CMK</li> <li>has kms-key alias</li> <li>provides you with an audit trail that shows when your CMK was used and by whom. </li> <li>pending deletion state for 7 - 30 days  <pre><code>- key looks like - aws/serviceName/**** . eg\n  - aws/rds/...\n  - aws/ebs/...\n</code></pre></li> <li> <p>key is <code>FREE</code> + pay for API call</p> </li> <li> <p>needs to be rotated</p> </li> <li>default : 365 days</li> <li>range : 90 - 2650 days</li> <li>have od rotation, at any time.</li> <li> <p>automatic yearly</p> </li> <li> <p>scope: region </p> </li> <li>for cross region copy will need 2 separate keys, once for each region</li> <li>eg: copy from region-1 to region-2<ul> <li>aws will decrypt using region-1-key</li> <li>aws will re-encrypt using region-2-key</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#integration","title":"Integration","text":"<ul> <li><code>IAM</code></li> <li><code>cloudTrail</code>, check log for KMS usage/audit. </li> <li><code>secret manager</code> : encrypt password with kms-key</li> <li><code>EC2</code>: encrypt AMI with kms</li> <li><code>ebs</code>, <code>rds</code>,  <code>s3-key</code>, <code>sqs-keys</code>, etc</li> <li><code>lambda</code>: encrypt env var</li> <li>...</li> <li>all other service which requires encryption.</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#key-policy","title":"key Policy","text":"<ul> <li>like s3 policy</li> <li>define who can access key.</li> <li>default policy</li> <li>already exists</li> <li>allows everyone in account  </li> <li>custom policy</li> <li>eg:<ul> <li>for cross account access, restricted access with in acct, etc</li> <li></li> <li>give access to specific services (lambda-fn)   <pre><code>lambda-1 copy ebs snapshot from one region to another region\n  - only lambda-1 must have access below 2 keys, no one else.\n    - region-1-key (to decrypt) \n    - region-2-key (to re-encrypt) \n</code></pre></li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#regionality","title":"Regionality","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#single-regional","title":"single regional","text":"<ul> <li>same key cannot be present in 2 diff regions.</li> <li>requires additional api call (for cross region)</li> <li>decrypt  call</li> <li> <p>re-encrypt call</p> </li> <li> <p>fact </p> </li> <li>CANNOT convert an existing single-Region key to a multi-Region key. </li> <li>CANNOT share an AWS KMS key to another region <ul> <li>alternative : use multi-region key</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#multi-regional","title":"multi regional","text":"<ul> <li>simplify but not recommended</li> <li>same key replicated in multiple region</li> <li>primary (policy-1)</li> <li>replicated key (policy-2, in another region)</li> <li>purpose</li> <li>encrypt in one region and use/decrypt in another region, seamlessly</li> <li>don't need to re-encrypt again with another region key</li> <li>use-case</li> <li>global Aurora DB</li> <li>global Dynamo DB</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#3-customer-managed-key-paid","title":"3. Customer managed key <code>PAID</code>","text":"<ul> <li>customer upload its own key. </li> <li>import key into kms, which generated outside aws</li> <li>rotation:  must enable it </li> <li>pricing </li> <li><code>1$/month</code> / key</li> <li>API calls : <code>0.03/10,000</code></li> <li>Dont support digital signature. </li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#b-hands-on","title":"B. hands on","text":"<pre><code>Compliance and regulatory requirements  SSE-KMS\nHigh-performance applications           SSE-S3\nTracking key usage for audit logs       SSE-KMS\nMinimal key management overhead         SSE-S3\n</code></pre>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#-create-key-1-symetric-type-aws-owned-choose-regionality-single-region-key-policy-add-json-or-use-console-to-define-multiple-options-rotation-yearly-yn-ready-action-disable-schedule-for-deletion-use-aws-cli-encypti-failtext-with-above-key-1","title":"<pre><code>- create key-1\n    - symetric\n        - type: aws owned\n- choose : regionality \n    - single region\n- key policy\n    - add json\n    - or use console to define multiple options.\n- rotation yearly : y/n\n\n// READY\n\n- action:\n    - disable\n    - schedule for deletion \n\n- use aws-cli : encypti failtext with above key-1 \n</code></pre>","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#c-examples","title":"C. Examples","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#11-s3-crr-replication","title":"1.1 S3 - <code>CRR</code> replication","text":"<ul> <li>here</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#12-s3-srr-replication","title":"1.2 S3  - <code>SRR</code> replication","text":"<ul> <li>bucket-1(key-1) --&gt; replicate(decrypt with key-1 &gt; encrypt with key-2) --&gt; bucket-2(key-2)</li> <li>add permission for both keys to ...</li> <li></li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#3-share-ami-cross-region","title":"3. share AMI cross region","text":"<p> - share AMI : update <code>launch-permission</code> for AMI to allow access - share kms-key-1 : update <code>kms-policy</code> to allow access - Account-b &gt;&gt; decrypt with kms-key-1 &gt;&gt; re-encrypt with its kms-key-2(Account-b)</p>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#4-ebs-volume-cross-region","title":"4. EBS volume (cross region)","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#5-multi-region-key-dynamo-rds","title":"5 multi region key - Dynamo / RDS","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#z-kms-more-for-dva","title":"Z. KMS: more ( for DVA)","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#1-encryptdecrypt-4kb","title":"1. Encrypt/decrypt (&lt; 4KB)","text":"<ul> <li>straight forward, nothing new</li> <li></li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#2-encryptdecrypt-4kb-big-files","title":"2. Encrypt/decrypt (&gt; 4KB) <code>big files</code>","text":"<ul> <li>happens at client side </li> <li>generating data key: <code>DEK</code></li> <li>using it for en/de</li> <li>can cache this and re-use<ul> <li>reduce the no of api call and save quota </li> </ul> </li> <li>CLI/SDK simplifies it, so use it.</li> </ul> <pre><code>## === way-1 ===\n## Step-1 generate DEK\n- aws kms generateDatakey\n  - plaintext DEK\n\n- aws kms generateDatakey --CMK-1\n  - plaintext DEK\n  - plaintext DEK + CMK-1 ==&gt; encrypted DEK (ciphertextBlob)\n\n- aws kms generateDatakeyWithoutPlaintext --CMK-1\n  - plaintext DEK + CMK-1 ==&gt; encrypted DEK (ciphertextBlob)\n\n## Step-2 perform encryption/decryption\n...\n...\n\n# === way-2 ===\n  pip i aws-encryption-sdk-cli\n\n  aws-encryption-cli --encrypt \\\n  --input &lt;input_file_or_directory&gt; \\\n  --output &lt;output_file_or_directory&gt; \\\n  --wrapping-keys key=arn:aws:kms:region:account-id:key/key-id\n\n  aws-encryption-cli --decrypt \\\n  --input &lt;encrypted_file_or_directory&gt; \\\n  --output &lt;decrypted_file_or_directory&gt;\n</code></pre>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#21-envelop-encryption","title":"2.1 envelop encryption","text":""},{"location":"01_aws/06_Security/04_1_KMS_SSA/#22-envelop-de-cryption","title":"2.2 envelop de-cryption","text":"<ul> <li>eg with s3</li> <li></li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#3-kms-request-quota","title":"3. KMS request quota","text":"<ul> <li>share quota across account.</li> <li>will get ThrottleException</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#exam","title":"EXAM","text":"<ul> <li>set of key-value pairs that contain additional contextual information about the data.</li> <li>encryption context offers another level of security for the encryption key.</li> <li>However, it is not useful for generating unique keys.</li> </ul>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#1","title":"1","text":"<pre><code>on s3 bucket has to update object-1 and object-2.\n- encrypt object-1 with key-1\n- encrypt object-2 with key-2\n\nprovison 2 sse-kms keys:\n\naws s3 cp object-1 s3://your-bucket/ --sse aws:kms --sse-kms-key-id key-1\naws s3 cp object-2 s3://your-bucket/ --sse aws:kms --sse-kms-key-id key-2\n</code></pre>"},{"location":"01_aws/06_Security/04_1_KMS_SSA/#2-encryption-context","title":"2 encryption context","text":""},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/","title":"AWS KMS CLI Commands","text":""},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#1-create-a-new-kms-key","title":"1. Create a New KMS Key","text":"<pre><code>aws kms create-key \\\n  --description \"Example KMS Key\" \\\n  --key-usage ENCRYPT_DECRYPT \\\n  --customer-master-key-spec SYMMETRIC_DEFAULT\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description","title":"Description:","text":"<ul> <li>Creates a new KMS key for encryption and decryption.</li> <li><code>--description</code>: A short description of the key.</li> <li><code>--key-usage</code>: Specifies the cryptographic operations.</li> <li><code>--customer-master-key-spec</code>: Specifies the key type.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#2-list-kms-keys","title":"2. List KMS Keys","text":"<pre><code>aws kms list-keys\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_1","title":"Description:","text":"<ul> <li>Lists all KMS keys in your account.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#3-describe-a-kms-key","title":"3. Describe a KMS Key","text":"<pre><code>aws kms describe-key \\\n  --key-id &lt;key-id&gt;\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_2","title":"Description:","text":"<ul> <li>Provides details about a specified KMS key.</li> <li>Replace <code>&lt;key-id&gt;</code> with the ID or ARN of the KMS key.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#4-enable-a-kms-key","title":"4. Enable a KMS Key","text":"<pre><code>aws kms enable-key \\\n  --key-id &lt;key-id&gt;\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_3","title":"Description:","text":"<ul> <li>Enables a disabled KMS key.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#5-disable-a-kms-key","title":"5. Disable a KMS Key","text":"<pre><code>aws kms disable-key \\\n  --key-id &lt;key-id&gt;\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_4","title":"Description:","text":"<ul> <li>Disables a KMS key to prevent its use.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#6-schedule-key-deletion","title":"6. Schedule Key Deletion","text":"<pre><code>aws kms schedule-key-deletion \\\n  --key-id &lt;key-id&gt; \\\n  --pending-window-in-days 30\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_5","title":"Description:","text":"<ul> <li>Schedules the deletion of a KMS key after a specified number of days (7 to 30).</li> <li><code>--pending-window-in-days</code>: Specifies the waiting period before deletion.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#7-cancel-key-deletion","title":"7. Cancel Key Deletion","text":"<pre><code>aws kms cancel-key-deletion \\\n  --key-id &lt;key-id&gt;\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_6","title":"Description:","text":"<ul> <li>Cancels a scheduled key deletion.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#8-encrypt-data","title":"8. Encrypt Data","text":"<pre><code>aws kms encrypt \\\n  --key-id &lt;key-id&gt; \\\n  --plaintext fileb://example.txt \\\n  --output text \\\n  --query CiphertextBlob &gt; encrypted.txt\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_7","title":"Description:","text":"<ul> <li>Encrypts data using the specified KMS key.</li> <li>Replace <code>example.txt</code> with the plaintext file.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#9-decrypt-data","title":"9. Decrypt Data","text":"<pre><code>aws kms decrypt \\\n  --ciphertext-blob fileb://encrypted.txt \\\n  --output text \\\n  --query Plaintext | base64 --decode &gt; decrypted.txt\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_8","title":"Description:","text":"<ul> <li>Decrypts previously encrypted data.</li> <li>Replace <code>encrypted.txt</code> with the file containing the encrypted data.</li> </ul>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#10-generate-data-key","title":"10. Generate Data Key","text":"<pre><code>aws kms generate-data-key \\\n  --key-id &lt;key-id&gt; \\\n  --key-spec AES_256 \\\n  --output text \\\n  --query CiphertextBlob &gt; data_key.txt\n</code></pre>"},{"location":"01_aws/06_Security/04_2_KMS_DVA-cli/#description_9","title":"Description:","text":"<ul> <li>Generates a data key that can be used for local encryption.</li> <li><code>--key-spec</code>: Specifies the key length (e.g., <code>AES_256</code> or <code>AES_128</code>).</li> </ul>"},{"location":"01_aws/06_Security/05_SSM-param-store/","title":"SSM (serverless)","text":""},{"location":"01_aws/06_Security/05_SSM-param-store/#1-intro","title":"1. Intro","text":"<ul> <li>serverless, fully managed</li> <li>parameter-store</li> <li>organize in structure/hierarchy pattern</li> <li> <p>versioning enabled. </p> </li> <li> <p>integration with:</p> </li> <li>CloudFormation : template can read configs.</li> <li>IAM : enforce restricted access.</li> <li>eventBidge : get events from store actions like : add,delete,update,access,etc</li> <li> <p>KMS : security, encrypt/decrypt configs</p> <ul> <li></li> </ul> </li> <li> <p><code>string</code>, <code>StringList</code>, <code>SecureString</code> (kms-key-1)</p> </li> </ul>"},{"location":"01_aws/06_Security/05_SSM-param-store/#2-type","title":"2. Type","text":""},{"location":"01_aws/06_Security/05_SSM-param-store/#21-standard-free","title":"2.1. Standard <code>free</code>","text":"<ul> <li><code>10k</code> params</li> <li>each, max size - <code>4 KB</code></li> </ul>"},{"location":"01_aws/06_Security/05_SSM-param-store/#22-advance-paid","title":"2.2 Advance <code>paid</code>","text":"<ul> <li>100K params</li> <li>each, max size - <code>8 KB</code> , </li> <li>additional feature</li> <li>attach iam-policies for secured access.</li> <li></li> <li>pricing</li> <li>5 cent/month</li> </ul>"},{"location":"01_aws/06_Security/05_SSM-param-store/#3-use-case","title":"3. use case","text":"<ul> <li>Store IAM policy</li> <li>Store config data for CloudFormation, Codebuild,etc</li> <li>Store secret</li> <li></li> </ul>"},{"location":"01_aws/06_Security/05_SSM-param-store/#4-cli","title":"4. CLI","text":"<pre><code>aws ssm put-parameter \\\n--name \"/my-app/config/db-password\" \\\n--value \"MySecurePassword123\" \\\n--type SecureString \\\n--key-id \"alias/my-kms-key\"\n\n\naws ssm get-parameter \\\n--name \"/my-app/config/db-password\" \\\n--with-decryption\n\naws ssm get-parameters \\\n--names \"/my-app/config/db-password\" \"/my-app/config/db-username\" \\\n--with-decryption\n\naws ssm delete-parameter \\\n--name \"/my-app/config/db-password\"\n</code></pre>"},{"location":"01_aws/06_Security/05_SSM-param-store/#99-hands-on","title":"99. hands on","text":"<pre><code>- create : /parent/child-1/param-1 - string\n- create : /parent/child-2/param-1 - SecuredString\n  - choose : kms-key-1\n-  standard 4096 chars max, 4kb max\n\n// ready\n\naws cli :\n  - get-parameter /parent/child-1/param-1\n\n  - get-parameter /parent/child-2/param-1\n  - get-parameter /parent/child-2/param-1 --with-cecryption\n\n  - get-parameter-by-path /parent\n  - get-parameter-by-path /parent/child-1\n\n  - access from lambda-1\n    - set env var: child='child-2'\n    - ssm=boto3.client('ssm', region1)\n    - ssm.get_parameters(names=['/parent/'+ child +'/param-1'], WithDecryption=true)\n    - failed:\n    - fix: update lambda iam role:\n      - allow read &gt; ssm:path-/parent\n      - allow kms : kms-key-1\n</code></pre>"},{"location":"01_aws/06_Security/06_secret_manager/","title":"Secret manager","text":""},{"location":"01_aws/06_Security/06_secret_manager/#intro","title":"Intro","text":"<ul> <li><code>Rotation</code></li> <li>enforce <code>rotation</code> of secrets every X days</li> <li> <p><code>Automate generation of secrets</code> on rotation (uses <code>Lambda</code>)</p> </li> <li> <p><code>replicate across region</code></p> </li> <li><code>primary</code></li> <li> <p><code>replica</code> in region</p> <ul> <li>while DR, can promote as primary</li> </ul> </li> <li> <p>Integration with:</p> <ul> <li>Amazon RDS (MySQL, PostgreSQL)</li> <li>Aurora</li> <li>KMS</li> <li>...</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/06_secret_manager/#exam-scenario","title":"Exam scenario","text":"<ul> <li>only database credential rotate automatically.</li> <li>for API key, use lambda which will request new key and update secret, programmatically.</li> </ul>"},{"location":"01_aws/06_Security/06_secret_manager/#1-api-gateway-api-key-stored-in-secret-manager-rotate-it","title":"1. API gateway API key stored in secret manager. rotate it.","text":""},{"location":"01_aws/06_Security/07_ACM/","title":"ACM (regional)","text":""},{"location":"01_aws/06_Security/07_ACM/#1-certificate","title":"1. certificate:","text":"<ul> <li>private</li> <li></li> <li>cert can be used inside org</li> <li>public </li> <li>cert for public internet</li> </ul>"},{"location":"01_aws/06_Security/07_ACM/#2-generate-certificate","title":"2. Generate certificate","text":""},{"location":"01_aws/06_Security/07_ACM/#by-internal-acm","title":"by internal / ACM","text":"<ul> <li>ACM generate cert</li> <li>import to ACM</li> <li>ACM automatically renews public certificates <code>60 days</code> before expiration</li> </ul>"},{"location":"01_aws/06_Security/07_ACM/#bt-external-provider","title":"bt External provider","text":"<ul> <li>eg: digicert</li> <li>generate cert for FQDN or with wildcard</li> <li>dev1.outbound.aws.org.com,  </li> <li>dev2.outbound.aws.org.com</li> <li>*.outbound.aws.org.com</li> <li>*.aws.org.com</li> <li>import to ACM</li> <li>no auto re-new</li> <li>AWS-Config <ul> <li>rule:acm-cert-expiracy-check to:</li> <li>sends eventBridge event to expiration, before <code>45 days</code> (default)</li> <li>can catch event --&gt; SNS alert, lambda,</li> <li>can change days from 45 to something else.</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/07_ACM/#3-certificate-validation-method","title":"3. certificate: Validation method","text":"<ul> <li>email </li> <li>receive validatin email, follow the link in email and validate it.</li> <li>will receive email expiry.</li> <li>dns : just, create <code>cname</code> entry in R53 with above dns</li> </ul>"},{"location":"01_aws/06_Security/07_ACM/#4-acm-integration-with-services","title":"4. ACM: integration with services","text":"<ul> <li>CloudFront </li> <li>can monitor days to expiry as a metric for ACM certificates </li> <li>can build alarms to monitor certificates based on days to expiry</li> <li>R-53</li> <li>ELB : ALB, NLB, ... </li> <li></li> <li>API gateway (3 types)</li> <li>edge-optimized : keep ACM cert in <code>us-east-1</code><ul> <li></li> </ul> </li> <li>regional +  private(with In vpc) <ul> <li>keep ACM cert in same region</li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/","title":"A. WAF (webapp FireWall)","text":""},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/#1-intro","title":"1. Intro","text":"<ul> <li>web-ACL</li> <li>work on layer:7, thus integrate with ALB </li> <li>not other ELB</li> <li>prevent SQL injection and Cross-Site Scripting (XSS)</li> <li><code>Web ACL rule</code> to allow/deny traffic on:</li> <li>protocol : http, udp, https</li> <li>source/target IP + port<ul> <li>up to <code>10,000 IPs</code> max in a set</li> <li>use multiple Rules for more IPs</li> </ul> </li> <li>body</li> <li>URI strings </li> <li>Size constraints</li> <li>geo-match <ul> <li>block countries (client IP)</li> </ul> </li> <li>Rate-based rules : <code>blanket</code>, <code>URI</code>, <code>IP-reputation</code><ul> <li>eg: 10 req/per</li> <li>this rule prevents DDoS protection</li> <li>https://aws.amazon.com/blogs/security/three-most-important-aws-waf-rate-based-rules/  </li> </ul> </li> <li>AWS managed rule (prebuilt rule; eg PHP rule, linus, windows, etc)</li> <li>create own rule - regular or rate-based</li> <li>rule-group - combine multiple rule into single logical unit. <pre><code>- keep IP `static/fixed`:\n    - use fixed for ALB\n    - use AWS global accelerator (has fixed any-cast IPs)\n</code></pre></li> </ul>"},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/#2-architecture-example","title":"2. Architecture example","text":"<ul> <li>App --&gt; ALB(layer:7) --&gt; WAF(layer:7):ACL --&gt; AWS global accelerator --&gt; web-client.</li> <li></li> </ul>"},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/#3-wafdeployment-option","title":"3. WAF::Deployment option","text":""},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/#regionally","title":"regionally","text":"<ul> <li>ALB </li> <li>API-gateway </li> <li>AppSync(GrapgQL-API)</li> </ul>"},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/#globally","title":"globally","text":"<ul> <li>CloudFront distribution</li> </ul>"},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/#4-exam-scenario","title":"4. exam scenario","text":"<ul> <li>block country and allow some IP from that country. use WAF  <pre><code>#1 \nAn online gaming company wants to block access to its application from specific countries. \nhowever, the company wants to allow its remote development team (from one of the blocked countries) to have access to the application.\nThe application is deployed on Amazon EC2, running under an ALB with WAF.\n\n- Use AWS \"WAF::geo-match-statement\" listing the countries that you want to block **\n- Use AWS \"WAF::IP-set-statement\"    that specifies the IP addresses that you want to allow through **\n\n  ALB,ACL does not have geo-retriction thing &lt;&lt;&lt;\n</code></pre></li> </ul>"},{"location":"01_aws/06_Security/08_WAF%2BFirewallManager/#b-firewall-manager-regional","title":"B. FireWall manager (regional)","text":"<ul> <li>All types of firewall, at common place.</li> <li>AWS org </li> <li> <p>management acct</p> <ul> <li>create security policy</li> <li>apply these policy on multiple member account in org</li> </ul> </li> <li> <p>Security policies :</p> </li> <li><code>WAF rules</code> (Application Load Balancer, API Gateways, CloudFront)</li> <li><code>AWS Shield Advanced</code> (ALB, CLB, NLB, Elastic IP, CloudFront)</li> <li><code>Security group</code> : EC2:ENI , ALB and ENI-resources in VPC</li> <li><code>R53 Resolver</code> ( DNS Firewall)</li> <li>AWS Network Firewall ?</li> </ul>"},{"location":"01_aws/06_Security/09_sheild/","title":"AWS Shield","text":"<ul> <li>Detection and mitigation against large and sophisticated <code>DDoS attack</code> (many requests at the same time)</li> <li>near real-time visibility into attacks</li> <li>integration with AWS WAF</li> </ul>"},{"location":"01_aws/06_Security/09_sheild/#aws-shield-standard","title":"AWS Shield : standard","text":"<ul> <li>free</li> <li>activated by-default.</li> <li><code>protects</code> from <code>layer3/layer4</code> attacks : SYN/UDP Floods? , Reflection attacks? </li> </ul>"},{"location":"01_aws/06_Security/09_sheild/#aws-shield-advance","title":"AWS Shield : Advance","text":"<ul> <li>for high-risk workloads.</li> <li>pricing : <code>$3000 / organization</code></li> <li>enabled consolidated billing for your aws org. </li> <li>24/7 access to DDoS response team (DRT)</li> <li>mitigate from layer7 attacks </li> <li>Automatically creates/deploys AWS WAF rules</li> <li>protects these services:</li> <li>ELB</li> <li>Amazon CloudFront distributions </li> <li>API gateway</li> <li>more:<ul> <li>AWS Global Accelerator</li> <li>Route 53</li> <li>EC2</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/09_sheild/#question","title":"Question:","text":"<pre><code>### 1 \n\nA financial services company recently launched an initiative to improve the security of its AWS resources.\nAnd it had enabled AWS Shield Advanced across multiple AWS accounts owned by the company.\nUpon analysis, the company has found that the costs incurred are much higher than expected.\n\nWhich of the following would you attribute as the underlying reason for the unexpectedly \nhigh costs for AWS Shield Advanced service?\n\nanswer:\nConsolidated billing has not been enabled. \nAll the AWS accounts should fall under a single consolidated billing for the monthly fee to be charged only once\n</code></pre>"},{"location":"01_aws/06_Security/10_HSM_DVA/","title":"CloudHSM","text":""},{"location":"01_aws/06_Security/10_HSM_DVA/#intro","title":"Intro","text":"<ul> <li> <p>HSM = <code>Hardware Security Module</code></p> </li> <li> <p>CloudHSM</p> </li> <li>service to provision HSM in high-availability  cluster</li> <li>tamper resistant, FIPS 140-2 Level 3 compliance</li> <li> <p>MFA support</p> </li> <li> <p>CloudHSM Client </p> </li> <li> <p>dedicated Software</p> </li> <li> <p>HSM cluster</p> </li> <li> <p></p> </li> <li> <p>integrated with KMS</p> </li> <li>supports SSE-C (symmetric + asymmetric keys)</li> <li></li> </ul>"},{"location":"01_aws/06_Security/99_more/","title":"introduction on:","text":""},{"location":"01_aws/06_Security/99_more/#a-gaurdduty","title":"A. GaurdDuty","text":"<ul> <li>fully managed</li> <li>enable it and try it, (30 days trail)</li> <li>collect from:</li> <li>dns logs</li> <li>vpc logs</li> <li>cloudTrail management event</li> <li>optionally enable these logs too<ul> <li>EKS,RDS,Aurora,EBS,Lambda,S3</li> <li>...</li> </ul> </li> <li>perform </li> <li>analyzes continuous streams of meta-data generated from your account and network activity using ML/AI</li> <li> <p>to detect any security threat and un-usual activity</p> <ul> <li>CryptoCurrency attack </li> <li>infrastructure deployments in a region that has never been used.</li> </ul> </li> <li> <p>fact </p> </li> <li>Disabling the service<ul> <li>will delete all remaining data, including your <code>findings and configurations</code></li> </ul> </li> <li>Suspending the service<ul> <li>stop the service from analyzing data </li> <li>but does not delete your existing <code>findings or configurations</code></li> </ul> </li> </ul> <p></p> <pre><code>#1\nDuring a review, a security team has flagged concerns over an Amazon EC2 instance querying IP addresses used for cryptocurrency mining.\nThe Amazon EC2 instance does not host any authorized application related to \"cryptocurrency mining\".\nWhich AWS service can be used to protect the Amazon EC2 instances from such unauthorized behavior in the future? \n- GaurdDuty**\n</code></pre>"},{"location":"01_aws/06_Security/99_more/#b-macie","title":"B. Macie","text":"<ul> <li>fully managed</li> <li>collect from:</li> <li>s3</li> <li>...</li> <li>perform:</li> <li>uses ML </li> <li>pattern match</li> <li>find sensitive data(PII) persnally identifiable information</li> <li>Send event-bridge notification</li> </ul>"},{"location":"01_aws/06_Security/99_more/#c-inspector","title":"C. Inspector","text":"<ul> <li>identify software vulnerability and network exposures (unintentional open ports)</li> <li>references:</li> <li>https://docs.aws.amazon.com/inspector/latest/user/what-is-inspector.html</li> <li>https://www.youtube.com/watch?v=SM_esXHbJ4M (check from 9:00)</li> <li>fully managed : create Assessment template</li> <li>select target</li> <li>select assessment package to run (need SSM agent to be installed)</li> <li>select duration.</li> <li>analyze and perform security assessment on assessment targets:</li> <li><code>container</code> (image scan)</li> <li><code>lambda</code> (code scan - CVE database)</li> <li> <p><code>ec2</code> (ssm agent)  (n/w, os, code/pkg scan)</p> </li> <li> <p>send finding to --&gt;  <code>event-bridge</code> + <code>AWS security Hub</code></p> </li> </ul> <p></p>"},{"location":"01_aws/06_Security/99_more/#d-nitro-enclave","title":"D. Nitro Enclave","text":"<ul> <li>isolated compute environment</li> <li>to process highly sensitive data<ul> <li>PII</li> <li>healthcare</li> <li>financial</li> <li>...</li> </ul> </li> </ul>"},{"location":"01_aws/06_Security/99_more/#e-more","title":"E. More","text":""},{"location":"01_aws/06_Security/99_more/#1-aws-security-hub","title":"1. AWS Security Hub","text":"<ul> <li>scenario : Audit performed on AWS account. have to fix complaince for future. which AWS service can use ?</li> <li>AWS Security Hub provides a comprehensive view of your security posture in AWS. </li> <li>It aggregates, organizes, and prioritizes security findings from multiple AWS services and third-party tools. </li> <li>It continuously monitors your environment for vulnerabilities and compliance violations by integrating with services:</li> <li>Amazon GuardDuty, </li> <li>AWS Config, </li> <li>Amazon Macie</li> <li>...</li> <li>AWS Lambda: automate response actions.</li> <li>It uses standards such as </li> <li>CIS AWS Foundations</li> <li>PCI DSS </li> <li>HIPAA</li> </ul>"},{"location":"01_aws/06_Security/99_more/#2-aws-systems-manager","title":"2. AWS Systems Manager","text":"<ul> <li>https://docs.aws.amazon.com/systems-manager/latest/userguide/what-is-systems-manager.html</li> <li>unified interface for managing your AWS resources. </li> <li>It provides operational insights and automation for tasks like</li> <li>patching </li> <li>configuration  management </li> <li>compliance </li> <li>Key features include:</li> <li>Automation: Automates common IT tasks like applying patches or updates across AWS resources.          </li> <li>Run Command:  <ul> <li>Allows remote execution of commands on EC2 instances without needing to log in. SSM agent must be installed </li> <li>no need to perform SSH</li> <li>can install packages</li> <li>create and assume role with IAM SSM permission.</li> </ul> </li> <li>Patch Manager: Automatically applies security patches to your systems.                                </li> <li>State Manager: Ensures that instances remain in the desired configuration state.                      </li> <li>Compliance: Tracks the compliance of your systems with internal policies and external regulations.    </li> </ul>"},{"location":"01_aws/07_monitoring/00_start/","title":"Monitoring in AWS","text":""},{"location":"01_aws/07_monitoring/00_start/#cloudwatch","title":"CloudWatch","text":"<ul> <li>Metrics: Collect and track key metrics</li> <li>Logs: Collect, monitor, analyze and store log files</li> <li>Events: Send notifications when certain events happen in your AWS</li> <li>Alarms: React in real-time to metrics / events</li> </ul>"},{"location":"01_aws/07_monitoring/00_start/#x-ray","title":"X-Ray","text":"<ul> <li>Troubleshooting application performance and errors</li> <li>Distributed tracing of microservices</li> </ul>"},{"location":"01_aws/07_monitoring/00_start/#cloudtrail","title":"CloudTrail","text":"<ul> <li>Internal monitoring of API calls being made</li> <li>Audit changes to AWS Resources by your users</li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/","title":"Cloudwatch","text":""},{"location":"01_aws/07_monitoring/01_CW-Metric/#a-cloudwatch-metric","title":"A. Cloudwatch : <code>Metric</code>","text":"<ul> <li><code>namespace-1</code> : </li> <li>metric-1 : attribute/dimension-1, ... upto attribute-30. eg; instanceId,EnvName,etc</li> <li>metric-2 : attribute/dimension-1, ...</li> <li>...</li> <li><code>metric</code> are variable for monitoring</li> <li>metric resolution : how offer metric get run/refresh</li> <li><code>default</code> : 5 min.</li> <li><code>standard</code> : 1 min</li> <li><code>high</code> : 1/5/10/30 sec<ul> <li>A CloudWatch Alarm set on a High-Resolution Custom Metric, can be triggered as often as every <code>10 seconds</code>. </li> <li>high-resolution <code>alarm</code> with a period of <code>10 seconds or 30 seconds</code> </li> <li>or you can set a regular alarm with a period of any multiple of <code>60 seconds</code></li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/#1-inbuilt-metric","title":"1. Inbuilt metric","text":"<ul> <li>metric enabled by default.</li> <li>can disable them.</li> <li>eg - for ec2:</li> <li><code>cpu utilization</code> </li> <li><code>network call</code></li> <li>...</li> <li>NOTE: ASG uses these metric for auto-scaling.<ul> <li>change metric resolution to standard/high for better response </li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/#2-custom-metric","title":"2. Custom metric","text":"<ul> <li>can Define and Send custom metric on EC2 or any other service (eg- cw:log-group,etc)</li> <li>eg:</li> <li><code>EC2::RAM/memory utilization</code></li> <li><code>EC2::disk utilization</code></li> <li><code>??::number of logged User</code></li> <li>...</li> <li>...</li> <li><code>CW-log::metric-filter-1</code><ul> <li>search pattern1 in log and create metric around it.</li> </ul> </li> <li> <p>Step-1 : Define/create  <pre><code># create log-metric-filter on log-group-1\n\nlog-group-1 &gt; metric-filter tab\n    - name: filter-1\n    - namespace: filter-namespace-1\n    - filter pattern : \"error\"\n    - metric value : 100\n    - so, when error found in metric will occur with value 100\n</code></pre></p> </li> <li> <p>Step-2 : send : PutMetricData API <pre><code>aws cloudwatch put-metric-data \\\n    --namespace &lt;namespace-1&gt; \\\n    --metric-name &lt;metric_name&gt; \\\n    --value &lt;value&gt; \\\n    [--dimensions &lt;name=value,...&gt;] \\\n    [--unit &lt;unit&gt;] \\\n    [--timestamp &lt;timestamp&gt;]\n</code></pre> <pre><code>aws cloudwatch put-metric-data \\\n    --namespace MyApp/Performance \\\n    --metric-data file://metrics.json\n\n# metrics.json    \n[\n  {\n    \"MetricName\": \"CPUUsage\",\n    \"Value\": 75.5,\n    \"Unit\": \"Percent\",\n    \"Dimensions\": [\n      { \"Name\": \"InstanceId\", \"Value\": \"i-12345678\" }\n    ]\n  },\n  {\n    \"MetricName\": \"DiskUsage\",\n    \"Value\": 60.0,\n    \"Unit\": \"Percent\"\n  }\n]\n</code></pre></p> </li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/#3-dashboard","title":"3 dashboard","text":""},{"location":"01_aws/07_monitoring/01_CW-Metric/#cwdashboard","title":"CW::dashboard","text":"<ul> <li>check on AWS console</li> <li>check by region for ec2 or other service</li> <li>check by namespace</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/#externaldashboard","title":"external::dashboard","text":"<ul> <li>create custom metric</li> <li>deliver the stream of metric data, using <code>KDF</code> to:</li> <li>3rd party : <code>datadog, splunk, dynatrace</code></li> <li>then use 3rd party dashboard</li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/#extra","title":"extra","text":""},{"location":"01_aws/07_monitoring/01_CW-Metric/#cli","title":"CLI","text":"<ul> <li>PutMetricData : push custom metric data, eg: RAM</li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/#metric-collected-by-cw-unified-agent","title":"metric collected by <code>CW unified agent</code>","text":"<ul> <li>installed on on-prem/Ec2.</li> <li>metric (just for idea, not for exam) </li> <li>CPU (active, guest, idle, system, user, steal)</li> <li>Disk metrics (free, used, total), Disk IO (writes, reads, bytes, iops)</li> <li>RAM (free, inactive, used, total, cached)</li> <li>Netstat (number of TCP and UDP connections, net packets, bytes)</li> <li>Processes (total, dead, bloqued, idle, running, sleep)</li> </ul>"},{"location":"01_aws/07_monitoring/01_CW-Metric/#aggregate-metric-from-asgs-ec2-instance","title":"Aggregate metric from ASG's ec2 instance.","text":"<ul> <li>install unified agen in all EC2 inatance in ASG</li> <li>agent config: use \"aggregation_dimension\" , to aggregate metric from all instance.</li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/","title":"CloudWatch Logs","text":"<ul> <li>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/29322962#overview</li> <li>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/37910042#overview</li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#cloudwatch-logs","title":"Cloudwatch : <code>logs</code>","text":"<ul> <li>expiration policies (defined at <code>log-group</code> level)</li> <li>never expire</li> <li>set 1 day to 10 years</li> <li>CloudWatch Logs do not expire unless a retention policy is set. </li> <li>logs are encrypted by KMS</li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#1-log-group","title":"1 <code>log group</code>","text":"<ul> <li>for each application create a log group</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#2-log-streams","title":"2 <code>Log streams</code>","text":"<ul> <li>instance within log group</li> <li>has log event</li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#3-log-insight","title":"3 <code>log insight</code>","text":"<ul> <li>query engine</li> <li>on historical logs-group on same/cross  aws account</li> <li><code>log query &gt;&gt;&gt; get result &gt;&gt;&gt; export / visualize on CW::dashboard</code></li> <li>purpose built query language</li> <li>find common query example on console itself.</li> <li>fetch event, sort event, filter event, save and add to CW::dashboard.</li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#4-log-source","title":"4 <code>log source</code>","text":"<ul> <li><code>SDK</code></li> <li>java/py app running on</li> <li>ECS/EKS</li> <li>container-agent : collect from containers</li> <li>AWS Lambda</li> <li>lambda-agent : collect from function logs </li> <li>VPC Flow Logs</li> <li>Route53 </li> <li>more:</li> <li>API Gateway</li> <li>Elastic Beanstalk : internal-app-agent</li> <li>CloudTrail </li> <li>EC2 / on-prem server</li> <li>but install <code>agent</code><ul> <li>CloudWatch Unified Agent : <code>new</code></li> <li>CloudWatch log Agent : <code>old</code></li> <li></li> <li></li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#5-export-logs","title":"5 <code>export logs</code>","text":""},{"location":"01_aws/07_monitoring/02_CW-Logs/#via-createexporttask","title":"via <code>CreateExportTask</code>","text":"<ul> <li>destination: Amazon S3</li> <li>not real time</li> <li>batch export</li> <li>takes up to <code>12 hrs</code></li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#via-log-group-subscription-filter","title":"via <code>log-group subscription-filter</code>","text":"<ul> <li>KDS Kinesis Data Streams</li> <li>KDF Kinesis Data Firehose</li> <li>Lambda</li> <li>OpenSearch</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#6-log-subscription-filter","title":"6 <code>log subscription-filter</code>","text":"<ul> <li>can create <code>max=2</code></li> <li>subscribe to log group</li> <li>also, can also to listen/subscribe to multiple same/cross account's log group </li> <li>and perform log aggregation:</li> <li></li> <li> <p>ignore above action, check below.</p> </li> <li> <p>listener action/s:</p> </li> <li>do some processing with Lambda</li> <li>deliver (KDF)</li> <li>stream (KFS)</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#7-live-trail","title":"7 <code>live trail</code>","text":"<ul> <li>for debugging</li> <li>select log-group &gt; log-instance (optional) &gt; start trail</li> <li>1 hr free every day</li> <li>close after done.</li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#8-metric-filter","title":"8 <code>metric filter</code>","text":"<ul> <li>log-group &gt; create metric on pattern-1</li> <li><code>max=3</code> dimension</li> <li>later on create alarm around this metric. 03_CW-Alarms.md</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#9-encrypt-log","title":"9 <code>encrypt log</code>","text":"<ul> <li>at log-group level</li> <li>can create loggroup with KMS encryption</li> <li>can also associate existing loggroup with kms key </li> <li>using CLI<ul> <li>aws logs associate-kms-keys --log-group-name --kms-key-id --region</li> </ul> </li> <li>not from console.</li> <li>Dont forgget to update key policy as well, to allow loggroup.</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#_1","title":"??","text":"<ul> <li>dashboard</li> <li>insight-rule-1 to ingest dashboard data</li> <li>insight-rule-2</li> <li>...</li> <li>powered by <code>sagemaker</code></li> <li>eg:</li> <li>lambda-insight,</li> <li>CW-container-insight</li> <li>app-insight</li> <li>cw-contributor-insight<ul> <li>build from <code>VPC logs</code>. etc</li> <li>find heaviest n/w user, urlWithMostError, IPs,</li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/02_CW-Logs/#99-hands-on","title":"99. hands on","text":"<pre><code>- create lambda \n- run multiple time\n- lambda \"log-group-1\" created :\n    - log instance-1\n    - log instance-2\n\n// actions on  log-group-1 :\n// 1. export to s3\n\n// 2. create subscription-filter (max=2)\naction: KDF &gt; S3\n\n// 4 . create log-stream-1 from log-group-1 &gt; start live tail\n...\n</code></pre>"},{"location":"01_aws/07_monitoring/03_CW-Alarms/","title":"Cloudwatch : <code>Alarm</code>","text":"<ul> <li>Trigger notifications for any metric value</li> <li>set condtion : %, min,max, etc</li> <li>set evaluation period.</li> <li>states</li> <li><code>ok</code> </li> <li><code>in-alarm</code></li> <li><code>insufficient-data</code></li> <li>action : </li> <li>ec2 : reboot,recover , stop</li> <li>ASG</li> <li>SNS alert : most common </li> <li>...</li> <li>composite alarm </li> <li><code>alarm1</code> AND/OR <code>alarm2</code></li> <li>help to reduce noise</li> <li> </li> <li> <p>alarm can be created on:</p> </li> <li>any metric<ul> <li>inbuild</li> <li>custom: eg log metric-filter</li> </ul> </li> <li>Ec2:status check<ul> <li>instance status</li> <li>attached EBS status</li> <li>...</li> </ul> </li> <li>... </li> </ul>"},{"location":"01_aws/07_monitoring/03_CW-Alarms/#d-demo","title":"D. demo","text":"<pre><code>// 5 . create alarm\n- launch ec2-i1 \n- CW &gt; create metric-1\n  - add ec2-i1\n  - type : cpu\n  - every 5 min, 3 of 3\n  - greater than 90%\n  - state action:\n    - ok &gt; action:\n    - in-alarrm &gt; action : terminate ec2-i1\n    - insufficient-data &gt; action :\n     &gt;&gt; manually update state from aws-cli\n\n...\n</code></pre>"},{"location":"01_aws/07_monitoring/03_CW-Alarms/#cli","title":"Cli","text":"<ul> <li>set-alarm-state <pre><code>This is particularly useful for testing purposes or manually managing alarm \n\naws cloudwatch set-alarm-state \\\n    --alarm-name &lt;alarm-name&gt; \\\n    --state-value &lt;state-value&gt; \\  # OK, ALARM, or INSUFFICIENT_DATA\n    --state-reason \"&lt;reason&gt;\"\n</code></pre></li> </ul>"},{"location":"01_aws/07_monitoring/04_AWS_Distro/","title":"A. OpenTelemetry","text":"<ul> <li>an open-source observability framework under <code>CNCF</code></li> <li>designed to capture and transmit telemetry data (traces, metrics, and logs) </li> <li>from your applications </li> <li>to monitoring and analytics platforms. </li> <li>aims </li> <li>to standardize how observability data is collected, processed, and exported.</li> </ul>"},{"location":"01_aws/07_monitoring/04_AWS_Distro/#component","title":"component","text":"<ul> <li><code>API</code> </li> <li>Provides a unified interface for generating telemetry data (traces, metrics, and logs)</li> <li><code>SDKs</code> </li> <li><code>OpenTelemetry Collector</code></li> <li>gateway to centralize telemetry data from multiple sources and route it to one or more backends</li> <li><code>Exporters</code> </li> <li>Transmit data to various observability platforms:<ul> <li>Datadog </li> <li>AWS X-Ray</li> <li>Prometheus </li> <li>Jaeger</li> <li>...</li> <li>mutliple destintion </li> <li>app --&gt; <code>aws x-ray sdk</code> --&gt;  sends data to x-ray (single destintion)</li> <li>app --&gt; <code>open telemetry lib</code> --&gt; multiple destintion/s</li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/04_AWS_Distro/#b-aws-distro","title":"B. AWS Distro","text":""},{"location":"01_aws/07_monitoring/04_AWS_Distro/#intro","title":"Intro","text":"<ul> <li>Secure, production-ready AWS-supported distribution of OpenTelemetry project</li> <li>Auto-instrumentation Agents to collect traces without changing your code</li> <li>Send traces and metrics to :</li> <li>multiple AWS services  : X-Ray, CloudWatch, ...</li> <li>partner solutions: Prometheus, ...</li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/","title":"X-Ray","text":""},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#-httpschatgptcomc677c6111-b1a8-800d-b8c6-462a6e11d1d6","title":"- https://chatgpt.com/c/677c6111-b1a8-800d-b8c6-462a6e11d1d6","text":""},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#aws-x-ray","title":"AWS X-ray","text":""},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#a-intro","title":"A. Intro","text":"<ul> <li>analyze traces <code>visually</code></li> <li></li> <li>Understand dependencies in a microservice architecture</li> <li>compatible services </li> <li>AWS Lambda, API Gateway</li> <li>Elastic Beanstalkok</li> <li></li> <li>ELB</li> <li>ECS, EC2</li> <li> <p>on-prem server with daemon installed</p> </li> <li> <p>concepts</p> </li> <li>request &gt; has component/s (each adds its <code>traces</code>) &gt; has segments and/or sub-segments<ul> <li><code>Segments</code>: each component (application / service) will send traces having segment/s</li> <li><code>Subsegments</code>: if need to more details in your segment</li> <li><code>Trace</code>: segments collected together to form an end-to-end trace</li> <li><code>Sampling</code>: decrease the amount of requests sent to X-Ray, reduce cost</li> <li><code>Annotations</code>: Key Value pairs used to index traces and use with filters</li> <li><code>Metadata</code>: Key Value pairs, not indexed, not used for searching</li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#b-sdk-and-daemon","title":"B. SDK and daemon","text":"<ul> <li>SDK</li> <li></li> <li>SDK will capture:<ul> <li>Calls to AWS services</li> <li>HTTP / HTTPS requests</li> <li>Database Calls (MySQL, PostgreSQL, DynamoDB)</li> <li>Queue calls (SQS)</li> </ul> </li> <li>X-Ray daemon</li> <li>low level UDP packet interceptor</li> <li>AWS Lambda / other AWS services already run the X-Ray daemon </li> <li>can send traces in cross account</li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#c-sampling-rule","title":"C. Sampling rule","text":"<ul> <li>control the amount of data that we record.</li> <li>no code changes, just configure it for deamon. </li> <li> <p>https://www.udemy.com/course/aws-certified-developer-associate-dva-c01/learn/lecture/19730096#overview</p> </li> <li> <p>Reservoir (Reservoir-based sampling)</p> </li> <li>Defines the number of requests to sample per second, before the fixed-rate sampling is applied.</li> <li>Rate (Fixed-rate sampling):</li> <li>Specifies the percentage of requests to sample.</li> <li>0.05 === 5 %</li> <li>1 == 100 %</li> <li>define matching criteria</li> <li> <p></p> </li> <li> <p>default : [ <code>Reservoir=1/sec, rate=5%</code>, criteria=* ]</p> </li> <li>sample-rule-1 (priority 1), sample-rule-2 (priority 9999), ...</li> <li>rule-2 will be applied</li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#b-x-ray-security","title":"B. X-Ray Security:","text":"<ul> <li>IAM for authorization</li> <li>KMS for encryption at rest</li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#c-x-ray-with","title":"C. X-Ray with:","text":""},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#c0-ec2on-prem-server","title":"C.0 Ec2/on-prem server","text":"<ul> <li>Ensure the EC2 IAM Role has the proper permissions</li> <li>Ensure the EC2 instance is running the X-Ray Daemon</li> <li>application code is instrumented with the X-Ray SDK</li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#c1-aws-lambda","title":"C.1 AWS lambda","text":"<ul> <li>Ensure IAM execution <code>AWSX-RayWriteOnlyAccess</code> role</li> <li>Enable  X-Ray Active Tracing</li> <li>application code is instrumented with the X-Ray SDK</li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#c2-beanstalk","title":"C.2 beanStalk","text":"<ul> <li>includes the x-ray deamon, just enable it.</li> <li>.ebextensions/xray.config</li> <li>Upload this file as part of your application source bundle <pre><code>option_settings:\n  aws:elasticbeanstalk:xray:\n    XRayEnabled: true\n</code></pre></li> <li>from console:</li> <li> <p>Enable X-Ray Daemon checkbox</p> </li> <li> <p>next, ec2 instance role:</p> </li> <li> <p>attach <code>AWSXRayDaemonWriteAccess</code> role</p> </li> <li> <p>application code is instrumented with the X-Ray SDK</p> </li> <li>attach permission/role</li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#c3-ecs","title":"C.3 ECS","text":"<ul> <li> <p>daemon </p> </li> <li> <p>task definition</p> </li> <li>container-1 : deamon (<code>2000:udp</code>)</li> <li>container-2 : app itself</li> <li>link both container from n/w standpoint using link </li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#d-x-ray-iam-permission","title":"D. X-Ray IAM <code>permission</code>","text":""},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#put","title":"Put","text":"<p><pre><code>- `PutTraceSegments`: Uploads segment documents to AWS X-Ray\n\n- `PutTelemetryRecords`: Used by the AWS X-Ray daemon to upload telemetry.\n  - SegmentsReceivedCount\n  - SegmentsRejectedCounts\n  - BackendConnectionErrors\u2026\n\n- `GetSamplingRules`: Retrieve all sampling rules (to know what/when to send)\n\n- `GetSamplingTargets &amp; GetSamplingStatisticSummaries`: advanced\n</code></pre> </p>"},{"location":"01_aws/07_monitoring/04_X-rays_DVA/#get","title":"Get","text":"<p><pre><code>- GetServiceGraph: main graph\n\n- BatchGetTraces: \n  Retrieves a list of  traces specified by ID. Each trace is a\n  collection of segment documents that  originates from a single request.\n\n- GetTraceSummaries: \n  Retrieves IDs  and annotations for traces available for\n  a specified time frame using an  optional filter. To get the full traces,\n  pass the trace IDs to BatchGetTraces.\n\n- GetTraceGraph: \n  Retrieves a service  graph for one or more specific trace  IDs.\n</code></pre> </p>"},{"location":"01_aws/07_monitoring/05_cloudTrail/","title":"Cloudtrail","text":""},{"location":"01_aws/07_monitoring/05_cloudTrail/#1-intro","title":"1. Intro","text":"<ul> <li>enabled by default</li> <li>history of events / API calls made within your AWS Account</li> <li>Provides governance, compliance and audit for your AWS Account.</li> <li>captures all Account <code>logs</code> and <code>Cloudtrail:events</code> <ul> <li><code>90 days</code> default retention</li> <li>for further analysis/investigation,</li> <li>log/event &gt;&gt;  s3 &gt;&gt; athena</li> <li></li> </ul> </li> <li>eg: </li> <li>DynamoDB table create API called --&gt; logged in CT + event sent to <code>eventBridge</code>,</li> <li> <p>similar endless API calls. </p> </li> <li> <p></p> </li> </ul>"},{"location":"01_aws/07_monitoring/05_cloudTrail/#2-cloudtrail-events","title":"2. Cloudtrail : events","text":""},{"location":"01_aws/07_monitoring/05_cloudTrail/#data-events","title":"<code>Data Events</code>","text":"<ul> <li>(on/off)</li> <li>Operations on resources data</li> <li>eg: </li> <li>Amazon <code>S3 object-level activity</code> (GetObject, DeleteObject, PutObject,etc)</li> <li>lambda invoke</li> </ul>"},{"location":"01_aws/07_monitoring/05_cloudTrail/#management-events","title":"<code>Management Events</code>","text":"<ul> <li>(on) : cannot disable </li> <li>Operations on resources</li> <li>eg:</li> <li>Configuring security (IAM AttachRolePolicy)</li> <li>Configuring rules for routing data (Amazon EC2 CreateSubnet)</li> <li>Setting up logging (AWS CloudTrail CreateTrail)</li> <li>Management <code>Read</code> Events </li> <li>Management <code>Write</code> Events</li> </ul>"},{"location":"01_aws/07_monitoring/05_cloudTrail/#insight-events","title":"<code>insight Events</code>","text":"<ul> <li>(on/off)</li> <li>Management-Events --&gt;  <code>CT:Insight &gt; (analyze write event, find anamolies and generate)</code> --&gt; insight-Events</li> <li>event for unusual activity</li> <li>eg: </li> <li>inaccurate resource provisioning</li> <li>hitting service limits</li> <li>Bursts of AWS IAM actions</li> <li>Gaps in periodic maintenance activity</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/05_cloudTrail/#3-cloudtrail-lake-service","title":"3. CloudTrail Lake service","text":"<ul> <li>fully managed, quick option.</li> <li>CloudTrail Lake is a managed data lake solution specifically designed for capturing, storing, and analyzing CloudTrail events.</li> <li>can store event/s for many years. set retention-period like 2years</li> <li>built-in query functionality (via SQL) to perform audits and analysis.</li> <li>Alternatively, integrate with <ul> <li>Amazon Athena or other analytics tools for more advanced queries.</li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/05_cloudTrail/#scenario-whizlab-237-capture-api-call-for-resource-access-and-changes-in-an-aws-acocunt-store-then-2-years-perform-audit-and-analysis-need-quick-solution-option-1-cloudtrail-lake-option-2-cloudtrailevent-s3-athena","title":"<pre><code>Scenario: whizlab #2.37\n- capture api call for resource access and changes in an aws acocunt\n- store then 2 years\n- perform audit and analysis\nneed quick solution\n\noption-1 : cloudtrail lake ***\noption-2 : cloudtrail:event --&gt; S3 --&gt; athena\n</code></pre>","text":""},{"location":"01_aws/07_monitoring/05_cloudTrail/#4-architecture-example","title":"4. Architecture Example","text":""},{"location":"01_aws/07_monitoring/05_cloudTrail/#integration-with-eventbridge","title":"integration with <code>EventBridge</code>","text":"<ul> <li>already integrated</li> <li> <p>all events end up going to default bus</p> </li> <li> <p>eg: get notified when user assuming role</p> </li> <li></li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/","title":"AWS config (regional)","text":""},{"location":"01_aws/07_monitoring/06_AWS_config/#1-intro","title":"1. Intro","text":"<ul> <li> <p>Records: aws-resource auditing and Compliance using config-rules.</p> </li> <li> <p>On event of changes/modification on AWS resources =&gt;  evaluate these rule, then:</p> </li> <li>take remediation action</li> <li> <p>and/or, send notification</p> </li> <li> <p>cannot not deny from evaluating. </p> </li> <li>for each aws-resource, on console can view :</li> <li>configured rules </li> <li>compliance status</li> <li>CloudTrail api call</li> <li>event table : <ul> <li>timeline of changes and other event.</li> </ul> </li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/#2-config-rule","title":"2. Config Rule","text":"<ul> <li><code>Json</code> configuration</li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/#21-aws-managed","title":"2.1 AWS managed","text":"<ul> <li>already defined, 75+</li> <li>eg:</li> <li>Check unrestricted SSH access to sg</li> <li>Do we have publicly accessed s3 buckets </li> <li>Any changes made on ALB </li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/#22-custom-rules","title":"2.2 Custom rules","text":"<ul> <li>define using Lambda function</li> <li>eg:</li> <li>evaluate :: EBS disk == type gp2</li> <li>evaluate :: EC2 instance == t2.micro<ul> <li>all instance</li> <li>by instance.id</li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/#3-action-on-compliance-failure","title":"3 Action on compliance failure","text":""},{"location":"01_aws/07_monitoring/06_AWS_config/#31-remediation-action","title":"3.1. remediation action","text":"<ul> <li><code>SSM</code> Automation Document</li> <li><code>custom</code> Automation Document, eg:</li> <li></li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/#32-notification","title":"3.2 notification","text":"<ul> <li>use Event-Bridge Event</li> <li>use SNS -&gt; filter -&gt; subscriber</li> <li> </li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/#4-pricing","title":"4. Pricing:","text":"<ul> <li>not free tier.</li> <li><code>$0.003</code>per configuration item/rule recorded per region,</li> <li><code>$0.001</code> per config rule evaluation per region</li> </ul>"},{"location":"01_aws/07_monitoring/06_AWS_config/#5-hands-on","title":"5. hands on","text":"<pre><code>- AWS config, option:\n    - Record for all resource **\n    - Record for specfic resource\n- create role-1\n- choose delivery method: S3 bucket ** / cross acct bucket\n- stream config change to SNS : T/F\n- Rules (75 + ) : checkbox\n    - approved amis by Id &gt; enter parameter/s : ami id \n    - approved amis by tag\n    - restricted-ssh &gt; no parameter\n        - play around &gt; add/remove inbound rule for port 22/ssh\n        - and check compliance status\n</code></pre>"},{"location":"01_aws/07_monitoring/99_quiz/","title":"DVA","text":""},{"location":"01_aws/07_monitoring/99_quiz/#1","title":"1","text":"<ul> <li>You have a couple of EC2 instances in which you would like </li> <li>their Standard CloudWatch Metrics to be collected every 1 minute. What should you do</li> <li> </li> <li><code>enable Detailed monitoring</code> paid</li> <li><code>enable basic monitoring</code> free, enabled by default<ul> <li>every 5 min</li> </ul> </li> </ul>"},{"location":"01_aws/07_monitoring/99_quiz/#4","title":"4","text":"<p><pre><code>You have an application hosted on a fleet of EC2 instances managed by an Auto Scaling Group that you configured its minimum capacity to 2. \nAlso, you have created a CloudWatch Alarm that is configured to scale in your ASG when CPU Utilization is below 60%. Currently, \nyour application runs on 2 EC2 instances and has low traffic and the CloudWatch Alarm is in the ALARM state. What will happen\n</code></pre> - The number of EC2 instances in an ASG can not go below the minimum capacity - remain in ALARM state  </p>"},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/","title":"Athena (serverless)","text":""},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#1-intro","title":"1. Intro","text":"<ul> <li>run adhoc SQL query serverless, at scale</li> <li>Most results are delivered within seconds.</li> <li>has integration with AWS glue bts.</li> <li>athena call <code>glue data crawler</code></li> <li>crawler, crawls over above source/s and prepare <ul> <li>metadata</li> <li>Glue Data Catalog</li> </ul> </li> <li>Athena uses these while performing query.</li> <li>query result will go to:</li> <li>S3 </li> <li>Amazon QuickSight (dashboard)  </li> <li> </li> </ul>"},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#2-pricing","title":"2. pricing","text":"<ul> <li>pay for data Scan : <code>$5 / TB</code></li> <li>save cost</li> <li>compressed  data</li> <li>columnar data</li> <li>S3:object.csv --&gt; aws-glue --&gt; parquet(columnar)</li> <li>organize data in S3 like <code>/year/month/day/hr/...</code> then scan by date.</li> </ul>"},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#3-data-source","title":"3. Data Source","text":"<ul> <li>can load data from below source into athena</li> <li>Athena will scan,query, analyze data using SQL</li> </ul>"},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#31-s3","title":"3.1 <code>S3</code>","text":"<ul> <li>S3 object:csv,json,avro,parquet(columnar format), </li> <li>vpc-logs</li> <li>elb-logs</li> <li>cloudtrail</li> <li>...</li> </ul>"},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#32-database","title":"3.2 <code>database</code>","text":"<ul> <li>on-prem/aws (relational/NoSQL) --&gt; aws-glue --&gt; parquet</li> </ul>"},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#33-kds-kineses-data-steam","title":"3.3 <code>KDS</code> - kineses data steam","text":""},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#34-datasource-connector","title":"3.4 <code>DataSource Connector</code>","text":"<ul> <li>backed by <code>AWS Lambda</code></li> <li>to run Federated Queries on RDS,CW,DynamoDB,etc to load data into athena.</li> <li></li> </ul>"},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#99-hands-on","title":"99. hands on","text":""},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#-bucket-1-enable-s3-access-log-copy-location-1-athena-create-data_source-1-query-editor-run-create-database-db1-get-query-from-internet-to-ddldml-to-get-se-access-log-into-tables-edit-query-with-location-1-run-query-to-perform-ddl-and-dml-table-created-bucket-1_logs-check-l-select-from-database-1bucket-1_logs-limit-10-query-more-standard-sql-and-see-report-more-recent-queries-saved-queries-also-encrypted-result","title":"<pre><code>- bucket-1 &gt;  enable s3-access log.\n- copy location-1\n\nathena:\n    - create data_source-1\n    - Query editor\n        - run : create DataBase db1;\n        - get query from internet, to DDL/DML to get se-access-log into tables.\n        - edit query with location-1.\n        - run query to perform ddl and dml, table created : bucket-1_logs\n        - check L select * from database-1.bucket-1_logs limit 10.\n        - query more standard sql and see report.\n\n more:\n - recent queries\n - saved queries - also encrypted result.   \n</code></pre>","text":""},{"location":"01_aws/08_Analytics/01_athena_adhocSQL_serverless/#99-exam","title":"99. exam","text":"<ol> <li>athena read dataset from encrypted s3 (kms-sse). options:</li> <li>share private key with athena</li> <li>kms-sse --&gt; change to sse-s3</li> <li>disable encyption</li> <li> <p>athena automatically decrypts, no need to provide key info  </p> </li> <li></li> </ol>"},{"location":"01_aws/08_Analytics/02_Redshift_OLAP/","title":"Redshift (Not serverless)","text":""},{"location":"01_aws/08_Analytics/02_Redshift_OLAP/#1-intro","title":"1. Intro","text":"<ul> <li>OLAP (online analytic processing) database</li> <li>data warehousing </li> <li>Redshift's internal storage </li> <li>does NOT have \"tiers\" of storage classes like Amazon S3</li> <li>load PB of data and perform query/analysis</li> <li>like athena, Integrated with aws:glue (crawler &gt; catalog)</li> <li>analytic query result goes to:</li> <li>S3 </li> <li>Amazon QuickSight (dashboard) </li> <li><code>Tableau</code></li> <li>...</li> </ul>"},{"location":"01_aws/08_Analytics/02_Redshift_OLAP/#2-data-source","title":"2. Data Source","text":"<ul> <li>load data from below  sources</li> <li>KDF</li> <li>s3</li> <li>program(Java:SDK): in-batches </li> <li>AWS glue/ETL</li> <li>...</li> </ul>"},{"location":"01_aws/08_Analytics/02_Redshift_OLAP/#3-cluster-architecture","title":"3. Cluster architecture","text":"<ul> <li>Cluster =&gt; leader Node =&gt; compute Node =&gt; 1000s of spectrum</li> <li>performance <code>(10x)</code>, than other data warehouses and athena</li> <li>leader node receives queries from client applications, parses the queries, and develops query execution plans</li> <li>coordinates the parallel execution of these plans with the compute nodes</li> <li>Aggregates the intermediate results</li> <li>parallel query engine </li> <li>run complex SQL</li> <li>faster-joins</li> <li>faster-aggregation</li> <li>uses indexes + Columnar storage</li> </ul>"},{"location":"01_aws/08_Analytics/02_Redshift_OLAP/#4-cross-referencing","title":"4. cross-referencing","text":"<ul> <li>Analysts can use Redshift SQL queries to access both :</li> <li>Redshift tables (<code>recent</code> data)  / hot data</li> <li>data in S3 (<code>historical</code> data) without moving data into redshift <ul> <li>Spectrum, allows you to run queries on data stored in Amazon S3,</li> <li>without having to move that data into your Redshift cluster.</li> </ul> </li> </ul>"},{"location":"01_aws/08_Analytics/02_Redshift_OLAP/#5-dr","title":"5. DR","text":"<ul> <li>single-AZ (by default)</li> <li>Multi-AZ  replication </li> <li>cross region-replication - explicitly enable</li> <li>incremental-snapshot(only new change), in every 8 hr. <ul> <li>retention: 35 days.</li> <li>stored in s3.</li> </ul> </li> <li>restore snapshot/s into new region : manually/automate.</li> <li></li> </ul>"},{"location":"01_aws/08_Analytics/02_Redshift_OLAP/#exam","title":"Exam","text":"<ul> <li>App </li> <li>less than year older data --&gt; redshift --&gt; <code>analytic-report-1</code></li> <li>older than year --&gt; s3</li> <li><code>analytic-report-2</code>,  reference from --&gt; s3 + redshift</li> <li>how to cross-reference s3 </li> <li></li> <li>Amazon Redshift AQUA (Advanced Query Accelerator) </li> <li>distributed query acceleration layer designed to speed up certain types of queries in Amazon Redshift, particularly complex analytical queries.</li> <li>boost bt 10x</li> <li>resolves network bandwidth + cpu processing bottleneck</li> <li>Datashare feature</li> <li>Cross-Account Data Sharing for Amazon Redshift</li> <li>https://aws.amazon.com/blogs/aws/cross-account-data-sharing-for-amazon-redshift/</li> </ul>"},{"location":"01_aws/08_Analytics/03_openSearch/","title":"OpenSearch","text":""},{"location":"01_aws/08_Analytics/03_openSearch/#1-intro","title":"1. Intro","text":"<ul> <li>old name - ElasticSearch</li> <li>load data from source and perform search and analysis</li> <li>open source, distributed search and analytics suite.</li> </ul>"},{"location":"01_aws/08_Analytics/03_openSearch/#2-sources","title":"2. Sources","text":""},{"location":"01_aws/08_Analytics/03_openSearch/#21-dynamodb-data-stream","title":"2.1 DynamoDB Data stream","text":"<ul> <li>search by primary key (partition + sort)</li> <li>perfotm search by any attribute then use OpenSearch</li> </ul>"},{"location":"01_aws/08_Analytics/03_openSearch/#22-cloudwatch","title":"2.2 CloudWatch","text":""},{"location":"01_aws/08_Analytics/03_openSearch/#23-kinesis-data-stream","title":"2.3 kinesis Data stream","text":""},{"location":"01_aws/08_Analytics/04_EMR_elasticMapReduce_hadoop/","title":"EMR ( Elastic Map Reduce)","text":"<ul> <li>cloud big data platform for processing vast amounts of data using open source tools such as : <pre><code>  - Apache Spark, \n  - Apache Hive, \n  - Apache HBase, \n  - Apache Flink, \n  - Apache Hudi\n  - Presto\n</code></pre></li> <li>3x faster</li> <li>Petabyte-scale analysis at less than half of the cost of traditional on-premises solutions</li> </ul>"},{"location":"01_aws/08_Analytics/04_EMR_elasticMapReduce_hadoop/#1-intro","title":"1. Intro","text":"<ul> <li>creates Hadoop/spark clusters</li> <li>Master Node: <ul> <li>Manage the cluster</li> <li>coordinate</li> <li>manage health</li> </ul> </li> <li>Core Node: <ul> <li>long running tasks </li> <li>store data</li> </ul> </li> <li> <p>Task Node (optional, for compute): </p> <ul> <li>Just to run tasks </li> <li>usually Spot instance</li> </ul> </li> <li> <p>For short-running jobs </p> </li> <li>you can spin up and spin down clusters and pay per second for the instances used.</li> <li>For long-running workloads, </li> <li>you can create highly available clusters that automatically scale to meet demand.</li> </ul>"},{"location":"01_aws/08_Analytics/04_EMR_elasticMapReduce_hadoop/#2-use-cases","title":"2. Use cases","text":"<ul> <li>data processing </li> <li>ML</li> <li>web-indexing`</li> <li>big-data/hadoop</li> </ul>"},{"location":"01_aws/08_Analytics/05_QuickSight_dashboard/","title":"QuickSight (Serverless)","text":""},{"location":"01_aws/08_Analytics/05_QuickSight_dashboard/#intro","title":"Intro","text":"<ul> <li>create interactive dashboards (used for analysis)</li> <li>ML-powered </li> <li>BI (business intelligence) service</li> <li>in-memory computation (AI/BI logic) - faster</li> <li>to access DashBoard, create quickSight user (diff from IAM-user)</li> <li>can publish/share dashboard.</li> <li>it is NOT an SQL query based analysis tool like Amazon Athena </li> </ul>"},{"location":"01_aws/08_Analytics/05_QuickSight_dashboard/#source","title":"Source","text":""},{"location":"01_aws/08_Analytics/06_glue_ETL/","title":"Glue (Serverless , ETL)","text":""},{"location":"01_aws/08_Analytics/06_glue_ETL/#intro","title":"Intro","text":"<ul> <li>AWS Glue is a fully managed extract, transform, and load (ETL) service </li> <li>makes easy for customers, to prepare and load their data for analytics.</li> <li>AWS Glue job is meant to be used for batch ETL data processing.</li> </ul>"},{"location":"01_aws/08_Analytics/06_glue_ETL/#glue-components","title":"Glue Components","text":"<ul> <li>Glue Data catalog : metadata</li> <li>Glue Data Crawler : scan source and create help to create metadata.</li> <li>Glue Elastic Views: virtual table.</li> <li>Glue DataBrew: clean and normalize data, using pre-built transformation</li> <li>Glue Job Bookmarks : prevent re-processing old data</li> </ul>"},{"location":"01_aws/08_Analytics/06_glue_ETL/#use-case","title":"Use case","text":"<ul> <li>very common</li> <li> </li> <li> </li> </ul>"},{"location":"01_aws/08_Analytics/06_glue_ETL/#1-transform-data-before-loading-to-redshift-data-warehouse","title":"1. transform data before loading to redshift data warehouse","text":""},{"location":"01_aws/08_Analytics/06_glue_ETL/#2-transform-csv-to-parquet-columnar-formatfaster-for-analysis-for-athena","title":"2. transform csv to parquet (columnar format,faster for analysis) --&gt; for athena","text":""},{"location":"01_aws/08_Analytics/06_glue_ETL/#3-prepare-data-for-analysis-and-loadstore-into-s3-as-target","title":"3. prepare data for analysis and load/store into S3 as target.","text":""},{"location":"01_aws/08_Analytics/06_glue_ETL/#more","title":"more","text":"<ul> <li>Glue Studio: new GUI to create, run and monitor ETL jobs in Glue</li> <li>Glue <code>Streaming</code> ETL :</li> <li>built on Apache Spark Streaming</li> <li>compatible with <ul> <li>Kinesis Data Streaming </li> <li>Kafka</li> </ul> </li> </ul>"},{"location":"01_aws/08_Analytics/07_lakeFormation/","title":"Lake Formation (Fully managed)","text":""},{"location":"01_aws/08_Analytics/07_lakeFormation/#intro","title":"Intro","text":"<ul> <li>https://aws.amazon.com/lake-formation/</li> <li>build on top of AWS glue</li> <li>central place to have all your data for analytics purposes.</li> <li>security :</li> <li>Fine-grained Access (row-level, column-level) </li> <li>Also centralized access for all other analytics related services at single place.</li> <li>It automates many complex manual steps :</li> <li>collecting (backend: s3) <ul> <li>Combine structured (RDS,csv,etc) and unstructured data</li> </ul> </li> <li>cleansing</li> <li>moving </li> <li>cataloging data</li> <li>de-duplicate (using ML Transforms)`,</li> <li>source blueprints for S3, RDS, Relational &amp; NoSQL DB</li> <li>...</li> </ul>"},{"location":"01_aws/08_Analytics/07_lakeFormation/#more","title":"more","text":""},{"location":"01_aws/08_Analytics/07_lakeFormation/#question-1-on-s3-the-data-lake-has-a-staging-zone","title":"Question-1 (on s3): The data lake has a staging zone","text":"<ul> <li>where intermediary query results are kept only for 24 hours. </li> <li>These results are also heavily referenced by other parts of the analytics pipeline.</li> <li>MOST <code>cost-effective strategy</code> for storing this intermediary query data ?</li> <li>options:   <pre><code>Amazon S3 Glacier Instant Retrieval storage class\n- minimum storage duration charge is 90 days, so this option is NOT cost-effective \n\nAmazon S3 Standard-Infrequent Access storage class\n- minimum storage duration charge is 30 days\n\nAmazon S3 Standard storage class  **\n- no minimum storage duration charge \n- no retrieval fee\n\nAmazon S3 One Zone-Infrequent Access storage class\n</code></pre></li> </ul>"},{"location":"01_aws/08_Analytics/08_kinesis_data_analytics/","title":"KDA - Kinesis Data Analytics (serverless)","text":"<ul> <li>Fully managed</li> <li>Automatic scaling</li> </ul>"},{"location":"01_aws/08_Analytics/08_kinesis_data_analytics/#a-kinesis-data-analytics-sql-application-legacy","title":"A. Kinesis Data Analytics (SQL Application) / legacy","text":"<ul> <li>SQL application --&gt; run on KDA --&gt;  real time analysis/process --&gt; stream</li> <li>Source : <code>KDS/KDF</code> + also reference data from S3</li> <li></li> </ul>"},{"location":"01_aws/08_Analytics/08_kinesis_data_analytics/#b-kinesis-data-analytics-flink-application-preferred","title":"B. Kinesis Data Analytics (Flink Application) / preferred","text":""},{"location":"01_aws/08_Analytics/08_kinesis_data_analytics/#1-intro","title":"1. Intro","text":"<ul> <li>new name : Managed service for apache Flink</li> <li>flink application (more advance than SQL) --&gt; run on KDA --&gt;  analysis/process --&gt; Stream</li> <li>to transform and analyze streaming data in real-time </li> <li>provides :</li> <li>storage - 50 GB per Kinesis Processing Unit (<code>KPU</code>).<ul> <li></li> </ul> </li> </ul>"},{"location":"01_aws/08_Analytics/08_kinesis_data_analytics/#2-most-common-use-cases","title":"2. most common use cases","text":"<ul> <li>streaming ETL</li> <li>continuous metric generation</li> <li>interactive querying of data streams. </li> <li>responsive real-time analytics</li> <li>log analytics,</li> <li>click stream analytics</li> <li>Internet of Things (IoT)</li> <li>ad tech</li> <li>gaming</li> <li>...</li> </ul>"},{"location":"01_aws/08_Analytics/08_kinesis_data_analytics/#3-pricing","title":"3. Pricing","text":"<ul> <li>no minimum fee or setup cost, </li> <li>and you only pay for the resources your streaming applications consume</li> </ul>"},{"location":"01_aws/08_Analytics/10_AWS_batch/","title":"AWS Batch","text":"<ul> <li>fully managed service </li> <li>that efficiently runs batch computing workloads</li> </ul>"},{"location":"01_aws/08_Analytics/10_AWS_batch/#key-features","title":"Key Features:","text":"<ul> <li>Compute Environment Management: </li> <li>Automatically provisions </li> <li>and scales the optimal compute resources (e.g., EC2, Spot Instances).</li> <li><code>Job Queues</code> </li> <li>Submit jobs to queues, </li> <li>and AWS Batch schedules them based on resource availability and priorities.</li> <li><code>Job Definitions</code></li> <li>Define how to run a batch job, </li> <li>including the Docker container image, vCPUs, memory, and other parameters.</li> </ul>"},{"location":"01_aws/08_Analytics/10_AWS_batch/#use-cases","title":"Use Cases:","text":"<ul> <li>High-performance computing (HPC)</li> <li>Data processing</li> <li>Large-scale simulations</li> </ul>"},{"location":"01_aws/08_Analytics/10_AWS_batch/#cost-efficient","title":"Cost-Efficient:","text":"<ul> <li>Integrates with Spot Instances for lower-cost compute resources.</li> </ul>"},{"location":"01_aws/08_Analytics/98_ELK_stack/","title":"Components of ELK Stack:","text":""},{"location":"01_aws/08_Analytics/98_ELK_stack/#e-elasticsearch","title":"E Elasticsearch","text":"<ul> <li>Purpose: Search and analytics engine for storing and querying logs/data.</li> <li>AWS Service: <code>Amazon OpenSearch Service</code> (successor to Elasticsearch service).</li> </ul>"},{"location":"01_aws/08_Analytics/98_ELK_stack/#l-logstash","title":"L Logstash","text":"<ul> <li>Purpose: Data processing pipeline to collect, transform, and send logs to Elasticsearch.</li> <li>AWS Alternative: Use <code>AWS Lambda</code>, <code>Kinesis</code>, or <code>Amazon OpenSearch Data Prepper</code> for similar functionality.</li> </ul>"},{"location":"01_aws/08_Analytics/98_ELK_stack/#k-kibana","title":"K Kibana","text":"<ul> <li>Purpose: Visualization and dashboard tool for Elasticsearch data.</li> <li>AWS Service: <code>Amazon OpenSearch Dashboard</code> (integrated with OpenSearch).</li> </ul>"},{"location":"01_aws/08_Analytics/99_Summary/","title":"99 Summary","text":""},{"location":"01_aws/08_Analytics/99_Summary/#1-aws-glue-etl","title":"1. AWS glue (ETL)","text":"<ul> <li><code>Crawler</code> prepare Metadata and prepare <code>catalog</code> (help in data discovery)</li> </ul>"},{"location":"01_aws/08_Analytics/99_Summary/#2-quicksight","title":"2. QuickSight","text":"<ul> <li>create interactive, ML powered, AI/BI <code>dashboard</code> (create user), share</li> <li>source (saas app, S3:CSV,etc ,DB )</li> </ul>"},{"location":"01_aws/08_Analytics/99_Summary/#3-athena","title":"3. Athena","text":"<ul> <li>uses glue crawler</li> <li>source(s3,KDS, DS-connectors) --&gt; <code>serverless SQL run</code>,at scale --&gt; result s3/QuickSight </li> <li><code>5$/TB scan cost</code>, save :</li> <li>compress</li> <li>formatted data : CSV, avro, parquet(using Aws glue) </li> <li>organise data in dataTime fashion.</li> </ul>"},{"location":"01_aws/08_Analytics/99_Summary/#4-redshift-olapdata-warehouse","title":"4. RedShift (OLAP/data wareHouse )","text":"<ul> <li>uses glue crawler, 10X faster</li> <li>Load PB of data in Cluster (master,worker with <code>spectrum</code>) from source(s3,KDS, prg, glue)</li> <li><code>|| sqs Run</code></li> <li>complex join and aggregation</li> <li>result goes to s3/QuickSight</li> </ul>"},{"location":"01_aws/08_Analytics/99_Summary/#5-opensearch","title":"5. OpenSearch","text":"<ul> <li>search and Analysis for <code>Unstructured Data</code> from CW:log + stream(DynoDB,KDS).</li> <li>CW:Logs,KDF --&gt; OpenSearch</li> </ul>"},{"location":"01_aws/08_Analytics/99_Summary/#6-emr","title":"6. EMR","text":"<ul> <li>Run <code>Hadoop</code> Cluster (Master.Core.task Nodes)</li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/","title":"DR","text":""},{"location":"01_aws/09_DR/01_dr-strategies/#1-intro","title":"1. Intro","text":"<ul> <li>Disaster </li> <li>event that has a negative impact on a company\u2019s business continuity or finances</li> <li>Disaster Recovery </li> <li>preparing for and recovering from a disaster.</li> <li>type:<ul> <li>On-premise =&gt; On-premise</li> <li>On-premise =&gt; AWS Cloud: <code>hybrid recovery</code></li> <li>AWS Cloud Region ` =&gt; AWS Cloud Region B</li> </ul> </li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/#2-key-terms","title":"2. Key terms","text":""},{"location":"01_aws/09_DR/01_dr-strategies/#rpo-recovery-point-objective","title":"RPO: Recovery <code>Point</code> Objective","text":"<ul> <li>taking backup in one hr, so if D happens, then can take restore from backup/point taken an hr ago.</li> <li>so rpo is 1hr here.</li> <li>1 min is expensive than 1 hr</li> <li>low RPO === expensive</li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/#rto-recovery-time-objective","title":"RTO: Recovery <code>Time</code> Objective","text":"<ul> <li>D happened, it took 2 hour to recover.</li> <li>there was downtime of 2 hr</li> <li>15 min is expensive than 2 hr.</li> <li>low RTO === expensive</li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/#3-strategies-to-optimize-rporto","title":"3. Strategies to optimize RPO/RTO","text":""},{"location":"01_aws/09_DR/01_dr-strategies/#a-backup-restore","title":"a. backup / restore","text":"<ul> <li>DB:</li> <li>RDS (single-region) --&gt; 1hr --&gt; backup/snapshot --&gt; S3(not directly accessible) in  same region (az-1 and az-2)</li> <li>DR happens &gt; az-1 goes down.</li> <li>recreate infra using IAC + R53</li> <li>or recover db from s3 snapshot (az-2 must have it)</li> <li>if region has outage.<ul> <li>use cross region replication for rds</li> <li>or use Aurora --&gt; have read Replica/s in other region </li> <li>or use global aurora --&gt;  have read Replica/s in other region ( &lt; 1 sec)</li> <li>and promote aurora read replica as primary in DR.</li> </ul> </li> <li>have your IAC ready, run it on DR</li> <li>code/app deploy : take AMI + docker images</li> <li>RTO is high, since getting up whole thing from scratch.</li> <li>RPO is 1hr here.</li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/#b-pilot-light","title":"b. Pilot light","text":"<ul> <li>A <code>small version of the app</code> (critical business workload) is always running in different region.</li> <li>update r53 to switch, on DR.</li> <li>continuously replicate critical db to this region.</li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/#c-warm-light","title":"c.  warm light","text":"<ul> <li>Full but <code>scaled-down version</code> of your system, up and running in different region</li> <li>Upon disaster, just <code>scale up</code> to <code>production load</code></li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/#d-multi-site","title":"d. multi site","text":"<ul> <li><code>active - active</code></li> <li>Full Production Scale is running AWS and On Premise</li> <li>on D, it will inactive - active.</li> <li>no recovery need to do.</li> <li>RTO is in second/min</li> <li>expensive</li> </ul>"},{"location":"01_aws/09_DR/01_dr-strategies/#4-dr-tips","title":"4. DR tips","text":"<ul> <li>Backup</li> <li>EBS Snapshots, RDS automated <code>backups</code> / Snapshots, etc\u2026</li> <li>Regular pushes to S3 / S3 IA / <code>Glacier</code>, Lifecycle Policy, <code>Cross Region Replication</code></li> <li> <p>From On-Premise: <code>Snowball</code> or <code>Storage Gateway</code></p> </li> <li> <p>High Availability</p> </li> <li>Use <code>Route53</code> to migrate DNS over from Region to Region</li> <li>RDS <code>Multi-AZ</code>, ElastiCache Multi-AZ, EFS, S3</li> <li><code>Site to Site VPN</code> as a recovery from <code>Direct Connect</code></li> <li> <p>Use <code>ASG</code>, ALB</p> </li> <li> <p>Automation</p> </li> <li><code>CloudFormation</code> / Elastic Beanstalk to re-create a whole new environment</li> <li><code>Reboot EC2 instances</code> with CloudWatch if alarms fail</li> <li>AWS <code>Lambda</code>  to automation to build infra, etc</li> <li> <p><code>IAC</code> / terraform</p> </li> <li> <p>on-prem tips</p> </li> <li><code>aws</code>:ec2-i1 &lt;&gt; import/export &lt;&gt; <code>on-pre</code>m:vm-1    <pre><code>- aws Amazon AMI \n  - download .iso file\n  - then run AMI on on-prem, \n    - with hyper-v, virtual-box, etc.\n</code></pre></li> </ul>"},{"location":"01_aws/09_DR/02_migration-1/","title":"More AWS service (overview) - DR related","text":""},{"location":"01_aws/09_DR/02_migration-1/#1-application-discovery","title":"1. Application discovery","text":"<ul> <li>scan server and gather info from on-prem VM/server. gather data can be track : <code>Migration Hub</code></li> <li>and then create <code>migration plan</code> out of it.</li> <li>Type of discovery(scan)</li> <li><code>agent-less</code> : gathers,<ul> <li>configuration</li> <li>memory</li> <li>disk usage</li> <li>network</li> </ul> </li> <li><code>agent-based</code> : gathers addintional info like:<ul> <li>live network details, connections between systems</li> <li>live system performance</li> <li>live running processes</li> <li>...</li> </ul> </li> </ul>"},{"location":"01_aws/09_DR/02_migration-1/#2-mgn-application-migration-service","title":"2. MGN : Application migration service","text":"<ul> <li>perform migration : </li> <li><code>Lift and shift</code>.</li> <li>convert <code>physical</code> server to <code>virtual</code> cloud server.</li> <li>supports wide range platform,os,db,volumes, etc</li> <li>hire dedicated engines to do this. <code>complex process</code>.</li> <li>minimal downtime.</li> <li></li> </ul>"},{"location":"01_aws/09_DR/02_migration-1/#3-sms-server-migration-service","title":"3. SMS : server migration service","text":"<ul> <li><code>incremental migration of live server data</code></li> </ul>"},{"location":"01_aws/09_DR/02_migration-1/#4-migration-hub","title":"4. Migration Hub","text":"<ul> <li>this help to <code>track</code> migration execution</li> </ul>"},{"location":"01_aws/09_DR/02_migration-1/#5-dms-and-sct","title":"5. DMS and SCT","text":"<ul> <li>DMS and SCT</li> </ul> <ul> <li>fact/s</li> <li>can also run <code>VMware software</code> on AWS</li> </ul>"},{"location":"01_aws/09_DR/02_migration-2/","title":"A. SCT","text":"<ul> <li>schema conversion tool, can install on op-prem devices.</li> <li>for heterogeneous migration, only</li> <li>eg: fssrr : oracle --&gt; SCT --&gt; Postgres/aurora</li> <li></li> </ul>"},{"location":"01_aws/09_DR/02_migration-2/#b-dms","title":"B. DMS","text":"<ul> <li>supports : <code>homo</code> + <code>hetero(with SCT)</code></li> <li>concept</li> <li>on prem db (large) --&gt; offline : snowball --&gt; aws cloud</li> <li>on-prem-db --&gt; <code>online : run DMS on EC2</code> --&gt; aws cloud<ul> <li><code>Serverless</code> option also there.</li> </ul> </li> </ul>"},{"location":"01_aws/09_DR/02_migration-2/#dms-source","title":"DMS : source","text":"<ul> <li><code>on-prem</code> : db ( Oracle, MS SQL Server, MySQL, MariaDB, PostgreSQL, MongoDB, SAP, DB2)</li> <li><code>azure</code> : sql-db</li> <li><code>aws</code>:<ul> <li>ec2 : db  ( Oracle, MS SQL Server, MySQL, MariaDB, PostgreSQL, MongoDB, SAP, DB2)</li> <li>rds</li> <li>aurora</li> <li>s3</li> <li>DocumentDB</li> </ul> </li> </ul>"},{"location":"01_aws/09_DR/02_migration-2/#dms-targets","title":"DMS : targets","text":"<ul> <li><code>on-prem</code> : db ( Oracle, MS SQL Server, MySQL, MariaDB, PostgreSQL, SAP)</li> <li><code>aws</code>:<ul> <li>ec2 : db ( Oracle, MS SQL Server, MySQL, MariaDB, PostgreSQL, SAP)</li> <li>rds</li> <li>aurora</li> <li>s3</li> <li>DocumentDB</li> <li>neptune</li> <li>redis</li> <li>DynamoDB </li> <li><code>analytic and stream kind</code>:<ul> <li>Kineses Data stream</li> <li>Apache kafka</li> <li>OpenSearch Service ?</li> <li>Redshift ?</li> </ul> </li> </ul> </li> </ul>"},{"location":"01_aws/09_DR/02_migration-2/#network-perspective","title":"network perspective","text":"<ul> <li>Transferring large amount of data into AWS, from <code>network perspective</code></li> <li>Over the <code>internet</code> / Site-to-Site VPN:</li> <li>Over <code>direct connect</code>1Gbps</li> <li>Over Snowball <code>offline</code></li> </ul>"},{"location":"01_aws/09_DR/02_migration-2/#dms-continuous-replication","title":"DMS : Continuous replication","text":"<ul> <li>use SCT and DMS</li> <li>also <code>enable multi-zone</code> on target db</li> </ul>"},{"location":"01_aws/09_DR/02_migration-2/#demo","title":"demo","text":"<pre><code>// 1. DMS - `enpoints`\n- endpoint-1 to connecto source DB\n- endpoint-2 to connecto target DB\n\n// 2. DMS - `replication-instance`\n  - choose starting point:\n    - discover and access\n        - give roadmap, \n        - generate path in few hrs\n    - convert\n        - for hetero, use sct\n        - takes weeks\n    - migrate\n        - choose:\n            - instance-based (mamge/admins ec2) **\n                - provision ec2 intance\n                - DMS version\n                - single-az/multi-az : az replication\n                - storage for ec2\n                - network\n                - maintence window\n            - serverless (no admin, migrated + replicates)\n                - EASY\n\n// 3. DMS `replication-task`\n- create task-1\n    - choose source endpoint\n    - choose target endpoin\n    - choose replication instance \n        - task setting : { json } - update it\n</code></pre>"},{"location":"01_aws/09_DR/02_migration-2/#scenario","title":"scenario","text":"<ul> <li>option-1: RDS &gt; <code>rds::snapshot</code> &gt; s3 &gt; restore &gt; Aurora</li> <li> <p>option-2: aurora &gt; create <code>read-replica from RDS</code>  &gt; promote it.</p> </li> <li> </li> <li>option-1 : ext-mysql &gt; <code>percona-mysql-tool</code>:<code>backup</code> &gt; s3 &gt; restore &gt; Aurora</li> <li>option-2 : ext-mysql &gt; <code>dump-util</code>  &gt; restore dumps &gt; aurora : SLOW (no s3)</li> </ul> <p></p> <ul> <li> </li> <li>option-1: RDS &gt; <code>rds</code>         :<code>snapshot</code> &gt; s3 &gt; restore &gt; Aurora</li> <li> <p>option-2: aurora &gt; create <code>read-replica</code> from RDS  &gt; promote it</p> </li> <li> </li> <li>option-1 : RDS &gt; <code>backup-tool</code>:<code>backup</code> &gt; s3 &gt; import(<code>aws_se_aurora extension</code>) &gt; Aurora</li> </ul> <p></p>"},{"location":"01_aws/09_DR/02_migration-2/#1-rdsmysql-migrateno-dms-auroraenginemysql","title":"1 RDS(<code>mySQl</code>)  --&gt; migrate(no DMS) --&gt; Aurora(engine:<code>mySQL</code>)","text":""},{"location":"01_aws/09_DR/02_migration-2/#2-ext-mysql-migrateno-dms-auroraenginemysql","title":"2 ext-mysql --&gt; migrate(no DMS) --&gt; Aurora(engine:<code>mySQL</code>)","text":""},{"location":"01_aws/09_DR/02_migration-2/#3-rdspostgres-migrateno-dms-auroraenginepostgres","title":"3 RDS(<code>postgres</code>)  --&gt; migrate(no DMS) --&gt; Aurora(engine:<code>postgres</code>)","text":""},{"location":"01_aws/09_DR/02_migration-2/#4-ext-postgres-migrateno-dms-auroraenginepostgres","title":"4 ext-postgres --&gt; migrate(no DMS) --&gt; Aurora(engine:<code>postgres</code>)","text":""},{"location":"01_aws/09_DR/03_awsbackup/","title":"AWS backup","text":"<ul> <li>like <code>aws firewall</code> is provides centralized security <code>in one place</code>.</li> <li>Similarly, AWS backup provide <code>centralized</code>,  backup <code>plan</code> and <code>policies</code> for all the <code>supported services</code>.</li> </ul>"},{"location":"01_aws/09_DR/03_awsbackup/#supported-services","title":"supported services","text":"<ul> <li>Amazon EC2 / Amazon EBS</li> <li>Amazon S3</li> <li>Amazon RDS (all DBs engines) / Amazon Aurora / Amazon DynamoDB</li> <li>Amazon DocumentDB / Amazon Neptune</li> <li>Amazon EFS / Amazon FSx (Lustre &amp; Windows File Server)</li> <li>AWS Storage Gateway (Volume Gateway)</li> <li>...</li> <li>...</li> <li>target place : everything backed up to <code>S3</code></li> </ul>"},{"location":"01_aws/09_DR/03_awsbackup/#features","title":"features","text":"<ul> <li>cross region backup</li> <li><code>cross account backup</code></li> <li>PITR</li> <li>define backup window + retention period(cant be changed)</li> <li>Enforce WORM, <code>vault lock policy</code> : backup cannot be deleted</li> <li>policies:<ul> <li><code>tag based</code></li> <li><code>cron expression</code>: montly, weekly, etc</li> </ul> </li> <li>jobs<ul> <li>scheduled <code>backup</code></li> <li>scheduled <code>restore</code></li> </ul> </li> </ul>"},{"location":"01_aws/09_DR/03_awsbackup/#demo","title":"Demo","text":"<pre><code>// BACKUP PLAN\n- create backup plan-1\n    - start options : \n        - from pre-built template : choose one - \"daily-monthly-1yr-retention\"\n        - new plan from scratch\n        - existing plan &gt; modify &gt; create new one\n    - backup policy &gt; rules:\n        - rule-1\n            - backup vault / target - create vault-1 \n            - backup window\n            - frequency\n            - lifecycle : move to cold storage &gt; after xxxx days/month : set days/month \n            - DR : copy to another region : choose another region.\n\n// READY\n plan-1 &gt; edit &gt; assign resource\n    - choose assignmnet-1 (created below)\n\n// ASSIGNMNET - to assign resource to plan\n- create assignmnet-1\n    -  create assignmnet-1-iam-role-1  \n    -  assignByResourceId : resource arn\n    -  assignByTag : key:env , value=prod\n       - anything taged as prod, will be backuped then.\n</code></pre>"},{"location":"01_aws/10_AI_ML/01-specific-services/","title":"ML services 1","text":""},{"location":"01_aws/10_AI_ML/01-specific-services/#a-media-related","title":"A. Media related","text":""},{"location":"01_aws/10_AI_ML/01-specific-services/#a1-amazon-rekognition","title":"A.1 Amazon <code>Rekognition</code>","text":"<ul> <li>Find objects, people, text, scenes in <code>images and videos</code></li> <li>Face Detection and analysis</li> <li>Celebrity Recognition</li> <li>path analysis/ pathing : eg: soccer game (video), sports game analysis</li> <li><code>Content Moderation</code> </li> <li>safer user experience by remove racist, etc offensive content</li> <li>flag them manual review.</li> <li>set <code>Minimum Confidence Threshold</code> flagged item</li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#b-speechtext-related","title":"B. speech/text related","text":""},{"location":"01_aws/10_AI_ML/01-specific-services/#b1-amazon-transcribe","title":"B.1 Amazon <code>Transcribe</code>","text":"<ul> <li><code>speech</code> --&gt; text, uses <code>ASR</code>(automatic speech recognition/deep ML)</li> <li>Automatically remove Personally Identifiable Information <code>(PII)</code></li> <li>Automatic <code>Language Identification</code></li> <li>identify 2\u201310 speakers in the audio clip</li> <li>use case: </li> <li>transcribe customer service calls </li> <li>captioning and subtitling</li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#b2-amazon-polly","title":"B.2. Amazon <code>polly</code>","text":"<ul> <li>TTS : text --&gt; <code>speech</code></li> <li>using AI-driven neural voices</li> <li> <p>create new voice for brand </p> </li> <li> <p>upload <code>lexicon</code>=== pronunciation and synthesis speech operation. eg:</p> </li> <li>Stylized words: St3ph4ne =&gt; \u201cStephane\u201d</li> <li> <p>Acronyms: AWS =&gt; \u201cAmazon Web Services\u201d</p> </li> <li> <p>uses <code>SSML</code> for customization, usecase:</p> </li> <li>ssml : Speech Synthesis <code>Markup Language</code>. <ul> <li> hello  lekhraj.  <li><code>emphasizing</code> specific words or phrases</li> <li><code>phonetic pronunciation</code></li> <li>including <code>breathing sounds, whispering</code></li> <li>using the <code>Newscaster speaking style</code></li> <li>Use case: Improving audiobook and e-learning narration.</li> <pre><code>Neural &amp; Standard TTS \u2013 Converts text to lifelike speech using AI-driven neural voices.\nUse case: Enhancing virtual assistants and IVR systems.\n\nMultiple Languages &amp; Voices \u2013 Supports 30+ languages with various voice options.\nUse case: Creating multilingual customer support bots.\n\nSpeech Marks &amp; SSML Support \u2013 Customizes speech with pauses, emphasis, and phonetic pronunciation.\nUse case: Improving audiobook and e-learning narration.\n\nStreaming &amp; Batch Processing \u2013 Real-time or offline synthesis for scalability.\nUse case: Generating voiceovers for videos and podcasts.\n\nLexicon Support \u2013 Custom pronunciations using lexicons.\nUse case: Ensuring correct pronunciation of brand or technical terms.\n\nCost-Effective &amp; Scalable \u2013 Pay-per-use pricing with high availability.\nUse case: Automating content narration for news or blogs.\n</code></pre>"},{"location":"01_aws/10_AI_ML/01-specific-services/#b3-amazon-translate","title":"B.3. Amazon <code>Translate</code>","text":"<ul> <li>language translation.</li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#b4-amazon-textract","title":"B.4. Amazon <code>textract</code>","text":"<ul> <li>extracts text, handwriting, and data from any scanned documents, forms and tables</li> <li>Use cases:</li> <li>Financial Services (e.g., invoices, financial reports)</li> <li>Healthcare (e.g., medical records, insurance claims)</li> <li>Public Sector (e.g., tax forms, ID documents, passports)</li> <li></li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#c-lex-and-connect","title":"C. lex and connect","text":""},{"location":"01_aws/10_AI_ML/01-specific-services/#c1-amazon-lex","title":"C.1 Amazon <code>lex</code>","text":"<ul> <li>same, its <code>Alexa</code> using ASR bts </li> <li> <ul> <li>better natural language understand.</li> </ul> </li> <li>use case: built <code>chat-bots</code></li> <li>integrate with <code>CRM</code> (customer relation management system)</li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#c2-amazon-connect","title":"C.2 Amazon <code>Connect</code>","text":"<ul> <li>cloud-based <code>virtual contact center</code></li> <li>Receive calls, create contact flows</li> <li>80% cheaper</li> <li></li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#d-natural-language-processing","title":"D. Natural Language Processing","text":""},{"location":"01_aws/10_AI_ML/01-specific-services/#d1-amazon-comprehend-serverless","title":"D.1 Amazon <code>Comprehend</code> (serverless)","text":"<ul> <li><code>NLP</code>, Natural Language Processing ( with more detailed analysis )</li> <li>find <code>insights and relationships</code> in text</li> <li><code>Language</code> of the text</li> <li>Extracts : <code>key-phrases, places, people, brands, events</code></li> <li>Understands <code>how positive or negative</code> the text is</li> <li><code>Analyzes</code> text using tokenization and parts of speech</li> <li>Automatically <code>organizes</code> a collection of text files by <code>topic</code> / article</li> <li>source : s3 </li> <li>target : Any - storage | DB | Data-warehouse</li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#d2-amazon-comprehend-medical-serverless","title":"D.2. Amazon <code>Comprehend Medical</code> (serverless)","text":"<ul> <li>uses <code>NLP</code> only to detect <code>PHI</code> (Protected Health Information), eg:</li> <li>Physician\u2019s notes</li> <li>Discharge summaries</li> <li>Test results</li> <li>Case notes</li> <li>create <code>strtutured</code> notes/graph, with related links</li> <li></li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#z-more","title":"Z. More","text":""},{"location":"01_aws/10_AI_ML/01-specific-services/#z1-amazon-forecast","title":"Z.1. Amazon <code>Forecast</code>","text":"<ul> <li>Use cases: Product Demand Planning, Financial Planning, Resource Planning.</li> <li>eg: </li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#amazon-kendra","title":"Amazon <code>kendra</code>","text":"<ul> <li><code>document search</code> service.</li> <li>incremental learning</li> <li></li> </ul>"},{"location":"01_aws/10_AI_ML/01-specific-services/#summary","title":"Summary","text":"<ul> <li><code>Rekognition</code>: face detection, labeling, celebrity recognition</li> <li><code>Transcribe</code>: audio to text (ex: subtitles)</li> <li><code>Polly</code>: text to audio</li> <li><code>Translate</code>: translations</li> <li><code>Lex</code>: build conversational bots \u2013 chatbots</li> <li><code>Connect</code>: cloud contact center</li> <li><code>Comprehend</code>: natural language processing</li> <li><code>SageMaker</code>: machine learning for every developer and data scientist</li> <li><code>Forecast</code>: build highly accurate forecasts</li> <li><code>Kendra</code>: ML-powered search engine</li> <li><code>Personalize</code>: real-time personalized recommendations</li> <li><code>Textract</code>: detect text and data in documents</li> </ul>"},{"location":"01_aws/10_AI_ML/02_sageMaker%2BPersonlize/","title":"ML service 2","text":""},{"location":"01_aws/10_AI_ML/02_sageMaker%2BPersonlize/#a-for-developers","title":"A. For developers","text":""},{"location":"01_aws/10_AI_ML/02_sageMaker%2BPersonlize/#a1-amazon-sagemaker","title":"A.1 Amazon <code>SageMaker</code>","text":"<ul> <li>Fully managed service for <code>developers / data scientists</code> to build <code>ML models</code></li> <li>label &gt; build  &gt; train &gt; apply model ,etc</li> <li>eg : predict exam score</li> <li></li> </ul>"},{"location":"01_aws/10_AI_ML/02_sageMaker%2BPersonlize/#a2-amazon-personlize","title":"A.2 Amazon <code>Personlize</code>","text":"<ul> <li>builds <code>real-time personalized recommendations</code> api</li> <li>Implement in days</li> <li>don\u2019t need to build, train,and deploy ML solutions</li> <li></li> </ul>"},{"location":"01_aws/97_more-services/01_CloudFormation/","title":"01 CloudFormation","text":""},{"location":"01_aws/97_more-services/01_CloudFormation/#cloud-formation-composer","title":"Cloud Formation + composer","text":"<ul> <li>IAC, stack, No manual resource creation</li> <li>declarative programing - yaml template, automatically detect what nneds to create first and so on.</li> <li>cost saving : automatically - delete/re-create some resource; schedule it.</li> <li>yaml --&gt; <code>composer</code>, helps to see <code>visual</code> all resource and relations b/w them.</li> <li>it adds some tag to each resource.</li> <li>replace &gt; upload new yaml &gt; <code>changeSet</code> &gt; add/update/delete, replace=t/f</li> <li>permission : CF &gt; stack-1(Attach Role-1::policy::s3&amp;sqs) &gt; stack-1 can create/update/delete s3 and sqs only.</li> <li></li> </ul>"},{"location":"01_aws/97_more-services/02_SES%2Bpinpoint/","title":"Other Service : sms and email related","text":""},{"location":"01_aws/97_more-services/02_SES%2Bpinpoint/#amazon-ses-simple-email-service","title":"Amazon <code>SES</code> (Simple Email Service)","text":"<ul> <li>Fully managed service</li> <li><code>Flexible IP</code> deployment.</li> <li>send emails <code>globally at scale</code></li> <li>Usecase: transactional, marketing and bulk email communications</li> <li>send emails <code>securely</code>, supports:</li> <li><code>DKIM</code> (DomainKeys Identified Mail)</li> <li><code>SPF</code> (Sender Policy Framework)</li> </ul>"},{"location":"01_aws/97_more-services/02_SES%2Bpinpoint/#amazon-pinpoint","title":"Amazon <code>pinpoint</code>","text":"<ul> <li><code>next level SMS</code>, Also support email, in-app messaging.</li> <li>Usecase: run <code>campaigns</code> by sending marketing, bulk,transactional SMS messages.</li> <li>features :</li> <li>Scalable 2-way; receive replies</li> <li>create message templates, </li> <li>create delivery schedules, </li> <li>highly-targeted segments, and full campaigns</li> <li><code>stream events</code> to other service (KDF, SNS, CW)</li> <li></li> </ul>"},{"location":"01_aws/97_more-services/03_SSM-and-more/","title":"1. SSM (System Session Manager)","text":"<ul> <li>3 ways to connect to ec2-i</li> <li>ssh</li> <li>ec2 instance connect</li> <li>ssm</li> <li>no SSH needed / secure alternative to ssh</li> <li>launch ec2-i1(window/Linux/mac) and attach <code>AmazonSSmManagedIntanceCore</code> policy. </li> <li>this will make <code>SSM agent</code>, active on ec2-i1.</li> <li></li> <li><code>FleetManager</code> service&gt; managedNode &gt; view :: all EC2 instance managed by SSM</li> <li>ec2-i1 &gt; start session</li> <li>launch blank terminal window : <code>secure shell</code></li> <li>run any command.</li> <li>once closed, check session history.</li> <li>Also, it sends session log data to <code>S3/CW</code></li> </ul>"},{"location":"01_aws/97_more-services/03_SSM-and-more/#ssm-other-relatedlinked-services","title":"SSM - other related/linked services","text":""},{"location":"01_aws/97_more-services/03_SSM-and-more/#2-systems-manager-runcommand","title":"2. Systems Manager - <code>RunCommand</code>","text":"<ul> <li>execute cmd/script across multiple ec2-i/s</li> <li>Integrated with <code>IAM &amp; CloudTrail</code></li> <li>output:</li> <li>log: <code>s3/Cw</code></li> <li>error : <code>sns</code></li> <li>trigger : user/manually + [ eventBridge &gt; event &gt; runCommand ]</li> <li></li> </ul>"},{"location":"01_aws/97_more-services/03_SSM-and-more/#3-systems-manager-patch-manager","title":"3. Systems Manager - <code>Patch Manager</code>","text":"<ul> <li>automate : OS updates, applications updates, security updates on multiple ec2-i/s(Linux, macOS, and Windows)</li> <li><code>on-demand</code> or schedule/maintenance-Window</li> <li></li> </ul>"},{"location":"01_aws/97_more-services/03_SSM-and-more/#4-systems-manager-maintenance-window","title":"4. Systems Manager - <code>maintenance Window</code>","text":"<ul> <li>has:</li> <li>Schedule</li> <li>Duration</li> <li>Set of <code>registered instances</code></li> <li>Set of <code>registered tasks</code></li> <li></li> </ul>"},{"location":"01_aws/97_more-services/03_SSM-and-more/#5-systems-manager-automation","title":"5. Systems Manager - <code>Automation</code>","text":"<ul> <li>Automation documnet - <code>Runbook</code>, define actions:</li> <li>restart instances, </li> <li>create an AMI, </li> <li>EBS snapshot</li> <li>etc</li> <li>trigger runbook:</li> <li>Manually using AWS Console, AWS CLI or SDK</li> <li>Amazon EventBridge</li> <li>schedule/Maintenance Windows</li> <li><code>AWS Config</code> (remediation rule)</li> </ul>"},{"location":"01_aws/97_more-services/04_cost-explorer/","title":"Cost Explorer","text":"<ul> <li>Create custom <code>reports</code> that analyze <code>cost and usage</code> data.</li> <li>visual report(graph)</li> <li><code>granularity</code>:  Monthly, hourly, resource level granularity</li> <li>recommends : <code>Savings Plan</code> </li> <li><code>Forecast usage</code> up to 12 months, based on previous usage</li> </ul>"},{"location":"01_aws/97_more-services/04_cost-explorer/#aws-cost-anomaly-detection","title":"AWS Cost Anomaly Detection","text":"<ul> <li>Continuously monitor your cost and usage, using ML to <code>detect unusual spends</code></li> <li>Sends anomaly detection report with <code>root-cause analysis</code>, with SNS.</li> </ul>"},{"location":"01_aws/97_more-services/05_AWS-Batch/","title":"AWS Batch","text":"<ul> <li>batch processing at any scale</li> <li>Efficiently run 100,000s of computing batch jobs.</li> <li>Batch jobs are defined as <code>Docker images</code> and run on <code>ECS</code></li> <li>dynamically launch EC2-i or Spot-Instances</li> <li>eg:</li> <li> </li> <li> <p>lambda vs Batch</p> </li> <li></li> </ul>"},{"location":"01_aws/97_more-services/06_AppFlow/","title":"App Flow","text":"<ul> <li>Fully managed <code>integration</code> service</li> <li>securely(encrypted) transfer (with filter&amp;validation) data, between <code>SaaS-applications</code> and <code>AWS</code></li> <li>trigger: schedule, event, od</li> <li>over internet or privateLink</li> </ul> <p>Don\u2019t spend time writing the integrations and leverage APIs immediately</p> <ul> <li><code>Sources</code>: </li> <li>Salesforce, Slack, ServiceNow</li> <li> <p>SAP, Zendesk </p> </li> <li> <p><code>Destinations</code> </p> </li> <li>aws     : S3, Amazon Redshift </li> <li>non-AWS : SnowFlake and Salesforce</li> </ul>"},{"location":"01_aws/97_more-services/07_Amplify/","title":"07 Amplify","text":""},{"location":"01_aws/97_more-services/07_Amplify/#-dva-28_3_amplifymd","title":"- DVA : 28_3_Amplify.md","text":""},{"location":"01_aws/97_more-services/07_Amplify/#amplify","title":"Amplify","text":"<ul> <li>similar to <code>beanStalk</code></li> <li><code>develop and deploy</code> scalable <code>full stack web and mobile applications</code></li> <li>common place to configure <code>set of services</code> app :</li> <li>upload code from VFS or directly</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/","title":"SSA Discussion","text":""},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#a-time-app-stateless","title":"A. Time App (stateless)","text":"<ul> <li>launch time app on Ec2 (t1.micro) in Az-1</li> <li>give current time</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#problem-1-need-staticfixed-ip","title":"<code>Problem-1</code>:  need static/fixed Ip","text":"<ul> <li>assign <code>elastic IP</code>(paid)</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#problem-2-more-user-more-traffic-increase-computing-capacity","title":"<code>Problem-2</code>: more user more traffic. increase computing capacity.","text":"<ul> <li><code>vertical scale</code> to m5, having downtime as well.</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#problem-3-even-more-traffic-scaling-but-no-downtime","title":"<code>problem-3</code> : even more traffic, scaling but no downtime","text":"<ul> <li><code>horizontal scaling</code> : 2 more m5.</li> <li>launch 3 m5 intances in Az-1 + attach elastic Ip/s.</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#problem-4-soo-many-elastic-ip","title":"<code>problem-4</code> : Soo many elastic IP.","text":"<ul> <li>r53 &gt; add a-record (with ttl) with <code>dns</code> name with service::ec2::ec2-i1/2/3</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#problem-5-ec2-i-health-issue-and-went-down","title":"<code>problem-5</code> : ec2-i health issue and went down.","text":"<ul> <li>add <code>ALB</code> in same AZ-1 + health check</li> <li>update sg of ec2-i and alb for allowed traffics.</li> <li>allow traffic from alb for security purpose.</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#problem-6-traffic-is-less-scaling-down","title":"<code>problem-6</code> : traffic is less, scaling down","text":"<ul> <li>add <code>ASG</code> &gt; deploy in az-1, can span over Az/s too. add min.max.desired</li> <li>az-3::ec-2i3 -- <code>reserve instance</code></li> <li></li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-01-StatelessApp/#problem-7-availability-issue-dr","title":"<code>problem-7</code> : Availability issue / DR","text":"<ul> <li>deploy<code>app/ec2-i</code> in multiple AZ / az-1, az-2, az-3</li> <li>deploy <code>ALB</code> in multiple AZ  / az-1, az-2, az-3 </li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/","title":"SSA Discussion","text":""},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#a-myclothescom-stateful","title":"A. MyClothes.com (Stateful)","text":"<ul> <li>has database for each user</li> <li>has user session data in shopping cart.</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-1-cart-lost-user-request-goes-to-different-ec2-i-everytime","title":"<code>Problem-1</code>:  cart lost &gt; user request goes to different ec2-i everytime.","text":"<ul> <li>Solution-1 : use <code>ELB stickiness</code>.</li> <li>Solution-2 : <code>client side cookies</code> to maintained cart. FE developer (make server stateless)<ul> <li>client side cookies can alter by hacker</li> <li>cannot store large-dataset</li> </ul> </li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-2-client-side-cookies-can-alter-by-hacker","title":"<code>Problem-2</code>: client side cookies can alter by hacker.","text":"<ul> <li>Solution-1 : use ElasticCache (server side cache). </li> <li>solution-2 : can use dynamoDB as well for temp record with TTL.</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-3-persist-user-data","title":"<code>problem-3</code> : Persist user data","text":"<ul> <li>use RDS</li> <li>also,update sg to allow restricted traffic.</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-4-read-performance-issue","title":"<code>problem-4</code> : read performance issue","text":"<ul> <li>add RDS Read replicas</li> <li>use elastiCache to cache frequently access use data.</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-5-rds-and-elasti-cache-availability-dr","title":"<code>problem-5</code> : RDS and Elasti-cache : Availability / DR","text":"<ul> <li>use multi-AZ</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#b-wordpress-stateful","title":"B. wordpress (stateful)","text":"<ul> <li>upload and store image on volumes.</li> <li></li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-1-multiple-volume-no-track-which-image-is-which-volume","title":"<code>Problem-1</code>:  multiple Volume, no track which image is which volume","text":"<ul> <li>use EFS</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#c-more","title":"C. more","text":""},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-1-quickly-instantiate-app","title":"<code>problem-1</code> : Quickly instantiate App","text":"<ul> <li><code>Golden AMI pattern</code> : Install your applications, OS dependencies etc.. beforehand and launch your EC2 instance from the Golden AMI</li> <li>Bootstrap using <code>User Data</code>: For dynamic configuration, use User Data scripts.</li> <li>Hybrid: mix Golden AMI and User Data (Elastic Beanstalk).</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-2-quickly-restore-rds-databases","title":"<code>problem-2</code> Quickly restore RDS Databases:","text":"<ul> <li>Restore from a snapshot: the database will have schemas and data ready!</li> </ul>"},{"location":"01_aws/98_SAA_discussion/11-02-StatefulAppWithDB%2BCache/#problem-3-quickly-restore-ebs-volumes","title":"<code>problem-3</code> Quickly restore EBS Volumes:","text":"<ul> <li>Restore from a snapshot: the disk will already be formatted and have data!</li> </ul> <p>use <code>BeanStalk</code> (managed srv), if dont want to deal with all above things, and have things already in place.</p>"},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/","title":"SSA Discussion","text":""},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/#a-todolist-app-serverless","title":"A. TodoList App (Serverless)","text":"<ul> <li>REST : web-client --&gt;  upload/dowload &gt; s3</li> <li>serverless Authentication : <code>cognito</code> --&gt; api-gateway</li> <li>scalable DB with high READ throughput : <code>DynamoDB</code></li> </ul>"},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/#problem-1-serverless-auth-to-api-gateway","title":"Problem-1 : serverless auth to api-gateway","text":"<ul> <li>use cognito:user-pool</li> </ul>"},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/#problem-2-serverless-auth-to-s3","title":"Problem-2 : serverless auth to s3","text":"<ul> <li>web-client --&gt; s3 or directly to s3</li> <li>authenticate with cognito:user-pool</li> <li>exchange auth token for access-token / temp AWS credential</li> <li>use token to access s3</li> </ul>"},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/#problem-3-reduces-cost-for-dynomodb-since-not-too-much-write","title":"Problem-3 : reduces cost for DynomoDB, since not too much write.","text":"<ul> <li>use DAX</li> <li>or use API-gateway cache feature.</li> </ul>"},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/#b-myblog-app-serverless","title":"B. MyBlog-App (Serverless)","text":"<ul> <li>blogs : more READs, less Write</li> <li>globally scale website (static files)  : <code>CF</code>, <code>S3 static Hosting</code>,</li> <li>photo upload &gt; thumbnail : <code>lambda</code></li> <li>welcome email : Lambda --&gt; <code>SES</code></li> </ul>"},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/#c-microservice","title":"C. Microservice","text":"<ul> <li>Not best, but AWS solves some problem:</li> <li>see mix of three different types.</li> <li>ms1 --&gt; ms2 : <code>sync</code> pattern.</li> <li>ms1 --&gt; SQS/KDS --&gt; ms2  : <code>A-sync</code> pattern</li> </ul>"},{"location":"01_aws/98_SAA_discussion/20-01-Servless%2BMS/#c-software-off-loading","title":"C. Software Off-loading","text":"<ul> <li>myApp --&gt; new version / update came.</li> <li>globally everyone downloading update from our app.</li> <li>need to optimize ASG to handle sudden request spike ?</li> <li>better way just put <code>CF in front of ELB</code></li> <li>since update is static file, cache it to CF</li> <li>And CF will scale to handle global requests.</li> <li>this is cheap option too.</li> </ul>"},{"location":"01_aws/98_SAA_discussion/22-01-BigData-Ingestion-pipeline/","title":"22 01 BigData Ingestion pipeline","text":""},{"location":"01_aws/98_SAA_discussion/22-01-BigData-Ingestion-pipeline/#big-data-ingestion-pipeline","title":"Big Data Ingestion Pipeline","text":""},{"location":"01_aws/98_SAA_discussion/22-01-BigData-Ingestion-pipeline/#a-sample-architecture","title":"A. Sample architecture","text":"<ul> <li><code>IoT Core</code> allows you to harvest data from <code>IoT devices</code></li> <li><code>Kinesis</code> is great for real-time data collection</li> <li><code>Firehose</code> helps with data delivery to S3 in near real-time (1 minute)</li> <li><code>Lambda</code> can help Firehose with data transformations</li> <li><code>S3</code> can trigger notifications to <code>SQS</code> --&gt; <code>Lambda</code> can subscribe to SQS</li> <li><code>Athena</code> is a serverless SQL service and <code>results</code> are stored in S3</li> <li>The reporting S3 bucket contains analyzed data and can be used by reporting tool such as <code>AWS QuickSight</code>, Redshift/OLAP, etc\u2026</li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/","title":"SSA Discussion","text":""},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#architecture","title":"Architecture","text":""},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#1-sqs-sns-and-lambda-with-dlq","title":"1. SQS, SNS and lambda with DLQ","text":"<ul> <li>after retry, move to DLQ</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#2-sqs-sns-fan-out-pattern","title":"2. SQS SNS : Fan-out pattern","text":""},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#3-s3-event","title":"3. S3 event","text":""},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#4-event-bridge-and-event-rules","title":"4. event bridge and event rules","text":"<ul> <li>rule give advance filter options</li> <li>can combine/have multiple rule and multiple targets</li> <li><code>Archive</code>, <code>Replay</code> Events</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#5-ct-logevent","title":"5. CT log/event","text":""},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#6-more-1","title":"6. more-1","text":""},{"location":"01_aws/98_SAA_discussion/29-01-event%2Bdecouple%2Bcache/#7-cache-strategies","title":"7. cache Strategies","text":""},{"location":"01_aws/98_SAA_discussion/29-02-network-1/","title":"SSA Dicussion","text":""},{"location":"01_aws/98_SAA_discussion/29-02-network-1/#a-block-ip-to-ec2-i","title":"A. Block IP to ec2-i","text":""},{"location":"01_aws/98_SAA_discussion/29-02-network-1/#1-nacl","title":"1. NACL","text":"<ul> <li>use VPC/subnet <code>ACL</code> : allow/deny rule(rule-priority)</li> <li>block a specific IP.</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-02-network-1/#21-allow-traffic-from-alb-only","title":"2.1. Allow traffic from ALB only","text":"<ul> <li>Again ACL has already blocked IP</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-02-network-1/#21-allow-traffic-from-alb-only-waf","title":"2.1. Allow traffic from ALB only + WAF","text":""},{"location":"01_aws/98_SAA_discussion/29-02-network-1/#3-cf-with-geo-restriction-waf","title":"3. CF with geo-restriction + WAF","text":""},{"location":"01_aws/98_SAA_discussion/29-03-HighPerformanceCompute-HCP/","title":"SAA discussion","text":""},{"location":"01_aws/98_SAA_discussion/29-03-HighPerformanceCompute-HCP/#a-high-performance-computing-hpc","title":"A. High Performance Computing (HPC)","text":"<ul> <li>not a service  </li> <li>combination of multiple service to maximize AWS computation potential.</li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-03-HighPerformanceCompute-HCP/#1-data-management-transfer","title":"1. Data Management &amp; Transfer","text":"<ul> <li>AWS Direct Connect:</li> <li>Move <code>GB/s</code> of data to the cloud, over a private secure network</li> <li>Snowball &amp; Snowmobile</li> <li>Move <code>PB</code> of data to the cloud</li> <li>AWS DataSync</li> <li>Move large amount of data between <code>on-premises</code> and  AWS:Storage(<code>S3, EFS, FSx for Windows</code>, NOT-EBS)</li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-03-HighPerformanceCompute-HCP/#2-compute","title":"2. Compute","text":"<ul> <li>instance type : CPU/GPU optimzed</li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-03-HighPerformanceCompute-HCP/#3-network","title":"3. Network","text":"<ul> <li>Placement group - <code>cluster</code>, for low latency</li> <li><code>EC2 Enhanced Networking</code> : High bandwidth + high PPS + lower latency</li> <li><code>intel 82599 VF</code> (old) 10 GB/s</li> <li><code>ENA</code> (new) elastic n/w adaptor : 100 GB/s</li> <li><code>EFA</code> (elastic fabric adaptor) <ul> <li>improved ENA : uses MPI(message passing interface) which by-pass OS to make network faster.</li> <li>for Linux only</li> <li>for tightly coupled workloads.</li> </ul> </li> <li>SR-IOV </li> <li>(Single Root I/O Virtualization) is a hardware-based network virtualization feature </li> <li>enhances network performance for EC2 instances by allowing direct access to the ENI</li> <li><code>ethtool -i eth0</code> # Check if SR-IOV is enabled</li> <li>only some instance with supported kernel version </li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-03-HighPerformanceCompute-HCP/#4-storage","title":"4. Storage","text":"<ul> <li>Nothing New:</li> <li>EBS</li> <li>EFS</li> <li>instant store</li> <li>s3</li> <li>FXs</li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-03-HighPerformanceCompute-HCP/#4-automation","title":"4. Automation","text":"<ul> <li><code>AWS batch</code></li> <li><code>AWS parallel Cluster</code></li> <li>Open-source cluster management tool to deploy HPC.</li> <li>Ability to enable EFA</li> <li>Automate creation of VPC,Subnet inside cluster</li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-04-Ec2-avaliability/","title":"SSA Discussion","text":""},{"location":"01_aws/98_SAA_discussion/29-04-Ec2-avaliability/#a-ec2-availability","title":"A. EC2 Availability","text":"<ul> <li>one instance goes down , bring another one </li> </ul>"},{"location":"01_aws/98_SAA_discussion/29-04-Ec2-avaliability/#1-using-cw-alarm-lambda","title":"1. using  CW alarm + lambda","text":""},{"location":"01_aws/98_SAA_discussion/29-04-Ec2-avaliability/#2-using-asg","title":"2. using  ASG","text":"<ul> <li>has EBS too</li> <li></li> </ul>"},{"location":"01_aws/98_SAA_discussion/99-01-SSA-security/","title":"99 01 SSA security","text":"<p>--&gt; sample architecture : kind on combination can have </p>"},{"location":"01_aws/98_SAA_discussion/99-01-SSA-security/#application-front-face-and-flow","title":"Application front face and flow","text":"<ul> <li> <p><code>step-1</code> : client --&gt;</p> </li> <li> <p><code>step-2</code> : Route 53 <code>DDoS protected</code> --&gt;</p> <ul> <li><code>step-3.1</code> : region/vpc</li> <li>with/without WAF --&gt; <code>API-gateway-regional</code> --&gt; ...</li> <li> <p>with/without WAF --&gt; alb --&gt; ...</p> </li> <li> <p><code>step-3.2</code> : edge Location <code>DDoS protected</code> --&gt;</p> </li> <li> <p><code>step-4.1</code> : with/without WAF --&gt; <code>API-gateway-edge-optimized</code> (global) --&gt; CF distribution (global) --&gt; ...</p> </li> <li> <p><code>step-4.2</code> :with/without WAF --&gt; <code>CF distribution</code>(global) --&gt; ...</p> <ul> <li><code>step-4.2.1</code> :region/vpc</li> <li>ec2</li> <li>with/without WAF --&gt; API-gateway-regional --&gt; ...</li> <li>with/without WAF --&gt; alb --&gt; ec2/container</li> <li>with/without WAF --&gt; alb --&gt; ASG --&gt; ec2/container</li> </ul> </li> <li> <p><code>step-4.3</code> : <code>Global Accelerator</code>(global) --&gt; endpoint-group[ region1:az1:abl-1, region2:az1:alb-2,... ]</p> <ul> <li><code>step-4.3.1</code> :region/vpc</li> <li>ec2</li> <li>with/without WAF --&gt; API-gateway-regional --&gt; ...</li> <li>with/without WAF --&gt; alb --&gt; ec2/container </li> <li>with/without WAF --&gt; alb --&gt; ASG --&gt; ec2/container</li> </ul> </li> </ul> </li> </ul>"},{"location":"01_aws/98_SAA_discussion/99-01-SSA-security/#protection-point","title":"protection point","text":"<ul> <li>shield advance</li> <li>shield standard</li> <li>WAF - web ACL</li> <li>network ACL ?</li> <li>subnet ACL</li> <li>ASG/EC2 -&gt; SG</li> </ul> <ul> <li>edge location : CF, acc, API-gateway-edge-optimzied</li> </ul>"},{"location":"01_aws/practice-test/readme/","title":"A. AWS-Certified-Cloud-Practitioner-Notes","text":"<ul> <li>https://github.com/muhammad-usman-108/AWS-Certified-Cloud-Practitioner-Notes/tree/master/practice-exam</li> <li>https://quizlet.com/600154168/flashcards?funnelUUID=22fce61a-8fdb-4f63-8f18-0ed160072b7d</li> </ul>"},{"location":"01_aws/practice-test/readme/#b-dva","title":"B. DVA","text":""},{"location":"01_aws/practice-test/readme/#1-discussion","title":"1. discussion:","text":"<ul> <li>network : https://chatgpt.com/c/6758e2f0-9fa4-800d-b601-939389407725</li> <li>DB : https://chatgpt.com/c/675945a8-f8b8-800d-a789-e07e6db38e8d</li> <li>lambda : https://chatgpt.com/c/675cb1da-8af8-800d-ab10-a286d742f4e4</li> <li>DynamoDB : https://chatgpt.com/c/675f4a6d-26b8-800d-b73e-a01c28a386b2</li> <li>API gateway : https://chatgpt.com/c/6761df7b-aa90-800d-b11f-c0e411c511fe</li> <li>SAM : https://chatgpt.com/c/6763704a-0a24-800d-b9a2-1866b9931f4d</li> <li>Security: </li> <li>cognito: https://chatgpt.com/c/676b51a6-3388-800d-a754-f5872af7a68a</li> <li>Monitor:</li> <li>x-ray : https://chatgpt.com/c/677c6111-b1a8-800d-b8c6-462a6e11d1d6\\</li> </ul>"},{"location":"01_aws/practice-test/readme/#2-practice-exam","title":"2. practice exam","text":""},{"location":"01_aws/practice-test/readme/#attempt-1","title":"Attempt-1","text":""},{"location":"01_aws/practice-test/readme/#-httpschatgptcomc676b620b-fa38-800d-87e3-f2a155799864","title":"- https://chatgpt.com/c/676b620b-fa38-800d-87e3-f2a155799864","text":""},{"location":"01_aws/practice-test/readme/#c-ssa","title":"C. SSA","text":"<ul> <li>https://quizlet.com/425396578/aws-solutions-architect-flash-cards/</li> </ul>"},{"location":"01_aws/practice-test/readme/#1-discussion-skip","title":"1. discussion (skip)","text":"<ul> <li>https://chatgpt.com/c/584769ed-a735-4fa0-958a-208113b7214b</li> <li>https://chatgpt.com/c/41d82701-9ccf-4399-974e-51d717071b9e</li> <li>https://chatgpt.com/c/c2249fb1-ff6e-4346-8c01-b4ecb93888c3</li> <li>compute: https://chatgpt.com/c/9acf4e73-b6e8-4267-82c2-7c3ef5b74b2f</li> <li>DB https://chatgpt.com/c/f3646de9-ab0a-4651-b6cb-eb094ddc7f66</li> <li>security : https://chatgpt.com/c/6e232391-80c5-4b99-9e57-b7f5b05c5d14</li> </ul>"},{"location":"01_aws/practice-test/readme/#2-practice-exam-udemy-stephene-green_circle","title":"2. practice exam (udemy stephene) :green_circle:","text":""},{"location":"01_aws/practice-test/readme/#attempt-1_1","title":"Attempt-1","text":""},{"location":"01_aws/practice-test/readme/#0-httpschatgptcomc8e9fe51d-10e5-41b5-9fa6-adc2eb99628f-17-q","title":"0 https://chatgpt.com/c/8e9fe51d-10e5-41b5-9fa6-adc2eb99628f <code>17 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#1-httpschatgptcomce0b834ff-6673-4d0b-bb08-6a98e8ea5ef6-9-q","title":"1 https://chatgpt.com/c/e0b834ff-6673-4d0b-bb08-6a98e8ea5ef6 <code>9 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#2-httpschatgptcomcacdf2121-6d4d-4b0e-bc1e-852e811bf9fe-22-q","title":"2 https://chatgpt.com/c/acdf2121-6d4d-4b0e-bc1e-852e811bf9fe <code>22 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#3-httpschatgptcomc65e552b7-4187-4d59-a8cf-5c6cea9f6ec8-26-q","title":"3 https://chatgpt.com/c/65e552b7-4187-4d59-a8cf-5c6cea9f6ec8 <code>26 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#4-httpschatgptcomc84d37d3c-43a8-4593-a578-f7fdd43b4d53-3-q","title":"4 https://chatgpt.com/c/84d37d3c-43a8-4593-a578-f7fdd43b4d53 <code>3 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#5-httpschatgptcomcc5ccdbcb-5407-454c-9f88-14bf38fddfc5-13-q","title":"5 https://chatgpt.com/c/c5ccdbcb-5407-454c-9f88-14bf38fddfc5 <code>13 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#6-httpschatgptcomcc07719cd-16bd-4bda-9b6e-b720f4ad5a9c-8-q","title":"6 https://chatgpt.com/c/c07719cd-16bd-4bda-9b6e-b720f4ad5a9c <code>8 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#attempt-2","title":"Attempt-2","text":""},{"location":"01_aws/practice-test/readme/#0","title":"0","text":""},{"location":"01_aws/practice-test/readme/#1-httpschatgptcomc677f94fe-bcd4-800d-97b6-8e267c307c51-16-q","title":"1 https://chatgpt.com/c/677f94fe-bcd4-800d-97b6-8e267c307c51 <code>16 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#2-httpschatgptcomc6788410d-5fd8-800d-bd9c-f2ff22f9e87d-19-q","title":"2 https://chatgpt.com/c/6788410d-5fd8-800d-bd9c-f2ff22f9e87d <code>19 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#3-httpschatgptcomc678aac00-9fb0-800d-b49d-9990e4dd7f03-14-q","title":"3 https://chatgpt.com/c/678aac00-9fb0-800d-b49d-9990e4dd7f03 <code>14 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#4-5-6-httpschatgptcomc67955968-7de8-800d-839c-607cf85a6037-24-q","title":"4 #5 #6 https://chatgpt.com/c/67955968-7de8-800d-839c-607cf85a6037 <code>24 Q</code>","text":""},{"location":"01_aws/practice-test/readme/#3-practice-exam-whizlab-yellow_circle","title":"3. practice exam (whizlab ) :yellow_circle:","text":""},{"location":"01_aws/practice-test/readme/#attempt-1_2","title":"Attempt-1","text":"<ul> <li>https://chatgpt.com/c/6799e17f-6f00-800d-9331-1c0572dee9d1  free</li> <li> </li> <li>topic-wise question Q as well : https://chatgpt.com/c/679b234b-bbb0-800d-8abc-85267ee02bf2  <code>38 Q</code></li> <li>https://acrobat.adobe.com/id/urn:aaid:sc:VA6C2:7bc03cbb-131d-4190-a0db-9bdecda8b5f9?viewer%21megaVerb=group-discover</li> <li>https://www.whizlabs.com/learn/course/aws-solutions-architect-associate/153/quiz/60503/report/8207667</li> <li>whizlab-ssa-exam-2.pdf</li> <li> </li> <li>https://chatgpt.com/c/67a128f7-403c-800d-9314-903f01a4911c <code>11 Q</code></li> <li>https://acrobat.adobe.com/id/urn:aaid:sc:VA6C2:1404e5d1-46d4-494b-aa0f-6ca76c2426e8?viewer%21megaVerb=group-discover</li> <li>https://www.whizlabs.com/learn/course/aws-solutions-architect-associate/153/quiz/60504/report/8213022</li> <li>whizlab-ssa-exam-3.pdf</li> <li> </li> <li>https://www.whizlabs.com/learn/course/aws-solutions-architect-associate/153/quiz/60697/report/8214367</li> <li>https://www.whizlabs.com/learn/course/aws-solutions-architect-associate/153/quiz/60698/report/8217730</li> <li>whizlab-ssa-exam-4-5.md</li> <li> </li> <li>https://www.whizlabs.com/learn/course/aws-solutions-architect-associate/153/quiz/60758/report/8229410</li> <li> </li> <li>https://chatgpt.com/c/67a50f18-381c-800d-9dba-26458c36916e #3 to #7 </li> <li> </li> </ul>"},{"location":"01_aws/practice-test/readme/#1-84","title":"1 <code>84 %</code>","text":""},{"location":"01_aws/practice-test/readme/#2-77","title":"2 <code>77 %</code>","text":""},{"location":"01_aws/practice-test/readme/#3-77","title":"3 <code>77 %</code>","text":""},{"location":"01_aws/practice-test/readme/#4-5-90-90","title":"4 / #5  <code>90 %</code> <code>90 %</code>","text":""},{"location":"01_aws/practice-test/readme/#6-74","title":"6 <code>74</code>","text":""},{"location":"01_aws/practice-test/readme/#7","title":"7 <code>?</code>","text":""},{"location":"01_aws/practice-test/readme/#8-final","title":"8 final :","text":""},{"location":"01_aws/practice-test/readme/#4-itexamslabcom-yellow_circle","title":"4. itexamslab.com :yellow_circle:","text":"<ul> <li>sample: https://www.itexamslab.com/amazon/saa-c03-dumps.html</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/02.offical_practice-Exam/","title":"02.offical practice Exam","text":"<ul> <li>When Amazon ECS uses Fargate for compute, it <code>incurs minimal costs</code> when the application is <code>idle</code>. </li> <li>Aurora Serverless also incurs no compute costs when it is <code>idle</code>.</li> <li>Data transfer to CloudFront is free of cost.</li> <li>data transfer from CloudFront to an on-premises location incurs a cost.</li> <li>S3 is cheaper for general storage, especially for large, infrequently accessed data.</li> <li>EFS is more expensive but better suited for workloads requiring shared file storage and lower latency</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-1.md/","title":"03.practice exam 1.md","text":"<p>  2.b on-premises IT infrastructure to AWS Cloud &gt;&gt;  <code>dedicated hosts</code>  6. a,b,c : use <code>lambda layer</code> for common code.   8. gaming &gt; single user &gt; session &gt; data &gt; cache &gt; use <code>elasticCache in front od RDS</code>.   12. a. S3 --&gt; <code>DMS</code> --&gt; kinesis  13. c. API gateway:throttles requests in case of sudden traffic spikes  14. c. on-prem (DatasyncAgent:<code>scheduled-task</code>) --&gt; AWS Direct connection --&gt; VPC gateway(interface) --&gt; resource,EFS   21. a,b : make the application more <code>resilient</code> to periodic spikes in request rates &gt;&gt; <code>CF distribution</code>  22. a. after 30 days can move to IA storage class.   28.  c. use <code>EC2 Reboot CloudWatch Alarm Action</code>  38. c. permission boundary for employees.    47.  b. replace existing &gt; try read &gt; always return latest value.  48*.  d. cloudTrail API calls.  49. b. traffic is routed to instance from ELB using <code>private IPS</code> of ENI of instance.   55. b,c <code>3000 msg/s</code> with batch  56. Aws global accelerator, has weights to end point group  </p>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/","title":"03.practice exam 2","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#1-aws-datasync","title":"1. AWS DataSync *","text":"<ul> <li>Media Company (on-prem) : </li> <li>video --&gt; upload --&gt; server:NFS</li> <li>migrate --&gt; AWS:EC2:EFS</li> <li>AWS DataSync:</li> <li>on-prem-server (datSync-agent) --&gt;  Connect how ? ---&gt; AWS:DataSync</li> <li>a: private VIF --&gt; VPC endpoint for EFS (correct)</li> <li>b: public VIF  --&gt; S3:event:L:move2EFS</li> <li>c: private VIF --&gt; VPC peering endPoint for EFS (wrong)</li> <li>d: VPC gateway:S3 --&gt; L &gt; move2EFS</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#2-acl-stateless","title":"2. ACL stateless","text":"<ul> <li>VPC &gt; Subnet:ACL-1  &gt; EC2-i1:sg-1 : App::port-P1</li> <li>sg-1, enable in-traffic on 80</li> <li>acl-1, enable in-traffic on 80</li> <li>fix: enable out-traffic on 80 for acl-1</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#3-cross-account-access-1","title":"3. Cross-account-access 1","text":"<ul> <li>AWS1:L --&gt; access AWS2:S3</li> <li>add both : <code>S3 bucket policy</code> + <code>L:role</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#4-cross-account-access-2","title":"4. Cross-account-access 2","text":"<ul> <li>AWS1:redshift(OLAP,||,Spectrum) --&gt; writing file,F1 to --&gt;  AWS2:S3:b1</li> <li>b1:owner unable to access F1.</li> <li>a. no implicit access to <code>cross account uploaded object</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#5-api-gateway","title":"5. API gateway  **","text":"<ul> <li><code>built-in user management</code> ?</li> <li>Cognito </li> <li>user-pool - Authentication  ( correct )</li> <li>identity pool - authorize API call.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#6-ec2-instance-class","title":"6. EC2 instance class","text":"<ul> <li>100 instance</li> <li>70 : RI</li> <li>30 : spot (batch)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#7-aurora","title":"7. Aurora","text":"<ul> <li><code>global</code> healthcare application </li> <li>low latency for database read/write </li> <li>DB Amazon Aurora that offers </li> <li><code>RPO of seconds</code></li> <li><code>RTO of a minute</code></li> <li>Sol :  use global Aurora DB</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#8-storage","title":"8. Storage *","text":"<ul> <li>Cheapest :</li> <li>EBS FS &gt;</li> <li>EFS &gt; EFS-IA &gt;</li> <li>S3 &gt; S3-IA &gt; S3-IA(one-Z)</li> <li>glacier :instance &gt; flexible &gt; deep-Archive</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#9-sg-easy","title":"9. SG : easy","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#10-asg","title":"10. ASG","text":"<ul> <li>ASG in AWS can indeed include Spot Instances. Moreover, the ASG can terminate Spot Instances if they fail health checks.</li> <li><code>Grace Period</code></li> <li><code>impaired status</code> of Ec2.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#11-sqs-fifo","title":"11. SQS FIFO","text":"<ul> <li>desktop-1,2,... n --&gt; send data in every minute --&gt; AWS compute service</li> <li>SQS FIFO with message/group ID </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#12-rds-encrypt","title":"12. RDS : encrypt","text":"<ul> <li>unencrypted instance &gt; take screenshot + with encryption &gt; restore it.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#13-kms","title":"13: KMS **","text":"<ul> <li>appl (key-1) --&gt; migrate to AWS</li> <li>Continue using same encryption key, k1</li> <li>use: <code>SSE-C</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#14","title":"14","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#15-private-hosted-zone","title":"15. private Hosted Zone **","text":"<ul> <li>not resolving DNS Queries</li> <li>a. fix NS, SOA entry record (Wrong)</li> <li>b. Enable <code>DNS hostnames</code> and <code>DNS resolution</code> for private hosted zones (correct)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#16-ec2-instance-class","title":"16.  EC2 instance class","text":"<ul> <li>Scenario : monthly , 2 hr work load, withstand with server failure.</li> <li>use: spot fleet</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#17-iam-policy","title":"17 : IAM policy","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#18-iam-policy","title":"18 : IAM policy  **","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#19-rds-performance","title":"19. RDS : performance","text":"<ul> <li>global IT company , user accross Glob</li> <li>using RDS: MySQL with read Replicas, still performance issue</li> <li>use : ARora:MySQL (global)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#20-cross-acct-share-rds-screenshot-securely","title":"20. Cross-Acct : share RDS screenshot securely","text":"<ul> <li>encrypt screenshot + KMS-key1</li> <li>share both with AWS2</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#21-ebs-terminateondelete-easy","title":"21. EBS: TerminateOnDelete, easy","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#22-analytics","title":"22. Analytics **","text":"<ul> <li>big data consulting firm</li> <li>data lake is split in S3/raw zone --&gt; Glue/ETL --&gt; S3/refined zones (keep 5 years) --&gt; athena(ad-hoc queries)</li> <li>MOST cost-optimal for storage only ?</li> <li>solution (2)</li> <li>compress data in ETL</li> <li>lifecycle policy to transition the raw zone data into Amazon S3 Glacier Deep, Archive after 1 day of object creation</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#23-upload-video","title":"23. upload video **","text":"<ul> <li>initially on fleet --&gt;  EC2-1:EBS-1, EC2-2:EBS-2, ...</li> <li>videos scattered among multiple EBS</li> <li>Solution : EFS + S3</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#24-cw-log12-send-to-dsownstream","title":"24. Cw-log1,2,... &gt; send to dsownstream","text":"<ul> <li>service : auto-scales</li> <li>no admin</li> <li>use <code>KDF</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#25-s3-encrypy-rotate-key-audit-key-usage","title":"25. S3 : encrypy, rotate key, audit key usage","text":"<ul> <li>use <code>SSE-SSE</code></li> <li>with SSE-S3, you cannot log the usage of the encryption key for auditing purposes</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#26-aurora-slow-with-too-much-read-easy","title":"26. Aurora slow with too much read : easy","text":"<ul> <li>add read replica</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#27-vpc-1-vpc-2-vpn-easy","title":"27. VPC-1, VPC-2,.. + VPN : easy","text":"<ul> <li>use transient gateway</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#28-ec2-hibernate","title":"28. Ec2: hibernate *","text":"<ul> <li>Every time the instance needs to be stopped and started again, </li> <li>the application takes about 3 minutes to start as some auxiliary software programs.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#29-terminate-ec2","title":"29. Terminate Ec2 &lt;&lt;&lt;","text":"<ul> <li>Instance A has the oldest launch template  </li> <li>Instance B has the oldest launch configuration **</li> <li>Instance C has the newest launch configuration </li> <li> <p>Instance D is closest to the next billing hour</p> </li> <li> <p><code>Default Termination Policy</code></p> </li> <li>instance that uses the oldest launch configuration first.</li> <li>next, it considers oldest age.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#30-hybrid-dr","title":"30. Hybrid DR","text":"<ul> <li>R53 fail over record b/w on-prem (P) and AWS (alb-dns as Secondary.)</li> <li>ALB &gt; ASg &gt; Ec2</li> <li>Storage gateway : migrate on-prem data volume to S3</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#31-use-rds-easy","title":"31 : Use RDS, easy","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#32-acm-cert-expiry","title":"32 : ACM cert expiry","text":"<ul> <li>AWS config managed rule.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#33-rds-read-replica-data-transfer-cost","title":"33 : RDS read replica --&gt; data transfer cost","text":"<ul> <li>within AZ/s in a region : replication : No charge</li> <li>across region : charges</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#34-ram-resource-access-manager","title":"34. RAM - Resource Access Manager *","text":"<ul> <li>AWS Organizations (region-1)</li> <li>AWS-1 : ec2-i1, ec2-i2, ..,</li> <li>AWS-2 : ec2-i1, ec2-i2, ...</li> <li>...</li> <li>all ec2-i privately contact</li> <li>Solution:</li> <li>Create a virtual private cloud (VPC) in an account </li> <li>and share one or more of its subnets with the other accounts using Resource Access Manager</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#35-placement-group","title":"35. placement group","text":"<ul> <li>50 Ec2 in each AZ, high ava</li> <li>use <code>partition</code> : 100 in each</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#36-static-s3-website-hosting","title":"36  static S3 website hosting","text":"<ul> <li>high performance, scalable, cost efficient</li> <li>R53:CF:S3  , CF:Custom-origin:On-prem, CF:L , </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#37-aws-org","title":"37 AWS org","text":"<ul> <li>Org-1 --&gt; move --&gt; Org-2</li> <li>Steps ? remove &gt; new invite &gt; Accept</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#38-fsx","title":"38. FSx","text":"<ul> <li>On-prem : has, DFSR Distributed file system replication service</li> <li>AWS : ?</li> <li>FSx for Window, yes</li> <li>Luster : for Linus, so no</li> <li>EFS : POSIX FS, so no</li> <li>S3 : no not FS</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#39-sginbound-easy","title":"39 : SG:inbound -  Easy","text":"<ul> <li>ALB(0.0.0.0/0, 443) &gt; ASG::EC2(sg-alb,80) &gt; RDS (sg-ec2-i, 5432)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#40-kinese-kdf","title":"40 Kinese KDF *","text":"<ul> <li>IoT --&gt; KDS --&gt; KDF</li> <li>server-Kinesis-agent --&gt; KDF : not coming, why ?</li> <li><code>Kinesis Agent cannot write to KDF for which source is already set as Amazon KDS</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#41-waf-block-ip-easy","title":"41. WAF : block IP, easy","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#42-single-tenancy-cheapest-option","title":"42 : single tenancy :  cheapest option","text":"<ul> <li>Dedicated instance</li> <li>or, Dedicated host</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#43-rds-screeshotr-encryption-thing-easy","title":"43 RDS : screeshotr encryption thing, easy","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#44-iam","title":"44 : IAM *","text":"<ul> <li>prevent develops from  assuming <code>AdministratorAccess</code> policy</li> <li>Solution : For each developer &gt; attach IAM permission boundary</li> <li>can only be applied to roles or users, <code>not IAM groups</code>.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#45-store-k-v-high-ava","title":"45 : Store  K-V (high Ava)","text":"<ul> <li>DynamoDB </li> <li>ElastiCache (wrong) - cannot use for k-v</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#46-s3-replication-with-kms","title":"46 S3 replication with KMS *","text":"<ul> <li>use multi-region KMS</li> <li>S3:batch for copy existing object.</li> <li>cannot convert an existing <code>single-Region key</code> to a<code>multi-Region key</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#47","title":"47","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#48-linux-instance-mount-network-fs","title":"48 Linux Instance &gt; mount <code>network</code> FS  **","text":"<ul> <li>file R/W frequently</li> <li>then infrequently</li> <li>which one : </li> <li>S3:Inteli, Glacier:deep - cannot mount these as FS</li> <li><code>EFS-IA</code> (92% lower) - correct </li> <li>Luster - for HCP</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#49-rdsmysql-storage-autoscale-with-less-admin","title":"49 RDS(MySQL) : Storage - AutoScale (with less Admin)","text":"<ul> <li>Option-1 ** : Enable RDS auto-scale, has to create CW:alarm, less than10% left</li> <li>Option-2 : Migrate to Aurora(MySQL) </li> <li>Although Aurora offers automatic storage scaling,  </li> <li>but ruled out, since systems administration effort to migrate from Amazon RDS MySQL to Aurora.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#50-traffic-spread-bw-prod-and-dev-testing","title":"50 : Traffic Spread b/w prod and dev (testing) **","text":"<ul> <li>Use ELB : listener</li> <li>use R53 resolver (Weighted)</li> <li>Use GA : listener</li> <li>endpoint-group -1 (weight-1)</li> <li>endpoint-group -1 (weight-2)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#51-secret-manager-easy","title":"51 Secret manager, easy","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#52-iam-policy","title":"52 IAM policy **","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#53-iam-easy","title":"53 IAM , easy","text":"<ul> <li>Attach IAM policy (DB,S3 access) on Ec2</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#54","title":"54","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#55-long-term-archival","title":"55 Long term Archival","text":"<ul> <li>snowball &gt; S3 &gt; Glacier **</li> <li>snowball &gt; Glacier</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#56-ec2-user-data","title":"56 Ec2 user Data","text":"<ul> <li>run once + executed root permission</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#57-asg-od-spot","title":"57 ASG (od + spot)","text":"<ul> <li><code>launch template</code>, new **</li> <li>launch Config, old</li> <li>launch template + config</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#58","title":"58","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#59-resource-shareing-with-multiple-vpc","title":"59 resource shareing with multiple VPC","text":"<ul> <li>VPC-1, VPC2, VPC-3 (resource-1), etc ==== All connected with transient gateway.</li> <li>share resource-1 with VPC-1/2</li> <li>Sol:</li> <li>VPC-endpoint-1:resource-1</li> <li>transient gateway (RAM) can <code>share VPC-endpoint-1</code> with VPC-1/2</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#60-s3-cross-account-access","title":"60 : S3 : Cross account access","text":"<ul> <li>S3 : specfic acct IAM user</li> <li>AWS2:u1,2,... </li> <li>solution : use S3 bucket policy</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#61-cognito","title":"61 Cognito","text":"<ul> <li>CF &gt; ALB &gt; ...</li> <li><code>attach cognito to ALB</code>, not to CF</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#62-efs-performance-mode","title":"62 EFS: performance mode","text":"<ul> <li>for Big Data processing : Max I/O</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#63-performance","title":"63 performance **","text":"<ul> <li>App : us-east-1</li> <li>Aurora</li> <li>Ec2 : web tier</li> <li>Eu user has performance issue</li> <li>Solution:</li> <li>Aurora : eu - READ instance</li> <li>Ec2 : eu deploy + r53 ( routing policy geoLocation or latency)</li> <li>Latency-Based Routing is likely the better choice</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#64-ec2-metric-cpu-utilization-alert","title":"64 : EC2 : metric &gt; CPU utilization &gt; alert","text":"<ul> <li>SNS + CW</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-2/#65-iam","title":"65 IAM","text":"<pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Sid\": \"Mystery Policy\",\n      \"Action\": [\n        \"ec2:RunInstances\"\n      ],\n      \"Effect\": \"Allow\",\n      \"Resource\": \"*\",\n      \"Condition\": {\n        \"StringEquals\": {\n          \"aws:RequestedRegion\": \"eu-west-1\"\n        }\n      }\n    }\n  ]\n}\n</code></pre>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/","title":"03.practice exam 3","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#1-aws-datasync","title":"1. AWS DataSync *","text":"<ul> <li>Media Company (on-prem) : </li> <li>video --&gt; upload --&gt; server:NFS</li> <li>migrate --&gt; AWS:EC2:EFS</li> <li>AWS DataSync:</li> <li>on-prem-server (datSync-agent) --&gt;  Connect how ? ---&gt; AWS:DataSync</li> <li>a: private VIF --&gt; VPC endpoint for EFS (correct)</li> <li>b: public VIF  --&gt; S3:event:L:move2EFS</li> <li>c: private VIF --&gt; VPC peering endPoint for EFS (wrong)</li> <li>d: VPC gateway:S3 --&gt; L &gt; move2EFS</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#2-acl-stateless","title":"2. ACL stateless","text":"<ul> <li>VPC &gt; Subnet:ACL-1  &gt; EC2-i1:sg-1 : App::port-P1</li> <li>sg-1, enable in-traffic on 80</li> <li>acl-1, enable in-traffic on 80</li> <li>fix: enable out-traffic on 80 for acl-1</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#3-cfdistribution-s3-static-data","title":"3. CF:distribution --&gt; S3 (static Data)","text":"<ul> <li>online gaming application </li> <li>users who download <code>static</code> assets such as historic leaderboard reports and the game tactics for various games. </li> <li>The current infrastructure and design are unable to cope up with the traffic and application freezes on most of the pages.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#4-aurora-serverless-vs-aurora","title":"4. Aurora Serverless vs Aurora","text":"<ul> <li>A leading bank </li> <li>Amazon EC2 Auto Scaling for their web servers. </li> <li>But, their MySQL relational database has now become a bottleneck<ul> <li>also need a fully managed auto scaling solution. </li> <li>use <code>Aurora Serverless</code>: Automatic Scaling (DB size) **</li> <li><code>Aurora</code> : traditional, Provisioned Capacity</li> </ul> </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#5-nlb","title":"5. NLB **","text":"<ul> <li>traffic routed through <code>private</code> IP, not public</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#6-repeated-nacl","title":"6.  -- Repeated --  NACL","text":"<ul> <li>stateless</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#7-asg-impaired-instance-recovery","title":"7. ASG : Impaired instance - Recovery","text":"<ul> <li>impair --&gt; <code>recovered instance</code> </li> <li>retain : elastic IP, private IP, elatic IP, metaData, instance ID</li> <li>doesn't retain : in-memory data.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#8-sharing-encrypted-ami-cross-regionacct","title":"8. Sharing encrypted AMI - cross region/Acct","text":"<ul> <li>yes can share AMI</li> <li>Also share KMS key </li> <li>manually de-crypt AMI with key then ?</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#9-sg-easy","title":"9. SG : easy","text":"<ul> <li>invalid inbound rule : on IGW</li> <li>allowed.valid : a ip, another-sg, ip/CIDR</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#10-eventbridge-scheduled-lambda","title":"10. EventBridge (Scheduled) --&gt; Lambda","text":"<ul> <li>A social media </li> <li>perform <code>weekly</code> database rollovers for a MySQL database server </li> <li>using a <code>serverless</code> cron job.</li> <li>takes about <code>5 minutes</code> to execute </li> <li>script written in <code>Python</code>.  </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#11-connection-draining","title":"11. connection draining","text":"<ul> <li>When connection draining is enabled, </li> <li>the ALB waits for the active connections to finish,</li> <li>before fully removing the instance from its target group</li> <li>And, New requests are no longer routed to the instance</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#12-vpc-endpoint","title":"12. VPC endpoint","text":"<ul> <li>VPC-1 (resource-1) --&gt; Access ? --&gt; VPC-2:SQS</li> <li>Sol: VPC-endpoint for SQS</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#13-storage-gateway","title":"13: Storage Gateway","text":"<ul> <li>Hybrid log</li> <li>AWS : S3 - full logs : gateway Volume (Cached-Volume / Stored-Volume)</li> <li>on-prem - Cache - most frequently log</li> <li>Sol:</li> <li><code>Gateway-Cached Volumes</code> ** : Primary data storage is in Amazon S3, with frequently accessed data cached locally.</li> <li><code>Gateway-Stored Volumes</code>: Primary data storage is on-premises, with cloud-based backup.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#14-network","title":"14  Network","text":"<ul> <li>VPC:igw &gt; Subnet,S1 &gt; rt &gt; route=internettraffic::igw</li> <li>hence S1 become public subnet</li> <li>NAT gtw is also launched in S1</li> <li>n/w translation will be done by ?</li> <li><code>igw</code> **</li> <li>not, nat gtw</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#15-asg-scaling-type","title":"15.  ASG : Scaling type","text":"<ul> <li>scenario : sqs:metric --&gt; ASG --&gt; target:Ec2</li> <li>step</li> <li>simple</li> <li><code>Target tracking</code> ** ec2 cpu </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#16-recover-app-ec2-instance-and-its-data","title":"16. Recover App EC2 instance and its data *","text":"<ul> <li>start up appl, small load and critical</li> <li>recover with in 10 min</li> <li>options:</li> <li>CW:alarm on ec2:ebs --&gt; remedy ( <code>correct</code> )</li> <li>CW:alarm on ec2:ebs + instant store --&gt; remedy</li> <li>EventBridge alert on ec2 --&gt; remedy</li> <li>AWS trust Advisor --&gt; remedy (<code>Wrong</code>)<ul> <li>Basic and Developer Support Plans</li> </ul> </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#17-sqs-save-cost","title":"17. SQS : save cost **","text":"<ul> <li>Visible timeout : prevent duplicate consume </li> <li>long poll  <code>correct</code></li> <li>short poll </li> <li>message timer : no</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#18-de-couple-micro-service-in-aws","title":"18. De-couple Micro-service in AWS","text":"<ul> <li>SQS </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#19-fifo-queue","title":"19. FIFO Queue","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#20","title":"20.","text":"<ul> <li>ALB &gt; ECS (no ASG) &gt; service </li> <li>ALB &gt; ECS (add ASG) &gt; service</li> <li>Automate: ASG  will look CPU utilization of :</li> <li><code>service</code> : yes</li> <li>ALB : no</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#21-r53","title":"21. R53","text":"<ul> <li>dn1 --&gt; dn2 (not root/TLD) : use <code>cname</code> **</li> <li>dn1 --&gt; dn2 (if aws resource) : then use <code>alias</code>.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#22-nat-gateway","title":"22. NAT gateway","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#23","title":"23.","text":"<ul> <li>fully managed, <code>NoSQL</code>, <code>persistent</code> data store with <code>in-memory caching</code> to maintain low latency that is critical for <code>real-time scenarios</code></li> <li><code>concurrent users</code> to touch up to a <code>million</code>, so the database should be able to <code>scale</code> elastically.</li> <li></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#24-vpc-sharing-in-aws-org","title":"24. VPC sharing in AWS org","text":"<ul> <li>share one/more subnet (resource) with member account</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#25-rdsmysql-auroramysql","title":"25. RDS,MySQL --&gt; Aurora,MySQL","text":"<ul> <li>need &lt; 1 sec replica replication</li> <li>no development work</li> <li>but require admin work</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#26-ipsec-or-s2s-vpn-connect","title":"26. IPSec or S2S vpn connect","text":"<ul> <li>aws:vgw &lt;--&gt; Cgw:on-prem</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#27-r53-dns-resolver-inboundoutbound-endpoint","title":"27. R53 : dns resolver : inbound/outbound endpoint ?","text":"<ul> <li>AWS &lt;--direct connect --&gt; on-prem</li> <li>not found in latest code.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#28-vpn-cloud-hub","title":"28. VPN cloud hub","text":"<ul> <li>onprem:loc-1 &lt;-- direct connect --&gt; AWS-1:Loc-1</li> <li>AWS-1:loc-2:VPC  &lt;-- S2S VPN ---&gt;  AWS-1:loc-2:VPC</li> <li>connect All</li> <li>sol: VPN cloud hub</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#29-window-file-system-on-aws-smb-protocol","title":"29. Window File system on AWS (SMB protocol)","text":"<ul> <li>EFS ? POXIS, so no</li> <li>EBS ? not fs, no</li> <li>S3 ? no</li> <li>FSx for Windows ? ** yes</li> <li>File storage-gateway to s3 ? ** can be</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#30-which-is-preferred-tenancy-for-an-ec2","title":"30. which is preferred tenancy for an ec2 :","text":"<ul> <li>defined in launch type **</li> <li>defined in VPC</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#31-scale-up-vertical","title":"31. scale up vertical","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#32-rds","title":"32. RDS","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#33-use-zone-id-to-identify-az","title":"33. use <code>zone-ID</code> to identify AZ","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#34-s3-gateway-endpoint","title":"34. S3 gateway endpoint","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#35","title":"35.","text":"<ul> <li>S3 for scalable storage</li> <li>Ec2(web app deploy) + GA (cache + latency)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#36","title":"36.","text":"<ul> <li>highly available and fault-tolerant solution</li> <li>to capture the clickstream events from the source </li> <li>and then provide a concurrent feed of the data stream to downstream</li> <li>sol : KDS or KDF</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#37-scps-facteffects","title":"37. SCPs fact/effects","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#38-migrate-postgres-to-redshift-dms","title":"38. migrate Postgres to redshift : DMS","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#39","title":"39.","text":"<ul> <li>static webApp (few allowed client IP):  </li> <li>old : EC2:sg(ip inbound rule)</li> <li>new : CF &gt; S3<ul> <li>sol: CF:<code>attach WAF with IP filtering</code> &gt; S3 (bcuket-policy : add <code>OAC</code>)      </li> </ul> </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#40-network-nat-instance","title":"40. network : NAT instance","text":"<ul> <li>instance : support port forwarding, attach sg, bastion server</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#41-dynamodb-pitr","title":"41.  DynamoDB : PITR","text":"<ul> <li>to remove corrupt data.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#42-nlb-target-alb","title":"42. NLB --&gt; target : ALB","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#43-real-time-data-processing-kds","title":"43. Real time data processing: KDS","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#44-rds","title":"44. RDS","text":"<ul> <li>create repeating Read instance for report tool</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#45-kdf","title":"45. KDF","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#46-change-tenancy","title":"46. Change tenancy","text":"<ul> <li>default --&gt; XXXX , yes</li> <li>dedicated/host --&gt; XXXX, no</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#47-file-system","title":"47. file system","text":"<ul> <li>window file System</li> <li>shared</li> <li>integration with AD</li> <li>Sol: FSx for window</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#48-kds-kda","title":"48. KDS --&gt; KDA","text":"<ul> <li>real time Analysis</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#49-r53","title":"49. R53","text":"<ul> <li>abc.com --&gt; www.abc.com</li> <li>cname</li> <li>alias : cost-effective</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#50-data-migration","title":"50. Data migration","text":"<ul> <li>on-prem ---?---&gt; S3,FSx,EFS</li> <li>DataSync</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#51-hcp","title":"51. HCP","text":"<ul> <li>for networking use <code>EFA</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#52-cloudformation-stackset","title":"52. Cloudformation : StackSet","text":"<ul> <li>Ideal for multi-account and multi-region deployments, <code>consistently</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#53-db-migration-sct-and-dms","title":"53. DB migration : SCT and DMS","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#54-compliance-aws-config","title":"54. Compliance : AWS config","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#55-ebs","title":"55. EBS","text":"<ul> <li>25k IOPS : <code>io1</code> provisioned IOPS SSD **</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#56-save-s3-outbound-cost","title":"56. Save S3 : outbound cost","text":"<ul> <li>CF</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#57-udp-appl-live-score-improve-latency","title":"57. UDP appl (Live score) - improve latency","text":"<ul> <li>GA : no</li> <li>CF : no , not static content</li> <li>ELB : NLB support UDP</li> <li>ASG : no way</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#58-elb-cross-zone-balance-enabledisable","title":"58. ELB : Cross Zone balance - enable/Disable","text":"<ul> <li>Az-1 ec2-1</li> <li>Az-2 ec2-1,2,3,4</li> <li>enabled: each 20%</li> <li>disabled : 50% in Az1 + 12.5 each in az-2</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#59-use-reservce-instance","title":"59. use Reservce instance","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#60-serverless-solution","title":"60. Serverless solution:","text":"<ul> <li>S3, L, Dyanmo, CF</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#61-postpone-delivery-of-new-message-in-sqs","title":"61.  postpone delivery of new message in SQS","text":"<ul> <li>set delay 0 - 15 min while sending.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#62-ad","title":"62. AD","text":"<ul> <li>simple AD === AWS AD</li> <li>AD Connector --&gt; to on-prem AD</li> <li>AWS AD service --&gt; trust both : on-prem + AWS simple AD</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#63-elastic-cache-purpose","title":"63. Elastic Cache : purpose ?","text":"<ul> <li>heavy READ</li> <li>?</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#64-spot-and-spot-fleet","title":"64. spot and spot fleet","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-3/#65-cross-region-replication-a-sec-global-aurora","title":"65. Cross Region Replication &lt; a sec : Global Aurora","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/","title":"Wrong:","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#14-ebs","title":"14 EBS","text":"<ul> <li>General Purpose SSD (gp2) volumes offer cost-effective storage thanks io1.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#20-snowball-edge","title":"20. Snowball Edge","text":"<ul> <li>Offers <code>storage Clustering</code>.</li> <li>cone - no</li> <li>mobile -  no</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#35-s2s-vpn-slow","title":"35. S2s VPN - SLOW **","text":"<ul> <li>Create an  <code>Transit Gateway</code> with equal cost multipath routing</li> <li>and add additional <code>VPN tunnels</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#40-kda","title":"40. KDA","text":"<ul> <li>performs analytics to provide near-real-time product recommendations</li> <li>KDS --&gt; KDA --&gt; relatime analysis amd result --&gt; KDF --&gt; S3 (store result)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#41-cf","title":"41. CF","text":"<ul> <li>Use <code>field level encryption</code> , protect sensitive data</li> <li>route to <code>multiple origins</code> based on the content-type ( static , dynamic)</li> <li><code>origin-group</code></li> <li>ava : primary and secondary origins + with <code>failover</code></li> <li>can use geo restriction.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#42-ec2","title":"42. EC2","text":"<ul> <li>Run custom Batch job script</li> <li>2000 record * 3 sec for each to process</li> <li>Lambda out</li> <li>Glue out, more for RTL</li> <li>KDS out, for a million of realtime processing.</li> <li>EC2 left.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#55-event-bridge-vs-sqs","title":"55. Event-bridge vs SQS","text":"<ul> <li>EB integrates directly with third-party SaaS partners.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#57-available-and-low-cost","title":"57. available and low cost","text":"<ul> <li>keep 2 az only</li> <li>use RI</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#correct","title":"Correct","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#1","title":"1.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#2","title":"2.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#3","title":"3.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#4","title":"4.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#5","title":"5.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#6","title":"6.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#7","title":"7.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#8","title":"8.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#9","title":"9.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#10","title":"10.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#11","title":"11.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#12","title":"12.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#13","title":"13:","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#15","title":"15.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#16","title":"16.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#17","title":"17.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#18","title":"18. *","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#19","title":"19.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#21","title":"21.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#22","title":"22.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#23","title":"23.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#24","title":"24.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#25","title":"25.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#26-nlb-vs-alb","title":"26. NLB vs ALB","text":"<ul> <li>NLB --&gt; expose public IP --&gt; SaaS</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#27","title":"27.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#28","title":"28.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#29","title":"29.","text":"<ul> <li>hybrid cloud infrastructure : <code>S3</code> alongside its <code>on-premises</code></li> <li>dedicated private connection between them : DX</li> <li>public internet (secondary / failover) :  Site-to-Site VPN</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#30","title":"30.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#31","title":"31.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#32","title":"32 .","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#33","title":"33.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#34","title":"34.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#36","title":"36.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#37","title":"37.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#38","title":"38.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#39","title":"39.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#43","title":"43.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#44","title":"44.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#45","title":"45.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#46-s3-replication","title":"46 . S3 replication","text":"<ul> <li>one-time copy of the data from b1 to b2</li> <li><code>S3 sync</code> command + Set up  <code>S3 batch</code> replication</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#47-r53-ttl","title":"47. R53 : TTL","text":"<ul> <li>record updated, but reflected</li> <li>could be TTL, is still in effect</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#48","title":"48.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#49","title":"49.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#50","title":"50.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#51","title":"51.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#52","title":"52.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#53","title":"53.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#54","title":"54.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#56","title":"56.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#58","title":"58.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#59-only-resource-based-policy-that-the-iam-service-supports","title":"59.  only <code>resource-based policy</code> that the IAM service supports","text":"<ul> <li><code>trust policy</code></li> <li>check more on : </li> <li>resource-based policy</li> <li>identity-based policy</li> <li>diff b/w SCP and trust policy</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#60","title":"60.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#61","title":"61.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#62","title":"62.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#63","title":"63.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#64","title":"64.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-4/#65","title":"65.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/","title":"03.practice exam 5","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#1","title":"1.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#2","title":"2.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#3","title":"3.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#4","title":"4.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#5","title":"5.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#6","title":"6.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#7","title":"7.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#8","title":"8.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#9","title":"9.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#10","title":"10.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#11","title":"11.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#12","title":"12.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#13","title":"13:","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#14","title":"14","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#15","title":"15.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#16","title":"16.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#17","title":"17.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#18","title":"18.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#19","title":"19.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#20","title":"20.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#21","title":"21.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#22","title":"22.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#23","title":"23.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#24","title":"24.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#25","title":"25.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#26","title":"26.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#27","title":"27.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#28","title":"28.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#29","title":"29.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#30","title":"30.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#31","title":"31.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#32","title":"32 .","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#33","title":"33.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#34","title":"34.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#35","title":"35.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#36","title":"36.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#37","title":"37.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#38","title":"38.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#39","title":"39.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#40","title":"40.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#41","title":"41.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#42","title":"42.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#43","title":"43.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#44","title":"44.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#45","title":"45.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#46","title":"46 .","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#47","title":"47.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#48","title":"48.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#49","title":"49.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#50","title":"50.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#51","title":"51.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#52","title":"52.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#53","title":"53.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#54","title":"54.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#55","title":"55.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#56","title":"56.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#57","title":"57.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#58","title":"58.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#59","title":"59.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#60","title":"60.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#61","title":"61.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#62","title":"62.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#63","title":"63.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#64","title":"64.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-5/#65","title":"65.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/","title":"03.practice exam 6","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#1","title":"1.","text":"<ul> <li>?</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#2","title":"2.","text":"<ul> <li>?</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#3","title":"3.","text":"<ul> <li>on-prem &lt;--DX --&gt; aws</li> <li>make resilient quickly</li> <li>select 2:</li> <li>a. add one more dx : take weeks to set up, no.</li> <li>b. add VPN (s2s) as backup</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#4","title":"4.","text":"<ul> <li>az-1 : ec2-1</li> <li>az-2 : ec2-2</li> <li>az-3 : ec2-3</li> <li>single storage, highly available</li> <li>sol:</li> <li>a. EBS : no single AZ</li> <li>b. EBS in single AZ, primary --&gt; backup --&gt; replicate on other AZ ebs : no, hacky</li> <li>c. s3 : yes, multi-AZ</li> <li>d. instant store :single AZ</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#5-lambda","title":"5. Lambda","text":"<ul> <li>lambda : 15 min</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#6-rds-fact","title":"6. RDS : fact","text":"<ul> <li>AZ1(primary ) &lt;-- <code>sync</code> : replicate--&gt; AZ-2(stand-by)</li> <li>select 3</li> <li>auto-fail over</li> <li>maintenance : happens on standby --&gt; then standby becomes primary, after maintenance. ?</li> <li>backup source : primary or standby ?</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#7-security-attack","title":"7. Security : Attack","text":"<ul> <li>EC2 &gt; query over IP (used for crypto-currency)</li> <li>sol : <code>Authgaurd</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#8-storage-poxis","title":"8. Storage : POXIS","text":"<ul> <li>POXIS file System on Cloud </li> <li>sol : <code>EFS</code> (ia, archived )</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#9-security-kms","title":"9. Security : KMS","text":"<ul> <li>SE encyption : SSE and fully aws managed key</li> <li>AES 256 algo</li> <li>sol : <code>SSE-S3</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#10-database-cache","title":"10. Database : cache","text":"<ul> <li>RDBMS : complex/slopw queries in <code>multi-thread env</code> &gt; cache ?</li> <li>sol:</li> <li>redis </li> <li>memcache</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#11-security-s3","title":"11. Security : S3","text":"<ul> <li>S3 bucket</li> <li>encrypt each file with a different encryption key</li> <li>sol : sse-kms with <code>encryption-context</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#12-placement-group","title":"12. placement group","text":"<ul> <li>large distributed and replicated workloads</li> <li>minimize correlated hardware failures</li> <li>which placement group will be better : </li> <li>Sol: </li> <li>partition ,</li> <li>spread, cluster - no</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#13-high-availability","title":"13: high availability","text":"<ul> <li>monolith app:ec2-1 : high ava + less cost</li> <li>Select 2 :</li> <li>create ELB + ASG </li> <li>ASG (min=1,d=2, max=2)</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#14-redshift","title":"14  Redshift","text":"<ul> <li>source:S3 --&gt; data warehouse using Amazon Redshift</li> <li>after 30 days, the data is rarely queried , not \"hot data\" anymore. </li> <li>You would like to <code>preserve the SQL querying capability</code> on your data </li> <li>and get the <code>queries started immediately</code>. </li> <li>Also, save the maximum amount of <code>cost</code></li> <li>Sol: ?</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#15-security-access-control-on-efs","title":"15. Security : Access control on EFS","text":"<ul> <li>EC2-i1/2/3 --&gt; EFS</li> <li>exercise access control, so that no one else mount efs</li> <li>select 2:</li> <li>ACL</li> <li>IAM access </li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#16-network-bastion-vs-nat","title":"16. network : bastion vs NAT","text":"<ul> <li>establish secure connection between on-prem and aws</li> <li><code>quick turnaround time</code> to set up connection</li> <li><code>Cost</code> </li> <li>sol:</li> <li>bastion host</li> <li>S2S</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#17-database-rds","title":"17. Database : RDS","text":"<ul> <li>RDS(single region) - slow due to analytic</li> <li>sol : create Read replica in same region, point  analytic app to this.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#18-network-nat","title":"18. network : NAT","text":"<ul> <li>private subnet-1 : ec2-1</li> <li>private subnet-2 : ec2-2</li> <li>ec2-1/2 need internet access for patch/maintenance</li> <li>sol: create <code>one</code> NAT in any public subnet and update rt accordingly for private subnets</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#19-security-ad","title":"19. Security : AD","text":"<ul> <li>run AD on AWS</li> <li>Also  trust on-prem AD</li> <li>sol: </li> <li>AWS Directory service </li> <li>Simple AC, no</li> <li>AD connector , no</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#20-decoupling","title":"20. Decoupling","text":"<ul> <li>Application layer --&gt; DynamoDB database : high spike : Write exception</li> <li>Application layer --&gt; decouple ? --&gt; DynamoDB database</li> <li>sol:</li> <li>SQS,  </li> <li>KDS:no, db not as target</li> <li>SNS:no, for alert</li> <li>DAX : no , cache</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#21-storage-instant-store-fact","title":"21. Storage : instant store fact","text":"<ul> <li>can we specify, volume size of instant store which launching ec2 ? no</li> <li>Ec2 AMI preserves instant store data ? no</li> <li>detach and reattach from one ec2 instance to another ? no</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#22-database","title":"22. Database","text":"<ul> <li>OLTP, rdbms</li> <li>un-predictable</li> <li>sol : aurora serverless</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#23-analytics","title":"23. Analytics","text":"<ul> <li>big data analysis job leveraging : spark</li> <li>source and target : S3</li> <li>Sol:</li> <li>AWS batch, EMR</li> <li>Glue</li> <li>Athena</li> <li>RedShift</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#24-firewall-manager","title":"24. Firewall manager","text":"<ul> <li>advance waf</li> <li>Advance sheild</li> <li>VPC sg</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#25-database-cache","title":"25. Database cache","text":"<ul> <li>relation DB</li> <li>sol : mem or redis</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#26-user-data-script","title":"26. user Data Script","text":"<ul> <li>run custom script</li> <li>metadata script : its URL, not script use to get runtime metadata of ec2 instance.</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#27-s3-storage-class-intelligent-tier","title":"27. S3 storage class : intelligent tier.","text":"<ul> <li>not sure behaviour</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#28-rds-read-replica","title":"28. RDS : read replica","text":"<ul> <li>with same capacity and compute power</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#29-security","title":"29. Security","text":"<ul> <li>AWS org</li> <li>Account 1 : developer 1 (admin)</li> <li>Account 2 : developer 2 (admin)</li> <li>restrict  developer change AWS cloudtrail, other service</li> <li>sol: <code>SCP</code></li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#30-network","title":"30. Network","text":"<ul> <li>bastion host/s</li> <li>sol: ALB/NLB --&gt; fleet of bastion/s</li> </ul>"},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#31","title":"31.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#32","title":"32 .","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#33","title":"33.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#34","title":"34.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#35","title":"35.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#36","title":"36.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#37","title":"37.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#38","title":"38.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#39","title":"39.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#40","title":"40.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#41","title":"41.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#42","title":"42.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#43","title":"43.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#44","title":"44.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#45","title":"45.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#46","title":"46 .","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#47","title":"47.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#48","title":"48.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#49","title":"49.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#50","title":"50.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#51","title":"51.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#52","title":"52.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#53","title":"53.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#54","title":"54.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#55","title":"55.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#56","title":"56.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#57","title":"57.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#58","title":"58.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#59","title":"59.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#60","title":"60.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#61","title":"61.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#62","title":"62.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#63","title":"63.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#64","title":"64.","text":""},{"location":"01_aws/practice-test/SSA-attempt-1/03.practice-exam-6/#65","title":"65.","text":""},{"location":"01_aws/practice-test/whizlab/whizlab-ssa-exam-4-5/","title":"Whizlab ssa exam 4 5","text":""},{"location":"01_aws/practice-test/whizlab/whizlab-ssa-exam-4-5/#4","title":"4","text":""},{"location":"01_aws/practice-test/whizlab/whizlab-ssa-exam-4-5/#-","title":"-","text":""},{"location":"01_aws/practice-test/whizlab/whizlab-ssa-exam-4-5/#5","title":"5","text":""},{"location":"01_aws/practice-test/whizlab/whizlab-ssa-exam-6-7/","title":"Whizlab ssa exam 6 7","text":""},{"location":"01_aws/practice-test/whizlab/whizlab-ssa-exam-6-7/#6","title":"6","text":""},{"location":"01_aws/practice-test/whizlab/whizlab-ssa-exam-6-7/#7","title":"7","text":""},{"location":"02_docker/00_architecture/","title":"00 architecture","text":""},{"location":"02_docker/00_architecture/#key-points","title":"key points","text":"<ul> <li>container/s not completed isolated and share host kernal/os, but isolated based namespaces.</li> <li>all the process run by container/s, runs on the host but in their own <code>Namespaces</code>.</li> <li>process isolation : a container cannot see anything out of its namespace.</li> <li><code>ps aux</code> show all process</li> <li>a - all user</li> <li>u - user-oriented format</li> <li>u - includes daemon process</li> <li>same process has diff pid in diff namespace. </li> <li>by default, docker runs container with <code>root</code> user on host (with less Linux capability)</li> <li>dockerfile &gt; USER &lt; userID &gt;</li> <li>docker run --user option</li> <li>Docker host : on host machine install docker</li> <li>eg: docker desktop on out laptops.</li> <li>all containers runs on this  docker host.</li> <li>.dockerignore : </li> <li>Specifies files/directories that should be excluded when building a Docker image.</li> <li>Reduces build context size</li> <li>Prevents sensitive files (e.g., .env, credentials.json) from accidentally being copied into the image.</li> </ul>"},{"location":"02_docker/00_architecture/#layered-arch","title":"Layered Arch","text":""},{"location":"02_docker/00_architecture/#registry","title":"Registry","text":""},{"location":"02_docker/00_architecture/#container-security","title":"Container Security:","text":"<ul> <li>--user &lt; userID &gt; </li> <li>--cap-add/drop &lt; CAPABILITY &gt;</li> <li>Add these at:</li> <li>container level :  </li> <li>pod level :        </li> <li>both present, container will override.</li> </ul> <ul> <li>pod-1</li> <li>c1<ul> <li>process-1: port-1</li> <li>process-2 : port-2</li> <li>...</li> </ul> </li> <li>c2<ul> <li>process-11 : port-11</li> <li>process-22 : port-22</li> <li>...</li> </ul> </li> </ul>"},{"location":"02_docker/00_architecture/#dockers-architecture","title":"Docker's architecture","text":"<ul> <li>Docker Engine / container-d</li> <li>core runtime that powers Docker. </li> <li>It is a lightweight, modular application consisting of:<ul> <li>Docker Daemon (<code>docker-d</code>) </li> <li>A background service </li> <li>manages Docker objects (containers, images, networks, volumes).</li> <li>Handles container lifecycle</li> <li>Pulls/pushes images from/to registries.</li> <li>create layers</li> <li>REST API \u2013 Allows interaction with the daemon programmatically (e.g., via CLI or SDKs).</li> <li>CLI (optional)</li> <li>container-d</li> </ul> </li> <li>Docker Images</li> <li>read-only template used to create containers</li> <li>each instruction in a Dockerfile creates a new layer</li> <li>Application code + dependencies (libraries, runtime)</li> <li>Metadata (environment variables, default commands)</li> <li>Container</li> <li>runnable instance of an image</li> <li>Isolated process running on the host OS via namespace.</li> <li>Shares the host kernel </li> <li>but has its own filesystem <pre><code>Docker Client (CLI)  \n       \u2193 (REST API)  \nDocker Daemon (dockerd) \u2192 Manages \u2192 Images \u2192 Containers  \n       \u2191  \nRegistry (Docker Hub, ECR, etc.)  \n</code></pre></li> </ul>"},{"location":"02_docker/00_commands/","title":"00 commands","text":"<ul> <li>docker <code>build</code> -t repoName/image-1:version . or -f Dockefile-1</li> <li>docker pull | push | login</li> </ul>"},{"location":"02_docker/00_commands/#image","title":"image","text":"<ul> <li>docker images  </li> <li>docker rmi image-1</li> <li>docker tag image-id-1 name:version/latest</li> </ul>"},{"location":"02_docker/00_commands/#container","title":"Container","text":""},{"location":"02_docker/00_commands/#common","title":"common","text":"<ul> <li>docker <code>run</code> </li> <li>your-command  (optional, eg sleep 5000) </li> <li>--name = container-name - c1</li> <li>-it </li> <li>-d </li> <li>-v </li> <li>--mount type=volume, source=vol-1, target=location-on-container</li> <li>-e k=v -e k=v ... </li> <li>-p host:container </li> <li>--network = n1 </li> <li>--user 100 </li> <li>--cap-add/drop CAPABILITY-1  --cap-add/drop CAPABILITY-2 ...</li> <li>--entrypoint python app-1.py --&gt; override ENTRYPOINT [\"python\", \"app-1.py\"]</li> <li> <p>registry-1/repoName-1/image-1:latest    image at last</p> </li> <li> <p>docker <code>ps</code> -a</p> </li> <li>docker start | stop | restart c1</li> <li>docker rm c1</li> <li>docker exec c1  <li>docker logs -f c1 : live log trail</li> <li>docker inspect nspect a container's network configuration</li>"},{"location":"02_docker/00_commands/#volume-and-network","title":"volume and network","text":"<ul> <li>docker volume create vol-name-1:location-on-host</li> <li>docker network create  --driver=bridge --subnet ... n1</li> </ul>"},{"location":"02_docker/00_commands/#dockerfile-text-file","title":"dockerfile (text file)","text":"<ul> <li>FROM : Specifies the base image</li> <li>ENDPOINT : </li> <li>Specifies the primary command to run inside the container</li> <li>always executed when the container starts</li> <li>any arguments provided to <code>docker run</code> will be appended to the command defined in ENTRYPOINT</li> <li>ENTRYPOINT [\"python\", \"app-1.py\"] : no argument</li> <li>CMD </li> <li>Purpose: Provides default arguments for the command specified in ENTRYPOINT</li> <li>ENTRYPOINT [\"python\"] + CMD [\"app-2.py\"]</li> <li>CMD [\"python\", \"app-1.py\"] --&gt; will also work</li> <li>RUN</li> <li>RUN apt-get update &amp;&amp; apt-get install -y curl</li> <li>RUN pip install</li> <li>ADD</li> <li>WORKDIR</li> <li>EXPOSE 8080</li> <li>COPY</li> <li>ENV NODE_ENV=production</li> <li>ARG APP_VERSION=1.0 , Defines build-time variables</li> <li>VOLUME /data</li> <li>USER userId  </li> <li>by default all process run the <code>root user</code> (with limited set of capability)</li> </ul> <p><pre><code>### apk ###\n\napk update\napk add --no-cache package-name (eg: curl)\napk del package-name\napk search package-name\napk info\n\n# Combine apk commands into one block to reduce image layers and improve build performance.\n# Use --no-cache to avoid storing index files and temporary data in the final image\n# rm -rf /var/cache/apk\n</code></pre> - Reduce size of image:   - Multi-stage builds   - Alpine-based images    - remove unnecessary dependencies.   - docker scan</p>"},{"location":"02_docker/01_docker-compose/","title":"Docker compose","text":""},{"location":"02_docker/01_docker-compose/#intro","title":"intro","text":"<ul> <li>tool used to define and run multi-container Docker applications on a single Docker host.</li> <li><code>docker-swam</code> is native container orchestration tool.</li> <li>file name : docker-compose.yml</li> <li>command : docker-compose up</li> </ul>"},{"location":"02_docker/01_docker-compose/#features","title":"Features","text":"<ul> <li><code>Service Definition</code>: expose container and access them dn.</li> <li><code>Multi-container Setup</code>: Simplifies the management of multiple related containers (like a web app, database, etc.) running on the same Docker host.</li> <li><code>Environment Variables</code>: Supports environment variable configuration for different environments (development, production, etc.).</li> <li><code>Networking</code>: Automatically creates a network for the services to communicate with each other.</li> <li><code>Volumes</code>: Supports persistent storage via volumes and allows mounting host directories to containers.</li> </ul>"},{"location":"02_docker/01_docker-compose/#versions","title":"versions :","text":""},{"location":"02_docker/01_docker-compose/#version-3","title":"version-3  **","text":"<ul> <li>example</li> <li>will start the nginx web server and the PostgreSQL database, </li> <li>linking them through the custom network : webnet. </li> <li>You can access the web service by navigating to http://localhost:8080 <pre><code>version: '3.8'\n\nservices:\n  web:\n    image: nginx:latest\n    container_name: nginx-web\n    ports:\n      - \"8080:80\"  # Maps port 8080 on the host to port 80 on the container\n    volumes:\n      - ./html:/usr/share/nginx/html  # Mounts the local 'html' folder to the container\n    networks:\n      - webnet\n\n  db:\n    image: postgres:latest\n    container_name: postgres-db\n    environment:\n      POSTGRES_USER: user\n      POSTGRES_PASSWORD: password\n      POSTGRES_DB: mydatabase\n    volumes:\n      - db-data:/var/lib/postgresql/data  # Persist database data\n    networks:\n      - webnet\n\nnetworks:\n  webnet:\n    driver: bridge\n\nvolumes:\n  db-data:\n    driver: local\n</code></pre></li> </ul>"},{"location":"02_docker/01_docker-compose/#version-2","title":"version-2","text":"<ul> <li>by default create one network ( name:current_dir_default ) and associate all containers with it.</li> <li><code>services</code>:<ul> <li>container-name-1 :<ul> <li>link not needed, already link all container/s (within default n/w) with each other.</li> <li>for external network can add link.</li> </ul> </li> <li>container-name-1 :</li> <li><code>depends on</code> :</li> <li>network/s:<ul> <li>network-1</li> <li>network-2</li> <li>one container can be associated with multiple networks</li> </ul> </li> </ul> </li> <li><code>networks</code>:<ul> <li>can also create</li> <li>network-1</li> <li>network-2</li> </ul> </li> </ul>"},{"location":"02_docker/01_docker-compose/#version-1","title":"version-1","text":"<ul> <li>container-name-1 :<ul> <li>image or build :</li> <li>ports:</li> <li>environment:<ul> <li>ENV_1: xxxxx</li> <li>ENV_2: xxxxxx</li> </ul> </li> <li>link:<ul> <li>db:db or just db, which become hostname.</li> <li>redis:rd</li> </ul> </li> </ul> </li> <li>container-name-2 :</li> <li>container-name-3 :</li> <li>note: sequence of container matters. v2 has depends-on.</li> </ul>"},{"location":"02_docker/02_engine/","title":"02 engine","text":""},{"location":"02_docker/02_engine/#docker-engine","title":"Docker engine","text":"<ul> <li>connect to remote dcoker host.</li> <li>export DOCKER_HOST=tcp://:2375 <li>docker info</li> <li>docker run -H=tcp://:2375"},{"location":"02_docker/02_engine/#namespace-pid","title":"Namespace - pid","text":"<ul> <li>namespace provides isolation</li> <li>all process running on host kernal, but namespace provodes isolation.</li> <li>same process has different pid in diff namespaces.</li> <li> </li> <li> <p>restrict resource, which running container:</p> </li> <li><code>--cpus</code>=0.5</li> <li><code>--memory</code>=500m</li> </ul>"},{"location":"02_docker/03_Storage/","title":"03 Storage","text":""},{"location":"02_docker/03_Storage/#astorage","title":"A.Storage","text":"<ul> <li>storage drivers : based on OS picks correct one.</li> </ul> <pre><code>side note: \n/var/lib/docker/below-folder --&gt; check this location\n  - containers\n  - images:  Stores all layers\n  - volumes : \n    - Docker-managed volumes to store data here\n    - Volumes can be shared between containers\n    - allow to manage data seperately from host \n    - /var/lib/docker/vol-1 -- better\n    - /path/to/host/dir  - host + container, both using them\n</code></pre> <ul> <li>first create volume </li> <li>docker volume create vol-1:location-on-host</li> <li> <p>check <code>/var/lib/docker/vol-1</code> then.</p> </li> <li> <p>second, it Mount</p> </li> <li>-v is old, use <code>--mount</code> on docker run ....</li> <li>--mount type=volume, source=vol-1 (/var/lib/docker/vol-1),           target=/container/path</li> <li>--mount type=bind,   source=/path/to/host/dir , target=/container/path</li> </ul>"},{"location":"02_docker/03_Storage/#zscreenshots","title":"Z.Screenshots","text":""},{"location":"02_docker/04_network/","title":"04 network","text":""},{"location":"02_docker/04_network/#network","title":"network","text":"<ul> <li>docker <code>inspect</code>  : it will network details"},{"location":"02_docker/04_network/#1-bridge","title":"1. bridge","text":"<ul> <li><code>project_dir_default</code> - one bridge n/w (default)</li> <li>all containers are connected.</li> <li></li> <li>can create many bridge n/w.</li> <li>docker network create  --driver=bridge --subnet ... n1</li> <li> </li> <li> <p>Embedded DNS</p> </li> <li><code>privateIP</code> == containerName(act as hostname)</li> <li></li> </ul>"},{"location":"02_docker/04_network/#2-host","title":"2. host","text":"<ul> <li>internet</li> <li>intranet - inf, cg, etc</li> </ul>"},{"location":"02_docker/04_network/#3-none","title":"3. none","text":"<ul> <li>c1 is not connected to host n/w + default n/w</li> <li>hence c1 cannot be exposed.</li> <li>c1 cannot connect to other container c2,c3,...</li> </ul>"},{"location":"02_docker/04_network/#screenshots","title":"Screenshots","text":""},{"location":"02_docker/05_developer-Notes/","title":"developer notes","text":"<ul> <li>java -Djarmode=layertools -jar ./target/spring-app-1.0.0.jar extract</li> <li>extract a Spring Boot layered JAR file </li> <li>Spring Boot 2.3.0+</li> <li>chmod +x ./target/spring-app-1.0.0.jar</li> <li>layes:<ul> <li>dependencies/</li> <li>spring-boot-loader/</li> <li>snapshot-dependencies/ (if any)</li> <li>application/</li> </ul> </li> </ul>"},{"location":"02_docker/readme/","title":"Readme","text":"<ul> <li>https://learn.kodekloud.com/user/courses/docker-training-course-for-the-absolute-beginner</li> </ul>"},{"location":"03_Kubernetes/01_k8s-interview-question/","title":"01 k8s interview question","text":"<ul> <li>reference/s:</li> <li>https://chat.deepseek.com/a/chat/s/7ad6e329-5ae5-4ae7-9d7c-e7fa955f4966</li> </ul>"},{"location":"03_Kubernetes/01_k8s-interview-question/#developer-question","title":"Developer Question","text":"<ul> <li>https://chat.deepseek.com/a/chat/s/82016b25-91dd-4e7a-9672-92979fe31339</li> <li>Checking Logs from Multiple Kubernetes Pods</li> <li>kubectl logs -l app=my-app -n my-namespace  [-c  ] --tail=100  // label <li>kubectl logs pod/pod-1 pod/pod-2 --prefix</li> <li>Kubernetes Dashboard provides a GUI. eg: lens.</li> <li>kubectl logs -l app=my-app --previous // for Crashed Pods</li> <li>filter log:<ul> <li>| jq 'select(.level == \"error\")'</li> <li>| grep \"ERROR\"</li> </ul> </li> <li>Default Location --&gt; Node-level: /var/log/containers/<ul> <li>Rotated every 10MB, max 5 files</li> <li>--container-log-max-size, --container-log-max-files</li> </ul> </li> <ul> <li>AWS cw log</li> <li>By default, EKS doesn't send application logs to CloudWatch - only control plane logs</li> <li>/aws/eks//cluster <li>/aws/eks//workload// <li>aws logs filter-log-events \\     --log-group-name \"/aws/eks/my-cluster/workload/my-namespace/my-pod\" \\     --start-time $(date -d '1 hour ago' +%s000) \\     --filter-pattern \"ERROR\"</li> <ul> <li>take heap dumps from pod before, it died</li> <li><code>-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/path/to/dump.hprof</code></li> <li>JVisual, jhat for local</li> <li>actuator will die, so cant use it.</li> </ul> <ul> <li>Access a service running in Kubernetes without exposing it publicly in dev env.</li> <li>forward traffic from your local machine to a Kubernetes service<ul> <li>kubectl port-forward svc/my-app-service 5000:80 -n  <li>8080 is the port on your local machine.</li> <li>80 is the port exposed by the my-app-servic</li> <li>forward directly to a pod (if the service has no pods<ul> <li>kubectl port-forward pod/my-pod-name 5000:80</li> </ul> </li> <ul> <li>Shell into a running pod</li> <li>kubectl exec -it  -- /bin/sh <ul> <li>Mount ConfigMap/Secret as volume <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  containers:\n  - name: app\n    image: nginx\n    volumeMounts:\n    - name: config-volume\n      mountPath: /etc/config  &lt;&lt;&lt;\n  volumes:\n  - name: config-volume\n    configMap:\n      name: my-config-1\n</code></pre></li> <li>Rolling Updates &amp; Rollbacks</li> <li>kubectl set image deployment/my-app app=nginx:1.25 (old)</li> <li>kubectl rollout status deployment/my-app</li> <li>kubectl rollout undo deployment/my-app  // prvious version</li> <li>kubectl rollout history deployment/my-app</li> </ul> <ul> <li>what is log file location in aws eks fargate , clould watch logs not enabled </li> <li>Default Log Behavior in Fargate (No CloudWatch)<ul> <li>Fargate does not store logs on disk</li> <li>CloudWatch Logs is disabled</li> <li>logs are ephemeral\u2014they disappear when the pod terminates or crashes.</li> <li>container\u2019s stdout/stderr buffer</li> <li>use Sidecar Container for Log Forwarding to S3</li> <li>image: amazon/aws-for-fluent-bit:latest</li> <li>env : AWS_REGION, S3_BUCKET</li> <li>awslogs driver : ```yaml containers:</li> <li>name: app   image: nginx   # Add logging driver   logging:     driver: awslogs     options:       awslogs-group: \"/eks/fargate-logs\"       awslogs-region: \"us-east-1\"       awslogs-stream-prefix: \"my-app\"   ```</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/readme/","title":"Readme","text":""},{"location":"03_Kubernetes/readme/#hands-on","title":"hands on:","text":"<ul> <li>deployment project (minikube) : readme.md</li> <li>terraform (cluster set-up) :  eks  | ecs</li> </ul>"},{"location":"03_Kubernetes/readme/#ckad-certfication","title":"CKAD (Certfication)","text":"<ul> <li>02_KCAD - Notes</li> <li>00_topic.md</li> <li>02_commands.txt</li> <li>03_lab.md</li> <li>00_sample_yaml</li> </ul>"},{"location":"03_Kubernetes/readme/#aws","title":"AWS","text":""},{"location":"03_Kubernetes/readme/#eks","title":"EKS","text":"<ul> <li>00_EKS_reference.md</li> <li>workshop : https://catalog.us-east-1.prod.workshops.aws/workshops/afee4679-89af-408b-8108-44f5b1065cc7/en-US/010-introduction/basics/concepts-objects</li> <li>eksctl: https://github.com/eksctl-io/eksctl/tree/main/examples</li> <li>Terraform Module : eks</li> </ul>"},{"location":"03_Kubernetes/readme/#ecs","title":"ECS","text":"<ul> <li>03_ECS</li> </ul>"},{"location":"03_Kubernetes/readme/#more","title":"More","text":""},{"location":"03_Kubernetes/readme/#interview-q-green_circle","title":"Interview Q :green_circle:","text":"<ul> <li>01_k8s-interview-question.md</li> </ul>"},{"location":"03_Kubernetes/readme/#kick-off-links","title":"kick off links","text":"<ul> <li>https://www.youtube.com/watch?v=qof9A8k64rA&amp;list=PLVz2XdJiJQxybsyOxK7WFtteH42ayn5i9&amp;ab_channel=JavaTechie</li> <li>https://www.youtube.com/watch?v=XuSQU5Grv1g&amp;t=527s&amp;ab_channel=KodeKloud</li> <li>https://learning.edx.org/course/course-v1:LinuxFoundationX+LFS158x+1T2024/home</li> <li>https://learning.edx.org/course/course-v1:edX+DemoX.1+2T2019/home</li> </ul>"},{"location":"03_Kubernetes/readme/#chatgpt","title":"chatgpt","text":"<ul> <li>k8s - 01 cases tudies https://chatgpt.com/c/6726267e-2a8c-487d-8ffe-937c2c4d0f0f</li> <li>k8s - 02 Containers https://chatgpt.com/c/9836b4c7-2b23-497e-b06b-16885e3e18aa</li> <li>k8s - 03 Components https://chatgpt.com/c/da40b952-dbd9-46a9-ad58-92c828a89118</li> <li>k8s - 04 helm https://chatgpt.com/c/da40b952-dbd9-46a9-ad58-92c828a89118</li> <li>k8s - Questions https://chatgpt.com/c/babb0cb6-b6f1-4427-8384-da10f068ed29</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/01_monolith_MicroServices/","title":"Kubernetes / K8s","text":"<ul> <li>Google/CNCF</li> <li>k8s - 01 intro: https://chatgpt.com/c/6726267e-2a8c-487d-8ffe-937c2c4d0f0f</li> <li>Monolithic  vs Microservice</li> <li>microservices advantages in the cloud</li> <li>monolith's challenges in the cloud</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/01_monolith_MicroServices/#monolithic","title":"Monolithic","text":"<ul> <li>Entire software run as <code>single heavy process</code> on <code>expensive hardware</code></li> <li>tightly couple</li> <li>legacy design and architecture.</li> <li>redundant logic, 1000 lines of code, no modern language and design principles.</li> <li> <p>built with a single technology stack</p> </li> <li> <p>Not designed to take full advantage of cloud-native features such as cloud's elasticity/auto-scaling, managed services, and distributed architectures.  </p> </li> <li>other challenges and limitation:</li> <li><code>scaling</code> of single feature in impossible, and scaling whole app is pricey.</li> <li><code>upgrade</code> : downtime and upgrade window.</li> <li><code>failure</code> in any part of a monolithic application can potentially bring down the entire system</li> <li>Higher <code>operational costs</code> and less efficient use of computational resources.</li> <li><code>size grows</code>: new updates/features, keep on making appl more <code>heavy</code>.</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/01_monolith_MicroServices/#micro-service","title":"Micro service","text":"<ul> <li>architecture: https://chatgpt.com/c/2f54de12-b416-4a76-80a0-ebd286b0c467</li> <li>small independent services,  lightweight applications, for each business/feature.</li> <li><code>On-demand scalability</code> : run MS on different hosts /Availability</li> <li><code>Optimal resource usage</code> : run on matching hardware-requirement| efficeint | low cost.</li> <li><code>distributed nature</code> : whole app is distributed among many MS. which adds up some complexity.</li> <li>Seamless updates(rollout)/rollbacks without any downtime.</li> <li><code>Fault-tolerance</code>:</li> <li>system continues to operate properly in the event of the failure of some of its components</li> <li><code>Service-discovery</code></li> <li>process of automatically detecting network locations of service instances.</li> <li><code>service registry</code> - database of available service instances. eg :  Netflix Eureka<ul> <li>client --&gt; <code>service registry</code> </li> <li>client --&gt; load balancer &gt; queries to service registry.</li> </ul> </li> </ul> <p>can run on Cloud and take full advantage of cloud.</p>"},{"location":"03_Kubernetes/00_kickOff/01_monolith_MicroServices/#monolithic-microservice","title":"Monolithic --&gt; Microservice","text":"<ul> <li>modernize monolith business applications / Distributed software.</li> <li>Not all monolithic app is good candidate.</li> <li>complex and risky, due to its tightly coupled components and dependencies.</li> <li>not smooth, has to survive below challenges:</li> <li><code>Refactoring phase</code> : break down into modules</li> <li><code>application resiliency</code> as whole.</li> <li><code>Choosing runtimes</code> on cloud : <ul> <li>underlying OS, hardware, library, runtime env for each MS. there might be conflict.</li> <li>running well on one hardware/runtine , but not working same on other.</li> <li>Solution:<code>Application containers</code>:</li> <li>encapsulated <code>lightweight</code> runtime environments.</li> <li>promised <code>consistent</code> software environments.</li> <li>each MS/module running in their own execution environments <code>isolated</code> from one another.</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/00_kickOff/02_Container_orchestration/","title":"02 Container orchestration","text":"<ul> <li>reference:</li> <li>Containers : https://chatgpt.com/c/9836b4c7-2b23-497e-b06b-16885e3e18aa</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/02_Container_orchestration/#a-containers","title":"A. Containers","text":"<ul> <li><code>isolated environment</code> : physical machine &gt; VM &gt; Containers(host OS)</li> <li>Containers are similar to VMs, but share the Operating System (OS) among the applications.</li> <li>Therefore, containers are considered lightweight.</li> <li>Similar to a VM, a container has its own filesystem, share of CPU, memory, process space, and more.</li> <li>As they are decoupled from the underlying infrastructure, they are portable across clouds and OS distributions.</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/02_Container_orchestration/#container-images","title":"Container images","text":"<ul> <li>eg: Docker image</li> <li>image built on OS-1 as base, can be run my machine having window OS. docker desktop in between.</li> <li>best suited for microservices/MS by providing <code>portability</code> and <code>isolated VM</code></li> <li><code>executable package</code>, which confine the  <code>code,runtime and dependencies, env var+configFile</code> in a pre-defined format.</li> <li>Composed of <code>multiple layers</code>, stacked on top of a base image.</li> <li>Images are stored in <code>repositories</code>, which can be public or private. eg : Docker Hub, ECR</li> <li><code>versioned</code> using tags</li> <li>Security:<ul> <li>Use <code>trusted base-images</code></li> <li>identify <code>vulnerabilities</code> in images and upgrade it. docker has built in scanner.</li> <li>regularly update images to include security patches.</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/00_kickOff/02_Container_orchestration/#container-runtime","title":"Container runtime","text":"<ul> <li>eg: Docker Engine</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/02_Container_orchestration/#b-container-orchestrators","title":"B. Container orchestrators","text":"<ul> <li>framework for managing containers at scale at runtime</li> <li>For Distributed-System (ms), provides deployment patterns of container.</li> <li>automate the deployment<ul> <li>release - rollout / rollback</li> </ul> </li> <li>scale</li> <li>service discovery + networking</li> <li>storage</li> <li>config + secrets</li> <li>orchestrators make things easier, when managing hundreds or thousands of containers.</li> <li>offerings: </li> <li>Docker Swarm (native)</li> <li>Kubernetes/k8s - minikube, EKS, AKS</li> <li>AWS - ECS</li> <li>marathon</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/","title":"03 k8s architcture+features","text":"<ul> <li>reference:</li> <li>https://chatgpt.com/c/da40b952-dbd9-46a9-ad58-92c828a89118</li> <li>https://www.youtube.com/playlist?list=PLVz2XdJiJQxybsyOxK7WFtteH42ayn5i9</li> <li>https://kubernetes.io/docs/concepts/overview/components/</li> <li>https://kubernetes.io/docs/tasks/tools/</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#k8s-architecture","title":"K8s Architecture","text":""},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#a-cluster","title":"A. cluster","text":""},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#master-node-1-control-panel","title":"<code>master Node</code> (1) / control panel","text":"<ul> <li>Checks memory, health, CPU, etc for each WorkerNode.<ul> <li><code>Kube-API Server</code> :<ul> <li>cluster-gateway</li> <li>any request comes to cluster --&gt; gateway --&gt; WorkerNode --&gt; ...</li> </ul> </li> <li><code>Scheduler</code><ul> <li>if WorkerNode-1 is 90%  and WorkerNode-1 is 30%, used.</li> <li>then scheduler will assign new pods in WorkerNode-1</li> <li>takes data from ETCD.</li> <li>responsible for assigning workloads (pods) to nodes.</li> <li>ensures workloads meet certain constraints and resource requirements.</li> </ul> </li> <li><code>ETCD</code> :Persistence store.</li> <li><code>Controller manager</code><ul> <li>runs <code>processes</code> in the background to regulate the state of the cluster.</li> <li>Types/eg:<ul> <li>Node Controller</li> <li>replication controller</li> <li>Endpoints Controller</li> <li>Service account and token Controller</li> </ul> </li> </ul> </li> <li><code>Cloud Controller Manager</code><ul> <li>enabling Kubernetes to interact with underlying cloud provider APIs.</li> </ul> </li> </ul> </li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#worker-node-many","title":"<code>worker Node</code> (Many)","text":"<ul> <li>Container <code>Runtime</code></li> <li>to run containers (present inside Pods)</li> <li><code>Kubelet</code></li> <li>agent running on each node.</li> <li>masterNode::API-Server &lt;--&gt;  Kubelet-WorkerNode</li> <li>Kubelet communicate with masterNode using API-server</li> <li><code>kube-proxy</code></li> <li>Network config</li> <li>Network traffic Rule (from/to nodes) ingress/outgress</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#service-account","title":"<code>Service Account</code>:","text":"<ul> <li>represents processes running inside the Kubernetes cluster.</li> <li>Managed within Kubernetes</li> <li>created inside ns</li> <li>Service accounts use secrets that are automatically created and mounted to pods running under them.</li> <li>permission / <code>RBAC</code> : create role and role-binding for SA. (fine granular access)</li> <li>authentication not needed.</li> <li>scenario / use case:</li> <li>pod using sa<ul> <li>sa token already generated and mounted on pod.</li> </ul> </li> <li>jenkin using sa - api call with sa token in Authorization header.<ul> <li>how to generate token</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#b-outside-cluster","title":"B. outside cluster","text":""},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#user","title":"<code>User</code>:","text":"<ul> <li>eg: An admin using <code>kubectl</code> to create a deployment.</li> <li>Represents a real human (<code>admins</code> / <code>developers</code>) or an external entity accessing the Kubernetes cluster.</li> <li>Users are not managed by Kubernetes itself.</li> <li>they are managed outside of Kubernetes and autheticated through an <code>ext identity provider, OIDC</code>, <code>certificate management</code>, etc.).<ul> <li>minikube : certificate management</li> <li>EKS : identity provider</li> </ul> </li> <li>fine granular access - create role and role binding<ul> <li>admin : when cluster created one default admin is created with admin access.</li> <li>developer user :<ul> <li>admin will create role and role binding</li> <li>role binding - &gt; role ref + subject(kind:user, name - use same user-name in kubeconfig file.) </li> </ul> </li> </ul> </li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#summary","title":"summary","text":""},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#1-k8s-componenets","title":"1. k8s componenets","text":"<ul> <li> <p>hierarchy :</p> <ul> <li><code>cluster</code> --&gt; <code>node</code> --&gt; <code>pod</code>,IP,workloads,posSpecYml/Json</li> <li><code>container</code> --&gt; <code>app</code></li> </ul> </li> <li> <p><code>Pods</code>:</p> <ul> <li>The smallest deployable units in Kubernetes that you create and manage.</li> <li>pod/node talk to each other using <code>Service</code> (has DNS).</li> </ul> </li> <li> <p><code>Replica Set</code>:</p> <ul> <li>one pod goes down another comes up from replica set.</li> <li>ensures certain no. of pod running at specific time at all the time.</li> <li>uses selectors(label query)</li> <li>scale in/out replica count : <code>horizontal scale</code>.</li> <li>span with cluster.</li> <li>Self-Healing:<ul> <li>If any of the pods managed by a ReplicaSet are deleted or fail, the ReplicaSet controller will create new ones to maintain the desired number of replicas.</li> </ul> </li> </ul> </li> <li> <p><code>Deployment Object</code></p> <ul> <li>higher-level concept that manages ReplicaSets + <code>updates on pods</code>/rollup/rollback.</li> </ul> </li> <li> <p><code>scheduler</code></p> <ul> <li>decides which node, a pod is assigned to.</li> </ul> </li> <li> <p><code>Kube-Controller-Manager</code></p> <ul> <li>Runs various controller processes in the background to regulate the state of the cluster.</li> <li>Node Controller, Replication Controller, Endpoints Controller,etc</li> </ul> </li> <li> <p><code>Services</code>:</p> <ul> <li>Abstract a set of pods and provide a consistent way to access them, even if the individual pods' IP addresses change.</li> </ul> </li> <li> <p><code>Nodes</code>:</p> <ul> <li>The worker machines in the Kubernetes cluster, which can run multiple pods.</li> <li>typically runs on a separate virtual machine (VM), but this is not a strict requirement.</li> <li>in AWS, each node is  seperate  VM for isolation.</li> <li>VMs can be easily resized, moved, or replicated,</li> <li>contains: kubelet, kube-proxy, container-runtime.</li> </ul> </li> <li> <p><code>Secret</code>:</p> <ul> <li>Store DB config, password, etc outside SB app. then we dont need to build it again.</li> <li>encrypted text, outside pod</li> </ul> </li> <li> <p><code>Config map</code> : Plain text, outside pod.</p> </li> <li> <p><code>ETCD</code> :</p> <ul> <li>key-Value database/store,</li> <li>1MB max of a value.</li> <li>store all its cluster data, such as cluster state, configurations, and metadata.</li> </ul> </li> <li> <p><code>services</code></p> <ul> <li>An abstract way to expose an application running on a <code>set of Pods</code>, as a network service.</li> <li>has DNS and static IP</li> <li>3 types:<ul> <li><code>ClusterIP</code> : Exposes the service on a cluster-internal IP.</li> <li><code>NodePort</code> : Exposes the service on each Node's IP at a static port</li> <li><code>LoadBalancer</code> : Creates an external load balancer in the cloud provider (if supported) and assigns a fixed, external IP to the service.</li> </ul> </li> <li>Single Service for Multiple Pods (all having same image)</li> <li>Separate Services for Different Pods (each having diff image)</li> </ul> </li> <li> <p>ingress controller (nginx, aws:alb, etc) and ingress-object</p> </li> <li> <p>admission controller, ServiceAcct, role, role binding.</p> </li> <li> <p>Add On:</p> <ul> <li><code>DNS Server</code></li> <li><code>metric Server</code></li> <li>Web based <code>UI</code></li> <li>Cluster level <code>logging</code></li> <li>ingress controller ??</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#2-k8s-features","title":"2. k8s features","text":"<ul> <li> <p>can be deployed on cloud(ec2), on-prem(host), IaaS (EKS).</p> </li> <li>Automate the Container deployment at <code>scale</code><ul> <li>Horizontal scaling : add up/down more pods.</li> </ul> </li> <li><code>Automated Rollouts and Rollbacks</code>:<ul> <li>Automatically roll out changes and roll them back if something goes wrong.</li> </ul> </li> <li><code>Service Discovery and Load Balancing</code>:<ul> <li>Automatically assigns stable IP addresses and a single DNS name() for a set of containers),</li> <li>to facilitate load balancing and service discovery.</li> </ul> </li> <li><code>Storage Orchestration</code>:<ul> <li>Automatically mounts the storage system of your choice:<ul> <li>whether from local storage</li> <li>public cloud providers</li> <li>or network storage systems.</li> </ul> </li> </ul> </li> <li><code>Self-Healing</code>:<ul> <li>Restarts failed containers, replaces and reschedules them, and kills containers that don\u2019t respond to user-defined health checks.</li> </ul> </li> <li><code>Secret and Configuration Management</code>:<ul> <li>Securely stores and manages sensitive information such as passwords, OAuth tokens, and SSH keys.</li> </ul> </li> <li><code>clustered systems</code> adv:<ul> <li>increased performance, cost efficiency, reliability, workload distribution, and reduced latency.</li> </ul> </li> <li>Implement policies to <code>secure access</code> to applications/MS/service running inside containers.</li> <li>Enable containers in a cluster to <code>communicate with each other</code> regardless of the host</li> <li><code>scheduling</code></li> <li><code>Monitoring</code></li> <li><code>Batch Execution</code>.</li> <li>Pv4/IPv6 dual-stack</li> </ul>"},{"location":"03_Kubernetes/00_kickOff/03_k8s-architcture%2Bfeatures/#screenshots-for-reference","title":"screenshots for reference","text":""},{"location":"03_Kubernetes/02_KCAD/00_certification-topic/","title":"00 certification topic","text":""},{"location":"03_Kubernetes/02_KCAD/00_certification-topic/#certification","title":"Certification","text":"<ul> <li>CNCF (cloud native cloud foundation) + linux foundation</li> <li>Certified Kubernetes Application Developer: https://www.cncf.io/certification/ckad/</li> <li>Candidate Handbook: https://www.cncf.io/certification/candidate-handbook</li> <li>Exam Tips: https://docs.linuxfoundation.org/tc-docs/certification/tips-cka-and-ckad</li> <li>not mcq</li> <li>editor for exam task  : vi or nano</li> <li>can refer official documentation in exam</li> <li><code>20KLOUD</code> - 20% off</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/00_certification-topic/#exam-topics","title":"exam : Topic/s","text":"<ul> <li>Core concept - recap (cluster(main/worker), pod, rs, deploymnet object, etc)</li> <li>Config</li> <li>Configmap</li> <li>SecurityContext</li> <li>secrets</li> <li>ServiceAcct</li> <li>Resource req</li> <li>Mutli-Container <code>pods</code></li> <li>different patterns - Ambassador, adaptor , sidecar</li> <li>some eg and use case on these</li> <li>Observability</li> <li>readiness and liveness</li> <li>Container logging</li> <li>Monitor</li> <li>debug app</li> <li><code>pods</code> design</li> <li>label, selector, anno</li> <li>rolling / rollout updates</li> <li>job and cron job</li> <li>Service </li> <li>networking</li> <li>policies</li> <li>State and persistence</li> <li>vol</li> <li>vol claims PVC</li> <li>ETCD is a <code>distributed</code> reliable key-value store used by kubernetes to store all data used to manage the cluster.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/00_certification-topic/#more-topic","title":"more Topic","text":"<ul> <li>Build, define, and modify container images</li> <li>Authentication, Authorization, and Admission Control</li> <li>KubeConfig</li> <li>API Groups</li> <li>Role-based access controls</li> <li>Understanding API deprecations</li> <li>Blue/Green or Canary deployments</li> <li>Helm</li> <li>Discovering and using resources that extend Kubernetes (CRD)</li> <li>Storage Classes </li> <li>Stateful Sets </li> <li>VolumeClaimTemplates</li> <li>Taints/Tolerations</li> <li>Node Affinity</li> <li>Pods, Replicasets &amp; Deployments</li> <li>Services</li> <li>Secrets</li> <li>Environment Variables</li> <li>Persistent Volumes</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/00_certification-topic/#learning-track","title":"learning Track","text":"<ul> <li> <p>first <code>absolute beginner</code></p> </li> <li> <p>then <code>admin</code></p> <ul> <li>HA cluster deploymnet</li> <li>scheduler</li> <li>logging/ monitor</li> <li>lifecycle</li> <li>maintenance</li> <li>security</li> <li>troubleshoot</li> </ul> </li> <li> <p>or, <code>developer</code> KCAD</p> <ul> <li>design and build cloud native app</li> <li>configMap</li> <li>secrets</li> <li>multi-container -pod</li> <li>job</li> <li>services</li> <li>pod design</li> <li>logging and monitoring</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/","title":"Lab / hands-on","text":"<ul> <li>udemy : https://www.udemy.com/course/certified-kubernetes-application-developer/learn/lecture/31756514#overview </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-2-core","title":"Section-2 : Core","text":"<ul> <li>https://uklabs.kodekloud.com/topic/pods-4/</li> <li>https://uklabs.kodekloud.com/topic/replicasets-2/</li> <li>https://uklabs.kodekloud.com/topic/deployments-5/</li> <li>https://uklabs.kodekloud.com/topic/namespaces-3/</li> <li>https://uklabs.kodekloud.com/topic/imperative-commands/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-3-configuration","title":"Section-3 : configuration","text":"<ul> <li>https://uklabs.kodekloud.com/topic/practice-test-docker-images-2/</li> <li>https://uklabs.kodekloud.com/topic/configmaps-2/</li> <li>https://uklabs.kodekloud.com/topic/commands-and-arguments/</li> <li>https://uklabs.kodekloud.com/topic/security-contexts-3/</li> <li>https://uklabs.kodekloud.com/topic/service-account-2/</li> <li><code>pending</code></li> <li>https://uklabs.kodekloud.com/topic/resource-limits-2/</li> <li>https://uklabs.kodekloud.com/topic/taints-and-tolerations-3/</li> <li>https://uklabs.kodekloud.com/topic/node-affinity-3/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#certification-tips-student-tips","title":"Certification Tips - Student Tips","text":"<ul> <li>Make sure you check out these tips and tricks from other students who have cleared the exam:</li> <li>https://www.linkedin.com/pulse/my-ckad-exam-experience-atharva-chauthaiwale/</li> <li>https://medium.com/@harioverhere/ckad-certified-kubernetes-application-developer-my-journey-3afb0901014</li> <li>https://github.com/lucassha/CKAD-resources</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-4-multi-container-pod","title":"Section-4 : Multi- container pod","text":"<ul> <li><code>pending</code>:</li> <li>https://uklabs.kodekloud.com/topic/multi-container-pods-3/</li> <li>https://uklabs.kodekloud.com/topic/init-containers-3/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-5-readiness-liveness","title":"Section 5 : readiness / liveness","text":"<ul> <li><code>pending</code>:</li> <li>https://uklabs.kodekloud.com/topic/readiness-probes-2/</li> <li>https://uklabs.kodekloud.com/topic/logging-2/</li> <li>https://uklabs.kodekloud.com/topic/monitoring-2/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-6-pod-design","title":"Section 6 : pod design","text":"<ul> <li><code>pending</code>:</li> <li>https://uklabs.kodekloud.com/topic/labels-and-selectors-2/</li> <li>https://uklabs.kodekloud.com/topic/rolling-updates-rollbacks-2/</li> <li>https://uklabs.kodekloud.com/topic/practice-test-de\u2026ent-strategies-2/ </li> <li>https://uklabs.kodekloud.com/topic/jobs-and-cronjobs/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-7-network-and-service","title":"Section 7 : network and service","text":"<ul> <li><code>pending</code></li> <li>https://uklabs.kodekloud.com/topic/kubernetes-services/ </li> <li>https://uklabs.kodekloud.com/topic/ingress-networking-1/</li> <li>https://uklabs.kodekloud.com/topic/ingress-networking-2/</li> <li>https://uklabs.kodekloud.com/topic/network-policies-4/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-8-state-persistence","title":"Section 8 : state persistence","text":"<ul> <li><code>pending</code></li> <li>https://uklabs.kodekloud.com/topic/persistent-volumes-5/</li> <li>https://uklabs.kodekloud.com/topic/storage-class-2/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-9-security","title":"Section 9 : security","text":"<ul> <li>https://uklabs.kodekloud.com/topic/practice-test-kubeconfig-4/  </li> <li>https://uklabs.kodekloud.com/topic/practice-test-ro\u2026ccess-controls-4/ </li> <li>https://uklabs.kodekloud.com/topic/practice-test-cluster-roles-4/ </li> <li>https://uklabs.kodekloud.com/topic/labs-admission-controllers-5/ </li> <li>https://uklabs.kodekloud.com/topic/labs-validating-and-mutating-admission-controllers-5/ </li> <li>https://uklabs.kodekloud.com/topic/lab-api-versions-deprecations-2/</li> <li>https://uklabs.kodekloud.com/topic/practice-test-custom-resource-definition-2/</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_lab/#section-10-helm","title":"Section 10 : HELM","text":""},{"location":"03_Kubernetes/02_KCAD/00_sample_yaml/admission-Control/webhook-App-logic/","title":"webhook App logic","text":"<ul> <li>Webhook logic</li> <li><code>Denies</code> all request for <code>pod</code> to run as <code>root</code> in container if no securityContext is provided.</li> <li>If no value is set for runAsNonRoot, a default of true is applied, and the user ID defaults to 1234</li> <li>Allow to run containers as root if <code>runAsNonRoot set explicitly to false</code> in the securityContext</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/01-container-d/","title":"01 container d","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/01-container-d/#container-d","title":"container-d","text":"<ul> <li>K8s initially supports docker runtime only (cli,api,build, volumne, auth, security, runtime/container-d)</li> <li>Afterward supports different Runtime/s via <code>CRI</code> - OCI-standard imageSpec and ContainerSpec</li> <li>OCI - Open Container Interface.</li> <li>Any image follows OCI/imageSpec is supported by k8s</li> <li>Any Container follows OCI/ContainerSpec is support</li> <li>runtime:<ul> <li>rkt</li> <li>docker ( supported via <code>dockershim</code>)</li> </ul> </li> <li>v1.24 <ul> <li><code>dockershim</code> removed </li> <li>docker is removed k8s</li> </ul> </li> <li>so, <code>container-d</code> is runtime for docker as per OCI/ContainerSpec for kubernetes.<ul> <li>now standalone project under CNCF</li> <li>needed only runtime, no other feature, then install it.</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/01-container-d/#command-line","title":"Command line","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/01-container-d/#a-for-container-d","title":"a. for container-d","text":"<ul> <li><code>ctl</code> -  debug purpose , not user-friendly</li> <li><code>ctl image</code> pull image1</li> <li> <p><code>ctl run</code> image1 c1-name</p> </li> <li> <p><code>nerdctl</code>  (advance/later)</p> </li> <li>docker like CLI for container-d. can run all docker cmd.</li> <li>supports docker <code>compose</code></li> <li>supports new feature/s:<ul> <li>encrypted image + image signing</li> <li>lazy pulling</li> <li>k8 namespace</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/01-container-d/#b-for-any-crioci-compatible-container","title":"b. For any CRI/OCI compatible container","text":"<ul> <li><code>crictl</code></li> <li>CLI for any CRI/OCI compatible container</li> <li>install separately</li> <li>from k8 community</li> <li>special debugging purpose</li> <li>aware of pods.</li> <li>syntax quite similar</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/02-pod/","title":"02 pod","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/02-pod/#pods","title":"PODS","text":"<ul> <li>containers are <code>encapsulated</code> inside pods</li> <li>horizontal <code>scale</code> up and down :</li> <li>add more pods - y</li> <li>add more container inside a pod - n</li> <li>add more worker nodes - n</li> <li>can have <code>multi-container</code> pod-1 (rare use-case)</li> <li>c1 - api</li> <li>c2 - some helper api</li> <li>both live/die together</li> <li>comm : shares same name network-namespace and storage by-default.<ul> <li>no need manually setup-</li> <li>that's one of the benefit with pod.</li> </ul> </li> <li>HPA <code>horizontal pod scaling</code> object</li> <li> <p>k autoscale deployment  deployment-1 --max=10 --cpu-percent=70 <pre><code>apiVersion\nkind\nmetadata\n  name:pod-1\n  label:\n  securityContext:  # can also add container level, set user only, not capability here.\nannotation:\n  secret.reloader.stakater.com/auto: \"true\" \n  configmap.reloader.stakater.com/auto: \"true\" \n  reloader.stakater.com/auto: \"true\"  \nspec:\n\n  tolerations:\n  nodeSelector:\n    kubernetes.io/arch: \"amd64\" # arm64\n    karpenter.sh/capacity-type: \"spot\"         &lt;&lt;&lt;\n\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution:\n      preferredDuringSchedulingIgnoredDuringExecution:\n      requiredDuringSchedulingRequiredDuringExecution: future\n\n  mounts:\n  volumes:\n\n  restartPolicy: Always / Never --&gt; container exited in pod will come up again.\n  serviceAccountName: sa-1 #default  is default sa\n  resources:  # better to use LimitRange object\n    request:\n    limit:\n  initContainers:\n    -\n    -\n  containers:\n    - name: c1\n      image: eg: image has ENTRYPOINT [\"sleep\"] &amp; CMD [\"10\"]\n      command: [\"sleep\"] ENTRYPOINT of dockerfile or --entrypoint of dcoker run ...\n        - sleep\n      args: [\"10\"] CMD of dockerfile or docker run --entrypoint &lt;&gt; ...\n        - 10\n      ports:\n        - containerPort: 8080\n        - containerPort: 8443\n      env:\n        - name:\n          value :\n        - name:\n          valueFrom: \n            configMapKeyRef :\n              - name:\n                key: \n        - name:\n          valueFrom: \n            secretKeyRef: \n              - name:\n                key: \n      securityContext:  # can also add metadata level (pod level)\n        runAsUser: &lt;userid&gt;\n        capabilities: # only supported here\n          add: [\"MAC_ADMIN\", \"SYS_TIME\", \"NET_ADMIN\"]\n          drop\" [\"ALL\"]\n        allowPrivilegeEscalation: false\n        runAsGroup: 101      \n        runAsUser: 101\n\n\n    - name: c2\n      image:\n</code></pre></p> </li> <li> <p>commands:  <pre><code>- kubectl get/describe pod pod-1\n\n- kubectl get pod &lt;pod-name&gt; -o yaml &gt; pod-definition.yaml\n  create yml out of existing pod\n\n- kubectl edit pod &lt;pod-name&gt;\n  - This will open the pod specification in an editor (vi editor\n\n  - only the properties listed below are editable:\n    spec.containers[*].image\n    spec.initContainers[*].image\n    spec.activeDeadlineSeconds\n    spec.tolerations\n    spec.terminationGracePeriodSeconds\n\n  - cannot edit the environment variables, service accounts, and resource limits \n\n option-1  :: delete and re-create\n  - if we attemp to edit, non-editable feild then it will create a temp copy of yaml.\n    copy of the file with your changes is saved in a temporary location.\n    - kubectl delete pod pod-1    \n    - kubectl create -f /tmp/kubectl-edit-ccvrq.yaml\n\n option-2  :: delete and re-create\n  - kubectl get pod pod-1 -o yaml &gt; my-new-pod.yaml\n  - kubectl delete pod pod-1    \n  - kubectl create -f  my-new-pod.yaml\n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/02-pod/#screenshots","title":"Screenshots","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/03-replicaSet/","title":"03 replicaSet","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/03-replicaSet/#a-replication-controller","title":"A. replication Controller","text":"<ul> <li><code>replicationController</code> is a older way</li> <li><code>ReplicaSet</code> is a new way, with some diff.</li> <li>makes sure specified number of pods running all the time.</li> <li>span across node/s</li> <li></li> <li>yml (spec)</li> <li>replicas : 3</li> <li>nest the pod file in <code>template</code> section</li> <li>it manages only pod defined in template</li> <li></li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/03-replicaSet/#b-replica-set","title":"B. Replica Set","text":"<ul> <li>concept and yml --&gt; almost same.</li> <li>it also manages pods, not defined in template section.</li> <li>thus having <code>spec.selector</code> (mandatory)</li> </ul> <pre><code>...\n...\nspec:\n    ...\n    ...\n    selector: \n        matchLabels:\n            type: front-end\n\n## Some commands:\n- kubectl get replicaset\n- kubectl create -f &lt;yaml&gt;\n- kubectl scale --replicas=6 -f replicaSet-definition.yaml\n- kubectl scale --replicas=6 replicaset replicaset-1\n- kubectl delete replicaset rs-1\n    - all linked pods will be deleted.\n-  kubectl get replicaset -o yaml &gt; sample.yaml\n\nNote: use rs\n</code></pre>"},{"location":"03_Kubernetes/02_KCAD/01_Core/03-replicaSet/#label-and-selector","title":"label and selector","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/04-deployment-object/","title":"04 deployment object","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/04-deployment-object/#deployment-object","title":"Deployment Object","text":"<ul> <li>deployment (has all revision history)</li> <li>replicationSet-1 (revison=1)</li> <li>replicationSet-2 (revison=2)</li> <li>...</li> <li>replicationSet-n (current)</li> <li>concept:</li> <li>deploy pod/s</li> <li>upgrade (upgrade all pods together)</li> <li>rollout (upgrade pods <code>one after another</code>)</li> <li>rollback</li> <li>pause and resume</li> <li>yaml is same as rs</li> <li> <p>just update kind to deployment object.</p> </li> <li> <p>some command  <pre><code>  - kubectl get deployments\n\n  - kubectl create deployment --image=nginx nginx\n\n  - kubectl create deployment --image=nginx nginx --dry-run -o yaml &gt; def.yaml\n\n  - kubectl scale deployment nginx --replicas=4\n\n  - kubectl edit deployment d1  :)\n    - With Deployments, you can easily edit \"any\" field/property of the POD template. \n    - unlike pod edit, few feilds can edit.\n    - Since the pod template is a child of the deployment specification, \n    - the deployment will automatically delete and create a new pod with the new changes. \n</code></pre></p> </li> </ul> <p></p> <p></p>"},{"location":"03_Kubernetes/02_KCAD/01_Core/04-deployment-object/#understand-yaml","title":"understand yaml","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/04-deployment-object/#properties","title":"properties","text":"<ul> <li>progressDeadlineSeconds: 600 , terminationGraceperiodSeconds: 30</li> <li>revisionHistoryLimit : 10</li> <li>strategy</li> <li>rollingUpdate<ul> <li>maxSurge:</li> <li>maxUnavailable: </li> </ul> </li> <li>type: recreate / rollingUpdate  *</li> <li>dnsPolicy: clusterFirst  </li> <li>how DNS resolution is handled within the pod.</li> <li><code>clusterFirst</code> : <ul> <li>Uses the <code>cluster\u2019s DNS</code> service first for resolution. </li> <li>If the DNS query fails, it will fall back to the <code>host\u2019s DNS</code>.</li> </ul> </li> <li>Default : <code>host\u2019s DNS</code></li> <li><code>None</code></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/04-deployment-object/#annotations-ignore","title":"annotations (ignore)","text":"<ul> <li><code>kubectl.kubernetes.io/restartedAt</code>: Used to trigger a manual restart of the pods within the Deployment. Setting this annotation to a new timestamp forces a rollout restart, commonly used for manual updates without changing the Deployment spec.</li> <li><code>prometheus.io/scrape</code></li> <li><code>prometheus.io/port</code>: Often used in Deployments where Prometheus monitoring is set up. Setting prometheus.io/scrape: \"true\" tells Prometheus to scrape metrics, and prometheus.io/port specifies the port to scrape from.</li> <li><code>app.kubernetes.io/name</code>,</li> <li><code>app.kubernetes.io/version</code>,</li> <li><code>app.kubernetes.io/component:</code> These labels are often applied as annotations for organizational purposes, helping to identify the application's name, version, and component type, improving tracking and monitoring.</li> <li><code>sidecar.istio.io/inject</code>: Common in clusters with Istio service mesh. Setting sidecar.istio.io/inject: \"false\" on a Deployment prevents Istio from injecting its sidecar container, useful for excluding specific pods from the mesh.</li> <li><code>checksum/config</code></li> <li><code>checksum/secret</code>: Used to force a Deployment rollout when ConfigMaps or Secrets change. By updating the checksum when there are updates, Kubernetes detects a change and re-deploys the pods.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/04_Stateful-sets/","title":"StatefulSet","text":"<ul> <li>additional points:</li> <li>pod come up sequentially / ordered by default.<ul> <li>spec &gt; <code>podManagemnetPolicy : OrderedReady</code> (default)</li> <li>change to <code>Parallel</code>, if needed.</li> </ul> </li> <li>no random pod name, each pod has ordinal-index at end.</li> <li>first pod is always <code>MASTER</code></li> <li>same like Deployment. Replace <code>Deployment</code> with <code>StatefulSet</code>.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/04_Stateful-sets/#headless-service-optional","title":"headless service ( optional )","text":"<ul> <li>scenario: mysql-pod-0 MASTER <code>(R/W)</code>, mysql-pod-1 (R), mysql-pod-2 (R) - write happen only from MASTER.</li> <li>create regular service with <code>ClusterIP: None</code> +  ( selector and ports ). eg: mysql-h</li> <li>headless service, creates DNS a-record to access pod directly only if:</li> <li>add <code>subdomain</code> and <code>hostname</code> for pod are present., adding manually bad. All ns will be same.</li> <li>rather add  <code>serviceName</code> in StatefulSet, it automatically assigns subdomain(mysql-h) and hostname(mysql-index) for pod/s (better).</li> <li></li> <li></li> <li>dns </li> <li>headless-service (No ClusterIP): pod-1.service-1.namespace-1.svc.cluster.local   </li> <li> <p>service (clusterIP): service-1.namespace-1.svc.cluster.local</p> </li> <li> <p>example : mysql-pod (DB replica)</p> </li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/04_Stateful-sets/#volume","title":"volume","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/04_Stateful-sets/#all-pod-needs-common","title":"all pod needs common","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/04_Stateful-sets/#separate-volume-for-each-pod","title":"separate volume for each pod.","text":"<ul> <li>add <code>volumeClaimTemplate</code> in statefulSet.  (outside spec)</li> <li>inside section is PVC only.</li> <li>if pod goes down, new pod will be attached to same PVC. thus stable storage.</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/05-Namespace/","title":"05 Namespace","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/05-Namespace/#namespace","title":"namespace","text":"<ul> <li>in command use : <code>--namespace=name-1</code> or just n=name-1</li> <li>or in definition yaml, just add <code>metadata &gt; namespace:name-1</code></li> <li>used for <code>isolation</code>.</li> <li>have <code>polices</code>:</li> <li>ResouceQuota : - to limit resource usage</li> <li>...</li> <li>ns already added by k8s:</li> <li>kube-system</li> <li>kube-public</li> <li> <p>default</p> </li> <li> <p>if having big-cluster which soo many pods, then better to create custom namespace </p> </li> <li>namespace-1 : <code>dev</code> - pod-1, pod2, pod-3,etc</li> <li>namespace-2 : <code>qa</code> - pod-1, pod2, pod-3</li> <li> <p>namespace-3 : <code>prod</code> - pod-1, pod2, pod-3</p> </li> <li> <p>Access services:</p> </li> <li>can access any service in same namespace by service-name(DN)</li> <li>can access any service in different namespace using this DN format:<ul> <li></li> <li></li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/05-Namespace/#kubectl-create-ns-dev-ns-apiversion-v1-kind-namespace-metadata-name-dev-kubectl-create-f-xyaml-kubectl-get-pods-all-namespace","title":"<pre><code>kubectl create ns dev-ns\n\napiVersion: v1\nkind: Namespace\nmetadata:\n  name: dev\n\nkubectl create  -f  x.yaml\nkubectl get pods --all-namespace\n</code></pre>","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/07-configMap/","title":"07 configMap","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/07-configMap/#config-map","title":"config Map","text":"<ul> <li>kubectl get/describe configmaps</li> <li>create (imperative)</li> <li>kubectl create configmap config-1 --from-literal=k1=v1 --from-literal=k2=v2 ...</li> <li> <p>kubectl create configmap config-1 --from-file=abc.properties</p> </li> <li> <p>create (declarative) <pre><code>apiVersion: v1\nkind: ConfigMap\nmetadata\n  name:config-map-1\ndata:\n  - name: K1\n    value: V1\n  ...\n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/07-configMap/#inject-configmap-as-env-var-into-pods","title":"inject configmap as env var into <code>pods</code>","text":"<ul> <li> <p>whole config <pre><code>envFrom:\n    - configMapRef:\n        name: config-map-1\n</code></pre></p> </li> <li> <p>specific single value <pre><code>env:\n    - name: ENV_1\n      valueFrom:\n        configMapKeyRef:\n            name:\n            key:  \n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/08-Secrets-with-encryption/","title":"08 Secrets with encryption","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/08-Secrets-with-encryption/#secrets-safe","title":"Secrets (safe)","text":"<ul> <li>Secret Store CSI Driver: https://www.youtube.com/watch?v=MTnQW9MxnRI&amp;ab_channel=KodeKloud</li> <li>secret created at namespace-1, anyone who has access can see it.</li> <li>can add role based access to secrets</li> <li>can also use 3rd secrets : AWS secret manange and integrate with k8s.</li> <li>Secrets are <code>not encrypted</code>, so it is not safer in that sense.</li> <li>just base64 encoded</li> <li>way kubernetes handles secrets:</li> <li>A secret is only sent to a node if a pod on that node requires it.</li> <li>Kubelet stores the secret into a tmpfs so that the secret is not written to disk storage.</li> <li>Once the Pod that depends on the secret is deleted, kubelet will delete its local copy of the secret data as well.</li> <li>better way : Helm Secrets, HashiCorp Vault , AWS secret manager.</li> </ul> <ul> <li>kubectl get/describe secrets</li> <li>create (imperative)</li> <li>kubectl create secret  s-1 --from-literal=k1=v1 --from-literal=k2=v2 ... <li>kubectl create secret generic s-1 --from-file=abc.properties</li> <li> <p>type:</p> <ul> <li><code>docker-registry</code>   Create a secret for use with a Docker registry</li> <li><code>generic</code> **           Create a secret from a local file, directory, or literal value</li> <li><code>tls</code>               Create a TLS secret</li> </ul> </li> <li> <p>create (declarative) <pre><code>apiVersion: v1\nkind: Secret\nmetadata\n  name:s-1\ndata:\n  K_1: V_1 (encoded with base64)\n  K_2: V_2 (encoded with base64)\n  ...\n</code></pre></p> </li>"},{"location":"03_Kubernetes/02_KCAD/01_Core/08-Secrets-with-encryption/#inject-secret-as-env-var-into-pods","title":"inject secret as env var into <code>pods</code>","text":"<ul> <li> <p>whole config <pre><code>envFrom:\n    - secretRef:\n        name: S-1\n</code></pre></p> </li> <li> <p>specific single value <pre><code>env:\n    - name: ENV_1\n      valueFrom:\n        secretKeyRef:\n            name:\n            key:  \n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/08-Secrets-with-encryption/#encryption-configuration","title":"Encryption Configuration","text":"<ul> <li>trying : encryption at rest (secrets in etcd)</li> <li>create EncryptionConfiguration, then add this pod &gt; container &gt;</li> <li> <p><code>--encryption-provider-config=/etc/kubernetes/enc/enc.yaml</code></p> </li> <li> <p>enc.yaml :</p> </li> <li>mount this file to pod volume</li> <li></li> <li>provider (4) - order matters. keep <code>aescbc</code> first in provider array.</li> <li> <p>there is commands to mention base64 <code>secret</code>. check official doc.</p> </li> <li> <p>pod &gt; conatiner :</p> </li> <li> <p></p> </li> <li> <p>after this if we create any new secret it will encrypted.</p> </li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/09-Security-context/","title":"09 Security context","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/09-Security-context/#security-context","title":"Security context","text":"<pre><code>pod &gt; container &gt;\n\n      securityContext:  # can also add metadata level (pod level)\n        runAsUser: &lt;userid&gt;\n        capabilities: # only supported here\n          add: [\"MAC_ADMIN\"]\n</code></pre>"},{"location":"03_Kubernetes/02_KCAD/01_Core/10_service-Account/","title":"10 service Account","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/10_service-Account/#service-account","title":"service Account","text":"<ul> <li><code>user Acct</code></li> <li><code>system Acct</code> . eg:</li> <li>jenkins, to deploy on appl on cluster</li> <li>account used by an app to interact with kube cluster<ul> <li>my-app.py --&gt; get list of all pods from cluster</li> </ul> </li> </ul> <ul> <li>create :: <code>k create serviceaccount sa-1</code></li> <li>then attach role-based-permission: how ?</li> <li>pending... using RBAC ?</li> <li><code>token</code>(JWT) with same that permission will be auto-created</li> <li>token has <code>no-expiry</code></li> <li>link sa-1 to pod :</li> <li>spec &gt; <code>serviceAccountName</code> (non-editable field)</li> <li>delete and re-create pod with new sa-2, if need to change. cant edit sa once pod created.</li> </ul> <ul> <li><code>default</code> serviceAccount - for every namespace, get created automatically</li> <li><code>k get serviceaccount</code></li> <li>has basic permission </li> <li>and serviceAccount token get mounted to every pod in that namespace as volume mount</li> <li>describe any pod-1 and check <code>mounts</code> and <code>volumes</code> section<ul> <li>k exec -it pod -- ls  mount-1(dir loc)</li> <li>cat token</li> </ul> </li> <li>Disable : <code>automountServiceAccountToken : false</code>, manually</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/10_service-Account/#service-account-token","title":"Service Account <code>Token</code>","text":"<ul> <li>k describe serviceaccount a1</li> <li>notice : <code>token: token-1</code></li> <li>stored inside <code>secret</code> ( secret name: token-1)</li> <li>this secret-object is linked to serviceaccount-object</li> <li>k describe secret token-1<ul> <li>can see entire: JWT token</li> <li>can be used as auth bearer token for to call kube-api</li> <li>curl kube-api --http-header \"Authorization : Bearer JWT-token\"</li> </ul> </li> <li>v1.22</li> <li>can request token with token-api, for sa-1</li> <li> <p>k create token sa-1</p> </li> <li>having expiry (default 1hr)</li> <li>before, we create sa which automatically creates token.</li> <li>secret(token) --&gt; mount --&gt; pod</li> <li> <p>command : ?</p> </li> <li>v1.24</li> <li>reduction of secret-based ServiceAccountToken</li> <li>token --&gt; mount --&gt; pod</li> <li> <p>command : ?</p> </li> <li> <p>can still create non-expiry old way token</p> <ul> <li>```   Secret:</li> </ul> <p>metadata:     name:     annotations:        kubernetes.io/service-account.name: sa-1 # create first   spec:     ...     ...   ```</p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/10_service-Account/#scenario","title":"Scenario","text":"<ul> <li>App-1 (hosted outside cluster) </li> <li>share token with this app</li> <li>App-2 (hosted/deployed inside cluster itself):</li> <li>no need to share</li> <li>just mount service-account's secret </li> <li>write code to read it</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/10_service-Account/#understand-yaml","title":"understand yaml","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/10_service-Account/#annotation","title":"annotation","text":"<ul> <li><code>eks.amazonaws.com/role-arn</code>: arn-1</li> <li><code>helm.sh/hook</code>: pre-install</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/10_service-Account/#properties","title":"properties","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/11_Resource-requirmnet/","title":"11 Resource requirmnet","text":"<ul> <li>summary:</li> <li>LimitRange - for NS-1 (100 GB) - total for ns</li> <li>resourceQuota  for all pod inside NS-1  (1 GB max to each pod)<ul> <li>pod&gt;resource - individual pod</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/11_Resource-requirmnet/#resource-requirement","title":"Resource Requirement","text":"<ul> <li>by default, no limit --&gt; any pod can use as much resource.</li> <li>pod &gt; spec &gt; containers &gt; <code>resources</code>:</li> <li><code>request</code> (minimum)<ul> <li>cpu: 1  --&gt; 1 count of CPU is equivalent to <code>1 vCPU</code>. That\u2019s 1 vCPU in AWS.</li> <li>memory: 256M</li> </ul> </li> <li> <p><code>limit</code> (maximum)</p> <ul> <li>cpu: 3 --&gt; will never go beyond. this.</li> <li>memory: 500M --&gt; but container can use more memory, beyon limit, if available on node, and eventually terminated with OOM.</li> </ul> </li> <li> <p>pod will be started at desirable-Node.</p> </li> <li>if none of the node has enough resource, then it will error  out : </li> <li>eg: FailedScheduling No nodes are available that match all of the following predicates:: Insufficient cpu</li> <li>4 behaviour</li> <li>no request , no limit</li> <li>no request , limit</li> <li>request , limit</li> <li>request , no limit  *** --&gt; make sure has pod has some resource request set.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/11_Resource-requirmnet/#limitrange","title":"LimitRange","text":"<ul> <li>manage resource usage within a namespace</li> <li>set limit at Namespace level, hence applied to all pod and need to define to each pod.</li> <li>this is effect only the newer pod.</li> <li>Types of Limits:</li> <li><code>min</code>: The minimum amount of a resource (e.g., CPU, memory) that must be requested by a container or Pod.</li> <li><code>max</code>: The maximum amount of a resource a container or Pod can request or consume.</li> <li><code>DefaultRequest</code>: If a container or Pod does not specify a request, Kubernetes assigns this default request.</li> <li><code>DefaultLimit</code>: If a container or Pod does not specify a limit, Kubernetes assigns this default limit.</li> <li><code>Resource Ratios</code>: Some LimitRange configurations also allow setting ratios for resources to ensure balanced use, especially for storage resources. ? <pre><code>apiversion: v1\nkind\" LimitRange\nmetadata:\n  name: \nspec:\n  limits:\n    - type: Container       # Container, pod, PVC\n      max:\n        cpu: \"2\"            # Maximum of 2 CPUs per container\n        memory: \"1Gi\"       # Maximum of 1Gi memory per container\n      min:\n        cpu: \"200m\"         # Minimum of 200m CPU per container\n        memory: \"100Mi\"     # Minimum of 100Mi memory per container\n      default:\n        cpu: \"500m\"         # Default CPU request if not specified\n        memory: \"200Mi\"     # Default memory request if not specified\n      defaultRequest:\n        cpu: \"300m\"         # Default CPU request\n        memory: \"150Mi\"     # Default memory request\n\n    - type : PersistentVolumeClaim \n      max:\n        storage: \n      min:\n        storage:  \n</code></pre></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/11_Resource-requirmnet/#resourcequota","title":"ResourceQuota","text":"<ul> <li>set limit on resource used by all pod in namespace, together. <pre><code>apiversion: v1\nkind\" ResourceQuota\nmetadata:\n  name:\n  namespace:\nspec:\n  hard:\n    requests.cpu\n    requests.memory\n    limit.cpu\n    limit.memory\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/12_pod-placement/","title":"pod placement on node","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/12_pod-placement/#a-taint-on-node-and-tolerance-on-pod","title":"A. taint (on node) and tolerance (on pod)","text":"<ul> <li>has nothing with security.</li> <li>just to set restriction on pods, meaning \"a pod must be scheduled on which node ?\".</li> <li>analogy :<ul> <li>person (node) - taint applied</li> <li>and bug (pod) - tolerance applied.</li> </ul> </li> <li> <p>k taint  nodes node1 taint1=blue:taint-effect</p> <ul> <li>taint-effect : </li> <li><code>NoSchedule</code> ** : new pod will not be scheduled + existing will stay.</li> <li><code>preferSchedule</code> : system will try but not guaranteed</li> <li><code>NoExecute</code> : new pod will not be scheduled + existing pod having no tolerations, will get be evicted</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/12_pod-placement/#demo","title":"Demo","text":"<ul> <li>Node - 1 (taint=blue:NoSchedule),2,3<ul> <li> <p>k taint nodes node1 taint1=blue:NoSchedule</p> </li> </ul> </li> <li>pod - A, B, C, D</li> <li>none of the pod got scheduled on Node-1, since no one is tolerant to Node-1.</li> <li>next, add tolerance to pod-D for taint=blue.<ul> <li>pod spec &gt; <code>tolerations</code> <pre><code>spec:\n  tolerations: #array\n  - key: \"taint1\"\n    operator: \"equals\"\n    value: \"blue\"\n    effect: \"NoSchedule\"\n    ## taint1 = blue : NoSchedule\n  -\n  -\n</code></pre></li> </ul> </li> <li>only Pod-D will get scheduled to Node-1</li> <li>NOTE: pod=D is tolerate to Node-1, but that does NOT mean, it will scheduled to only Node-1.<ul> <li>Pod A,B,C --&gt; go to node 2,3</li> <li>Pod D --&gt; can go to Node 1,2,3 (all)</li> </ul> </li> <li>fact-1 </li> <li>master node is like worker node and can run pods.</li> <li>but schedular nevers  assign any pod to master</li> <li>becoz master has taint.</li> <li>check this &gt;&gt;  k describe  node <code>kubemaster</code> | grep taint</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/12_pod-placement/#b-node-selector","title":"B. Node Selector","text":"<ul> <li>scenario: want POD-D (big prcocess) to run only in Node-1 (larger Node) (refer above demo)</li> <li>solution:</li> <li>add label in Node-1 &gt; <code>size: large</code></li> <li>in pod spec, use node-selector.</li> <li>pod spec &gt; <code>NodeSelector</code> &gt; label-1: value-1</li> <li>demo:     <pre><code>- k label nodes node-1 size=large\n- pod:\n    spec:\n        nodeSelector: \n            size: large\n            # this pod will go node-1 only.\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/12_pod-placement/#c-node-affinity","title":"C. Node Affinity","text":"<ul> <li>scenario: </li> <li>want pod-D to go Node-1(Large) <code>or</code> Node-2(Medium)</li> <li>but <code>not</code> node-1(small)</li> <li>affinity to handle some complex combination / expression</li> <li>demo:     <pre><code>apiVersion: v1\n  kind: Pod\nmetadata:\n  name: pod-d\nspec:\n  affinity:\n    nodeAffinity:\n      requiredDuringSchedulingIgnoredDuringExecution: #hard constraint - preferred\n        nodeSelectorTerms:\n          - matchExpressions:\n           - key: size\n             operator: In\n             values:\n               - Large\n               - Medium\n           - key: size\n             operator: NotIn #more - Exists\n             values:\n               - Small  \n  containers:\n  - name: nginx\n    image: nginx\n</code></pre></li> <li>type:</li> <li> <p><code>required</code>DuringScheduling <code>Ignored</code>DuringExecution</p> <ul> <li>this rule is a hard requirement, </li> <li>meaning that Kubernetes must find a node that matches the specified criteria to schedule the Pod.</li> <li>ignored during execution (if node labels change after the Pod is scheduled)</li> </ul> </li> <li> <p><code>preferred</code>DuringScheduling <code>Ignored</code>DuringExecution</p> <ul> <li>This rule is a soft requirement,</li> <li>meaning Kubernetes prefers to place the Pod on a node matching the criteria.</li> <li>but will still schedule it elsewhere if no matching nodes are available.</li> </ul> </li> <li> <p><code>required</code>DuringScheduling <code>required</code>DuringExecution (planned for future) --&gt; this will evict pod if expression/label change in b/w.</p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/13_controller/","title":"Controller","text":"<ul> <li>written in go</li> <li>responsible for watching the status of object in etcd and make necessary changes.</li> <li></li> <li>Analogy:</li> <li>object file has description. json/yaml.</li> <li>controller are real program to read this configuration and perform real magic bts.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/14_PDB/","title":"14 PDB","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/14_PDB/#poddisruptionbudget-pdb","title":"PodDisruptionBudget (PDB)","text":"<ul> <li>Kubernetes resource that helps ensure high availability during voluntary disruptions, such as:</li> <li>Node maintenance/draining (e.g., kubectl drain)</li> <li>Cluster autoscaling (node removal)</li> <li>**Manual pod evictions</li> <li>Rolling updates** </li> </ul> <p>10_podDisruptionBudget.yaml</p>"},{"location":"03_Kubernetes/02_KCAD/01_Core/15_DeamonSet/","title":"15 DeamonSet","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/15_DeamonSet/#deamonset","title":"DeamonSet","text":""},{"location":"03_Kubernetes/02_KCAD/01_Core/15_DeamonSet/#intro","title":"intro","text":"<ul> <li>https://chatgpt.com/c/684e249b-7b64-800d-95df-2aee3d508bf6</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/15_DeamonSet/#when-to-use-daemonset","title":"When to use DaemonSet:","text":"<ul> <li>Log collection : Splunk</li> <li>Monitoring : Datadog</li> <li>Networking (e.g., CNI plugins) : ingress-controller</li> <li>Node-local storage management</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/01_Core/15_DeamonSet/#ccgg-example","title":"ccgg example","text":"<ul> <li>obs</li> <li>opentelemetry-*     Distributed tracing and observability (instrumented apps/services)</li> <li>datadog             Observability platform (metrics, logs, traces)</li> <li>splunk-kubernetes   Logging via Splunk integration</li> <li>cost</li> <li>flexera             Likely for software asset or cloud cost management</li> <li>cloudability        Cost and usage monitoring tool</li> <li>networkin/services</li> <li>cert-manager        Manages SSL/TLS certificates (likely with Let's Encrypt or ACM)</li> <li>chaos-mesh          Chaos engineering (resilience testing of services)</li> <li>ingress-nginx       Ingress controller using NGINX</li> <li>more</li> <li><code>karpenter</code>         Dynamic cluster autoscaler (more efficient than Cluster Autoscaler)</li> <li><code>external-secrets-operator</code> Syncs secrets from AWS Secrets Manager/SSM into Kubernetes secrets</li> <li>namespace-controller    Custom or enhanced namespace lifecycle management</li> <li><code>reloader</code>          Auto-restarts pods when ConfigMap/Secret changes</li> <li>rafay-*             Rafay is a Kubernetes management platform (deployment pipelines, governance)</li> <li>velero              Backup and restore of cluster resources and persistent volumes</li> <li>wiz                 Container/cloud security platform (runtime &amp; config scan)</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/01_Multi-Container-pod-design/","title":"01 Multi Container pod design","text":"<ul> <li>if any container fails, pod failed.</li> <li>All containers  in pod are expected to stay alive at all times.</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/01_Multi-Container-pod-design/#initcontainers","title":"initContainers","text":"<ul> <li>purpose:  task that will be run only one time when the pod is first created.</li> <li>When a POD is first created the initContainer is run, </li> <li>and the process in the initContainer must run to a completion before the real container hosting the application starts.</li> <li>configure multiple such initContainer.<ul> <li>run one at a time in sequential order</li> </ul> </li> <li>If any of the initContainers fail to complete, Kubernetes restarts the Pod repeatedly until the Init Container succeeds.</li> <li>https://kubernetes.io/docs/concepts/workloads/pods/init-containers/</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/01_Multi-Container-pod-design/#design-pattern-for-multiple-container-pod","title":"Design pattern for multiple-container pod","text":""},{"location":"03_Kubernetes/02_KCAD/02_pod-design/01_Multi-Container-pod-design/#a-sidecar","title":"A. Sidecar","text":"<ul> <li>One main container performs the primary task, </li> <li>and additional containers (sidecars) provide supporting functionality, like <code>logging, proxying, or data syncing</code>.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/01_Multi-Container-pod-design/#b-adaptor","title":"B. Adaptor","text":"<ul> <li>An adapter container transforms data or interfaces between different systems or services, making them compatible with the main application.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/01_Multi-Container-pod-design/#c-ambassador","title":"C. Ambassador","text":"<ul> <li>A container (ambassador) acts as a proxy for external services,</li> <li>managing <code>network requests and responses</code> for the main container.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/02_label%2Bselectors/","title":"02 label+selectors","text":""},{"location":"03_Kubernetes/02_KCAD/02_pod-design/02_label%2Bselectors/#label-selector","title":"Label, Selector","text":"<ul> <li>used to group and select object</li> <li>add label/s in pods</li> <li>select pods in <code>deployment</code>, <code>service</code> and <code>rs</code> object with selector<ul> <li></li> </ul> </li> <li>NodeSelector</li> <li>PodSelector</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/02_label%2Bselectors/#annotation","title":"annotation","text":"<ul> <li>used to record detail for infomatory purpose.</li> <li>eg: metadata &gt; annotations</li> <li>buildVersion: v23.78</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/03-Deployments/","title":"Deployment","text":""},{"location":"03_Kubernetes/02_KCAD/02_pod-design/03-Deployments/#rollout","title":"rollout","text":"<ul> <li>when we first create deployment, it performs a rollout with revision=1  === replicaSet-1</li> <li>next, if deployment object is upgraded, new rollout happens with revision=2 === replicaSet-2</li> <li>eg: updating label, image,etc</li> <li>k set image deployment-1 c1=image:version  --record=true </li> <li>or, k edit deployment deployment-1 --record=true<ul> <li><code>--record</code> flag to save the command used to create/update a deployment against the revision number.</li> </ul> </li> <li> </li> <li> <p>check rollout status</p> </li> <li>k rollout status deployment deployment-1 --&gt; status for deployment, status of each replica/pod</li> <li>k rollout history deployment deployment-1 --revision=1 --&gt; show revision history</li> <li>Also run : k decribe deploymnet and  check <code>events</code></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/03-Deployments/#rollout-strategies","title":"rollout strategies :","text":"<ul> <li> <p><code>Recreate</code></p> <ul> <li></li> <li>scaling down replicas = 0, then scale up to replicas-count (eg: 5)</li> </ul> </li> <li> <p><code>Rolling update</code> (default)</p> <ul> <li></li> <li>scale down replicas by 1, and scale up by 1.</li> <li>if there is error with while deployment, it won't scale down further to maintain app availability.</li> </ul> </li> <li> <p><code>Blue green</code></p> <ul> <li>service (select pod by label <code>L1</code>)  --&gt; Deployment-object-1, <code>blue</code>&gt;&gt; RS &gt;&gt; POD/s (all has L1)</li> <li>Deployment-object-2, <code>green</code> &gt;&gt; RS &gt;&gt; POD/s (all has L2)</li> <li>once all pod in L2 are healthy</li> <li>update service to select pod by <code>L2</code></li> <li></li> </ul> </li> <li> <p><code>canary</code></p> <ul> <li></li> <li>route small traffic to deployment-canary's pod, usinf common label selector on service</li> <li>once looks ok, the delete canary</li> <li>rollout changes to primary-deploymnet object.</li> <li></li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/03-Deployments/#rollback","title":"rollback:","text":"<ul> <li>k rollout undo deployment/deployment-1 --to-revision=1</li> <li>destroys the pod in replicaSet-2 (current)</li> <li>bring back pod in replicaSet-1 (previous)</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/04-jobs/","title":"04 jobs","text":""},{"location":"03_Kubernetes/02_KCAD/02_pod-design/04-jobs/#job","title":"Job","text":"<ul> <li><code>ReplicaSet</code> : make sure set of pod running all the time</li> <li><code>Job</code> : make sure set pod of completed desired task and exited then.</li> </ul> <pre><code>apiVersion: batch/v1\nkind: Job\nmetadata: \n    name:\nspec:  # &lt;spec of job&gt;\n    completions: 3   &lt;&lt;&lt;&lt; sequentially starts pod one after another\n    parallelism: 3   &lt;&lt;&lt;&lt; if present, then parallel pods runs\n    template: #pod\n        spec:\n            restartPolicy: Never  &lt;&lt;&lt;&lt; prevent restart\n            conatiners:\n                - \n                - \n</code></pre>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/04-jobs/#cronjob","title":"CronJob","text":"<ul> <li>jobs runs instantly</li> <li>cronJob can be <code>scheduled</code> <pre><code>apiVersion: batch/v1beta\nkind: CronJob\nmetadata:\n    name:\nspec: # &lt;spec of Cronjob&gt;\n    schedule: \"*/1 * * * * *\"\n    jobTemplate:\n        &lt;spec of job&gt;\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/02_pod-design/04-jobs/#screenshot","title":"Screenshot:","text":""},{"location":"03_Kubernetes/02_KCAD/03_observability/01_readiness%2Bliveness/","title":"01 readiness+liveness","text":"<ul> <li>pod status</li> <li><code>pending</code> - when first created</li> <li><code>creatingContainer</code> - once scheduled</li> <li> <p><code>Running</code> - once all container started</p> </li> <li> <p>pod condition  : array of <code>true/false</code>. describe pod and check these.</p> </li> <li>podScheduled</li> <li>initialized</li> <li>containersReady</li> <li><code>Ready</code> : all container ready. pod ready</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_observability/01_readiness%2Bliveness/#readiness","title":"Readiness","text":"<ul> <li> <p>eg: jenkin pod ready but actual process take additional 15 section to come up.</p> <ul> <li>which is confusing. because service can start sending traffic to pod once READY.</li> <li>solution: readiness probe : helps to get actual application/process status</li> </ul> </li> <li> <p></p> </li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_observability/01_readiness%2Bliveness/#liveness","title":"liveness","text":"<ul> <li> <p>fact:</p> <ul> <li>docker run nginx &gt; <code>exited</code>,  since no process running</li> <li>k run nginx --image=nginx &gt; <code>exited &gt; re-run &gt; exited &gt; re-run &gt; ....</code></li> </ul> </li> <li> <p>container is up in pod, but application is NOT healthy (some code bug)</p> </li> <li>liveness probe can be deifined to periodically test if app is healthy.</li> <li>developer define defination of healthy.</li> <li></li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_observability/02_Container-logging/","title":"02 Container logging","text":"<ul> <li>single c pod</li> <li>k logs -f pod-1</li> <li>multi c pod</li> <li>k logs -f pod-1 container-1</li> <li>k logs -f pod-1 container-2</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_observability/03_monitor%2Bdebug/","title":"03 monitor+debug","text":"<ul> <li>check more  on admin course</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/03_observability/03_monitor%2Bdebug/#metric-server","title":"metric Server","text":"<ul> <li><code>heapster</code> is depreated. now came as <code>metric Server</code></li> <li>in memory analytic</li> <li>does not store on disk</li> <li>hence cannot check history on analytics.</li> <li><code>kubelet</code> has <code>C-advisor</code>, responsible to receiver performance data of date and send to metric-server</li> <li>run:</li> <li> </li> <li> <p>commands:</p> </li> <li>k top node</li> <li>k top pod</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/","title":"pod/container communication","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#a-within-pod","title":"A. within pod","text":"<ul> <li>no service needed, just use localhost.</li> <li>use <code>localhost</code> for container/s comm inside a pod.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#b-services","title":"B. Services","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#clusterip-pod-pod-default","title":"ClusterIP: (pod &lt;==&gt;  pod) : default","text":"<ul> <li>Exposes the service internally within the cluster. </li> <li>check for service IP (internal cluster IP, stable) </li> <li>manually grab it and use.</li> <li>or use auto generated env var. <code>&lt;service-Name&gt;_SERVICE_HOST</code></li> <li>or use coreDNS - <code>&lt;service-Name&gt;.&lt;namespace&gt;</code></li> <li>Accessible only within the cluster via a stable IP.</li> <li>also performs load balancing.</li> <li>enables loose coupling between pod/microservices</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#nodeport-outside-world-pod","title":"NodePort: (outside world &lt;==&gt; pod)","text":"<ul> <li>external-client --&gt; internet --&gt; k8s-cluster --&gt;  <code>node-1|2|..[static-node-ip:node-port]</code>--&gt; <code>nodePort-service[internal-ip:service-port]</code>--&gt; <code>pod/s[internal-ip:target-port]</code> </li> <li>maps <code>port-on-Node</code> to <code>pod</code>::container::process(port)</li> <li>listens traffic on node-port and forward traffic to pod.</li> <li>Can be accessed externally using <code>&lt;NodeIP&gt;:&lt;NodePort&gt;</code>.</li> <li>Kubernetes cluster allocates a port (usually between 30000-32767) on all nodes.</li> <li><code>uascase</code> : external-load-balance (aws-alb) --&gt; send traffic to node-port service/s (so, 3 node === 3 services, once on each Node/ec2)<ul> <li>manually create exter alb ahead of time.</li> </ul> </li> <li></li> <li><ul> <li>note: cloud-logo with 10.244.0.0, represents internal-network, here.</li> </ul> </li> <li>multipod service<ul> <li></li> <li></li> <li>span over multiple nodes</li> </ul> </li> <li>Node IP can be changed. </li> <li>if 3 nodes, then 3 endpoints</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#loadbalancer-outside-pod","title":"LoadBalancer: (outside &lt;==&gt;  pod)","text":"<ul> <li>calls cloud provider API and automatically creates external lb inside cloud infra, that routes the traffic to this service.</li> <li>so use this, if deploying services on AWS,etc</li> <li>Note: for minikube</li> <li>minikube service lb-service-name --&gt; it will give external url.</li> <li>in EKS, we don't need this additional step, can always see external url.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#headless-service-outside-pod-directly","title":"headless service: (outside &lt;==&gt;  pod, directly)","text":"<ul> <li> <p>allows direct access to individual pod IPs without a load balancer or cluster IP. </p> </li> <li> <p>Key Features:</p> </li> <li><code>clusterIP: None</code></li> <li><code>DNS-based Pod Discovery</code>:<ul> <li>Each pod gets its own DNS entry, useful for stateful applications where each pod has a unique identity </li> <li>(e.g., databases like Cassandra or StatefulSets).</li> </ul> </li> <li> <p><code>Direct Pod Access</code>:</p> <ul> <li>Clients connect to pods directly, without load balancing.</li> </ul> </li> <li> <p>Use Cases:</p> </li> <li><code>Stateful</code> applications (e.g., databases) that require direct access to specific pods.</li> <li>Service discovery for applications that need <code>pod-level DNS</code> (e.g., my-headless-service-0.my-headless-service).</li> <li>This approach offers more control over pod communication compared to standard services.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#deploy-frontend-on-k8s","title":"deploy frontend on K8s","text":"<ul> <li>deploy frontend as pod/deploymnet object in k8s cluster</li> <li>have fe-service (expose on 8080), loadbalance Type</li> <li>host fe with nginx. </li> <li>front end code --&gt; while makeing api call, use <code>/my-be/***</code></li> <li>in nginx.conf file</li> <li>location <code>/my-be/</code> { proxy-pass https://fe-sevice.namespace1:8080 } </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#understand-yaml","title":"understand yaml","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#properties","title":"properties","text":"<ul> <li><code>Enableservicelink</code>  : T/F - environment variables for services are automatically injected into the pod</li> <li><code>sessionAffinity</code> : None</li> <li><code>internalTrafficPolicy</code> Cluster or local(node)</li> <li><code>ipFamily</code> :IPv4</li> <li><code>ipFalimilyPolicy</code>: singleStack</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/01-services/#annotation","title":"annotation","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/","title":"02 ingress","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#a-scenario","title":"A. Scenario","text":"<ul> <li>K8s Cluster has : </li> <li><code>app-1</code> : online shop - deploymnet-object-1</li> <li></li> <li> <p>access app-1:</p> <ul> <li>with nodeIp:port</li> <li>with proxy</li> <li></li> <li>with <code>loadBalancer-service-1</code> + <code>gcp-lb-1</code></li> </ul> </li> <li> <p><code>app-2</code> : video-stream app - deploymnet-object-2</p> </li> <li>deploy it same cluster, as new deploymnet object</li> <li> <p>access : with <code>loadBalancer-service-2</code> + <code>gcp-lb-2</code></p> </li> <li> <p>add <code>gcp-lb-3</code> --&gt; forward/route traffic to  gcp-lb-1 or gcp-lb-2</p> </li> <li>routing rules:<ul> <li>/apparel --&gt; gcp-lb-1</li> <li>/video --&gt; gcp-lb-2</li> </ul> </li> <li> <p>end result : gcp-lb-3 &gt;&gt; gcp-lb-1/2 &gt;&gt; k8s service-1/2</p> </li> <li> <p>Next, add security (SSL, firewall). but where ? best place,  having less maintenance :</p> </li> <li>add at app-1/2 level : problem , if application grows</li> <li>add at proxy / gcp-lb-1/2/3 level</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#b-ingress","title":"B. ingress","text":"<ul> <li>Another k8s object, think of as Layer-7 load balance where :</li> <li>will add routing rule, to forward traffic to multiple k8s service/s</li> <li>will add SSL</li> <li>will add firewall</li> <li>thus, simplfies all such config at central place.</li> <li>ingress object components:</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#ingress-controller-pod","title":"ingress controller (pod)","text":"<ul> <li>proxy server, will be used for routing,forwarding, security</li> <li>need to deploy this server, does not come by default</li> <li>eg: <code>nginx server</code> : deploy at as pod <ul> <li>1 configmap for Nginx configuration </li> <li>2 SA (with access to all these object)</li> <li></li> <li>3 expose this pod with service ( NodePort / loadBalancer)</li> <li></li> </ul> </li> </ul> <pre><code>#1 \n\nkind: ConfigMap\napiVersion: v1\nmetadata:\n  name: nginx-configuration\nspec:\n</code></pre> <pre><code>#2\n\nkind: ServiceAccount\napiVersion: v1\nmetadata:\n  name: nginx-ingress-sa-1\nspec:\n # Roles ?\n # ClusterRole ?\n # RoleBinding ?\n</code></pre> <p><pre><code>  #3\n\n  apiVersion: v1\n  kind: Service\n  metadata:\n    name: nginx-ingress\n  spec:\n    type: NodePort\n    ports:\n      - port: 80\n        targetPort: 80\n        protocol: TCP\n        name: http\n      - port: 443\n        targetPort: 443\n        protocol: TCP\n        name: https\n    selector:\n      name: nginx-ingress\n ```\n</code></pre>   ## ingress-controller pod ##</p> <p>apiVersion: extensions/v1beta1   kind: Deployment   metadata:     name: nginx-ingress-controller   spec:     replicas: 1     selector:       matchLabels:          name: nginx-ingress     template:       metadata:         labels:         name: nginx-ingress       spec:         containers:           - name: nginx-ingress-controller             image: quay.io/kubernetes-ingresscontroller/nginx-ingress-controller:0.21.0             args:             - /nginx-ingress-controller             - --configmap=$(POD_NAMESPACE)/nginx-configuration             env:             - name: POD_NAME               valueFrom:                 fieldRef:                   fieldPath: metadata.name             - name: POD_NAMESPACE               valueFrom:                 fieldRef:                   fieldPath: metadata.namespace             ports:             - name: http               containerPort: 80             - name: https               containerPort: 443</p>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#_1","title":"```","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#ingress-resources","title":"ingress resources","text":"<ul> <li>Ingress Object having:</li> <li>routing / forwarding rules</li> <li>Security : SSL, firewall, etc.</li> <li>eg: rule-1(path-1/2/...),  rule-2(path-1/2/...)</li> <li></li> <li></li> </ul> <pre><code>apiVersion: extensions/v1beta1\nkind: Ingress\nmetadata:\n  name: ingress-1\nspec:\n  rules:\n  - host: my-online-store.com\n    http:\n      paths:\n      - path: /wear\n        backend:\n          serviceName : wear-service\n          servicePort : 80\n      - path: /watch\n        backend:\n          serviceName : watch-service\n          servicePort : 80 \n\n  - host: watch.my-online-store.com\n    http:\n      paths:\n      - path: *\n        backend:\n          serviceName : wear-service\n          servicePort : 80\n\n  - host: watch.my-online-store.com\n    http: \n      paths:\n      - path: *\n        backend:\n          serviceName : watch-service\n          servicePort : 80\n</code></pre>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#understand-yaml","title":"understand yaml","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#properties","title":"properties","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/02_ingress/#annotation","title":"annotation","text":"<ul> <li><code>alb.ingress.kubernetes.io/backend-protocol</code>: HTTP: </li> <li>Specifies the protocol (HTTP in this case) used to communicate between the load balancer and the backend pods.</li> <li><code>alb.ingress.kubernetes.io/certificate-arn</code>: \"{{ .Values.certificateArn }}\":</li> <li>Associates an SSL certificate (from AWS Certificate Manager) with the load balancer, enabling HTTPS traffic.</li> <li><code>alb.ingress.kubernetes.io/group.name</code>: \"{{ .Values.component }}-ingress-group\": </li> <li>Defines a group name to manage multiple Ingress resources as a single Application Load Balancer (ALB) group.</li> <li><code>alb.ingress.kubernetes.io/listen-ports</code>: '[{\"HTTP\": 80},{\"HTTPS\": 443}]': </li> <li>Configures the ALB to listen on both HTTP (port 80) and HTTPS (port 443).</li> <li><code>alb.ingress.kubernetes.io/load-balancer-attributes</code>:</li> <li>Sets various load balancer attributes, such as enabling access logs and specifying the S3 bucket and prefix where logs are stored.</li> <li><code>alb.ingress.kubernetes.io/scheme: internal</code>: </li> <li>Makes the load balancer internal, meaning it\u2019s only accessible within the VPC and not publicly exposed.</li> <li><code>alb.ingress.kubernetes.io/ssl-policy</code>: ELBSecurityPolicy-FS-1-2-Res-2020-10: </li> <li>Specifies the TLS policy for secure connections. This policy enforces certain encryption standards.</li> <li><code>alb.ingress.kubernetes.io/ssl-redirect</code>: \"443\": </li> <li>Redirects HTTP traffic to HTTPS by specifying port 443 as the target.</li> <li><code>alb.ingress.kubernetes.io/tags</code>: \"k1=v1,...\"</li> <li>Adds tags to the ALB with information such as costCenter, envType, expDate, and ppmcId, useful for resource management and tracking.</li> <li><code>alb.ingress.kubernetes.io/target-type</code>: ip: </li> <li>Specifies that the target type for the ALB is ip, meaning it targets pod IPs directly, which is often used with EKS clusters.</li> <li><code>external-dns.alpha.kubernetes.io/hostname</code>: \"{{ .Values.hostname }}\": </li> <li>Allows the ExternalDNS controller to manage DNS records for the specified hostname.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/03_network-policies/","title":"03 network policies","text":""},{"location":"03_Kubernetes/02_KCAD/04_services%2BNetworking/03_network-policies/#network-policy","title":"network policy","text":"<ul> <li>cluster has VPC span across nodes.<ul> <li>by default all traffic <code>allow</code> b/w ALL pods, services.</li> <li>can add restriction with n/w policy.</li> <li>pod, services  === VM, has IP:port in VPC.</li> <li></li> <li></li> </ul> </li> <li>policy:<ul> <li>in rule added to allow incoming traffice, then default respomse out is allowed.</li> <li>And don't add separate egress rule.</li> <li>eg: DB-pod &lt;---allow---- API-pod. good. enough</li> <li>yml definition:</li> <li>ingress --&gt; from : cidr block, other pod of ns-1, etc <pre><code>apiVersion: networking.k8s.io/v1\nkind: NetworkPolicy\nmetadata:\n  name: db-policy\nspec:  # apply on pods\n  podSelector:\n    matchLabels:\n      role: frontend  \n  policyTypes:\n  - Ingress\n  # - Egress\n  ingress: # define `from` and `ports`\n  - from:\n    # -------rule-1--------\n    - podSelector:  \n        matchLabels:\n          name: api-pod\n      # ------ AND -------    \n      nameSpaceSelector:\n        matchLabel:\n          name: prod \n     # ------- OR, rule-2--------    \n    - ipBlock\n        cidr:             \n    ports:\n    - protocol: TCP\n      port: 3306\n  - ...\n  - ...\n</code></pre></li> </ul> </li> <li> <p>case-1 : AND <pre><code>  - podSelector:\n    nameSpaceSelector:\n    ipBlock\n</code></pre></p> </li> <li> <p>case-2 : OR <pre><code>  - podSelector:\n  - nameSpaceSelector:\n  - ipBlock\n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/01_volume/","title":"A. Volume (in pod)","text":"<ul> <li>by-default pop are <code>transient</code>. data in not retained after pod is terminated.</li> <li>how to persist data processed by the containers. </li> <li>sol - <code>Volume</code></li> <li></li> <li>volume Types:</li> <li><code>emptyDir</code> - Temporary storage created when a pod starts, Deleted when the pod is terminated</li> <li><code>nfs</code>: Mounts a remote NFS server directory into the pod.</li> <li><code>awsElasticBlockStore / gcePersistentDisk / azureDisk</code></li> <li><code>csi</code> : third-party storage providers to integrate with Kubernetes</li> <li><code>hostpath</code> - mount File or directory from the host node's filesystem into a pod</li> <li></li> <li>Create volume and mount it in single pod. <pre><code>apiVersion: v1\nkind: Pod                       &lt;&lt;&lt;&lt;&lt;\nmetadata:\n    name: \nspec:\n    containers:\n    - ...\n      volumeMounts:\n        - mountPath: /opt\n          name: data-volume\n\n    volumes:                    &lt;&lt;&lt;&lt;&lt;&lt; CONFIGURED VOLUME WITHIN POD\n    - name: data-volume\n      hostPath:                 # source-1 - Node local dir\n        path: /data\n        type: Directory\n      ---- OR ----\n      awsElasticBlockStore:     # source-2 - aws EBS\n        volumeID: \n        fsType:   \n</code></pre></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/01_volume/#b-central-volume","title":"B. Central Volume","text":""},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/01_volume/#pv-persistent-volume","title":"PV - Persistent Volume","text":"<ul> <li>having multiple pod, then maintain storage <code>centrally</code></li> <li>and carve out part of to each pod using <code>claims</code> (PVC)</li> <li>usually admin creates PV. and user creates PVC <pre><code>apiVersion: v1\nkind: PersistentVolume\nmetadata:\n    name: pv-vol1\nspec: \n    accessModes:   # how to mount\n    - ReadWriteOnce  # ReadOnlyMany,  ReadWriteOnce,  ReadWriteMany\n    capacity:\n        storage: 1Gi\n    hostPath:                   # source-1\n        path: /tmp/da\n    ---- OR ----    \n    awsElasticBlockStore:       # source-2\n        volumeID: \n        fsType:\n    ---- OR ----    \n    azureDisk:\n        ...    \n</code></pre></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/01_volume/#pvc-persistent-volume-claims","title":"PVC - Persistent Volume claims","text":"<ul> <li>request for binding to storage/PV based on :</li> <li>capacity</li> <li>accessMode/s</li> <li>volume Modes</li> <li>storage class</li> <li>labels and selectors.</li> <li><code>1-to-1</code> b/w PV and PVC</li> <li>once a PV is bind</li> <li>then no other PVC will get bind to that PV&gt;</li> <li>smaller PVC  can get binded to  big PV (if thats the only match)</li> <li>state: <code>pending</code> + bind</li> <li>if delete PVC, then PV is retain (by default). even data inside PV</li> <li><code>pesistentVolumeClaimPolicy: Retain</code> </li> <li>options:<ul> <li><code>retain</code> - keep PV with data (default)</li> <li><code>Delete</code> - delete PV</li> <li><code>recycle</code> -  keep PV only, scrap all Data</li> </ul> </li> <li>definition:</li> <li>we don't define binding in definition</li> <li> <p>it just finds matching one at runtime. &lt;&lt;&lt;&lt;</p> <pre><code>  apiVersion: v1\n  kind: PersistentVolumeClaim\n  metadata:\n      name: myclaim\n  spec:\n    # storageClassName: \n    accessModes:\n      - ReadWriteOnce\n    resources:\n      requests:           &lt;&lt;&lt; request\n        storage: 500Mi\n        ...\n        ... \n</code></pre> </li> <li> <p>Next, use it inside - <code>pod, deployment and RS object</code> <pre><code># pod,RS,D object:\nspec:\n   ...\n   ...    \n   volumes:\n   - name: mypd\n     persistentVolumeClaim:\n       claimName: myclaim\n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/01_volume/#screenshots","title":"Screenshots:","text":""},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/02_storage-class/","title":"02 storage class","text":""},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/02_storage-class/#storage-class","title":"Storage class","text":"<ul> <li><code>static</code> provisioning </li> <li>specify PV first. Storage created ahead of time with static config</li> <li>then define PVC<ul> <li>if matches then get bind</li> </ul> </li> <li><code>dynamic</code> provisioning</li> <li>define storageClass/SC with parameter</li> <li> <p>then define PVC</p> <ul> <li>PVC will use SC to provision needed storage.</li> <li>so, SC creates PV dynamically.</li> </ul> </li> <li> <p>with Storage-Class can define  <code>Dynamic Storage provisioner</code> <pre><code>apiVersion: v1\nkind: StorageClass\nmetadata:\n   name: gcp-sc-1\nprovisioner: kubernetes.io/gce-pd  &lt;&lt;&lt;&lt;&lt;  \nparameters:\n  type:\n  replication-types:  \n\n  next, use it  inside PVC\n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/05_state-persistence/02_storage-class/#screenshots","title":"Screenshots","text":"<ul> <li>static</li> <li></li> <li>dynamic</li> <li></li> </ul> <p>VolumeClaimTemplate</p>"},{"location":"03_Kubernetes/02_KCAD/06-security/01-Authentication/","title":"Authentication","text":"<ul> <li>K8s cluster (<code>kube-apiserver</code>, running as system pod), will be accessed by :</li> <li><code>users (Admin / developer)</code> - we don't create them in k8s </li> <li><code>SA</code> : we create these in k8s.</li> <li> <p><code>end user</code> : out of scope. will be handled <code>inside application</code> deployed on k8s pod.</p> </li> <li> <p>NOTE : kube-apiserver is running as pod.</p> </li> <li>hence always update : /etc/kubernetes/manifests/kube-apiserver.yaml.</li> <li>ps -ef | grep kube-apiserver </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/01-Authentication/#authentication-mechanism","title":"Authentication mechanism","text":""},{"location":"03_Kubernetes/02_KCAD/06-security/01-Authentication/#1-static-password-file-basic-auth","title":"1. Static password file  (basic Auth)","text":"<ul> <li>Modify the kube-apiserver startup options -<ul> <li>command section : add <code>--basic-auth-file=user-details.csv</code></li> </ul> </li> <li>usage: curl -v -k https://master-node-ip:6443/api/v1/pods <code>-u \"u1:p1\"</code></li> <li>user-detail.csv --&gt; pwd_1, username_1, userId, groupId</li> <li>plain text file , hence not recommended. deprecated in Kubernetes version 1.19</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/01-Authentication/#2-static-token-file","title":"2. Static token file","text":"<ul> <li>add <code>--token-auth-file=user-token-detail.csv</code> </li> <li>token_1, username_1, userId, groupId</li> <li>usage: curl -v -k https://master-node-ip:6443/api/v1/pods <code>--header \"Authorization: Bearer token_1\"</code></li> <li>plain text file , hence not recommended. deprecated in Kubernetes version 1.19</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/01-Authentication/#3-certificate","title":"3. Certificate","text":"<ul> <li>Note : generate certificates for different Kubernetes components and for a user and use them in the Kubernetes cluster is not in the scope of the official CKAD exam</li> <li>we don't create them in k8s</li> <li>first generate certificate for user. </li> <li>All users certificates are stored at  --&gt; <code>/etc/kubernetes/pki/users</code></li> <li>check : 02-kubeconfig.md <pre><code>1. Generate a Private Key for the User:\n- openssl genrsa -out newuser.key 2048\n\n2. Create a Certificate Signing Request (CSR):\n- openssl req -new -key newuser.key -out newuser.csr -subj \"/CN=newuser/O=your-organization\"\n\n3. Sign the Certificate with Minikube\u2019s CA\n- openssl x509 -req -in newuser.csr -CA ~/.minikube/ca.crt -CAkey ~/.minikube/ca.key -CAcreateserial -out newuser.crt -days 365 -extensions v3_req\n\n4. Add the New User to kubeconfig\n- kubectl config set-credentials newuser --client-certificate=newuser.crt --client-key=newuser.key\n- kubectl config set-context newuser-context --cluster=minikube --user=newuser\n# minikube cluster a;lready exist.\n\n5. Switch to the New User Context\nkubectl config use-context newuser-context\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/01-Authentication/#4-external-id-service-oktaldap","title":"4. External ID service - okta,LDAP.","text":"<ul> <li>not in scope.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/02-kubeConfig-file/","title":"kubeConfig File","text":"<ul> <li>read by <code>kubectl</code> cmd.</li> <li>this file, present at<code>$HOME/.kube/config</code> (default file)</li> <li>view file : kubectl config view</li> <li>can setup/use custom file --&gt; kubectl .... --kubeconfig=new-file</li> <li>has 3 section</li> <li><code>1. cluster</code> : <ul> <li>--server my-kube-playground:6443 (cluster-1)</li> <li>--certificate-authority cacert.crt</li> </ul> </li> <li><code>3. context</code>  --&gt; which user will connect to which cluster, that mapping<ul> <li>admin_1 will connect to cluster-1</li> </ul> </li> <li><code>2. users</code> : admin_1<ul> <li>--client-key            admin_1.key</li> <li>--client-certificate    admin_1.crt</li> </ul> </li> <li>Note: above 4 option/s --xxxx, get attached to every kubectl command we make.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/02-kubeConfig-file/#screenshots","title":"ScreenShots","text":"<ul> <li>add more entries for other clusters and users</li> <li></li> <li>there are 3 contexts, make one default.<ul> <li>after <code>kind</code>, add <code>current-context: dev-user@google</code></li> </ul> </li> <li>can also define <code>namespace</code> in context:</li> <li></li> <li><code>certificates</code></li> <li>can put base64 encoded certificate data, as well. Rather than filepath.</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/02-kubeConfig-file/#commands","title":"Commands","text":"<ul> <li>kubectl config view</li> <li>kubectl config use-context prod-user@production-cluster </li> <li>this will update <code>current-context</code> feild.</li> <li>kubectl config -h</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/03-API-Group/","title":"API Group","text":"<ul> <li>so far, we were using kubectl utility. can also achieve same using REST api.</li> <li>First, get <code>master-node-address</code> and port .</li> <li>minikube ip</li> <li> <p>kubectl config view --minify -o jsonpath='{.clusters[0].cluster.server}'</p> </li> <li> <p>API groups / categories  --&gt; all k8s resources are grouped under:</p> </li> <li>/metrics</li> <li>/healthz</li> <li>/version --&gt; cluster version. ?</li> <li><code>/api</code> * --&gt; core  functionalities.</li> <li><code>/apis</code> * --&gt; named. more organized. future functionalities.</li> <li> <p>/logs --&gt; integrating with 3rd part logging server.</p> </li> <li> <p>so, not all user can  call all api. will authorize user, will give granular permission. check here </p> </li> <li> <p>try:</p> </li> <li>curl http://localhost:6443 -k</li> <li>curl https://master-node-address:6443/version</li> <li>curl https://master-node-address:6443/api/v1/pods</li> <li></li> <li>fixes authentication issue:<ul> <li>Fix-1 :: passing--&gt; --key --cert --cacert</li> <li>fix-2 :: use <code>kubectl proxy</code> server.</li> <li>It forwards the request to kubeapi server with key,cacert,and cert.</li> <li>run on port <code>8001</code>. </li> <li>curl http://localhost:8001/api</li> <li>Note: <code>kube proxy</code> and <code>kubectl proxy</code>, are different. check later.</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/03-API-Group/#1-api","title":"1. /api","text":"<ul> <li>curl http://localhost:6443/api -k | grep \"name\"</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/03-API-Group/#2-apis","title":"2. /apis","text":"<ul> <li>curl http://localhost:6443/apis -k | grep \"name\"</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/","title":"Authorization","text":"<ul> <li>check kube-apiserver setting:</li> <li>kubectl get pods -n kube-system -o wide + then describe pod</li> <li>cat /etc/kubernetes/manifests/kube-apiserver.yaml</li> <li>ps -aux | grep kube-apiserver</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#a-common-task-for","title":"A. Common task for :","text":"<ul> <li><code>Admin</code> </li> <li>scaling : add node in cluster</li> <li>network and security Policies</li> <li>ResourceQuota and limits - storage</li> <li>setting up RBAC rules</li> <li>DR and backup.</li> <li><code>Developer</code></li> <li>app deploymnet</li> <li>configMap and secrets</li> <li>horizontal scaling - add pod</li> <li>manage services, expose pods.</li> <li>monitor and debugging, logging.</li> <li><code>sa</code> (eg: jenkins)</li> <li>Accessing the Kubernetes API for tasks like resource discovery, scaling, or <code>configuration changes</code> within applications.</li> <li>Running Jobs and CronJobs, workloads</li> <li><code>Automation</code> for admin and developer task.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#b-authorization-mode","title":"B. Authorization Mode","text":"<ul> <li>kubectl get pods -n kube-system -o wide</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#1-node","title":"1. Node","text":"<ul> <li>built-in special authorizer for kubelets.</li> <li>allows Kubernetes nodes (<code>kubelets</code>) to access only resources needed to manage pods on that node.</li> <li>READ : service, nodes, pods, </li> <li>Write : pod status, node status, event</li> <li>Note: group system-node --&gt; kubelets are part of this.</li> <li>request coming from this group is authorized by special authorizer  ( called Node-Authorizer )</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#2-abac-attribute-based","title":"2. ABAC (attribute based)","text":"<ul> <li>built-in.</li> <li>permissions are defined in a policy JSON file with specific attributes like user, namespace, verb, resource, etc.</li> <li>ABAC is <code>less flexible</code>, thus difficult to manage.</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#3-rbac-role-based","title":"3. RBAC (Role based)","text":"<ul> <li>built-in</li> <li>Most efficient. like in aws.</li> <li>create role-1 (permission-1, 2, ...)</li> <li>then associate users (u1, u2, group1, sa1 ...) with role-1</li> <li>Create below 2 definitions:</li> <li>Role --&gt; <code>rules</code>: list of [ apigroup, resources, verb, resourceName ]<ul> <li>role for namespace scoped resource</li> <li>eg: pod, service, sa</li> </ul> </li> <li>RoleBinding --&gt; <code>subject/s</code> (user,sa) and <code>roleRef</code> </li> <li></li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#4-webhook","title":"4. webhook","text":"<ul> <li><code>open policy agent</code>, helps to connect to 3rd party authorization server.</li> <li>forwards authorization requests to an external service over a webhook API.</li> <li>use-case: custom authorization logic outside of Kubernetes</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#5-6-always-allowed-denied","title":"5. / 6.  Always allowed / denied","text":"<ul> <li>configure above modes in kubeapi config. </li> <li>authorization-mode=</li> <li>can setup multiple mode. it moves to from one to another until authorized.</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/04-Authorization/#c-check-access","title":"C. Check Access","text":"<ul> <li>kubectl auth can-i [create|delete]    [deploymnets|node|pods] --as user1 --namespace ns1</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/06-Cluster-roles/","title":"06 Cluster roles","text":"<ul> <li>k api-resources -namespaced=true</li> <li>k api-resources -namespaced=false</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/06-Cluster-roles/#cluster-role-and-binding","title":"cluster Role and binding","text":"<ul> <li>primarly to create role for <code>cluster</code>-scoped-resource. eg: node, pv</li> <li>Also, create role for <code>namespace</code>-scoped-resource. eg: pod, etc</li> <li> <p>this will add role for that resource in all namespace inside clusters.</p> </li> <li> <p></p> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/","title":"Admission Controller","text":""},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/#concept","title":"concept","text":"<ul> <li>kubectl --&gt; kube-apiserver --&gt; ? &gt; ? &gt; ? &gt; create pod</li> <li>kubectl --&gt; kube-apiserver --&gt; <code>authentication</code> --&gt; <code>Authorization</code> --&gt; additional actions  --&gt; create pod</li> <li>use Admission controller for more security measures.</li> <li>use built in or create your own.</li> <li>additional actions:</li> <li>allow/deny request </li> <li>validate configuration </li> <li>perform operations </li> <li> <p>can change can the request itself.</p> </li> <li> <p>example for additional task:</p> </li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/#a-enabled-or-disabled","title":"A. enabled or disabled","text":"<ul> <li>enabled or disabled on the API server, via the <code>--enable-admission-plugins</code> flag</li> <li>kube-apiserver -h | grep enable-admission-plugins : wont work, try below.</li> <li>k exec kube-apiserver-controlplane -n kube-system -- kube-apiserver -h | grep enable-admission-plugins *</li> <li>ps -ef | grep kube-apiserver | grep admission-plugins</li> <li>edit:<ul> <li>kube-apiserver.service</li> <li>/etc/kubernetes/mainifests/kube-apiserver.yaml * --&gt; when we update this file, it take few to restart.so wait.</li> <li></li> </ul> </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/#b-some-built-in-admission-controller","title":"B. some built-in  Admission Controller","text":"<p> - <code>NamespaceLifecycle</code> :   - preventing creation of resources in non-existent   - make sure  ns - <code>default, kube-system and kube-public</code> cannot be deleted. - <code>NamespaceAutoProvision</code> deprecated : creates ns if not exists. - <code>NamespaceExists</code> deprecated - <code>LimitRanger</code> :  Enforces limits and resource requests on Pods and Containers within a namespace - <code>ResourceQuota</code>:  - <code>ServiceAccount</code> : Automatically assigns a default service account to Pods that do not specify one. - <code>DefaultStorageClass</code> :  Assigns a default StorageClass to PersistentVolumeClaims (PVCs) - <code>NodeRestriction</code> : restricting kubelets to modifying resources associated with their own node.   - usually disabled - <code>EventRateLimit</code> : Limits the number of event objects a single source can generate in a given timeframe</p>"},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/#c-types","title":"C. Types","text":""},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/#c1-updatingmutating-admission-controller","title":"C.1 updating/mutating Admission Controller","text":"<ul> <li>runs first,  (before validation   Admission Controller )</li> <li>change/update object yaml/description before creating.</li> <li>eg: <code>DefaultstorageClass</code>, <code>NamespaceAutoProvision</code></li> <li>it updates PVC object : add <code>storageClassName: default</code>. was initially not present.</li> <li></li> <li>inspect after creation, <code>k describe pvc myclaim | grep StorageClass</code></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/#c2-validating-admission-controller","title":"C.2 validating Admission Controller","text":"<ul> <li>allow or deny create|edit|delete requests.</li> <li>eg:  <code>NamespaceExists</code>, <code>NamespaceLifecycle</code></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/06-security/07-Admission-controller/#d-external-admission-controller-admissionhook","title":"D. external Admission Controller / AdmissionHook","text":"<ul> <li>custom-built, with own validating and mutating logic.</li> <li>2 in-built Admission Controller present to support this.</li> <li><code>MutatingAdmissionHook</code></li> <li><code>ValidatingAdmissionHook</code></li> <li> </li> <li> <p>Steps:</p> </li> <li>1 create <code>webhook app</code> <ul> <li>with 2 POST REST api <code>/validate</code> and <code>/mutate.</code></li> <li>create in any language. py,java, node</li> <li>follow request / response json format. check official doc.</li> </ul> </li> <li>2 Next, deploy this webhook app <ul> <li>inside k8s cluster as pod and svc. </li> <li>Or, external server.</li> </ul> </li> <li> <p>3 next, create  configuration objects </p> <ul> <li>validationWebhookConfiguration / MutatingWebhookConfiguration object.</li> <li>has <code>connection detail</code> to webhook app.</li> <li>has <code>rule/s,</code> when to call these webhook api.</li> </ul> </li> <li> <p>screenshots for more understaning:</p> </li> <li></li> <li></li> <li></li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/","title":"01 API version","text":""},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#api-version","title":"API Version","text":"<ul> <li><code>apiVersion:</code> api-group/api-version</li> <li>alpha, beta and stable</li> <li>check:</li> <li>kubectl api-versions</li> <li> <p>kubectl api-resources</p> </li> <li> <p>k8s supports multiple version. handle multiple version:</p> </li> <li><code>preferred</code><ul> <li>typically the latest stable version of that resource.</li> <li>eg: apps/v1 for deploymnet.</li> </ul> </li> <li><code>stored</code><ul> <li>version in which Kubernetes stores resource data in its etcd database, internally.</li> </ul> </li> <li>enable version. eg:</li> <li>kube-apiserver.yaml --&gt; add <code>--runtime-config=rbac.authorization.k8s.io/v1alpha1</code></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#api-deprecations-rules","title":"API Deprecations rules","text":""},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#rule-1","title":"rule-1","text":"<ul> <li>API element may only be removed, by incrementing the version.</li> <li></li> <li>in yaml it can be still alpha1, but internally it switch to alpha2.</li> <li>since alpha2 is <code>preferred</code> and <code>stored</code> version.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#rule-2","title":"rule-2","text":"<ul> <li>API version must be able to round-trip in given release without information loss.</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#rule-3","title":"rule-3","text":"<ul> <li>older version must be supported  for some duration</li> <li><code>GA/stable</code> - 12 months or 3 releases</li> <li><code>beta</code> - 12 months or 3 releases</li> <li><code>alpha</code> - anytime deprecate.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#rule-4","title":"rule-4","text":"<ul> <li>v2 just now came and released in current release. </li> <li>then it can be become preferred/stored.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#rule-5","title":"rule-5","text":"<ul> <li>v1-Alpha1 &gt; v1-Alpha2 &gt; V1-beta1 &gt; v1-beta2 &gt; <code>v1</code></li> <li>v2-Alpha1 &gt; v2-Alpha2 &gt; V1-beta1 &gt; v1-beta2 &gt; <code>v2</code> &gt; after this can deprecate <code>v1</code>.</li> </ul> <ul> <li>eg:</li> <li></li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/01-API-version/#kubectl-convert","title":"<code>Kubectl Convert</code>","text":"<ul> <li>install this utility first. check official doc.</li> <li>https://kubernetes.io/docs/tasks/tools/install-kubectl-linux/#install-kubectl-convert-plugin   <pre><code>- steps (linux)\n  - curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl-convert\"\n  - curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl-convert.sha256\"\n  - echo \"$(cat kubectl-convert.sha256) kubectl-convert\" | sha256sum --check\n  - sudo install -o root -g root -m 0755 kubectl-convert /usr/local/bin/kubectl-convert\n  - kubectl convert --help\n</code></pre></li> <li>kubectl convert -f old-file.yaml --output-version apps/v2 --&gt; it will priny new converted yaml file.</li> <li>eg:  k convert -f ingress-old.yaml --output-version networking.k8s.io/v1 &gt; ingress-new.yaml </li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/02-Custom-resource-defintions/","title":"02 Custom resource defintions","text":""},{"location":"03_Kubernetes/02_KCAD/08_Others/02-Custom-resource-defintions/#custom-resource","title":"Custom Resource.","text":""},{"location":"03_Kubernetes/02_KCAD/08_Others/02-Custom-resource-defintions/#step-1-custom-resource-definition-crd","title":"STEP-1 : custom <code>resource definition</code> (CRD)","text":"<ul> <li><code>k create -f flightticket.yaml</code></li> <li><code>k get flighttickets</code>. it will go into <code>pending</code> state.</li> <li><code>k create -f flightticket.yaml</code></li> <li>now its in etcd.</li> <li>note: scope - <code>Namespaced</code> or <code>clustered</code>.</li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/02-Custom-resource-defintions/#step-2-custom-controller-cc","title":"STEP-2 : Custom <code>controller</code> (CC)","text":"<ul> <li>next, look into etcd and take action.</li> <li>clone : https://github.com/kubernetes/sample-controller.git (language : go)</li> <li>run it as pod inside cluster.</li> <li></li> </ul>"},{"location":"03_Kubernetes/02_KCAD/08_Others/02-Custom-resource-defintions/#operator-framework-intro","title":"operator framework (INTRO)","text":"<ul> <li>CRD and CC can be deployed together as single entity using this.</li> <li>perform addition things too. check operatorhub.io</li> <li>install it and us it.</li> <li>Note: out of scope in CKAD exam.</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/","title":"02 01 EKS Cluster","text":""},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#referencechatgpt","title":"Reference/chatgpt","text":"<ul> <li>cluster setup </li> <li>https://chat.deepseek.com/a/chat/s/1125c5bb-48e4-4aff-9e3e-4720011cfd45  </li> <li>https://chat.deepseek.com/a/chat/s/da139fc5-e06f-42e3-8419-a2c17a94a9cf </li> <li>create first user </li> <li>https://chatgpt.com/c/673940a9-d1cc-800d-a117-847107be2e53 </li> <li>https://chatgpt.com/c/67371203-d934-800d-94f1-3c996d9584dd</li> <li>Authentication + IRSA  : https://chatgpt.com/c/67342f43-7220-800d-8831-68fe91ea7a87</li> <li>aws-auth : https://chatgpt.com/c/6734280e-7d48-800d-b410-280da79926fe</li> <li>pipeline</li> <li>https://chatgpt.com/c/67346f23-ce58-800d-9b35-a0ccf088f920</li> <li>https://chatgpt.com/c/67352892-e094-800d-a053-9a51c1074097</li> <li>https://chatgpt.com/c/67358116-3f1c-800d-96c6-c6d447f1b283</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#a-kubernetes-architecture","title":"A. kubernetes Architecture","text":"<ul> <li>03_k8s-architcture+features.md</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#b-eks-cluster","title":"B EKS cluster","text":""},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#b1-master-node-control-panel","title":"B.1 master node / control panel","text":"<ul> <li>kube-apiserver</li> <li>coreDNS</li> <li>controllers</li> <li>add ons:</li> <li>metric server</li> <li>logging server</li> <li>datadog agent</li> <li>splunk agent</li> <li>ingress-controller / ALB controller (gateway)</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#b2-worker-node","title":"B.2 worker node","text":"<ul> <li>kubelet</li> <li>kube proxy</li> <li>docker / container-d</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#b3-setup-network","title":"B.3 setup network","text":"<ul> <li>awsvpc</li> <li>none</li> <li>host</li> <li>bridge</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#b4-cloud-service","title":"B.4 cloud service","text":"<ul> <li>ALB (alb-controller, install with helm)</li> <li>EBS / EFS</li> <li>Aws Secrets manager -&gt; externalSecret -&gt; k8s:Secret</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d-eks-cluster-setup-platform-team-terraformhcl-yellow_circle","title":"D. EKS cluster Setup (platform team) :: terraform/HCL :yellow_circle:","text":""},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#options","title":"options","text":"<ul> <li>AWS managed service (EKS - fargate)</li> <li>AWS managed service (EKS - ec2 launch type)</li> <li>Node </li> <li>Nodegroup</li> <li>https://www.udemy.com/course/docker-kubernetes-the-practical-guide/learn/lecture/22628019#overview</li> <li>https://www.udemy.com/course/docker-kubernetes-the-practical-guide/learn/lecture/22628021#overview</li> <li>AWS :: EC2</li> <li>spin up EC2 machine</li> <li>set up VPC</li> <li>software installation manually</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#artifacts","title":"artifacts","text":"<ul> <li>HCP workspace: https://app.terraform.io/app/lekhrajdinkar-org/workspaces/aws-config-maps-outbound-dev2-eks/runs </li> <li>HCL configuration : terraforn config</li> <li>aws provider using <code>role-1</code> (will become admin user)   <pre><code>=== attach on role-1 ====\n- AmazonEKSClusterPolicy\n- AmazonEKSWorkerNodePolicy\n- AmazonEKSServicePolicy\n- inline\n  - eks:AccessKubernetesApi, DescribeCluster, ListClusters,\n  - iam:getRole,PassRole\n</code></pre></li> <li>command/s</li> <li>kubectl cluster-info</li> <li>aws eks update-kubeconfig --cluster cluster-1 --region r1 <pre><code>  - `master`: https://C7467B80CEF6669327EE0493423B84A5.gr7.us-west-2.eks.amazonaws.com\n  - `CoreDNS` : https://C7467B80CEF6669327EE0493423B84A5.gr7.us-west-2.eks.amazonaws.com/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d1-create-2-iam-roles","title":"D.1 create :: 2 IAM-roles","text":"<ul> <li>cluster-role-1 :</li> <li>standard policy</li> <li>node-group-role-1</li> <li>container registry policy</li> <li>worker node policy </li> <li>CNI policy</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d2-create-vpc-for-eks","title":"D.2 create :: VPC for EKS","text":"<ul> <li>create vpc-1 </li> <li>with standard cloudformation template.</li> <li>on your own</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d3-create-cluster","title":"D.3 create :: cluster","text":"<ul> <li>choose cluster type : public and private</li> <li>Configure AWS temp credential for role-1(become admin): getStsToken, gimme-aws-creds(okta)</li> <li>input :</li> <li>cluster name - cluster-1</li> <li>cluster-role-1</li> <li>vpc-1</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d4-associate-oidc-provider","title":"D.4 Associate :: OIDC provider","text":"<ul> <li>Associate identity provider (OIDC)  </li> <li>used for IRSA </li> <li>an OIDC provider (oidc-1) is automatically associated with it.</li> <li> <p>if not found manually configured</p> <ul> <li>eksctl utils associate-iam-oidc-provider --cluster $cluster_name --approve</li> </ul> </li> <li> <p>READY  :green_circle:</p> </li> <li>aws eks describe --cluster=cluster-1</li> <li>aws eks update-config --cluster=cluster-1</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d5-admin-user-automatic-created","title":"D.5 admin user (automatic created)","text":"<ul> <li>Note: users === outside k8s user / federated === represent aws <code>IAM user/role</code></li> <li>admin-user (role-1) auto created</li> <li>user-2 (eks-cluster-role-1-for-federated-user) </li> <li>created role : https://us-east-1.console.aws.amazon.com/iam/home?region=us-west-2#/roles/details/eks-cluster-role-1-for-federated-user?section=permissions</li> <li> <p>kubectl edit configmap aws-auth -n kube-system <pre><code>aws-auth: (kube-system namespace)\n========\n...\nmapRoles: |\n  - rolearn: arn:aws:iam::123456789012:role/role-1\n    username: arn:aws:iam::123456789012:role/role-1    \n    groups:\n      - system:masters         \n...\n</code></pre> <pre><code>kubeconfig\n============\n...\nusers:\n- name: arn:aws:iam::123456789012:role/role-1\n  user:\n    exec:\n      apiVersion: client.authentication.k8s.io/v1beta1\n      args:\n      - --region\n      - us-west-2\n      - eks\n      - get-token  === sts:GetCallerIdentity  with your IAM credentials (e.g., from ~/.aws/credentials or an IAM role).  &lt;&lt;&lt;&lt;\n      - --cluster-name\n      - maps-outbound-us-west-2-dev2-eks-fargate-cluster\n      - --output\n      - json\n      command: aws\n</code></pre> </p> </li> <li> <p>Authentication flow <pre><code>- aws eks get-token\n- sts:GetCallerIdentity with your IAM credentials (e.g., from ~/.aws/credentials or an IAM role).\n- AWS STS returns a presigned **URL** containing - user ID, account ID, roleArn\n  - kubectl cli, converts to --&gt;  k8s-aws-v1.&lt;base64-encoded-sts-**url**&gt;\n  - k8s-aws-v1.aHR0cHM6Ly9zdHMuYW1hem9uYXdzLmNvbS8...\n- send this token to the EKS cluster\u2019s API server with Authorization header  &lt;&lt;&lt;&lt;\n  - API server decodes the token to extract the STS presigned URL\n  - forwards the URL to **AWS IAM Authenticator**\n  - The authenticator checks the **aws-auth** ConfigMap in the kube-system namespace\n</code></pre></p> </li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d6-create-nodegroup","title":"D.6 Create :: Nodegroup","text":"<ul> <li>compute tab </li> <li>add <code>Nodegroup</code>(ec2 machines)</li> <li>input:</li> <li>node-group-role-1</li> <li>vpc-1</li> <li>instance-type</li> <li>scaling</li> <li>it will  install k8s software needed for worker node.</li> <li>READY :green_circle:</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d7-volumes-efs","title":"D.7 volumes : EFS","text":"<ul> <li>storageClass (CSI) + pvc</li> <li>integrate 3rd party storage on k8s -EFS</li> <li>https://github.com/kubernetes-sigs/aws-efs-csi-driver</li> <li>install this driver :: kubectl apply -k \"github.com/kubernetes-sigs/aws-efs-csi-driver/deploy/kubernetes/overlays/stable/?ref=release-2.0\"</li> <li>add EFS in same vpc-1 </li> <li>add security-group to allow traffic with in VPC. <pre><code>      # PV\n      ...\n      ...\n      volumnMode: Filesystem\n      storageClassName: efs-sc-1\n      csi:\n        driver: efs.csi.aws.com\n        volumehandle:  fs-1  # id  of fs created above\n\n      ---\n      # SC\n      ...\n      ...\n        name: efs-sc-1\n      spec:\n        provisoner: efs.csi.aws.com\n\n      ---\n      # PVC\n      ...\n      ...\n        name: efs-pvc-1\n      spec:\n        storageClassName: efs-sc-1\n        resources:\n          requests:\n            storage: 5Gi\n\n      ---\n\n      # pod\n       volumns:\n          - name:\n            pvc:\n              claimname: efs-pvc-1\n\n       container:\n        - ...\n          ...\n          volumnMounts:\n            - name: \n              mountpath: /app/abc  \n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_01_EKS_Cluster/#d8-add-on","title":"D.8 add-on","text":"<p>15_DeamonSet.md</p>"},{"location":"03_Kubernetes/04_EKS/02_02_EKS-AddUser%2BServiceAcct/","title":"02 02 EKS AddUser+ServiceAcct","text":""},{"location":"03_Kubernetes/04_EKS/02_02_EKS-AddUser%2BServiceAcct/#a-create-eks-user-non-admin","title":"A. create :: eks-user (non-admin)","text":"<ul> <li>eg: user-app( broad-access-role )</li> <li>same as admin. but remove this group <code>system:masters</code></li> <li>RBAC </li> <li>create ClusterRole and ClusterRoleBinding for this group. (for cluster-level resource)</li> <li>create Role and RoleBinding for this group. (for ns-level resource)</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_02_EKS-AddUser%2BServiceAcct/#1-updateadd-aws-auth-configmap","title":"1. update/Add : aws-auth configmap","text":"<pre><code>mapRoles: |\n  - rolearn: arn:aws:iam::123456789012:role/aws-role-1\n    username: aws-role-1-user    \n    groups:\n      - app_DevLead         \n</code></pre>"},{"location":"03_Kubernetes/04_EKS/02_02_EKS-AddUser%2BServiceAcct/#2-clusterrole-developer-role-1","title":"2. ClusterRole : developer-role-1","text":"<ul> <li>allow access to  any resource in namespace <pre><code>kind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: developer-role-1\n# edit rules - fine grain \nrules:\n- apiGroups: [\"\"]\n  resources: [\"namespace\"]\n  verbs: [\"*\"]\n  labelSelector\n    matchLabels:\n        atm-id: \"aa003199\" \n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_02_EKS-AddUser%2BServiceAcct/#3-clusterrolebinding-developer-role-1-app_devleadgroup","title":"3. ClusterRoleBinding :  developer-role-1 === app_DevLead(group)","text":""},{"location":"03_Kubernetes/04_EKS/02_02_EKS-AddUser%2BServiceAcct/#apiversion-rbacauthorizationk8siov1-kind-clusterrolebinding-metadata-name-developer-role-1-binding-subjects-kind-group-name-app_devlead-apigroup-rbacauthorizationk8sio-roleref-kind-clusterrole-name-developer-role-1-apigroup-rbacauthorizationk8sio","title":"<pre><code>apiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: developer-role-1-binding\nsubjects:\n- kind: Group\n  name: app_DevLead\n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: developer-role-1\n  apiGroup: rbac.authorization.k8s.io\n</code></pre>","text":""},{"location":"03_Kubernetes/04_EKS/02_02_EKS-AddUser%2BServiceAcct/#b-create-service-account","title":"B. create :: service Account","text":"<ul> <li>create eks object yaml, inside ns.</li> <li>for permission to k8s-resource : <code>role and role-binding</code></li> <li>for permission to aws-resource : <code>IRSA</code></li> <li>annotate service account with <code>aws iam role</code>.</li> <li>Pods assuming IAM roles via serviceAccount(annotated role-1)</li> <li>fact : also attaching role on fargate-role:</li> <li>pulling image</li> <li>eni</li> <li>...</li> </ul> <p>Untitled Diagram.drawio</p>"},{"location":"03_Kubernetes/04_EKS/02_03_nodegroup%2BfargateProfile/","title":"A. Nodegroup","text":""},{"location":"03_Kubernetes/04_EKS/02_03_nodegroup%2BfargateProfile/#1-intro","title":"1. intro","text":"<ul> <li>collection of nodes (virtual machines) within a cluster that share the same/Homogeneous configuration. </li> <li>same instance type, </li> <li>disk size, </li> <li>AMI (Amazon Machine Image)</li> <li>...</li> <li>Scaling + Availability</li> <li>Workload Separation, eg:</li> <li>nodegroup-1: frontend/s (need to more secure security, facing interbet)</li> <li>nodegroup-2: backend/s + batch processing/s</li> <li>...</li> <li>Cost Optimization :Use different instance-types in separate node groups to optimize costs based on workload requirements. </li> </ul> <pre><code>aws eks create-nodegroup \\\n--cluster-name my-cluster \\\n--nodegroup-name my-nodegroup-1 \\\n--subnets subnet-12345678 subnet-87654321 \\\n--instance-types t3.medium \\\n--scaling-config minSize=1,maxSize=10,desiredSize=2 \\\n--ami-type AL2_x86_64 \\\n--node-role arn:aws:iam::123456789012:role/EKSNodeInstanceRole\n</code></pre>"},{"location":"03_Kubernetes/04_EKS/02_03_nodegroup%2BfargateProfile/#b-fargate-profile","title":"B. Fargate profile","text":""},{"location":"03_Kubernetes/04_EKS/02_03_nodegroup%2BfargateProfile/#1-intro_1","title":"1 intro","text":"<ul> <li>input:</li> <li>namespace + additional label </li> <li>podExecutionRoleArn : role-1 (used by pods) - to Pull container images from ECR,Create ENIs, etc</li> <li>subnets</li> <li>Also, SA annotated with role-2, mounted on pod.</li> <li>Used by the Pod for AWS SDK/API calls</li> <li>for accessing AWS services (like S3, DynamoDB, etc.)</li> <li>https://chatgpt.com/c/684c5acc-4de4-800d-9b8b-2bb44031a6e5</li> </ul>"},{"location":"03_Kubernetes/04_EKS/02_03_nodegroup%2BfargateProfile/#2-create-with-eks-eksctl-crd-trf","title":"2 create with eks eksCtl, CRD, trf","text":"<p><pre><code># =========CRD============\napiVersion: eks.amazonaws.com/v1\nkind: FargateProfile\nmetadata:\n  name: dev-fargate-profile\nspec:\n  clusterName: your-eks-cluster-name\n  podExecutionRoleArn: arn:aws:iam::123456789012:role/your-pod-execution-role\n  selectors:\n    - namespace: dev-ns\n</code></pre> <pre><code># ==========aws cli===========\naws eks create-fargate-profile \\\n  --cluster-name cluster-1 \\\n  --fargate-profile-name profile-1 \\\n  --namespace dev-ns \\\n  --pod-execution-role-arn arn:aws:iam::123456789012:role/your-pod-execution-role\n  --lable env=dev-pod\n</code></pre> <pre><code># ==========trf===========\nresource \"aws_eks_fargate_profile\" \"eks_fargate_profile\" {\n  cluster_name = aws_eks_cluster.eks_cluster.name\n  fargate_profile_name = \"${local.prefix}-fargate-profile\"\n  pod_execution_role_arn = aws_iam_role.eks_pod_exec_role.arn\n\n  subnet_ids = aws_subnet.eks_private_subnet[*].id\n\n  selector {\n    namespace = var.namespace\n  }\n  depends_on = [\n    aws_eks_cluster.eks_cluster,\n    aws_iam_role.eks_pod_exec_role\n  ]\n}\n</code></pre></p>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-00-start/","title":"03 EKS Developer 00 start","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-00-start/#1-deployment-folder","title":"1. deployment folder","text":"<ul> <li>manifest yaml :: spring_app_v2</li> <li>10_podDisruptionBudget.yaml</li> <li>09_HPA.yaml vs Cluster Autoscaler</li> <li>deployment : deployment-1</li> <li>metric (single / mutli) : <ul> <li>cpu and memory </li> <li>custom metric </li> <li>high traffic</li> </ul> </li> <li>behaviour : policy - up /down<ul> <li>stabilization window</li> <li>no/% of pod up/down, every x seconds</li> </ul> </li> <li>must see: https://chat.deepseek.com/a/chat/s/00db1638-b5bc-4a70-a585-4a487e210a63 <ul> <li>scenarios:</li> <li>configure HPA for a stateful application</li> <li>mplement a \"warm pool\" for sudden traffic spike</li> </ul> </li> <li>08_external_secret.md</li> <li>annotation:</li> <li>07_annotation-ingress.md</li> <li>07_annotation-Pod.md</li> <li>07_annotation-sa.md</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-00-start/#2-commnds","title":"2. Commnds","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-00-start/#aws-ec2-describe-subnets-filters-namevpc-idvaluesvpc-id-from-output-region-us-west-2-aws-ec2-describe-vpcs-vpc-ids-vpc-id-from-output-region-us-west-2-aws-eks-list-fargate-profiles-cluster-name-your-cluster-name-region-us-west-2-aws-ec2-describe-vpc-endpoints-filters-namevpc-idvaluesvpc-id-from-output-region-us-west-2-aws-ec2-describe-route-tables-filters-namevpc-idvaluesvpc-id-from-output-region-us-west-2-aws-ec2-describe-security-groups-filters-namevpc-idvaluesvpc-id-from-output-region-us-west-2-aws-eks-describe-cluster-name-maps-outbound-us-west-2-dev2-eks-fargate-cluster-region-us-west-2-query-clusteridentityoidcissuer-aws-iam-create-open-id-connect-provider-url-httpsoidceksus-west-2amazonawscomid867fafa03f6706024b5895223d5d3451-client-id-list-stsamazonawsco-aws-eks-get-token-cluster-name-maps-outbound-us-west-2-dev2-eks-fargate-cluster-region-us-west-2-aws-eks-update-kubeconfig-name-maps-outbound-us-west-2-dev2-eks-fargate-cluster-region-us-west-2-aws-eks-describe-update-name-maps-outbound-us-west-2-dev2-eks-fargate-cluster-update-id-388626d9-068d-3325-b988-f15ecd94ee51-region-us-west-2-got-update-it-from-trf-logs-kubectl-get-configmap-aws-logging-n-kube-system","title":"<pre><code>aws ec2 describe-subnets --filters \"Name=vpc-id,Values=vpc-id-from-output\" --region us-west-2\naws ec2 describe-vpcs --vpc-ids vpc-id-from-output --region us-west-2\naws eks list-fargate-profiles --cluster-name your-cluster-name --region us-west-2\naws ec2 describe-vpc-endpoints --filters \"Name=vpc-id,Values=vpc-id-from-output\" --region us-west-2\naws ec2 describe-route-tables --filters \"Name=vpc-id,Values=vpc-id-from-output\" --region us-west-2\naws ec2 describe-security-groups --filters \"Name=vpc-id,Values=vpc-id-from-output\" --region us-west-2\n\n\naws eks describe-cluster  --name maps-outbound-us-west-2-dev2-eks-fargate-cluster --region us-west-2 --query \"cluster.identity.oidc.issuer\"\naws iam create-open-id-connect-provider --url https://oidc.eks.us-west-2.amazonaws.com/id/867FAFA03F6706024B5895223D5D3451 --client-id-list sts.amazonaws.co\naws eks get-token  --cluster-name maps-outbound-us-west-2-dev2-eks-fargate-cluster --region us-west-2\naws eks update-kubeconfig --name maps-outbound-us-west-2-dev2-eks-fargate-cluster --region us-west-2\n\naws eks describe-update --name maps-outbound-us-west-2-dev2-eks-fargate-cluster  --update-id 388626d9-068d-3325-b988-f15ecd94ee51 --region us-west-2\n# got update it from trf logs\n\nkubectl get configmap aws-logging -n kube-system\n</code></pre>","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-00-start/#3-comparison-ecs-vs-eks","title":"3. Comparison :: ECS vs EKS","text":"<ul> <li>02_Containers_ECS.md vs 02_Kubernetes_EKS.md</li> <li> <p><code>Clusters</code></p> <ul> <li>logical grouping of tasks or services.</li> <li>Equivalent to <code>Cluster in Kubernetes</code></li> </ul> </li> <li> <p><code>Tasks</code> === pod</p> <ul> <li>A single running copy of a container defined by a task definition.</li> </ul> </li> <li> <p><code>Task Definitions</code> == pod</p> <ul> <li>Blueprints for your application that specify the container images, CPU, memory, and other settings.</li> </ul> </li> <li> <p><code>Services</code>  === Replica Set</p> <ul> <li>Allows you to run and maintain a specified number of instances of a task definition simultaneously.</li> </ul> </li> <li> <p><code>Container Instances</code> == work Nodes</p> <ul> <li>Amazon EC2 instances registered to your cluster and used to run tasks.</li> <li>Equivalent in Kubernetes: <code>Nodes</code></li> </ul> </li> <li> <p><code>Elastic Load Balancing (ELB)</code>   === Service (specifically, LoadBalancer type)</p> <ul> <li>Distributes incoming application traffic across multiple targets.</li> </ul> </li> <li> <p><code>Auto Scaling</code> === Horizontal Pod Autoscaler</p> <ul> <li>Adjusts the desired count of tasks in a service automatically based on criteria.</li> </ul> </li> <li> <p><code>ECS Agent</code> === Kubelet</p> <ul> <li>Software that runs on each container instance and communicates with ECS to start and stop tasks.</li> </ul> </li> <li> <p><code>ECS Fargate</code></p> <ul> <li>A serverless compute engine for containers that eliminates the need to manage EC2 instances.</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-00-start/#3-okta-ignore","title":"3. Okta (ignore)","text":"<ul> <li>https://dev-16206041-admin.okta.com/</li> <li>https://dev-16206041.okta.com/</li> <li>https://dev-16206041-admin.okta.com/admin/app/oidc_client/client/0oal3d72smuSHBhwF5d7#tab-general<ul> <li>client_id : 0oal3d72smuSHBhwF5d7</li> <li>issuer URI :</li> <li>https://dev-16206041.okta.com/oauth2/default (default)</li> <li>https://dev-16206041.okta.com/oauth2/ausl3dg4kkpyvEBft5d7</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/","title":"03 EKS Developer 01 HPA","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#-httpschatdeepseekcomachats00db1638-b5bc-4a70-a585-4a487e210a63","title":"- https://chat.deepseek.com/a/chat/s/00db1638-b5bc-4a70-a585-4a487e210a63","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#a-pod-disruption-budgets","title":"A. pod disruption budgets","text":"<ul> <li>maintain availability during scaling</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#b-hpa","title":"B. HPA","text":"<ul> <li>FSR :: 09_HPA.yaml </li> <li>Monitor scaling events ?</li> <li>HPA vs Cluster Autoscaler</li> <li>node level scaling</li> <li>Use node affinity/taints</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#b1-create","title":"B.1 create","text":"<ul> <li>deployment : deployment-1</li> <li>metric (single / mutli) :<ul> <li>cpu and memory</li> <li>custom metric</li> <li>high traffic</li> </ul> </li> <li>behaviour : policy - up /down<ul> <li>stabilization window</li> <li>no/% of pod up/down, every x seconds <pre><code>metrics:\n- type: Resource\n  resource:\n    name: cpu\n    target:\n      type: Utilization\n      averageUtilization: 70\n\nbehavior:\n  scaleUp:\n    policies:\n      - type: Pods\n        value: 2\n        periodSeconds: 15\n      - type: Percent\n        value: 50\n        periodSeconds: 60\n    selectPolicy: Max\n</code></pre></li> </ul> </li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#b2-extcustom-metric-datadog","title":"B.2  Ext/custom metric (datadog)","text":"<ul> <li>intro</li> <li>capture application-specific load patterns</li> <li>eg: no of business req count , no of transaction, etc</li> <li>good for stateful app</li> <li>flow: app-metric &gt; datadog/prometheous &gt; HPA (monitor it) &gt; perform scaling</li> <li>hands-on</li> <li>Deploy datadog Adapter/agent in cluster</li> <li>list all datadog metrics: curl \"https://api.datadoghq.com/api/v1/metrics?api_key=${DD_API_KEY}&amp;application_key=${DD_APP_KEY}\"</li> <li>eg: datadog.nginx.net.request_per_s</li> <li>datadog.{} <li>...</li> <li>kubectl get --raw \"/apis/external.metrics.k8s.io/v1beta1/namespaces/default/datadog.nginx.net.request_per_s\" | jq <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: nginx-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: nginx\n  minReplicas: 2\n  maxReplicas: 10\n  metrics:\n    - type: External\n      external:\n        metric:\n          name: datadog.nginx.requests_per_s\n          selector:\n            matchLabels: # Automatic tags/label are added\n              kube_container_name: nginx\n              kube_service: my-webapp\n              kube_namespace: ns-1\n              pod_name: pod-1\n        target:\n          type: AverageValue\n          averageValue: 100  # Scale when average requests per second per pod exceeds 100\n</code></pre></li>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#b3-warm-pool","title":"B.3 warm pool","text":"<ul> <li>pending...</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#b4-troubleshoot-scaling-issue","title":"b.4 troubleshoot :: scaling issue","text":"<ul> <li>kubectl describe hpa</li> <li>kubectl get events</li> <li>hpa-controller logs</li> <li>Verify cluster has available resources</li> <li>Verify readiness/liveness probe configuration</li> <li>Optimize container images</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#c-scenarios","title":"C. scenarios:","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#c1-configure-hpa-for-a-stateful-application","title":"C.1 configure HPA for a stateful application","text":"<ul> <li>StatefulSets instead of Deployments</li> <li>Implement PV and PVC</li> <li>external storage class </li> <li>CSI : EFS, S3</li> <li>init containers for storage preparation</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#c2-mission-critical-autoscaling-strategy","title":"C.2 Mission-critical autoscaling strategy","text":"<ul> <li>implement a warm pool for sudden traffic spike</li> <li>Implement readiness probes on pod</li> <li>Implement multi-metric scaling (CPU, memory, custom metrics like queue length)</li> <li>Combine with cluster autoscaler for node-level scaling </li> <li>configure:</li> <li>aggressive scale-up (low stabilization window, high percent/pod-count) </li> <li>conservative scale-down</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#c3-time-based-auto-scaling","title":"C.3 Time based auto-scaling","text":"<ul> <li>did metric-based scaling so far, above.</li> </ul>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#option-1-cronhpa-controller-modifies-hpa-specs-on-schedule","title":"Option-1 : CronHPA controller : modifies HPA specs on schedule","text":"<pre><code># === insatll er controller with helm ==\nhelm repo add stable https://charts.helm.sh/stable\nhelm install cronhpa stable/cronhpa\n</code></pre> <pre><code>apiVersion: autoscaling.cronhpa.io/v1\nkind: CronHorizontalPodAutoscaler\nmetadata:\n  name: myapp-cronhpa\nspec:\n   scaleTargetRef:\n     apiVersion: apps/v1\n     kind: Deployment  # scale deploymnet\n     name: myapp\n   schedules:\n   - name: \"business-hours\"\n     description: \"Scale up during business hours\"\n     schedule: \"0 9 * * MON-FRI\"  # At 09:00 AM Monday-Friday\n     targetSize: 10\n   - name: \"off-hours\"\n     description: \"Scale down after hours\"\n     schedule: \"0 18 * * MON-FRI\" # At 06:00 PM Monday-Friday\n     targetSize: 2\n   - name: \"weekend\"\n     description: \"Weekend scaling\"\n     schedule: \"0 0 * * SAT\"      # At midnight on Saturday\n     targetSize: 1\n</code></pre>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-01-HPA/#option-2-cronjon-to-patch-hpa","title":"Option-2 : CronJon to patch HPA","text":"<ul> <li>kubectl patch hpa my-hpa --patch '{\"spec\": {\"minReplicas\": 10}}'  <pre><code>apiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n  name: myapp-hpa\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: myapp\n  minReplicas: 1\n  maxReplicas: 15\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n</code></pre></li> </ul> <pre><code># Scale-up CronJob (runs at 8:45 AM weekdays)\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: scale-up\nspec:\n  schedule: \"45 8 * * MON-FRI\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: kubectl\n              image: bitnami/kubectl\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  kubectl patch hpa myapp-hpa \\\n                    --type='json' \\\n                    -p='[{\"op\": \"replace\", \"path\": \"/spec/minReplicas\", \"value\": 5}]'\n          restartPolicy: OnFailure\n\n# Scale-down CronJob (runs at 7:00 PM weekdays)\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  name: scale-down\nspec:\n  schedule: \"0 19 * * MON-FRI\"\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          containers:\n            - name: kubectl\n              image: bitnami/kubectl\n              command:\n                - /bin/sh\n                - -c\n                - |\n                  kubectl patch hpa myapp-hpa \\\n                    --type='json' \\\n                    -p='[{\"op\": \"replace\", \"path\": \"/spec/minReplicas\", \"value\": 1}]'\n          restartPolicy: OnFailure\n</code></pre>"},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-Deployment/","title":"03 EKS Developer Deployment","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-Deployment/#deployment","title":"Deployment","text":""},{"location":"03_Kubernetes/04_EKS/03_EKS_Developer-Deployment/#1-strategy","title":"1. strategy","text":"<ul> <li>helm install --&gt; will create deploymnet object with whatever stragey mentioned in deploymnet object. <pre><code>strategy:\n  type: RollingUpdate\n  rollingUpdate:\n    maxSurge: 25%\n    maxUnavailable: 25%\n</code></pre></li> <li>maxSurge: 25% \u2192 up to 25 extra pods (new version) can be created \u2192 total pods may reach 125 during update.</li> <li>maxUnavailable: 25% \u2192 up to 25 old pods can be taken down at a time \u2192 at least 75 pods remain available during update.</li> <li>customize:     <pre><code>helm install myapp ./chart \\\n  --set strategy.rollingUpdate.maxSurge=30 \\\n  --set strategy.rollingUpdate.maxUnavailable=10\n</code></pre> -</li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG-MCP-cluster/","title":"cg - MCP cluster","text":"<ul> <li>multi tenant(shared) kube env in 2 aws region. Dedicated AWS account - mcp-aws</li> <li>platform-team already provisioned EKS cluster with add on:</li> <li>VPC</li> <li>establish OpenID connect</li> <li>Cluster Role + worker Node (cluster auto-scale)</li> <li>ingress controller (eg: nginx)</li> <li>agents - security, logging, monitoring, reloader-rollout on configmap changes,</li> <li>or, fargate profile for each ATMID &gt; select NS labeled with ATmID</li> </ul> <ul> <li>on-boarding request, provide:</li> <li><code>cluster name</code>: mcp-etc|im-use1|usw2-dev|qa|prod-ns-01</li> <li><code>role</code> --&gt; our AWS account: <code>Broad-access-role</code></li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG-MCP-cluster/#a-platform-team-action","title":"A platform-team Action","text":""},{"location":"03_Kubernetes/04_EKS/99_CG-MCP-cluster/#action-1-share-kubeconfig","title":"action-1 : share KubeConfig","text":"<ul> <li>cluster already created, share connection detail over SSM parameter store</li> <li>cluster_info</li> <li>kubeconfig (cluster-1, user-1, context-1) <pre><code>## Example\n\napiVersion: v1\nkind: Config\nclusters:\n- name: mcp-im-usel-dev-ns-01\n  cluster:\n  server: https://kube-admin\n  cacert-data: b64....\n  contexts:\n- name: mcp-im-usel-dev-ns-01\n  context:\n  cluster: mcp-im-usel-dev-ns-01\n  user: mcp-im-usel-dev-ns-01\n  current-context: mcp-im-usel-dev-ns-01\n\nusers:\n- name: mcp-im-usel-dev-ns-01\n  user:\n  exec:\n  apiVersion: client.authentication.k8s.io/v1beta1\n  command: aws\n  args:\n  - eks\n  - get-token\n  - --region\n  - us-east-1\n  - --cluster-name\n  - mcp-im-usel-dev-ns-01\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG-MCP-cluster/#action-2-add-iamidentity-provider-for-eks","title":"Action-2 : add IAM:Identity provider for EKS","text":"<ul> <li>aws eks describe-cluster </li> <li>--name  <li>--region  <li>--query <code>\"cluster.identity.oidc.issuer\"</code> </li> <li>--output text</li> <li>add OIDC provider in IAM:identity provider of our AWS acct.</li> <li><code>issuerId</code> - https://oidc.eks.us-west-2.amazonaws.com/id/eks-cluster-id</li> <li><code>audience</code> - sts.amazonaws.com </li> <li>why ?</li> <li>IRSA</li> <li>POD-1 running in eks-cluster(aws-1) has to assume role in aws-tenant-1.</li> <li>pod- has sa-1<ul> <li>annotated with aws-tenant-1/role-1 </li> <li>not with aws-1/role-1</li> </ul> </li>"},{"location":"03_Kubernetes/04_EKS/99_CG-MCP-cluster/#action-3-authentication","title":"action-3 : Authentication","text":"<ul> <li>02_OIDC+first_admin_user+new_user.md</li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG-MCP-cluster/#action-4-rbac","title":"Action-4 : RBAC","text":"<ul> <li>create ClusterRole --&gt; to access resource for namespace label with atmid.</li> <li>create ClusterRoleBinding. <pre><code>kind: ClusterRole\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: atmid-role\n# edit rules - fine grain \nrules:\n- apiGroups: [\"\"]\n  resources: [\"namespace\"]\n  verbs: [\"*\"]\n  labelSelector\n    matchLabels:\n        atm-id: \"aaaaaaa\"          &lt;&lt;&lt;\n\n---\n\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: developer-role-1-binding\nsubjects:\n- kind: Group\n  name: developer-group-1  \n  apiGroup: rbac.authorization.k8s.io\nroleRef:\n  kind: ClusterRole\n  name: atmid-role\n  apiGroup: rbac.authorization.k8s.io\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG-MCP-cluster/#b-developer-actions","title":"B Developer actions","text":"<ul> <li>namespace(label-atmid)</li> <li>atm_id-dev|qa|prod-description</li> <li>add tags : ATM ID</li> <li>deployment object</li> <li>services  object (cluster IP)</li> <li> <p>ingress-rule object (host/{path} --&gt; map to above services)</p> </li> <li> <p>service account - sa1 (for pod exec)</p> </li> <li>annotate sa object with : <code>eks.amazonaws.com/role-arn:</code> pod-exec-iam-role:arn</li> <li>add inline-policy to role - &gt; access s3,sqs, etc</li> <li>add trusted-policy :   <pre><code>{\n  \"Effect\": \"Allow\",\n  \"Principal\": {\n    \"Federated\": \"arn:aws:iam::&lt;account-id&gt;:oidc-provider/oidc.eks.&lt;region&gt;.amazonaws.com/id/&lt;eks-cluster-id&gt;\"\n  },\n  \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n  \"Condition\": {\n    \"StringEquals\": {\n      \"oidc.eks.&lt;region&gt;.amazonaws.com/id/&lt;eks-cluster-id&gt;:sub\": \"system:serviceaccount:&lt;namespace&gt;:&lt;service-account-name&gt;\"\n    }\n  }\n}\n</code></pre></li> <li>configMap object</li> <li>External secret object </li> <li>ext store : aws secret manager   <pre><code>pending...\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_Ext-secret-2/","title":"99 CG Ext secret 2","text":""},{"location":"03_Kubernetes/04_EKS/99_CG_Ext-secret-2/#a-external-secretsio","title":"A. external-secrets.io","text":"<ul> <li>check here pls : 05-external-secret-aws.yaml</li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_Ext-secret-2/#1-secretstore","title":"1. SecretStore","text":"<ul> <li>provider : aws</li> <li>region</li> <li>serviceAccountRef : sa-1 (aws-isra-role-1) <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\",\n        \"secretsmanager:ListSecrets\"\n      ],\n      \"Resource\": [\n        \"arn:aws:secretsmanager:us-east-1:35326752882:secret:aws-secretManager-*\",\n      ]\n    }\n  ]\n} \n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_Ext-secret-2/#2-externalsecret","title":"2. ExternalSecret","text":"<ul> <li>secretStoreRef : above one</li> <li>target : k8s-secret-1 </li> <li>data :</li> <li>k8s-secret-1.key-1 = remoteRef ( aws-secretManager-1.key-1 )</li> <li>k8s-secret-1.key-2 = remoteRef ( aws-secretManager-2.key-1 )</li> <li>...</li> <li>mapping between k8s and aws</li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_Ext-secret-2/#valusyaml-helm","title":"valus.yaml (HELM)","text":"<ul> <li>just for reference / ccgg <pre><code># External Secrets Operator (ESO) - Secret Store\nsecretStore:\n  create: true\n  region: us-east-1\n  serviceAccountName: backend-eso-as-deo3\n\n# External Secrets Operator - External Secrets\nexternalSecrets:\n  db:\n    create: false\n    refreshInterval: 1m\n    targetName: db-credential # target kubernetes-secret name\n    amsSecretManagerSecretName: \"aws-secretManager-1\" # source AMS Secrets manager secret\n    amsSecretManagerSecretKey1: username # source key1 in AMS Secrets manager\n    targetSecretKey1: username # target kubernetes secret key1\n    amsSecretManagerSecretKey2: password # source key2 in AMS Secrets manager\n    targetSecretKey2: password # target kubernetes secret key2\n\n  tls:\n    create: true\n    refreshInterval: 1m\n    targetName: fsr-backend-release-deo3-tls-cert # target kubernetes-secret name\n    amsSecretManagerSecretName: \"aws-secretManager-2\" # source AMS Secrets manager secret\n    amsSecretManagerSecretKey1: certificate # source key1 in AMS Secrets manager\n    targetSecretKey1: tls.crt # target kubernetes secret key1\n    amsSecretManagerSecretKey2: private_key # source key2 in AMS Secrets manager\n    targetSecretKey2: tls.key # target kubernetes secret key2\n</code></pre></li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_Ext-secret/","title":"99 CG Ext secret","text":"<ul> <li>Deploy the External Secrets Operator to your Kubernetes cluster. <pre><code>helm repo add external-secrets https://charts.external-secrets.io\nhelm repo update\nhelm install external-secrets external-secrets/external-secrets\n</code></pre></li> <li>ensure Kubernetes service account has access to AWS Secrets Manager. <pre><code>{\n  \"Version\": \"2012-10-17\",\n  \"Statement\": [\n    {\n      \"Effect\": \"Allow\",\n      \"Action\": [\n        \"secretsmanager:GetSecretValue\"\n      ],\n      \"Resource\": \"arn:aws:secretsmanager:&lt;region&gt;:&lt;account-id&gt;:secret:&lt;secret-name&gt;*\"\n    }\n  ]\n}\n</code></pre></li> <li>Deploy Kubernetes ExternalSecret</li> <li><code>SecretStore</code> </li> <li><code>ExternalSecret</code> <pre><code># ------ SecretStore ---------\n\napiVersion: external-secrets.io/v1beta1\nkind: SecretStore\nmetadata:\n  name: aws-secret-store\nspec:\n  provider:\n    aws:\n      service: SecretsManager\n      region: &lt;your-region&gt;\n      auth:\n        jwt:\n          serviceAccountRef:\n            name: &lt;your-service-account&gt;\n            namespace: &lt;namespace&gt;\n\n# ----- ExternalSecret -------\n\napiVersion: external-secrets.io/v1beta1\nkind: ExternalSecret\nmetadata:\n  name: my-secret\nspec:\n  refreshInterval: 1h\n  secretStoreRef:\n    name: aws-secret-store\n    kind: SecretStore\n  target:\n    name: my-k8s-secret\n    creationPolicy: Owner\n  data:\n  - secretKey: username\n    remoteRef:\n      key: my-secret-key\n      property: username\n  - secretKey: password\n    remoteRef:\n      key: my-secret-key\n      property: password\n</code></pre></li> <li>kubectl get secret my-k8s-secret</li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_IRSA/","title":"99 CG IRSA","text":"<ul> <li>https://chatgpt.com/c/67240e7e-6e38-800d-8e1d-3b7f1a8fe509</li> <li>for AWS resource permission - use IRSA</li> <li>for K8s resource - use K8s:RBAC - role and roleBinding. </li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_IRSA/#irsa","title":"<code>IRSA</code>","text":"<ul> <li>AWS-IAM-role for k8s-service-Accounts.</li> <li>allows assigning AWS IAM roles to Kubernetes Service Accounts on Amazon EKS clusters.</li> <li>enables pods running in the cluster to securely access AWS resources.</li> <li>benefits:</li> <li>IRSA leverages AWS\u2019s <code>temporary</code> credentials.</li> <li><code>Fine-grained access</code>-  Each pod can assume an IAM role with specific permissions.</li> <li><code>Secure authentication</code> - Uses Amazon\u2019s OpenID Connect (OIDC) provider to securely authenticate Service Accounts with IAM.<ul> <li>EKS-cluster(oidc-1) &gt; NS &gt; create SA</li> <li>oidc-1 will authenticate SA </li> </ul> </li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_IRSA/#steps","title":"Steps","text":"<ul> <li>Enable the OIDC Provider for Your EKS Cluster</li> <li>Create an IAM role - <code>role-1-sa-1</code></li> <li>permission policy : add</li> <li>trust policy<ul> <li>trusted principle - OIDC provider federated user.</li> <li>serviceAccount in k8s object &gt; authenticated by OIDC &gt; become federated user to assume role.  </li> <li>notice condition: audience is <code>sa of ns</code></li> <li>check this : trusted_policy_k8s_federated_sa.tftpl <pre><code>{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n    {\n        \"Effect\": \"Allow\",\n        \"Principal\": {\n            \"Federated\": \"arn:aws:iam::533267082359:oidc-provider/oidc.eks.us-west-2.amazonaws.com/id/C1D7C8CD6FB2C01B2998093B7999CB8D\"\n        },\n        \"Action\": \"sts:AssumeRoleWithWebIdentity\",\n        \"Condition\": {\n            \"StringEquals\": {\n                \"oidc.eks.us-west-2.amazonaws.com/id/C1D7C8CD6FB2C01B2998093B7999CB8D:sub\": \"system:serviceaccount:dev-ns:spring-app-sa\"\n            }\n        }\n    }\n]\n}\n</code></pre></li> </ul> </li> <li>create sa-1 k8s object and annotate</li> <li>eks.amazonaws.com/role-arn: arn:aws:iam:::role/<code>role-1-sa-1</code> <li>Associate the Service Account with Your <code>Pods</code>. </li> <li>serviceAccountName: sa-1</li>"},{"location":"03_Kubernetes/04_EKS/99_CG_IRSA/#summary","title":"summary","text":"<ul> <li>The Kubernetes service account (sa-1) is used by a pod running in the EKS cluster.</li> <li><code>sa-1</code> is annotated with the ARN of <code>iam-role-1</code>, allowing it to be linked to AWS permissions.</li> <li><code>oidc-1</code>, acts as a federated identity provider for <code>sa-1</code></li> <li>sa-1 gets token from odic-1</li> <li>token verified by iam:identity provider</li> <li>trusted policy of <code>iam-role-1</code>, permits sa-1 to assume it.</li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-Pod/","title":"Annotation","text":""},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-Pod/#pod-instrumentationopentelemetryioxxxxxx","title":"pod : instrumentation.opentelemetry.io/xxxxxx","text":"<ul> <li>The OpenTelemetry Operator must be installed in the cluster.</li> <li> <p>The pod\u2019s namespace should have the operator\u2019s Instrumentation resource configured ```yaml apiVersion: v1 kind: Pod metadata:   name: my-java-app   annotations:     # Enable OpenTelemetry auto-instrumentation (Java)     instrumentation.opentelemetry.io/inject-java: \"true\"</p> </li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-Pod/#optional-specify-the-opentelemetry-collector-endpoint","title":"(Optional) Specify the OpenTelemetry Collector endpoint","text":"<p>instrumentation.opentelemetry.io/otel-collector-endpoint: \"http://otel-collector:4317\"</p>"},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-Pod/#optional-set-the-service-name","title":"(Optional) Set the service name","text":"<p>instrumentation.opentelemetry.io/otel-service-name: \"my-java-service\"</p>"},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-Pod/#optional-additional-java-agent-settings","title":"(Optional) Additional Java agent settings","text":"<p>instrumentation.opentelemetry.io/java-image: \"ghcr.io/open-telemetry/opentelemetry-operator/autoinstrumentation-java:latest\" instrumentation.opentelemetry.io/java-jvm-args: \"-Dotel.traces.sampler=parentbased_traceidratio -Dotel.traces.sampler.arg=0.1\"</p>"},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-Pod/#optional-disable-metricslogs-if-needed","title":"(Optional) Disable metrics/logs if needed","text":"<p>instrumentation.opentelemetry.io/otel-metrics: \"false\" instrumentation.opentelemetry.io/otel-logs: \"false\" spec:   containers: - name: my-java-app   image: my-java-app:1.0.0  ```</p>"},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-ingress/","title":"Annotation","text":""},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-ingress/#1-on-ingress-nginxingresskubernetesioxxxxxx","title":"1. on ingress : nginx.ingress.kubernetes.io/xxxxxx","text":"<ul> <li>set up CORS for UI </li> <li>notice: ssl/tls: certificated added on secret.</li> <li>Ensure you have an NGINX Ingress Controller installed <pre><code>apiVersion: networking.k8s.io/v1\nkind: Ingress\nmetadata:\n  name: backend-ingress\n  annotations:\n    nginx.ingress.kubernetes.io/enable-cors: \"true\"\n    nginx.ingress.kubernetes.io/cors-allow-origin: \"https://ui-dew4.app-1.msi-dev.lekhraj.com\"\n    nginx.ingress.kubernetes.io/cors-allow-methods: \"GET, PUT, POST, DELETE, PATCH, OPTIONS\"\n    nginx.ingress.kubernetes.io/cors-allow-headers: \"DNT, User-Agent, X-Requested-With, If-Modified-Since, Cache-Control, Content-Type, Range, Correlation-id, authorization\"\n    nginx.ingress.kubernetes.io/cors-expose-headers: \"Content-Length, Content-Range\"\n    nginx.ingress.kubernetes.io/proxy-read-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-send-timeout: \"300\"\n    nginx.ingress.kubernetes.io/proxy-next-upstream: \"off\"\nspec:\n  ingressClassName: nginx\n  rules:\n  - host: backend-dew4.app-1.msi-dev.lekhraj.com\n    http:\n      paths:\n      - path: /\n        pathType: Prefix\n        backend:\n          service:\n            name: ui-service\n            port:\n              number: 8080\n  tls:\n  - hosts:\n    - backend-dew4.app-1.msi-dev.lekhraj.com\n    secretName: app-backend-release-dev4-tls-cert\n</code></pre></li> <li>SSL setup</li> <li>option-1 : ingress controller + tls</li> <li> <p>option-2 : ALB-controller + ACM</p> </li> <li> <p>ingress scenario-1 :</p> <ul> <li>App1.ui.org.com \u2192 service.ui (ClusterIP)</li> <li>App1.api.org.com \u2192 service.api (ClusterIP)</li> <li>R53: Cname <pre><code>Subdomain         Type  Target\napp1.ui.org.com   A     Ingress Controller's Load Balancer hostname &lt;&lt;\napp1.api.org.com  A     Ingress Controller's Load Balancer hostname &gt;&gt;\n</code></pre></li> </ul> </li> <li>ingress scenario-2 :</li> <li>App1.ui.org.com \u2192 service.1 (ClusterIP)</li> <li>App1.ui.org.com \u2192 service.2 (ClusterIP)</li> <li>App1.ui.org.com would go service1/2</li> <li>ans: reolve by age. so service1 (since older)</li> </ul>"},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-sa/","title":"Annotation","text":""},{"location":"03_Kubernetes/04_EKS/99_CG_annotation-sa/#sa-eksamazonawscomrole-arn","title":"sa : eks.amazonaws.com/role-arn","text":"<p><pre><code>    apiVersion: v1\n    kind: ServiceAccount\n    metadata:\n        annotations:\n          eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/my-role\n ```\n\n- EKS mutates the Pod spec to add:\n  - A **projected volume** for the AWS IAM token (aws-lam-token).\n  - A **projected volume** for Kubernetes API credentials (kube-api-access-*).\n  - A **downwardAPI** volume for Pod metadata.\n- yaml : VOLUMEs\n```yaml\n  - name: aws-lam-token\n    projected:\n    sources:\n      - serviceAccountToken:\n          audience: sts.amazonaws.com  # AWS STS audience\n          expirationSeconds: 86400     # 24-hour token validity\n          path: token                  # Mounted at `/var/run/secrets/eks.amazonaws.com/serviceaccount/token`\n\n  - name: kube-api-access-j4hxt\n    projected:\n    sources:\n      - serviceAccountToken:\n          expirationSeconds: 3607      # Short-lived Kubernetes API token\n          path: token\n      - configMap:\n          name: kube-root-ca.crt      # Cluster CA certificate\n          items:\n            - key: ca.crt\n              path: ca.crt\n ```\n```yaml\n  downwardAPI:\n    items:\n    - fieldRef:\n        fieldPath: metadata.namespace  # Injects the Pod's namespace\n        path: namespace\n</code></pre> - yaml: pod <pre><code>apiVersion: v1\nkind: Pod\nmetadata:\n  name: my-pod\nspec:\n  serviceAccountName: my-service-account  # Linked to an IAM role (for IRSA)\n  containers:\n  - name: app\n    image: nginx\n    volumeMounts:\n    - name: aws-iam-token\n      mountPath: /var/run/secrets/aws-iam-token\n    - name: kube-api-access-j4hxt\n      mountPath: /var/run/secrets/kubernetes.io/serviceaccount\n  volumes:\n  - name: aws-iam-token\n    projected: {...}  # As in above snippet\n  - name: kube-api-access-j4hxt\n    projected: {...}  # As in above snippet\n</code></pre></p>"},{"location":"03_Kubernetes/05_helm/01_helm-chart-kickoff/","title":"reference","text":"<ul> <li>https://chat.deepseek.com/a/chat/s/3d8b4d99-81b7-4dac-ad69-519f9bc33dea</li> <li>https://chatgpt.com/c/be9c3fd6-6caf-40c0-82c6-a7c28814284c</li> </ul>"},{"location":"03_Kubernetes/05_helm/01_helm-chart-kickoff/#helm","title":"HELM","text":"<ul> <li>install : https://helm.sh/docs/intro/quickstart/</li> <li>install docker + kubeCTL + having Cluster running</li> <li>stores release info in configMap/Secret in same namespace where release done</li> <li>export HELM_DRIVER=configmap</li> <li>helm install myrelease ./mychart --debug --dry-run</li> <li>doesn't directly call kubectl behind the scenes.  Helm has its own Go client libraries that communicate directly with the Kubernetes API server.</li> <li>Smart Update Detection</li> <li>It compares the current state in Kubernetes with your new manifests</li> <li>Only resources with actual changes will be updated</li> <li>single-release-multiple-revisions model</li> <li>release-blue : revision 1, 2,....</li> <li>release-green : revision 1, 2,....</li> </ul>"},{"location":"03_Kubernetes/05_helm/01_helm-chart-kickoff/#intro","title":"Intro","text":"<ul> <li>definition:</li> <li><code>template engine</code> for K8s manifest yml files.</li> <li><code>package manager</code> for Kubernetes.</li> <li>benefit/s:</li> <li>simplifies the process of defining, installing, and managing Kubernetes applications.</li> <li>reuse across env and clusters.</li> </ul>"},{"location":"03_Kubernetes/05_helm/01_helm-chart-kickoff/#key-components","title":"Key Components","text":"<ul> <li>chart : collections of files that describe a <code>related set of Kubernetes resources</code>.</li> <li><code>Chart.yaml</code>: metadata - name, version, and description.</li> <li><code>Values.yaml</code>: <ul> <li>default configuration values.</li> <li>Users can override these values based on env while installing chart.</li> <li>values-dev,prod,etc.</li> </ul> </li> <li><code>Templates</code>: <ul> <li>A directory that contains the Kubernetes resource definitions. </li> <li>yml : deployment/service/configmap/PersistentVolume </li> </ul> </li> <li><code>Charts</code>: dependencies<ul> <li>directory that can contain dependent charts.</li> </ul> </li> </ul>"},{"location":"03_Kubernetes/05_helm/01_helm-chart-kickoff/#commands","title":"commands:","text":"<ul> <li>helm repo add bitnami https://charts.bitnami.com/bitnami</li> <li> <p>helm repo list    ```</p> <ul> <li>NAME            URL                                                  bitnami         https://charts.bitnami.com/bitnami                   puppet          https://puppetlabs.github.io/puppetserver-helm-chart   hashicorp       https://helm.releases.hashicorp.com ```</li> </ul> </li> <li> <p>create or pull</p> </li> <li>helm <code>create</code> spring-helm. </li> <li>helm pull --untar bitnami/wordpress</li> <li>helm <code>list</code> </li> <li>helm <code>install</code> release-v2 spring-helm  # <code>uninstall</code></li> <li>-f custom-values.yaml</li> <li>--set key1=value1,key2=value2</li> <li>each release has name. here <code>release-v2</code></li> <li><code>--set</code> image.repository=,image.tag= <li>helm <code>upgrade</code> release-v2 spring-helm</li> <li>Each upgrade creates a new revision of the same release </li> <li>helm <code>delete</code> release-v2</li> <li>helm <code>history</code> release-v2</li> <li>hows all revisions for release-2</li> <li>helm <code>rollback</code> release-v2 revision-n</li> <p></p>"},{"location":"03_Kubernetes/05_helm/01_helm-chart-kickoff/#scenario-jt","title":"Scenario / JT","text":"<ol> <li>deploy in order :  pod-2(kafka) &gt;  then, pod-3(Database) &gt; then, pod-1(SB)</li> <li><code>issues</code> without helm:</li> <li>so many deployment/service manifest yml : single chart with nested child chart</li> <li>deploy them in order : chart with dependent chart.</li> <li>rollout/rollback/version them all together : rollback, history, etc</li> <li>run deployment with env specific values :</li> </ol>"},{"location":"04_terraform/Notes/00_devOps/","title":"00 devOps","text":"<ul> <li>reference:</li> <li>Overview: https://chatgpt.com/c/67457115-702c-800d-9c19-7cd222a8deff</li> </ul>"},{"location":"04_terraform/Notes/00_devOps/#devops","title":"DevOps","text":"<ul> <li>collaboration between development team and operations teams </li> <li>improve the speed, quality, and reliability of SDLC / software delivery.</li> <li>automation </li> <li>continuous integration (CI) </li> <li>continuous delivery (CD)</li> <li>monitoring<ul> <li>Continuous monitoring of the production environment for issues</li> <li>cloudwatch &gt; datadog &gt; service-now </li> <li>splunk on on-prem</li> <li>more: Prometheus, Grafana</li> </ul> </li> <li>faster feedback loops.<ul> <li>due to frequent release from CD pipeline, users get frequent update.</li> </ul> </li> <li></li> </ul>"},{"location":"04_terraform/Notes/00_devOps/#a-iac","title":"A. IAC","text":"<ul> <li>Terraform </li> <li>shared EKS cluster</li> <li>AWS CDK (on AZF aws account) </li> <li>generated cloud formation template using - java, <code>typescript</code></li> <li>cdk synth</li> <li>cdk deploy stack-1</li> </ul>"},{"location":"04_terraform/Notes/00_devOps/#b-ci","title":"B. CI","text":""},{"location":"04_terraform/Notes/00_devOps/#tasks","title":"tasks:","text":"<ul> <li>Developers commit their code changes to VCS.</li> <li>After each commit, an automated build is triggered to compile the code, ensuring that the new code doesn\u2019t break the project.</li> <li>build process - maven package</li> <li>triggers Junit (automated testing)</li> <li>Early detection of bugs</li> <li>trigger code scan - <code>synk</code></li> <li>static scan - vulnerability.</li> <li>dynamic scan</li> <li>code coverage</li> <li><code>merging</code> code changes from different contributors into a shared repository frequently (develop branch)</li> <li>manual review.</li> <li>triggers CD pipeline to deploy to pre-prod env - dev1, qa1</li> </ul>"},{"location":"04_terraform/Notes/00_devOps/#tools","title":"tools:","text":"<ul> <li>Version Control: Git (GitHub, Bitbucket)</li> <li>Test Automation: JUnit, Selenium, karma &amp; jasmine.</li> <li>Harness CI pipeline</li> </ul>"},{"location":"04_terraform/Notes/00_devOps/#c-cd","title":"C. CD","text":""},{"location":"04_terraform/Notes/00_devOps/#tasks_1","title":"tasks","text":"<ul> <li>CD takes the concept of CI, a step further by automating the release process</li> <li>automatically deployed to a staging or pre-production environment for further testing</li> <li>staging environment closely matches the production environment</li> <li>Automated Rollbacks on failure</li> <li>type:</li> <li>Continuous Deployment<ul> <li>automatically deployed to production without human intervention</li> </ul> </li> <li>Continuous Delivery<ul> <li>Changes are automatically deployed to staging or <code>pre-production</code> environments</li> <li>but require manual approval for <code>production</code> deployment</li> <li>monthy release planned.</li> </ul> </li> </ul>"},{"location":"04_terraform/Notes/00_devOps/#tools_1","title":"tools","text":"<ul> <li>AWS CodePipeline - old</li> <li>Harness CD pipeline</li> <li>deployment with <code>Kubernetes and Docker</code> - microservices</li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/","title":"01 kickoff","text":"<ul> <li>https://chatgpt.com/c/672bc367-e60c-800d-9fc4-5782d0a7741b - question</li> <li>https://chatgpt.com/c/672cec04-fb0c-800d-a873-d0ad332219fb - sample aws config.</li> <li>https://chatgpt.com/c/2f328724-50e4-427d-8c04-0a17e9747150 - </li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#a-official-tutorial","title":"A. Official Tutorial:","text":"<ul> <li>check more : https://developer.hashicorp.com/terraform/tutorials</li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#fundamental","title":"Fundamental","text":"<ul> <li>https://developer.hashicorp.com/terraform/tutorials/configuration-language</li> <li>https://developer.hashicorp.com/terraform/tutorials/cli</li> <li>https://developer.hashicorp.com/terraform/tutorials/modules/module</li> <li>https://developer.hashicorp.com/terraform/tutorials/provision</li> <li>https://developer.hashicorp.com/terraform/tutorials/state/state-import</li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#cloud","title":"Cloud","text":"<ul> <li>https://developer.hashicorp.com/terraform/tutorials/cloud</li> <li>https://developer.hashicorp.com/terraform/tutorials/aws-get-started/</li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#bterraform-intro","title":"B.Terraform  - intro","text":"<ul> <li>Switching from one provider (e.g., AWS) to another (e.g., Azure) usually requires rewriting the configuration.</li> <li>https://registry.terraform.io/providers/</li> <li>https://registry.terraform.io/providers/kreuzwerker/docker/latest/docs</li> <li>https://registry.terraform.io/providers/hashicorp/aws/latest/docs</li> <li>However, Terraform provides ways to make this process more manageable/consistent.</li> <li>Define common Variables,Outputs, modules, etc across providers.</li> <li><code>tf providers</code>:</li> <li>automatically finds dependencies b/w resources and deploy in correct order.</li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#c-install-setup","title":"C. install / setup","text":"<ul> <li>windows: install binary in local, set PATH.</li> <li></li> <li>next, run locally or through HCP </li> <li>HCP (hashicorp cloud plateform) : remote state</li> <li>create account. (signup with github)</li> <li>create org (<code>lekhrajdinkar-org</code>) </li> <li>create projects (<code>default project</code> and <code>maps</code>)  </li> <li>under projects &gt; add workspace (cli/api driven)<ul> <li></li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/banzai-dev_api-driven</li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/docker</li> <li></li> </ul> </li> <li>check out confiurationCode from git<ul> <li>root-module &gt;&gt; main.tf &gt;&gt; <code>terraform</code> { <code>cloud</code> { update this } }</li> </ul> </li> <li>benefits<ul> <li>state mgt</li> <li>run history</li> <li>workspace Variable + env var</li> <li>suitable for long-running iac</li> </ul> </li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#basic-commands","title":"Basic Commands","text":"<ul> <li>https://developer.hashicorp.com/terraform/tutorials/cli/init</li> <li><code>terraform -version</code>  # Terraform v1.9.0 <pre><code>  console       Try Terraform expressions at an interactive command prompt\n  fmt           Reformat your configuration in the standard style\n  force-unlock  Release a stuck lock on the current workspace\n  get           Install or upgrade remote Terraform modules\n  graph         Generate a Graphviz graph of the steps in an operation\n  import        Associate existing infrastructure with a Terraform resource\n  login         Obtain and save credentials for a remote host , [ HCP-cluser &gt; org &gt;project &gt; workspace ]\n  logout        Remove locally-stored credentials for a remote host\n  metadata      Metadata related commands\n  output        Show output values from your root module\n  providers     Show the providers required for this configuration\n  refresh       Update the state to match remote systems\n  show          Show the current state or a saved plan\n  state         Advanced state management\n  taint         Mark a resource instance as not fully functional\n  test          Execute integration tests for Terraform modules\n  untaint       Remove the 'tainted' state from a resource instance\n  version       Show the current Terraform version\n\n  workspace     Workspace management\n    Subcommands:\n    delete    Delete a workspace\n    list      List Workspaces\n    new       Create a new workspace\n    select    Select a workspace\n    show      Show the name of the current workspace\n</code></pre></li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#d-quick-hands-on","title":"D. Quick hands on","text":""},{"location":"04_terraform/Notes/01-kickoff/#provider-docker","title":"provider : Docker","text":"<ul> <li>cd .../04_terraform/project/docker  &lt;&lt;&lt;&lt;</li> <li>login to workspace (<code>docker</code>): https://app.terraform.io/app/lekhrajdinkar-org/workspaces/docker</li> <li>clone project from git.</li> <li> <p>or, can try sample project : git clone https://github.com/hashicorp/tfc-getting-started.git</p> </li> <li> <p>terraform login</p> </li> <li>copy token from, C:\\Users\\Manisha\\AppData\\Roaming\\terraform.d\\credentials.tfrc.json</li> <li>or create new token : https://app.terraform.io/app/settings/tokens?source=terraform-login</li> <li></li> <li>terraform init - finds and downloads required provider. <pre><code>Initializing HCP Terraform...\nInitializing provider plugins...\n- Finding kreuzwerker/docker versions matching \"~&gt; 3.0.1\"...\n- Installing kreuzwerker/docker v3.0.2...\n- Installed kreuzwerker/docker v3.0.2 (self-signed, key ID BD080C4571C6104C)\nPartner and community providers are signed by their developers.\nIf you'd like to know more about provider signing, you can read about it here:\nhttps://www.terraform.io/docs/cli/plugins/signing.html\nTerraform has created a lock file .terraform.lock.hcl to record the provider\nselections it made above. Include this file in your version control repository\nso that Terraform can guarantee to make the same selections by default when\nyou run \"terraform init\" in the future.\n</code></pre></li> <li>terraform fmt : formatting</li> <li>terraform validate : validate configuration/s</li> <li>terraform plan : prints out execution plan.</li> <li>failed : https://app.terraform.io/app/lekhrajdinkar-org/workspaces/docker/runs/run-8hZLDTrQfEJ27ixj</li> <li>provider \"docker\" { } empty - fix it.</li> <li>terraform apply</li> <li>ran run directly, without running plan.</li> <li>terraform destroy -auto-approve -target=aws_s3_bucket.example_bucket (specific resource)</li> <li>print out execute plan for destroy</li> <li>confirm to apply.</li> <li>terraform destroy </li> <li><code>terraform refresh</code> : if we manully delete something.</li> <li><code>terraform plan -destroy</code></li> </ul>"},{"location":"04_terraform/Notes/01-kickoff/#provider-aws","title":"provider : aws","text":"<ul> <li>cd .../04_terraform/project/banzai-dev_api-driven   &lt;&lt;&lt;&lt;</li> <li>pre-work: configure awscli + gimme-aws-creds</li> <li>login to https://app.terraform.io/app/lekhrajdinkar-org/workspaces/banzai-dev_api-driven</li> <li>init</li> <li>plan and apply</li> <li>next, make some changes and update tf file resource. say ami id</li> <li>plan and apply</li> <li>plan -destroy</li> <li>destroy -auto-approve</li> </ul>"},{"location":"04_terraform/Notes/02-HCL/","title":"02 HCL","text":"<ul> <li>https://developer.hashicorp.com/terraform/tutorials/configuration-language</li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#hcl-hashicorp-configuration-language","title":"HCL ( HashiCorp Configuration Language)","text":""},{"location":"04_terraform/Notes/02-HCL/#a-basic","title":"A. basic","text":"<ul> <li>used write <code>configuration</code> - to create infra.</li> <li>String-interpolation </li> <li><code>web-sg-${var.resource_tags[\"project\"]}-${var.resource_tags[\"environment\"]}</code></li> <li>write in JSON or yaml</li> <li>state file <code>terraform.tfstate</code> - keep it secure and encrypted.</li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#b-project-structure","title":"B. project structure","text":"<ul> <li><code>terraform { ... required_version=\"\", required_provider={} }</code></li> <li>can make declaration anywhere. But its good practice to have seperate files.</li> <li>keep them in same-folder (<code>root-module</code>)</li> <li>every Terraform configuration is part of a module   <pre><code>  - root module:\n      - main.tf\n      - backend.tf - org, `TF_CLOUD_ORGANIZATION`=org1\n      - variable.tf\n      - provider.tf\n      - dev.qa,prod.`tfvars`\n      - s3-resource.tf, sqs-resource.tf, etc\n      - output.tf\n      - /directory-1/\n              child-module-1/\n              \u251c\u2500\u2500 main.tf\n              \u251c\u2500\u2500 variables.tf\n              \u251c\u2500\u2500 outputs.tf\n      - /directory-2/child-module-2.tf\n\n      ** root-module can use other module's config file\n</code></pre></li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#c-language-constructs","title":"C. Language constructs","text":""},{"location":"04_terraform/Notes/02-HCL/#1-provider","title":"1.  provider","text":"<ul> <li>aws : https://registry.terraform.io/providers/hashicorp/aws/latest</li> <li>providerName_resourceType --&gt; aws_<code>key_pair</code> , aws_<code>security_group</code></li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#2-variable-name32-char-max","title":"2. variable  (name,32 char max)","text":"<ul> <li><code>types</code> </li> <li>number, string, bool</li> <li>list(T), map(T) - key is string  type and value is of T type.</li> <li>tuple, object({k1 = string  k2 = number  }) <li>any</li> <li>check : variable.tf</li> <li>assign value : </li> <li>via <code>tfvars</code> file --&gt; check values-dev, values-prod.tfvars</li> <li>via <code>env variables</code> prefixed with TF_VAR_ <li>default values.</li> <li>use variable : var.&lt;&gt; <li>replace default value:   <code>-var</code>, <code>-var-file</code></li> <li>terraform apply -var var1=val1</li> <li>terraform apply -var-file var1=val1.tfvar</li> <li><code>validation</code> { condition=, error_message=}</li> <li>sensitive = true : mandatory</li> <li>apply will prompt to enter values </li> <li>or can provide via <code>.tfvars</code> file too.</li>"},{"location":"04_terraform/Notes/02-HCL/#3-output","title":"3. output","text":"<ul> <li><code>terraform output</code> -&gt; query : output1, json, etc.</li> <li><code>terraform output output-1</code> --&gt; view a specific output</li> <li>after terraform apply, output will get printed on console.</li> <li>sensitive = true --&gt; will not be printed on logs. : will not be printed on logs.</li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#4-locals","title":"4. locals","text":"<ul> <li>locals { instance_count = var.environment == \"production\" ? 5 : 1 }</li> <li>name to complex expressions or repeated values</li> <li>making your configuration easier to read and maintain.</li> <li>sensitive = true : will not be printed on logs.</li> <li>usage : local.&lt;&gt;"},{"location":"04_terraform/Notes/02-HCL/#5-resource","title":"5. resource","text":"<ul> <li><code>attribute</code> : ( optional, mandatory)</li> <li>argument - property we pass. eg <code>ami</code></li> <li>attribute - property resource has, once created. eg: <code>id</code>.</li> <li><code>dynamic attribute</code>. eg  :<code>tags</code> <pre><code>dynamic \"tags\" {\n  for_each = &lt;collection&gt;\n  content {\n   # use each.value\n   # \"${count.index}\" \n  }\n}\n\nresult :: tags = [ content-0, content-1, etc ]\n</code></pre></li> <li><code>meta-attribute</code> eg : <code>count</code> in resource</li> <li>Manage <code>similar resources</code> with count.</li> <li><code>replicates</code> the given resource with given count.   <pre><code>      eg: resource \"aws_instance\" \"app\" { count = 4 }\n        - length(aws_instance.app) : 4\n        - aws_instance.app : list of all instances.\n        - aws_instance.app.*.id : list of ids\n        - aws_instance.app[0] : first instance tr provisioned.\n        - aws_instance.app[count.index] : current index, useful while iterate.\n</code></pre></li> <li>Resource Lifecycle <pre><code>lifecycle {\n    create_before_destroy = true\n    prevent_destroy = true #for critical resource\n    ignore_changes = [ tags]\n    ...\n  }\n</code></pre></li> <li>Resource dependencies</li> <li>terraform graph</li> <li><code>Implicit</code>, eg: ec2 &gt; ingress , automatically infer by attribute.</li> <li><code>Explicit</code> : certain scenario, need to tell explicitly using <code>deponds_on</code><ul> <li>eg : depends_on = [aws_s3_bucket.r1, aws_instance.r1]</li> </ul> </li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#6-variable-set","title":"6. variable set","text":"<ul> <li>use variable across workspace/s.  </li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#7-functions","title":"7. Functions","text":"<ul> <li>check complete list : https://developer.hashicorp.com/terraform/language/functions</li> <li>numeric -&gt; abs(-12.3),ceil/floor(5.2), log(number, base), parseint(\"100\", 2/10/16),  pow(3, 2)</li> <li>string -&gt; format,start|endswith, join(\"-\", [\"foo\", \"bar\", \"baz\"]), regex(pattern, string), replace, split, substr, upper/lower, etc</li> <li>collection</li> <li><code>lookup</code>(map,key) - like map1.get(k1) in java.</li> <li><code>key</code>(var.projects)</li> <li><code>sort</code>(key(var.projects))</li> <li><code>value</code>(var.projects)</li> <li><code>slice</code>(var.private_subnet_cidr_blocks, 0, 2)</li> <li>merge()</li> <li>count()</li> <li>length()</li> <li>file system</li> <li><code>templatefile</code>(tftpl-file-1, map)</li> <li><code>file</code>(file-1)</li> <li>Date time</li> <li>IP netwpork</li> <li><code>jsonencode</code>(), <code>try</code>(expression1, expression2, ..., fallback)</li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#8-terraform-template","title":"8. Terraform template","text":"<ul> <li><code>.tftpl</code> files</li> <li>used as templates for generating configuration-files / other-text-files.</li> <li><code>dynamically generate</code> files by substituting variables and expressions within the template.</li> <li>eg:      <pre><code># user_date.tftpl &gt;&gt; shell script text file having lots of placeholders- ${placeholder-1}, etc\nuser_data= `templatefile`(\"user_data.tftpl\", { placeholder-1 = var.value1, placeholder-2 = var.value2 })\n</code></pre></li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#9-expressions","title":"9. expressions","text":"<ul> <li>ternary operation</li> <li>count criteria</li> <li>associate_public_ip_address = (<code>count.index</code> == 0 ? true : false)</li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#10-for-each","title":"10. for-each","text":"<ul> <li>for-each = var.projects, projects is map(object)  [p1:{}, p2:{}]</li> <li><code>each.key</code> and <code>each.value</code></li> <li>for-each = var.projects, projects is list/set(object)  [0:{}, 1:{}]</li> <li><code>each.key</code> === index,  <code>each.value</code> === item</li> <li>eg:</li> <li>value = { for p in sort(keys(var.project)) : p =&gt; module.elb_http[p].elb_dns_name }</li> <li>for_each = { for i, instance in var.allowed_ports : i =&gt; instance }</li> <li>use case: with resource, dynamic attribute in resource, module, output, etc</li> <li>fact : <code>mutliple for_each</code> on resource:</li> <li>cannot use two for_each expressions directly at the same level within a single resource block.  &lt;&lt;&lt;</li> <li>However, can have multiple dynamic blocks, each with its own for_each. eg:<ul> <li>resource \"aws_instance\" \"example\" {</li> <li>for_each</li> <li>dynamic \"tag\" { for_each ... }</li> <li>dynamic \"ingress\" { for_each ... }</li> <li>}</li> </ul> </li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#11-data-source","title":"11. data source","text":"<ul> <li>makes configuration more dynamic</li> <li>query (<code>read only</code>) external information or resources that are not managed by your Terraform configuration.</li> <li>dynamically fetch data from <ul> <li>APIs eg:</li> <li>query information about your <code>VPC</code>, subnet, sg</li> <li>query <code>machine image IDs</code> from a cloud provider</li> <li>other Terraform state backends</li> <li>Terraform outputs from other configurations.</li> </ul> </li> <li>eg: <code>aws_ami</code>, <code>aws_vpc</code>, <code>aws_security_group</code> <pre><code>data \"aws_vpc\" \"main\" {\n  filter {\n    name   = \"tag:Name\"\n    values = [\"main-vpc\"]\n  }\n}\n\nresource \"aws_subnet\" \"example\" {\n  vpc_id            = data.aws_vpc.main.id  # Reference the VPC ID\n  cidr_block        = \"10.0.1.0/24\"\n  availability_zone = \"us-west-2a\"\n}\n</code></pre></li> <li>inline datasource. eg: <pre><code>data \"aws_iam_policy_document\" \"example\" {\n  statement { ... }\n  statement { ... }\n}\n</code></pre></li> <li><code>data \"aws_caller_identity\" \"current\" {}</code></li> <li>retrieve details about the AWS account and credentials currently being used to execute the Terraform code</li> <li>returns : account_id, arn, user_id</li> </ul>"},{"location":"04_terraform/Notes/02-HCL/#z-more","title":"Z. More","text":"<pre><code>client-webapp = {\n      public_subnets_per_vpc  = 2,\n      private_subnets_per_vpc = 2,\n      instances_per_subnet    = 2,\n      instance_type           = \"t2.micro\",\n      environment             = \"dev\"\n    },\n    internal-webapp = {\n      public_subnets_per_vpc  = 1,\n      private_subnets_per_vpc = 1,\n      instances_per_subnet    = 2,\n      instance_type           = \"t2.nano\",\n      environment             = \"test\"\n    }\n---\nproject-root/\n\u251c\u2500\u2500 config1/\n\u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u251c\u2500\u2500 variables.tf\n\u2502   \u251c\u2500\u2500 outputs.tf\n\u251c\u2500\u2500 config2/\n\u2502   \u251c\u2500\u2500 main.tf\n\u2502   \u251c\u2500\u2500 variables.tf\n|   \u251c\u2500\u2500 outputs.tf\n\n- Each configuration (in config1/ and config2/) is independent of the other. \n- You need to run Terraform commands separately for each configuration.\n- Each configuration will have its own state file.\n- Resources defined in one configuration are not aware of resources defined in another configuration\n---\nssh-keygen -C \"your_email@example.com\" -f ssh_key\n\nresource \"aws_key_pair\" \"ssh_key\" {\n  key_name = \"ssh_key\"\n  public_key = file(\"ssh_key.pub\")\n}\n</code></pre>"},{"location":"04_terraform/Notes/03_module/","title":"03 module","text":""},{"location":"04_terraform/Notes/03_module/#modules","title":"modules","text":""},{"location":"04_terraform/Notes/03_module/#concept","title":"concept","text":"<ul> <li>organize config into smaller config.</li> <li>import from Each other.</li> <li>each directory represents a separate configuration.</li> <li>benefits:</li> <li><code>Reusability</code>: Write code once and reuse it in multiple configurations or environments.</li> <li><code>Maintainability</code>: Encapsulate complex configurations into simpler, reusable components.</li> <li><code>Organization</code>: Keep your Terraform code organized by grouping related resources together.</li> <li>Type:</li> <li><code>remote</code> : <ul> <li>\"terraform-aws-modules/vpc/aws\"</li> <li>relying on the work of others to implement common infrastructure scenarios.</li> <li>Like, packages, modules, libraries in other prog language</li> </ul> </li> <li><code>local</code> : localFileSystem -  \"./directory-1/child-module-1.tf\"</li> <li>if child-module-1 has 2 variable and no default value set.</li> <li>then have provide/pass value, while import module.   &lt;&lt;&lt;&lt;    <pre><code>module \"child-module-1\" {\n  source = \"./directory-1/child-module-1.tf\"\n  child_var_1 = value-1\n  child_var_2 = value-1  &lt;&lt;&lt;&lt;\n  ...\n  ...\n  # rather than passing soo many varaible, pass object. -- good practice.\n}\n</code></pre></li> <li>terraform init | get  --&gt; installs the module. </li> <li><code>${path.module}</code> --&gt; built-in expression ,file path of the current module being executed</li> </ul>"},{"location":"04_terraform/Notes/03_module/#example-my-s3-module","title":"example: my s3 module","text":"<ul> <li>check : s3</li> <li>resource aws_s3_bucket</li> <li>resource aws_s3_bucket_<code>logging</code></li> <li>resource aws_s3_bucket_<code>public_access_block</code></li> <li>resource aws_s3_bucket_<code>versioning</code> - t/f</li> <li>mfa_delete - t/f</li> <li>resource aws_s3_bucket_<code>server_side_encryption</code></li> <li>SSE-S3, SSE-KMS</li> <li>resource aws_s3_<code>bucket_ownership_controls</code></li> <li>ACL disable<ul> <li>objects in this bucket are owned by this account.</li> <li>Access to this bucket and its objects is specified using only policies.</li> </ul> </li> <li>ACL enable<ul> <li>Objects in this bucket can be owned by other AWS accounts</li> </ul> </li> <li>resource aws_s3_<code>bucket_policy</code></li> <li>resource aws_s3_<code>bucket_replication_configuration</code></li> <li><code>more</code></li> <li>s3 event notification</li> <li>object lock : WORM - enable / disable.</li> <li>static website hosting</li> </ul>"},{"location":"04_terraform/project/config-3-aws/readme/","title":"HCP workspace: aws-config-maps-outbound-<code>dev1</code>-<code>all</code>","text":"<ul> <li>cd ./</li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/aws-config-maps-outbound-dev1-all</li> <li>deploys these 3 modules : </li> <li>iam</li> <li>s3</li> <li>ecs</li> <li> <p>terraform plan --var-file .\\env\\dev1.tfvars</p> </li> <li> <p>run other module on <code>dev2</code>, individually</p> </li> <li>separate workspace created. (CLI-driver)</li> </ul>"},{"location":"04_terraform/project/config-3-aws/readme/#hcp-workspace-aws-config-maps-outbound-dev2-configname","title":"HCP workspace: aws-config-maps-outbound-<code>dev2</code>-<code>&lt;configName&gt;</code>","text":"<ul> <li>terraform plan --var-file ....\\env\\dev2.tfvars</li> <li>terraform apply --var-file ....\\env\\dev2.tfvars --auto-approve</li> </ul>"},{"location":"04_terraform/project/config-3-aws/readme/#aws-config-maps-outbound-dev2-eks","title":"aws-config-maps-outbound-<code>dev2</code>-eks","text":"<ul> <li>cd ./modules/eks</li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/aws-config-maps-outbound-dev2-eks</li> </ul>"},{"location":"04_terraform/project/config-3-aws/readme/#aws-config-maps-outbound-dev2-sqs-sns","title":"aws-config-maps-outbound-<code>dev2</code>-sqs-sns","text":"<ul> <li>cd ./modules/lambda</li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/aws-config-maps-outbound-dev2-sqs-sns</li> </ul>"},{"location":"04_terraform/project/config-3-aws/readme/#aws-config-maps-outbound-dev2-lambda","title":"aws-config-maps-outbound-<code>dev2</code>-lambda","text":"<ul> <li>cd ./modules/sqs_sns</li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/aws-config-maps-outbound-dev2-lambda</li> </ul>"},{"location":"04_terraform/project/config-3-aws/readme/#aws-config-maps-outbound-dev2-vpc","title":"aws-config-maps-outbound-<code>dev2</code>-vpc","text":"<ul> <li>cd ./modules/vpc</li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/aws-config-maps-outbound-dev2-vpc</li> </ul>"},{"location":"04_terraform/project/config-3-aws/readme/#aws-config-maps-outbound-dev2-eventbridge","title":"aws-config-maps-outbound-<code>dev2</code>-eventbridge","text":"<ul> <li>cd ./modules/eventbridge</li> <li>https://app.terraform.io/app/lekhrajdinkar-org/workspaces/aws-config-maps-outbound-dev2-eventbridge</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/","title":"01 kick off","text":""},{"location":"05_harness/Notes/01_kick_off/#-httpsdeveloperharnessiodocscontinuous-deliveryget-startedkey-concepts","title":"- https://developer.harness.io/docs/continuous-delivery/get-started/key-concepts","text":""},{"location":"05_harness/Notes/01_kick_off/#harness","title":"Harness","text":""},{"location":"05_harness/Notes/01_kick_off/#a-onboarding","title":"A. onboarding","text":"<ul> <li>https://app.harness.io/ng/account/e0wDKKO_S46x3M75TWv0iw/all/settings/</li> <li>Account: <code>lekhrajdinkar</code> </li> <li>Organization: <code>default</code><ul> <li>project</li> <li>outbound-api : dashboard<ul> <li>pipelines </li> <li>users </li> <li>Environments</li> <li>Services</li> </ul> </li> <li>outbound-ui : dashboard<ul> <li>...</li> <li>...</li> </ul> </li> </ul> </li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#b-project-1-app-outbound-api-green_circle","title":"B. project 1 - app-outbound-api :green_circle:","text":""},{"location":"05_harness/Notes/01_kick_off/#b1-pre-work-plateform-team-yellow_circle","title":"B.1. pre-work (plateform team) :yellow_circle:","text":""},{"location":"05_harness/Notes/01_kick_off/#1-setup-secrets","title":"1 setup : secrets","text":"<ul> <li>aws</li> <li>aws_eks_get_token<ul> <li>aws eks get-token  --cluster-name maps-outbound-us-west-2-dev2-eks-fargate-cluster --region us-west-2</li> <li>Need to update token manually, once expired</li> <li>https://app.harness.io/ng/account/e0wDKKO_S46x3M75TWv0iw/all/settings/secrets/aws_eks_get_token/overview</li> </ul> </li> <li>aws_eks_cluster_ca_data</li> <li>aws_533267082359_secret_access_key</li> <li>minikube</li> <li>minikube-admin-client-key</li> <li>minikube-admin-client-crt</li> <li>C:\\Users\\Manisha.minikube\\profiles\\minikube</li> <li>github-access-token-org</li> <li>terraform-hcp-dev</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#2-setup-delegates","title":"2 setup : delegates","text":"<p>02_delegates.md</p>"},{"location":"05_harness/Notes/01_kick_off/#3-setup-connectors","title":"3 setup : connectors","text":"<ul> <li>kubernetes</li> <li>k8s-eks-cluster-connector</li> <li>k8s-minikube-cluster-connector</li> <li>github-lekhrajdinkar-connector</li> <li>terraform-hcp-connector</li> <li>aws</li> <li>aws-secret-manager-connector</li> <li>aws-account-connector</li> <li>more</li> <li>nexus-repo-connector </li> <li>service-now-connector</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#4-access-control","title":"4 Access control","text":"<ul> <li>service account : none</li> <li>user group : <code>app_DevLead</code> (LDAP role)</li> <li>u1, u2</li> <li>roles</li> <li>found 19, built-in. eg: pipeline-executor</li> <li>create custom role<ul> <li>pipeline-owner</li> <li>pipeline-developer</li> </ul> </li> <li>role has defined granular permission.<ul> <li>resource/s : action/s</li> <li>service  : R , W, Edit, View, etc</li> <li>template : R , W, Edit, View, etc</li> <li>pipeline : R , W, Edit, View, etc</li> <li>...</li> </ul> </li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#b2-cd-pipeline-developer-team-yellow_circle","title":"B.2. CD pipeline (developer team) :yellow_circle:","text":""},{"location":"05_harness/Notes/01_kick_off/#1-template","title":"1 Template","text":"<ul> <li>can create template for : step, stages, pipeline</li> <li>then re-use it.</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#2-pipeline","title":"2 pipeline","text":"<ul> <li>https://app.harness.io/ng/account/e0wDKKO_S46x3M75TWv0iw/all/orgs/default/projects/mapsoutboundapi/pipelines</li> <li>pipeline &gt; stages (build, deploy, another pipleline) &gt; steps (run, image push, etc)</li> <li>pipeline variable<ul> <li>input-set-env-1</li> <li>input-set-env-2</li> <li>...</li> </ul> </li> <li>triggers : on git actions</li> <li>codebase : github connector + repoName</li> <li>studio/yaml</li> <li>save : inline / gitrepo</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#3-services","title":"3 services","text":""},{"location":"05_harness/Notes/01_kick_off/#4-environment","title":"4 environment","text":"<ul> <li>env-group</li> <li>oz-dev<ul> <li>dev1 (pre-prod)</li> <li>dev2 (pre-prod)</li> <li>prod\\</li> </ul> </li> <li>created but not used/referenced in pipeline. ??    </li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#d-project-2-ccgg-green_circle","title":"D. project 2 - ccgg :green_circle:","text":""},{"location":"05_harness/Notes/01_kick_off/#d0-platform-team-shared-templates","title":"D.0. platform team shared templates","text":""},{"location":"05_harness/Notes/01_kick_off/#template-gauntlet-scan","title":"template : gauntlet-scan","text":"<ul> <li>input: image-container-registry + image(tf,k8s,aws)</li> <li>env var: git-branch, atm, env_gate (oz_dev)</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#template-servicenow","title":"template : serviceNow","text":"<ul> <li>input: CRQ no</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#d1-m-app-pipelines","title":"D.1. M-app :pipelines","text":""},{"location":"05_harness/Notes/01_kick_off/#1-iac-terraform-pipeline-inputcomponent-in-out-kafka-engine","title":"1. iac-terraform-pipeline ( input::component - in, out, kafka, engine)","text":"<ul> <li>stage1</li> <li>gauntlet scan</li> <li>bash :: TRF_PLAN</li> <li>stage2 - TRF_PLAN_APPROVAL</li> <li>harness-template-2 :: manual approval</li> <li>stage3</li> <li>gauntlet scan</li> <li>bash :: TFR_APPLY</li> </ul> <pre><code>terraform -v\ntfr_workspace=&lt;+pipeline.variables.tf_ws&gt;\ntfe_ws_id=&lt;+pipeline.variables.tf_ws_id&gt;\ntfe_host=&lt;+pipeline.variables.tf_host&gt;\n\n# login\n# option-1\nwget ccggAnsible/tfeSync.zip\nunzip tfeSync.zip\n./tfesync -w tfe_ws_id\n# option-2\nterrafom login -p $TFE_TOKEN\n\n# create :: credential.trfc.son with $TFE_TOKEN\n# create :: backend.tf with tf_ws_id\nterrafom init\nterrafom plan -var-file ./env/${ENV}.tfvars\n</code></pre>"},{"location":"05_harness/Notes/01_kick_off/#2-interface-pipeline-devqaprod-3-diff-pipeline","title":"2. interface-pipeline-dev/qa/prod (3 diff pipeline)","text":"<ul> <li>stage 1 : BUILD</li> <li>gauntlet scan</li> <li>get version (from branch name)</li> <li><code>harness-template-1</code> :: build and push to docker Hub, or</li> <li> <p><code>harness-template-2</code> :: build and push to AWS-ECR, or </p> <ul> <li>aws connector (aws secret key from broadAccessRole)</li> <li>aws account id + region</li> <li>image name</li> <li>codebase, already present in pipeline</li> </ul> </li> <li> <p>stage 2 (only for prod pipeline)  : servicenow</p> </li> <li>stage 3  : DEPLOY</li> <li><code>bash</code> :: deploy to ECS</li> </ul>"},{"location":"05_harness/Notes/01_kick_off/#1-git-version-git_branch-pipelinevariablesgit_branch-version-git_branchsplit1-version_with_seq-version-pipelinesequenceid-2-deploy-to-ecs-current_role-aws-sts-get-caller-identity-export-printf-aws_access_keys-aws_secret_access_keys-aws_session_tokens-aws-sts-assume-role-harness-pipleline-role-session-name-query-credentialaccesskeyid-secretaccesskey-sessiontoken-output-text-current_role-aws-sts-get-caller-identity-old_tasksaws-ecs-list-task-cluster-service-name-region-query-tasjarn-output-text-for-task-in-old_tasks-do-aws-ecs-stop-task-cluster-service-name-region-aws-ecs-stop-task-cluster-service-name-region-force-new-deployment","title":"<pre><code># === 1 git version ===========\n\nGIT_BRANCH = &lt;+pipeline.variables.GIT_BRANCH&gt;\nVERSION = $GIT_BRANCH.split('\\/')[1]\nVERSION_WITH_SEQ = \"${VERSION}-\"&lt;+pipeline.sequenceId&gt;\n\n# === 2 deploy to ECS  =========== \n\ncurrent_role = $(aws sts get-caller-identity)\nexport $(printf \"AWS_ACCESS_KEY=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s\")\n$(aws sts assume --role harness-pipleline-role --session-name --query \"Credential.[AccesskeyId, SecretAccesskey, SessionToken] --output text\")\n\ncurrent_role = $(aws sts get-caller-identity)\n\nold_tasks=$(aws ecs list-task --cluster --service-name --region    --query tasjArn[*] --output text)\nfor task in old_tasks; \ndo aws ecs stop task --cluster --service-name --region\naws ecs stop task --cluster --service-name --region --force-new-deployment\n</code></pre>","text":""},{"location":"05_harness/Notes/01_kick_off/#d2-p-app-pipelines-common-for-all-env","title":"D.2. P-app :pipelines (common for all env)","text":""},{"location":"05_harness/Notes/01_kick_off/#1-app-pipeline","title":"1. app-pipeline","text":"<ul> <li>Stage 1 Build : </li> <li>gauntlet scan </li> <li>get version(from helm) </li> <li>dind &gt; dockerize </li> <li>push app-image to nexus-dev </li> <li>update helm-value.yml with new image detail</li> <li>push helm-chart to nexus-dev</li> <li>Stage 2 Deploy-dev/qa : </li> <li>copy2ECR (primary) &gt; helm (primary)</li> <li>copy2ECR (secondary) &gt; helm (secondary)</li> <li>Stage 3 service-now</li> <li>Stage 4 Deploy-prod</li> <li>gauntlet scan - image (not codebase) - input:imageName+version</li> <li>promote to prod (nexus dev &gt;&gt; nexus-prod)</li> <li>copy2ECR (primary) &gt; helm (primary)</li> <li>copy2ECR (secondary) &gt; helm (secondary)</li> </ul> <pre><code>#========== 1 get version (from helm chart) ===========\n\nhelmVersion=$(cat $HELM_CHART_DIR/chart.yaml | grep version:)\nappVersion=$(cat $HELM_CHART_DIR/chart.yaml | grep version:)\n# major and minor version using regex in $major $minor\n\n#========== 2 dockerize ===========\n\ndocker login -u &lt;+pipeline.getvalue(nexus_user)&gt; -p  &lt;+pipeline.getvalue(nexus_password)&gt;\ndocker build -t nexus-dev/$image:appVersion --label git_branch= --label=commit_id=\ndocker push  nexus-dev/$image:appVersion\n\n#========== 3  update helm (new image) &gt;&gt; push helm-chart to nexus-dev  ===========\nyq --version\nhelm e -i '.image.name = env(repoAndImageName)' $HELM_CHART_DIR/value.yaml\nhelm e -i '.image.tag = env(version)' $HELM_CHART_DIR/value.yaml\n\nhelm lint  $HELM_CHART_DIR --value=$HELM_CHART_DIR/value.yaml\nhelm package  $HELM_CHART_DIR\nhelm registry login -u &lt;+pipeline.getvalue(nexus_user)&gt; -p  &lt;+pipeline.getvalue(nexus_password)&gt;\nhelm push  $image:helmVersion nexus-dev\n\n#========== 4 copy2ECR  (nexus dev &gt;&gt; ecr) ===========\ncrane version\ncrane auth login -u &lt;+pipeline.getvalue(nexus_user)&gt; -p  &lt;+pipeline.getvalue(nexus_password)&gt; nexus-dev-registry\n\n# copy from nexus to ecr \nexport $(printf \"AWS_ACCESS_KEY=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s\")\n$(aws sts assume --role harness-pipleline-role --session-name --query \"Credential.[AccesskeyId, SecretAccesskey, SessionToken] --output text\")\necr_password=$(aws ecr get-login-password --region)\ncrane auth login -u AWS -p  ecr_password erc-repo\n\n# copy app-image and helm\ncrane cp nexus-prod/$app_image:$app_image $ecr-repo-prod/$app_image:$app_image\ncrane cp nexus-prod/$app_image:$app_image-helm $ecr-repo-prod/$app_image:$app_image-helm\n\n#========== 5 Promote to prod (nexus dev &gt;&gt; nexus prod &gt;&gt; ECR) ===========\n\ncrane version\ncrane auth login -u &lt;+pipeline.getvalue(nexus_user)&gt; -p  &lt;+pipeline.getvalue(nexus_password)&gt; nexus-dev-registry\ncrane auth login -u &lt;+pipeline.getvalue(nexus_user_prod)&gt; -p  &lt;+pipeline.getvalue(nexus_password_prod)&gt; nexus-prod-registry\n\n# copy from nexus to ecr (of Life cycle AWS )\nexport $(printf \"AWS_ACCESS_KEY=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s\")\n$(aws sts assume --role harness-pipleline-role --session-name --query \"Credential.[AccesskeyId, SecretAccesskey, SessionToken] --output text\")\necr_password=$(aws ecr get-login-password --region)\ncrane auth login -u AWS -p  ecr_password erc-repo\n\n# copy app-image : nexus dev &gt;&gt; nexus prod &gt;&gt; ECR\ncrane cp nexus-dev/$app_image:$app_image nexus-prod/$app_image:$app_image \ncrane cp nexus-prod/$app_image:$app_image $ecr-repo-prod/$app_image:$app_image\n\n# copy helm  : nexus dev &gt;&gt; nexus prod &gt;&gt; ECR\ncrane cp nexus-prod/$app_image:$app_image-helm $ecr-repo-prod/$app_image:$app_image-helm\ncrane cp nexus-dev/$app_image:$app_image-helm nexus-prod/$app_image:$app_image-helm \n\n#========== 6. Helm install ===========\nkubectl version\nhelm version\n\nexport $(printf \"AWS_ACCESS_KEY=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s\")\n$(aws sts assume --role harness-pipleline-role --session-name --query \"Credential.[AccesskeyId, SecretAccesskey, SessionToken] --output text\")\n\naws ssm get-parameter --region --name \"mc/cluster-1/kubeconfig\" --query \"parameter.Value\" --output text &gt; kubeconfig\n\nexport KUBECONFID=\"$PWD/kubconfig\"\nkubectl auth can-i create deployment -n ns-1\n\necr_password=$(aws ecr get-login-password --region)\nhelm registry login -u AWS -p ecr_password\n\nhelm pull oci://$ecr_repo/$image:$appVersion  --version $helmVersion\ntar ...  \nhelm upgrade --install $RELEASE_NAME $image:$appVersion --value ./values.yaml -n --wait 300s --atomic\n</code></pre>"},{"location":"05_harness/Notes/01_kick_off/#2-lambda-layer-pipeline","title":"2. lambda layer pipeline","text":"<pre><code>  export $(printf \"AWS_ACCESS_KEY=%s AWS_SECRET_ACCESS_KEY=%s AWS_SESSION_TOKEN=%s\")\n  $(aws sts assume --role harness-pipleline-role --session-name --query \"Credential.[AccesskeyId, SecretAccesskey, SessionToken] --output text\")\n\n  pip3 install ${requiements_path} --target ./python/lib/python3.11/site-packages\n  python3 -c \"import shutil.make_archive(${ZIP_FILE} , 'zip', root_dir = '.' base_dir='python')\"\n  aws s3 cp ${layer_name}.zip\n</code></pre>"},{"location":"05_harness/Notes/01_kick_off/#d3-f-app-pipelines","title":"D.3. F-app :pipelines","text":"<ul> <li>later</li> </ul>"},{"location":"05_harness/Notes/02_delegates/","title":"02 delegates","text":""},{"location":"05_harness/Notes/02_delegates/#harness-delegate","title":"harness delegate","text":""},{"location":"05_harness/Notes/02_delegates/#intro","title":"intro","text":"<ul> <li>lightweight, secure worker process that runs within our infrastructure</li> <li>Kubernetes cluster</li> <li>VM</li> <li>execute tasks on behalf of the Harness Platform.</li> <li>It acts as a communication bridge between <code>Harness SaaS</code> and <code>our environment</code></li> <li>ensuring secure</li> <li>scalable</li> <li> <p>efficient pipeline operations</p> </li> <li> <p>Key Roles of a Delegate</p> </li> <li> <p>Task Execution:</p> <ul> <li>Delegates perform pipeline actions directly in your environment, such as: <pre><code>- git clone\n- prepare image - Dind\n- run terrafom - login plan apply.\n  - deploy aws iac ; inbound, outbound,etc\n  - kafka iac\n- prepare version from pipeline variable.\n- Deploying artifacts to Kubernetes, ECS, or VMs.\n  - run helm\n  - run k8s manifest\n- Running scripts (e.g., Shell, PowerShell).\n  - push to ecr\n  - restart ecs\n- Connecting to cloud providers (AWS, Azure, GCP).\n- Integrating with tools like Terraform, or databases.\n- Push to Nexus\n- push helm package to nexux/ecr\n</code></pre></li> </ul> </li> <li> <p>Security:</p> <ul> <li>Delegates make outbound connections to Harness SaaS</li> <li>They execute tasks within our network, avoiding exposure of sensitive credentials to external systems.</li> </ul> </li> <li> <p>Connectivity:</p> <ul> <li>Harness SaaS sends tasks to the Delegate via a persistent connection (gRPC/HTTPs).</li> <li>The Delegate polls for tasks, executes them locally, and sends results back.</li> </ul> </li> <li> <p>Scalability: </p> <ul> <li>Add multiple Delegates for high availability or workload distribution.</li> <li>Harness auto-scales task execution across available Delegates.</li> </ul> </li> <li> <p>Types of Delegates:</p> </li> <li>Kubernetes Delegate: Runs as a Pod (most common for containerized environments).</li> <li>Docker Delegate: Runs as a container on VMs or bare metal.</li> <li>Shell Script Delegate: Installed via script on Linux/Windows hosts.</li> </ul>"},{"location":"05_harness/Notes/02_delegates/#run-delegate","title":"Run delegate","text":""},{"location":"05_harness/Notes/02_delegates/#1-terraform-provider","title":"1. terraform provider","text":"<ul> <li>this terraform module, deploys helm chart on K8s cluster (minikube)</li> <li>trf: terraform-helm-delegate</li> <li>kubeconfig set to minikube</li> <li>delegate added : https://app.harness.io/ng/account/e0wDKKO_S46x3M75TWv0iw/all/settings/delegates/list </li> </ul>"},{"location":"05_harness/Notes/02_delegates/#2-docker","title":"2. docker","text":"<pre><code>        docker run  --cpus=1 --memory=2g \\\n        -e DELEGATE_NAME=docker-delegate \\\n        -e NEXT_GEN=\"true\" \\\n        -e DELEGATE_TYPE=\"DOCKER\" \\\n        -e ACCOUNT_ID=e0wDKKO_S46x3M75TWv0iw \\\n        -e DELEGATE_TOKEN=MGY2OGJmMWQwYjMwZGM5NDYzZDM5NGFlMDg5Mzk4NzY= \\\n        -e DELEGATE_TAGS=\"\" \\\n        -e LOG_STREAMING_SERVICE_URL=https://app.harness.io/log-service/ \\\n        -e MANAGER_HOST_AND_PORT=https://app.harness.io harness/delegate:24.10.84200\n\n        docker run  --cpus=1 --memory=2g -e DELEGATE_NAME=docker-delegate -e NEXT_GEN=\"true\" -e DELEGATE_TYPE=\"DOCKER\" -e ACCOUNT_ID=e0wDKKO_S46x3M75TWv0iw -e DELEGATE_TOKEN=MGY2OGJmMWQwYjMwZGM5NDYzZDM5NGFlMDg5Mzk4NzY= -e DELEGATE_TAGS=\"\" -e LOG_STREAMING_SERVICE_URL=https://app.harness.io/log-service/  -e MANAGER_HOST_AND_PORT=https://app.harness.io harness/delegate:24.10.84200\n</code></pre>"},{"location":"05_harness/Notes/02_delegates/#3-k8s-manifest","title":"3. K8s manifest","text":"<pre><code>apiVersion: v1\nkind: Namespace\nmetadata:\n  name: harness-delegate-ng\n\n---\n\napiVersion: rbac.authorization.k8s.io/v1\nkind: ClusterRoleBinding\nmetadata:\n  name: harness-delegate-ng-cluster-admin\nsubjects:\n  - kind: ServiceAccount\n    name: default\n    namespace: harness-delegate-ng\nroleRef:\n  kind: ClusterRole\n  name: cluster-admin\n  apiGroup: rbac.authorization.k8s.io\n\n---\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: kubernetes-delegate-account-token\n  namespace: harness-delegate-ng\ntype: Opaque\ndata:\n  DELEGATE_TOKEN: \"MGY2OGJmMWQwYjMwZGM5NDYzZDM5NGFlMDg5Mzk4NzY=\"\n\n---\n\n# If delegate needs to use a proxy, please follow instructions available in the documentation\n# https://ngdocs.harness.io/article/5ww21ewdt8-configure-delegate-proxy-settings\n\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  labels:\n    harness.io/name: kubernetes-delegate\n  name: kubernetes-delegate\n  namespace: harness-delegate-ng\nspec:\n  replicas: 1\n  minReadySeconds: 120\n  selector:\n    matchLabels:\n      harness.io/name: kubernetes-delegate\n  template:\n    metadata:\n      labels:\n        harness.io/name: kubernetes-delegate\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"3460\"\n        prometheus.io/path: \"/api/metrics\"\n    spec:\n      terminationGracePeriodSeconds: 3600\n      restartPolicy: Always\n      containers:\n      - image: us-docker.pkg.dev/gar-prod-setup/harness-public/harness/delegate:25.05.85903\n        imagePullPolicy: Always\n        name: delegate\n        securityContext:\n          allowPrivilegeEscalation: false\n          runAsUser: 0\n        ports:\n          - containerPort: 8080\n        resources:\n          limits:\n            memory: \"2048Mi\"\n          requests:\n            cpu: \"0.5\"\n            memory: \"2048Mi\"\n        livenessProbe:\n          httpGet:\n            path: /api/health\n            port: 3460\n            scheme: HTTP\n          initialDelaySeconds: 10\n          periodSeconds: 10\n          failureThreshold: 3\n        startupProbe:\n          httpGet:\n            path: /api/health\n            port: 3460\n            scheme: HTTP\n          initialDelaySeconds: 30\n          periodSeconds: 10\n          failureThreshold: 15\n        envFrom:\n        - secretRef:\n            name: kubernetes-delegate-account-token\n        env:\n        - name: JAVA_OPTS\n          value: \"-Xms64M\"\n        - name: ACCOUNT_ID\n          value: e0wDKKO_S46x3M75TWv0iw\n        - name: MANAGER_HOST_AND_PORT\n          value: https://app.harness.io\n        - name: DEPLOY_MODE\n          value: KUBERNETES\n        - name: DELEGATE_NAME\n          value: kubernetes-delegate\n        - name: DELEGATE_TYPE\n          value: \"KUBERNETES\"\n        - name: DELEGATE_NAMESPACE\n          valueFrom:\n            fieldRef:\n              fieldPath: metadata.namespace\n        - name: INIT_SCRIPT\n          value: \"\"\n        - name: DELEGATE_DESCRIPTION\n          value: \"\"\n        - name: DELEGATE_TAGS\n          value: \"\"\n        - name: NEXT_GEN\n          value: \"true\"\n        - name: CLIENT_TOOLS_DOWNLOAD_DISABLED\n          value: \"true\"\n        - name: DELEGATE_RESOURCE_THRESHOLD\n          value: \"\"\n        - name: DYNAMIC_REQUEST_HANDLING\n          value: \"false\"\n\n---\n\napiVersion: autoscaling/v2\nkind: HorizontalPodAutoscaler\nmetadata:\n   name: kubernetes-delegate-hpa\n   namespace: harness-delegate-ng\n   labels:\n       harness.io/name: kubernetes-delegate\nspec:\n  scaleTargetRef:\n    apiVersion: apps/v1\n    kind: Deployment\n    name: kubernetes-delegate\n  minReplicas: 1\n  maxReplicas: 1\n  metrics:\n  - type: Resource\n    resource:\n      name: cpu\n      target:\n        type: Utilization\n        averageUtilization: 70\n  - type: Resource\n    resource:\n      name: memory\n      target:\n        type: Utilization\n        averageUtilization: 70\n\n---\n\nkind: Role\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: upgrader-cronjob\n  namespace: harness-delegate-ng\nrules:\n  - apiGroups: [\"batch\", \"apps\", \"extensions\"]\n    resources: [\"cronjobs\"]\n    verbs: [\"get\", \"list\", \"watch\", \"update\", \"patch\"]\n  - apiGroups: [\"extensions\", \"apps\"]\n    resources: [\"deployments\"]\n    verbs: [\"get\", \"list\", \"watch\", \"create\", \"update\", \"patch\"]\n\n---\n\nkind: RoleBinding\napiVersion: rbac.authorization.k8s.io/v1\nmetadata:\n  name: kubernetes-delegate-upgrader-cronjob\n  namespace: harness-delegate-ng\nsubjects:\n  - kind: ServiceAccount\n    name: upgrader-cronjob-sa\n    namespace: harness-delegate-ng\nroleRef:\n  kind: Role\n  name: upgrader-cronjob\n  apiGroup: \"\"\n\n---\n\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: upgrader-cronjob-sa\n  namespace: harness-delegate-ng\n\n---\n\napiVersion: v1\nkind: Secret\nmetadata:\n  name: kubernetes-delegate-upgrader-token\n  namespace: harness-delegate-ng\ntype: Opaque\ndata:\n  UPGRADER_TOKEN: \"MGY2OGJmMWQwYjMwZGM5NDYzZDM5NGFlMDg5Mzk4NzY=\"\n\n---\n\napiVersion: v1\nkind: ConfigMap\nmetadata:\n  name: kubernetes-delegate-upgrader-config\n  namespace: harness-delegate-ng\ndata:\n  config.yaml: |\n    mode: Delegate\n    dryRun: false\n    workloadName: kubernetes-delegate\n    namespace: harness-delegate-ng\n    containerName: delegate\n    delegateConfig:\n      accountId: e0wDKKO_S46x3M75TWv0iw\n      managerHost: https://app.harness.io\n\n---\n\napiVersion: batch/v1\nkind: CronJob\nmetadata:\n  labels:\n    harness.io/name: kubernetes-delegate-upgrader-job\n  name: kubernetes-delegate-upgrader-job\n  namespace: harness-delegate-ng\nspec:\n  schedule: \"0 */1 * * *\"\n  concurrencyPolicy: Forbid\n  startingDeadlineSeconds: 20\n  jobTemplate:\n    spec:\n      template:\n        spec:\n          serviceAccountName: upgrader-cronjob-sa\n          restartPolicy: Never\n          containers:\n          - image: harness/upgrader:latest\n            name: upgrader\n            imagePullPolicy: Always\n            envFrom:\n            - secretRef:\n                name: kubernetes-delegate-upgrader-token\n            volumeMounts:\n              - name: config-volume\n                mountPath: /etc/config\n          volumes:\n            - name: config-volume\n              configMap:\n                name: kubernetes-delegate-upgrader-config\n</code></pre>"},{"location":"06_messaging/01_messaging_protocols/","title":"Messaging Protocols","text":"<ul> <li>Messaging protocols define the rules and standards for exchanging messages between applications or services.</li> <li>These protocols enable communication in distributed systems </li> <li>ensure reliability, security, and efficiency.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#1-advanced-message-queuing-protocol-amqp","title":"1. Advanced Message Queuing Protocol (AMQP)","text":"<ul> <li>Description: A binary protocol designed for reliable and interoperable message queuing.</li> <li>Key Features:<ul> <li>Supports message queuing, routing, and transactions.</li> <li>Provides guaranteed delivery with acknowledgments.</li> <li>Exchange types: <code>Direct</code>, <code>Fanout</code>, <code>Topic</code>, and <code>Headers</code>.</li> <li>Supports persistent and transient messages.</li> </ul> </li> <li>Common Use Cases:<ul> <li>Financial transactions.</li> <li>Distributed systems requiring reliability.</li> </ul> </li> <li>Supported by: RabbitMQ, Apache Qpid.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#2-message-queuing-telemetry-transport-mqtt","title":"2. Message Queuing Telemetry Transport (MQTT)","text":"<ul> <li>Description: A lightweight protocol designed for resource-constrained devices and networks.</li> <li>Key Features:<ul> <li>Publishes messages to topics with a \"publish-subscribe\" model.</li> <li>Three levels of Quality of Service (QoS):<ol> <li>At most once (fire-and-forget).</li> <li>At least once (guaranteed delivery with duplication possible).</li> <li>Exactly once (guaranteed no duplication).</li> </ol> </li> <li>Minimal bandwidth usage and overhead.</li> </ul> </li> <li>Common Use Cases:<ul> <li>IoT (Internet of Things).</li> <li>Sensor data and telemetry.</li> </ul> </li> <li>Supported by: Mosquitto, HiveMQ, RabbitMQ (via plugin).</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#3-streaming-text-oriented-messaging-protocol-stomp","title":"3. Streaming Text Oriented Messaging Protocol (STOMP)","text":"<ul> <li>Description: A simple, text-based protocol for message queuing.</li> <li>Key Features:<ul> <li>Works with \"subscribe\" and \"send\" commands.</li> <li>Operates over WebSocket for web applications.</li> <li>Easy to implement but lacks advanced queuing features like AMQP.</li> </ul> </li> <li>Common Use Cases:<ul> <li>WebSocket-based messaging.</li> <li>Chat applications.</li> </ul> </li> <li>Supported by: RabbitMQ, ActiveMQ.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#4-kafka-protocol","title":"4. Kafka Protocol","text":"<ul> <li>Description: A proprietary protocol designed for Apache Kafka, optimized for high-throughput, distributed messaging.</li> <li>Key Features:<ul> <li>Designed for partitioned logs with message offsets.</li> <li>Handles high-throughput real-time streaming.</li> <li>Messages are persisted in a distributed, fault-tolerant manner.</li> </ul> </li> <li>Common Use Cases:<ul> <li>Event-driven architectures.</li> <li>Real-time analytics.</li> <li>Log aggregation.</li> </ul> </li> <li>Supported by: Apache Kafka.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#5-httprest-representational-state-transfer","title":"5. HTTP/REST (Representational State Transfer)","text":"<ul> <li>check here : 04_REST.md </li> <li>Description: A stateless, text-based protocol commonly used for APIs.</li> <li>Key Features:<ul> <li>Simple request-response model using HTTP verbs (GET, POST, PUT, DELETE).</li> <li>Message formats: JSON or XML.</li> <li>Easy integration with web applications.</li> </ul> </li> <li>Common Use Cases:<ul> <li>Web services and APIs.</li> <li>Microservices communication.</li> </ul> </li> <li>Supported by: All modern web servers and clients.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#6-google-protocol-buffers-grpc","title":"6. Google Protocol Buffers (gRPC)","text":"<ul> <li>check here: 08_gRPC+webflux.md </li> <li>Description: A high-performance, open-source RPC framework by Google.</li> <li>Key Features:<ul> <li>Uses Protocol Buffers (Protobuf) for serialization.</li> <li>Supports bi-directional streaming.</li> <li>Highly efficient binary format.</li> </ul> </li> <li>Common Use Cases:<ul> <li>Low-latency communication in microservices.</li> <li>Distributed systems needing real-time communication.</li> </ul> </li> <li>Supported by: Google Cloud, gRPC libraries.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#7-more-skip","title":"7 more (skip)","text":""},{"location":"06_messaging/01_messaging_protocols/#71-openwire","title":"7.1. OpenWire","text":"<ul> <li>Description: A binary protocol used by Apache ActiveMQ for efficient message communication.</li> <li>Key Features:<ul> <li>Optimized for ActiveMQ brokers.</li> <li>High performance and compact.</li> </ul> </li> <li>Common Use Cases:<ul> <li>Applications built on ActiveMQ.</li> </ul> </li> <li>Supported by: Apache ActiveMQ.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#72-simplestreaming-network-protocol-snmp","title":"7.2. Simple/Streaming Network Protocol (SNMP)","text":"<ul> <li>Description: A lightweight messaging protocol for network management.</li> <li>Key Features:<ul> <li>Focused on telemetry and monitoring.</li> <li>\"Push\" model for alerts.</li> <li>Efficient in resource-constrained networks.</li> </ul> </li> <li>Common Use Cases:<ul> <li>IoT.</li> <li>Network monitoring systems.</li> </ul> </li> <li>Supported by: RabbitMQ (via plugins), custom brokers.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#73-zeromq-protocol","title":"7.3. ZeroMQ Protocol","text":"<ul> <li>Description: A high-performance messaging library for concurrency and distributed systems.</li> <li>Key Features:<ul> <li>Offers multiple messaging patterns (Pub/Sub, Req/Rep, Push/Pull).</li> <li>Operates over various transports (TCP, IPC, PGM).</li> <li>No broker required (peer-to-peer).</li> </ul> </li> <li>Common Use Cases:<ul> <li>High-speed trading platforms.</li> <li>Systems with custom messaging patterns.</li> </ul> </li> <li>Supported by: ZeroMQ library.</li> </ul>"},{"location":"06_messaging/01_messaging_protocols/#key-differences-between-messaging-protocols","title":"Key Differences Between Messaging Protocols","text":"Protocol Binary/Text Pattern Reliability Use Cases Examples AMQP Binary Queues/Exchanges High Reliable queuing RabbitMQ, Apache Qpid MQTT Binary Pub/Sub Medium IoT, telemetry Mosquitto, HiveMQ STOMP Text Pub/Sub Low WebSocket messaging RabbitMQ, ActiveMQ Kafka Binary Partitioned Logs High Event streaming, analytics Apache Kafka HTTP/REST Text Request-Response Medium APIs, web services All web servers gRPC Binary RPC High Real-time microservices Google Cloud, Kubernetes OpenWire Binary Queues/Topics Medium ActiveMQ-based applications Apache ActiveMQ SNMP Binary Monitoring/Telemetry Medium IoT, monitoring RabbitMQ (via plugin) ZeroMQ Binary Custom Patterns High Peer-to-peer communication ZeroMQ library"},{"location":"06_messaging/kakfa/Notes_01-start/","title":"reference","text":"<ul> <li>project : kafka</li> <li>udemy:<ul> <li>https://www.udemy.com/course/apache-kafka</li> <li>https://conduktor.io/apache-kafka-for-beginners</li> <li>slides : https://learn.conduktor.io/kafka/ </li> </ul> </li> <li>https://chatgpt.com/c/674a1fef-5634-800d-b445-dfa969b74011</li> <li>ccgg program : https://chatgpt.com/c/68007bd1-4a04-800d-ace4-39873a168454 </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#kafka","title":"kafka","text":""},{"location":"06_messaging/kakfa/Notes_01-start/#a-intro","title":"A intro","text":"<ul> <li>real-time data streaming pipelines. (primary task)</li> <li>data stream : unbounded/endless sequence of data, with data throughput can high or low. eg:<ul> <li>Log Analysis - Log stream from multiple ms.</li> <li>Web Analytics - modern web app measure user activity.</li> </ul> </li> <li><code>open-source</code>, managed by confluent(linkedIn)</li> <li>distributed system<ul> <li>cluster + brokers/nodes (has <code>TOPICS</code>)</li> <li>scalable and fault-tolerant to node loss.</li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#b-install","title":"B install","text":"<ul> <li>1 curl -L https://releases.conduktor.io/quick-start -o docker-compose.yml &amp;&amp; docker compose up -d --wait &amp;&amp; echo \"Conduktor started on http://localhost:8080\"</li> <li>2 https://github.com/conduktor/kafka-beginners-course/tree/main/conduktor-platform - worked(old one)</li> <li>next:<ul> <li>for new update: https://conduktor.io/get-started</li> <li>check all container: https://releases.conduktor.io/quick-start -o docker-compose.yml</li> <li>launch UI/conduktor : http://localhost:8080</li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#c-use-cases","title":"C use cases","text":"<ul> <li>https://chatgpt.com/c/6748bff9-8df8-800d-8faa-ac5244853529</li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#1-as-a-data-integration-layer","title":"1 as a data integration layer","text":"<ul> <li>producer  and consumer system/s, with diff data-format + schema, protocol</li> <li></li> <li></li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#2-decouple-systems","title":"2 Decouple systems","text":""},{"location":"06_messaging/kakfa/Notes_01-start/#3-microservice-communication","title":"3 Microservice communication","text":""},{"location":"06_messaging/kakfa/Notes_01-start/#4-integration-with-big-data-technologies","title":"4 Integration with Big Data technologies","text":""},{"location":"06_messaging/kakfa/Notes_01-start/#5-event-sourcing-store","title":"5 Event-sourcing store","text":""},{"location":"06_messaging/kakfa/Notes_01-start/#6-activity-tracker","title":"6 Activity Tracker","text":"<ul> <li>Gather metrics from many different locations</li> <li>collect logs</li> <li> <p>collect web user activity</p> </li> <li> <p></p> </li> <li></li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#d-fundamental-component","title":"D fundamental / component","text":"<ul> <li>https://chatgpt.com/c/6748c06d-048c-800d-996e-6ca852cd0329</li> <li><code>producer</code> --&gt; kafka-Cluster [ broker &gt; topic &gt; partition ] --&gt; <code>consumer group/s</code> [consumer-1,... ]</li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#0-broker","title":"0 broker","text":"<ul> <li>single Kafka server</li> <li>kakfa store data in a directory on the broker disk.</li> <li>if we connect to any broker, then can discover and connect to other broker in the same cluster<ul> <li>Every broker in the cluster has metadata about all the other brokers</li> <li>therefore any broker in the cluster is also called a <code>bootstrap server</code>.</li> <li></li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#1-topics","title":"1 topics","text":"<ul> <li>roughly analogous to SQL tables (not queryable)</li> <li>data store in <code>binary-format</code></li> <li>data retention: 7 days (default) + offset.retention.min=24*60 (default) #broker level config </li> <li>partitions : topic is broken down into a number of partitions<ul> <li>to achieve high throughput and scalability + parallel consumer/s</li> <li>Kafka does a good job of distributing partitions evenly among the available brokers.</li> <li>up to 200,000 partition (with zookepeer)</li> <li>without zoo kepeer - millions of partition.</li> </ul> </li> <li>offset - integer value that Kafka adds to each message as it is written into a partition. from 0.   <pre><code>## Consumer setting to commit offset:\n# a. Auto \n- enable.auto.commit=true \n- auto.commit.interval.ms=5000\n- offsets.retention.minutes --&gt; once commited, offset will be availble for another 24 hr by default, to that consumer-group.\n\n# b. Manual\n- enable.auto.commit=false \n- KafkaConsumer.CommitSync()/CommitASync();\n\n# c Manaul advance\n- skip it\n- stores offset externally\n</code></pre></li> <li>replicas / In-Sync Replicas (ISR)<ul> <li>to archive - resilience and availability   <pre><code>cluster - broker-1,  broker-2 , broker-3 (3 brokers)\nTopic-1 - partition-1 , partition-2, partition-3\n\n# initial distribution (with RF=1)\nbroker-1 : [ partition-1 ]\nbroker-2 : [ partition-2 ]\nbroker-3 : [ partition-3 ]\n\n# add replication: RF=? \n- RF=2  \n  broker-1 : [ partition-1, partition-3-isr1 ]\n  broker-2 : [ partition-2, partition-1-isr1 ]\n  broker-3 : [ partition-3, partition-2-isr1 ]\n\n- RF=3\n  broker-1 : [ partition-1, partition-3-isr1, partition-2-isr2 ]\n  broker-2 : [ partition-2, partition-1-isr1, partition-3-isr2 ]\n  broker-3 : [ partition-3, partition-2-isr1, partition-1-isr2 ]\n\n- RF=4 (invalid) :  must be &lt;= no of broker\n</code></pre></li> </ul> </li> <li></li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#2-producer","title":"2 producer","text":"<ul> <li>application - java/py with kafka client.</li> <li>Kafka producers only write data to the leader broker for a partition</li> <li>specify a level of acknowledgment <code>acks</code><ul> <li>acks=0 : written successfully</li> <li>acks=1 : written successfully + acknowledged by leader</li> <li>acks=all : written successfully + acknowledged by leader + accepted by all ISR</li> </ul> </li> <li>if  ack not received, the producer retries.<ul> <li>retries : 0 - 2^32</li> <li>retry.backoff.ms = 100 ms (default) # retry delay</li> <li>delivery.timeout.md=    # max time for delivery, afterwards exception which developer has to handle.</li> </ul> </li> <li> <p>idempotent producer</p> <ul> <li>use kafka 3+</li> <li>detects duplicate and prevent it.</li> <li>has retry ability with duplicate check.</li> <li></li> </ul> </li> <li> <p>kafka 3+ sets below  <pre><code>  - producer.idempotence = true\n  - acks=all\n  - min.insync.replicas=2 # leader + at leat one replica.\n  - reties= MAX_INT\n  - delivery.timeout.ms = 120000 # 2 min\n  - max.in.flight.request.oer.connection=5\n</code></pre></p> </li> <li> <p>archive message:</p> <ul> <li>at <code>producer level</code></li> <li>at <code>broker level</code><ul> <li>consumes CPU cycle, thus performance issue.</li> </ul> </li> </ul> </li> <li> <p>High throughput producer:</p> <ul> <li>partition class<ul> <li>RoundRobin<ul> <li></li> </ul> </li> <li>sticky (looks for batch.size + linger.ms)<ul> <li>linger.ms = 10ms # <code>accumulate</code> message for 10 ms and then send</li> <li>batch.size = 16000 # <code>accumulate</code> message till 16 kb and then publish</li> <li>note: increase above values, to achieve High throughput</li> <li></li> </ul> </li> </ul> </li> <li>compression (use snappy)<ul> <li>compression.type=snappy</li> <li>spring.kafka.producer.properties.compression.type=snappy</li> </ul> </li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#3-message","title":"3 message","text":"<ul> <li><code>message-value</code> : content</li> <li> <p><code>message-key</code></p> <ul> <li>null : load balance , round-robin fashion into p1,p2,...</li> <li>non-null :<ul> <li>all messages that share the same key, will always go to same partition.</li> <li>true unless partition NOT chnages </li> <li>uses hashing <code>murmur2 algo</code></li> </ul> </li> </ul> </li> <li> <p></p> </li> <li><code>Kafka Message Serializers</code> / <code>Kafka Message Deserializers</code><ul> <li>IntegerSerializer</li> <li>StringSerializer</li> <li>converts message-value/key into byte streams</li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#4-consumer","title":"4 Consumer","text":"<ul> <li>application - java/py,etc with kafka client.</li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#41-pull-model-skip","title":"4.1 pull model (skip)","text":"<ul> <li>instead of having Kafka brokers continuously push data to consumers,</li> <li>consumers must request data from Kafka brokers</li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#42-consumer-group","title":"4.2 consumer group","text":"<ul> <li>each partition of topic is consumed by one consumer within a consumer group </li> <li>Messages are effectively divided among the consumers.</li> <li>static consumer in group --&gt; having <code>group.instance.id</code> is also set. </li> <li></li> <li></li> <li></li> <li> <pre><code>topic with 2 partition consumed by :\n- consumer-1\n- consumer-2\n- consumer-group-1 (consumer-3, sonsumer-4(idempotent)).\n    - consumer-4 leave and comes back within thresold time, the will get same partition again. &lt;&lt;&lt;\n\nTogether, Consumer-3 and Consumer-4 consume all messages from the topic, \ndividing the workload between the two partitions.\n</code></pre></li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#43-publish-subscribe-behavior","title":"4.3 Publish-Subscribe Behavior","text":"<ul> <li>topic-1{p-1, p-2,p-3} --&gt; consumer/s:<ul> <li>consumer-group-1(consumer-1 on p-1 ,consumer-2 on p-2,p-3 ) === <code>subscriber-1</code></li> <li>consumer-group-2(consumer-1 on p-1,consumer-2 on p-2, consumer-3 on p-3, consumer-4 :: IDLE ) === <code>subscriber-2</code></li> <li>consumer-group-2(consumer-1) === <code>subscriber-3</code><ul> <li>If a SINGLE consumer consumes data from multiple partition (p-0,p-1,p-3)</li> <li>the message ordering is not guaranteed across multiple partitions. </li> </ul> </li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#44-commit-offset-green_circle","title":"4.4 commit offset :green_circle:","text":"<pre><code>  ## Consumer setting to update it:\n  # a. Auto \n  - enable.auto.commit=true + auto.commit.interval.ms=1000 (1 min)\n\n  # b. Manual\n  - enable.auto.commit=false \n  - consumer processing - A-sync or sync \n  - KafkaConsumer.CommitSync()/CommitASync();\n</code></pre>"},{"location":"06_messaging/kakfa/Notes_01-start/#45-delivery-semantic-just-concept","title":"4.5 Delivery semantic (just concept)","text":"<ul> <li>scenario-1 :: <code>at most once</code> (max=1)<ul> <li>consumer &gt; poll &gt; processing synchronously (will take around 2 min)</li> <li>offset auto-updated by 1, after 1 min of polling.</li> <li>early offset update, since processing stilling going on.</li> </ul> </li> <li>Scenario-2 :: <code>at least once</code> (min=1)<ul> <li>consumer &gt; poll &gt; processing synchronously (will take around 20 sec)</li> <li>2 message read, and broker crashed while processing 3rd.</li> <li>offset not updated.</li> <li>broker is up again and will consume from old offset</li> <li>above 2 messages will be processed again.</li> <li>so keep consumer <code>idempotent</code></li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#46-rebalance-green_circle","title":"4.6 Rebalance :green_circle:","text":"<ul> <li>whenever consume leaves/joins group, rebalance happens</li> <li>moving partition b/w consumers.</li> <li>if static member leave the group and joins back within session.timeout.ms, the gets it original partition.</li> <li></li> <li></li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#47-liveliness-yellow_circle","title":"4.7 liveliness :yellow_circle:","text":"<ul> <li>threads running on broker to check  of consumer/s:</li> <li>heartbeat thread<ul> <li>heartbeat.interval.ms=</li> </ul> </li> <li>poll thread<ul> <li>checks time-interval b/w 2 poll() calls</li> <li>max.poll.interval.ms= 5minute(default) # keep high for Bigdata.</li> <li>side note: if needed update max.poll.records</li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#48-replay-yellow_circle","title":"4.8 replay :yellow_circle:","text":"<ul> <li>consumer config : auto.offset.rest=???? # update these for topic, for replay <ul> <li><code>latest</code> - read latest, no history</li> <li><code>earliest</code> - read from offset 0, all history</li> <li><code>none</code> - throws exception no offset found.<ul> <li>offset.retention.minutes=</li> </ul> </li> <li><code>specific-value</code>. eg:500</li> <li><code>shiftby</code></li> <li>fact: replay has wont no impact on imdepotent-consumer</li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#47-advance-config-skip","title":"4.7 Advance config (skip)","text":"<ul> <li>long polling mechanism  --&gt; fetch.max.wait.ms=</li> <li>can read from geographically the closest replica. <ul> <li>partition-0 (leader) : aws-region1-az1</li> <li>partition-1 (isr) : aws-region1-az2</li> <li>consumer runinng on az2, then can configure to read from partition-1 (isr) only.</li> <li>use this, if want to reduce aws network cost </li> <li>config on consumer:<ul> <li>rack.id= usw2-az2</li> <li>replica.selcetor.class= RackAwareReplicaSelector</li> <li>client.rack= data-center-id</li> </ul> </li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#5-more","title":"5 more","text":"<ul> <li> <p>5.1 Kafka Connect</p> <ul> <li>Kafka Connect Source Connectors</li> <li>Kafka Connect Sink Connectors</li> </ul> </li> <li> <p>5.2 Schema Registry</p> </li> <li> <p>5.3 ksqlDB</p> <ul> <li>transform Kafka topics to SQL-like database</li> <li>thus can perform SQL-like operation</li> </ul> </li> <li> <p>5.4 Zookeeper</p> <ul> <li>like master node in k8s cluster.</li> <li>Zookeeper is used to track cluster state, membership, and leadership.</li> <li>Being Eliminated from Kafka v4.x. less secure</li> <li>metadata management in the Kafka world</li> <li>perform leader elections</li> <li>stores configurations for topics and permissions.</li> <li>does NOT store consumer offsets</li> <li>ensemble / Zookeeper cluster: 3,5, 7,...</li> <li></li> </ul> </li> <li> <p>5.5 Kafka KRaft Mode</p> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#programs","title":"Programs","text":"<ul> <li>https://chatgpt.com/c/674a1fef-5634-800d-b445-dfa969b74011 <pre><code>    &lt;dependency&gt;\n        &lt;groupId&gt;org.springframework.kafka&lt;/groupId&gt;\n        &lt;artifactId&gt;spring-kafka&lt;/artifactId&gt;\n    &lt;/dependency&gt;\n\nspring.kafka.bootstrap-servers=localhost:9092\nspring.kafka.consumer.group-id=kafka-generic-consumer-group\nspring.kafka.consumer.auto-offset-reset=earliest/latest/none\n\nspring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer\n</code></pre></li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#producer","title":"producer","text":"<pre><code> - @Autowired KafkaTemplate&lt;String, String&gt; kafkaTemplate;\n - String message = objectMapper.writeValueAsString(student);\n - kafkaTemplate.send(\"topic-1\", message);\n</code></pre>"},{"location":"06_messaging/kakfa/Notes_01-start/#produce-sysn-async","title":"produce - sysn + async","text":"<ul> <li>sysc - send(produceRecord)</li> <li>a-sync  - send(produceRecord, <code>new Callback() { @override onCompletion ... }</code>)</li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#produce-in-batch","title":"produce in batch","text":"<ul> <li>props.put(\"batch.size\",\"400\");</li> <li>key must be null</li> <li>props.put(\"partitioner.class\",\"RR); // for demo purpose only.</li> <li>consumer side<ul> <li>read messages in batch <code>poll()</code></li> <li>process batch <code>for(m:messages)</code></li> <li>then update offset manually</li> <li>keep consumer code, idempotent.</li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#produce-with-key-k1k2k3","title":"produce with key (k1,k2,k3)","text":"<ul> <li>add consumer group with 3 consumer/s</li> <li>check ordering :)</li> </ul>"},{"location":"06_messaging/kakfa/Notes_01-start/#consumer","title":"consumer","text":"<p><pre><code> @KafkaListener(topics = {\"kafka-topic-1\", \"kafka-topic-2\"}, groupId = \"kafka-generic-consumer-group\") m(String s) {...}\n</code></pre> - consume : props.groupId(\"group.id\",\"\") + props.put(\"group.instance.id\",\"\") static consumer - props.put(\"auto.offset.rest\",\"earliest\")</p>"},{"location":"06_messaging/kakfa/Notes_01-start/#scenario-1-generic-consumer-for-diff-schema","title":"scenario-1: generic consumer for diff schema","text":"<pre><code>kafka-topic-1 (schema : student)\nkafka-topic-2 (schema- customer)\nkafka-generic-consumer-1 : subscribed to kafka-topic-1 and kafka-topic-2.\n\n# producer sending json \n# De-Serailize json to string\n# while consuming, Objectmapper.readObject(jsonStr, student/customer.class)\nspring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer\n</code></pre>"},{"location":"06_messaging/kakfa/Notes_01-start/#scenario-2-partitions-consumer","title":"scenario-2 : partitions &lt; consumer","text":"<pre><code>Topic: topic-1 with 2 partitions (partition-0 and partition-1).\nConsumer Group: topic-1-group-1.\nConsumers: c1, c2, c3, c4.\n\n# Partition Assignment\npartition-0: Assigned to c1.\npartition-1: Assigned to c2.\nc3 and c4 are idle because there are not enough partitions for them.\n</code></pre>"},{"location":"06_messaging/kakfa/Notes_01-start/#scenario-3-partitions-consumer","title":"scenario-3 : partitions &gt; consumer","text":"<pre><code>Topic: topic-1 with 4 partitions (partition-0, partition-1, partition-2, partition-3).\nConsumer Group: topic-1-group-1.\nConsumers: c1, c2\n\n# Partition Assignment :\n\n## --- Using RangeAssignor --- \nc1: partition-0, partition-1.\nc2: partition-2, partition-3.\n\n## ---  Using RoundRobinAssignor --- \nc1: partition-0, partition-2.\nc2: partition-1, partition-3.\n</code></pre>"},{"location":"06_messaging/kakfa/Notes_03_project_wikimedia/","title":"Notes 03 project wikimedia","text":"<ul> <li>EventStreams is a web service that exposes continuous streams of structured event data. </li> <li>https://stream.wikimedia.org/v2/ui/#/?streams=recentchange</li> <li>consumed:<ul> <li>https://codepen.io/Krinkle/pen/BwEKgW</li> <li>https://esjewett.github.io/wm-eventsource-demo/</li> <li>https://github.com/conduktor/kafka-beginners-course </li> <li>read event and push to kafka topic</li> <li>kafka consumer poll from topic and insert to OpenSearch document db.</li> </ul> </li> </ul>"},{"location":"06_messaging/kakfa/Notes_04_extended/","title":"reference:","text":""},{"location":"06_messaging/kakfa/Notes_04_extended/#-httpsgithubcomconduktorkafka-connect-wikimedia","title":"- https://github.com/conduktor/kafka-connect-wikimedia","text":""},{"location":"06_messaging/kakfa/Notes_04_extended/#kafka-extended-api-intro","title":"Kafka Extended API (<code>intro</code>)","text":""},{"location":"06_messaging/kakfa/Notes_04_extended/#a-kafka-connect","title":"A. Kafka connect","text":"<p> - use case: <pre><code>  - external-source --&gt; kafka topic\n  - kafka topic     --&gt; external-sink\n</code></pre> - all abt re-using connector code. - use in ETL   - don't write your owen producer/consumer code. find connector and re-use.   - look at : https://www.confluent.io/hub</p> <ul> <li>benefit:</li> <li>fault tolerated</li> <li>idempotent producer / consumers</li> <li>ordering </li> <li>other common issues pre-fixed :)</li> <li>project:</li> <li>https://github.com/conduktor/kafka-connect-wikimedia</li> <li>https://www.udemy.com/course/apache-kafka/learn/lecture/11567132#overview</li> <li>https://www.confluent.io/hub/confluentinc/kafka-connect-elasticsearch</li> </ul>"},{"location":"06_messaging/kakfa/Notes_04_extended/#b-kafka-stream","title":"B. kafka stream","text":"<ul> <li>kafka:topic-1 --&gt;  kafka:topic-1</li> <li></li> </ul>"},{"location":"06_messaging/kakfa/Notes_04_extended/#c-schema-registry","title":"C. schema registry","text":""},{"location":"06_messaging/kakfa/Notes_04_extended/#summary","title":"Summary","text":""},{"location":"06_messaging/kakfa/Notes_05_case-studies/","title":"Notes 05 case studies","text":""},{"location":"06_messaging/kakfa/Notes_05_case-studies/#1","title":"1","text":""},{"location":"06_messaging/kakfa/Notes_05_case-studies/#2","title":"2","text":""},{"location":"06_messaging/kakfa/Notes_05_case-studies/#3","title":"3","text":""},{"location":"06_messaging/kakfa/Notes_05_case-studies/#4","title":"4","text":""},{"location":"06_messaging/kakfa/Notes_05_case-studies/#5","title":"5","text":""},{"location":"06_messaging/kakfa/Notes_05_case-studies/#6","title":"6","text":""},{"location":"06_messaging/rmq/01_kickoff/","title":"01 kickoff","text":"<ul> <li>references</li> <li>www.rabbitmq.com/tutorials</li> <li>https://chatgpt.com/c/67532c74-a6d8-800d-8ad3-13afd07dcd8e</li> <li>https://docs.spring.io/spring-boot/reference/messaging/amqp.html#messaging.amqp</li> <li>https://www.rabbitmq.com/tutorials/tutorial-two-java-stream - <code>stream</code><ul> <li>skip</li> <li>using Kafka</li> </ul> </li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#rabbitmq","title":"RabbitMQ","text":"<ul> <li>Producer  --&gt; Exchange &gt;&gt; binding &gt;&gt; Queue --&gt; consumer</li> <li>open-source message broker system</li> <li>use-case : Distributed system, microservices, etc</li> <li><code>message persistence</code> </li> <li><code>acknowledgments</code></li> <li><code>Scalability</code>:</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#a-install-docker","title":"A install (docker)","text":""},{"location":"06_messaging/rmq/01_kickoff/#docker-run-d-hostname-my-rabbit-name-my-rabbit-p-56725672-p-1567215672-rabbitmq3-management-e-ssl_optionsverifyverify_none-rabbitmqlatest-console-guestguest-httplocalhost15672","title":"<pre><code>docker run -d --hostname my-rabbit --name my-rabbit -p 5672:5672 -p 15672:15672  rabbitmq:3-management -e ssl_options.verify:verify_none rabbitmq:latest\n&gt;&gt; console : guest/guest http://localhost:15672/\n</code></pre>","text":""},{"location":"06_messaging/rmq/01_kickoff/#b-exchange","title":"B Exchange","text":"<ul> <li>Type:</li> <li><code>Direct</code>** : Routes messages to queues based on <code>message routing key</code>.</li> <li><code>Topic</code>    : Routes messages to queues based on <code>\"wildcard matching\" of the routing key</code>.</li> <li><code>Fanout</code>   : Routes messages to <code>all queues</code> bound to it.</li> <li><code>Headers</code>  : Uses <code>message headers</code> for routing.</li> <li>Binding: relationship between an exchange and a queue </li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#queues","title":"Queues:","text":"<ul> <li>Buffers that store messages until consumed</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#1-standard-queue","title":"1. Standard Queue","text":"<ul> <li>Description: Basic FIFO (First In, First Out) queue.</li> <li>Features:</li> <li>Messages are delivered in the order they arrive.</li> <li>Messages are removed once consumed (unless re-queued).</li> <li>Use Case: General-purpose message processing.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#2-priority-queue","title":"2. Priority Queue","text":"<ul> <li>Description: Messages are prioritized based on a priority level assigned during publishing.</li> <li>Features:</li> <li>Higher-priority messages are delivered first.</li> <li>Configured using the <code>x-max-priority</code> argument.</li> <li>Use Case: Scenarios requiring prioritization, such as alerting systems.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#3-lazy-queue","title":"3. Lazy Queue","text":"<ul> <li>Description: Stores messages on disk rather than in memory.</li> <li>Features:</li> <li>Designed for handling large queues.</li> <li>Reduces memory usage but increases disk I/O.</li> <li>Use Case: High-volume message storage where memory efficiency is critical.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#4-quorum-queue-recommended-for-new-projects","title":"4. Quorum Queue (Recommended for New Projects)","text":"<ul> <li>Description: A distributed queue type for high availability and data integrity.</li> <li>Features:</li> <li>Uses the Raft consensus algorithm.</li> <li>Replaces classic mirrored queues.</li> <li>Supports leader elections and replication across nodes.</li> <li>Use Case: Applications needing high reliability and fault tolerance.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#5-classic-mirrored-queue-deprecated-in-rabbitmq-39","title":"5. Classic Mirrored Queue (Deprecated in RabbitMQ 3.9+)","text":"<ul> <li>Description: Replicates messages across multiple nodes for high availability.</li> <li>Features:</li> <li>Each node has a mirror of the queue.</li> <li>Message replication can cause performance overhead.</li> <li>Use Case: Legacy setups requiring HA before quorum queues were available.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#6-ttl-queue","title":"6. TTL Queue","text":"<ul> <li>Description: Messages in this queue expire after a specified time-to-live (TTL).</li> <li>Features:</li> <li>Set TTL per queue or message using the <code>x-message-ttl</code> argument.</li> <li>Expired messages are dropped or moved to a dead-letter exchange.</li> <li>Use Case: Temporary message holding, like caching.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#7-dead-letter-queue-dlq","title":"7. Dead Letter Queue (DLQ)","text":"<ul> <li>Description: A queue to which messages are routed if they are rejected or expired.</li> <li>Features:</li> <li>Helps capture unprocessable messages.</li> <li>Configured using dead-letter exchanges.</li> <li>Use Case: Error handling and debugging.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#8-exclusive-queue","title":"8. Exclusive Queue","text":"<ul> <li>Description: A queue limited to a single connection.</li> <li>Features:</li> <li>Automatically deleted when the connection closes.</li> <li>Private to the declaring consumer.</li> <li>Use Case: Temporary or session-specific tasks.</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#99-key-differences-between-queue-types","title":"99 Key Differences Between Queue Types","text":"Queue Type Message Storage High Availability Priority Support Order Guarantee Standard Memory/Disk No No Yes Priority Memory/Disk No Yes No (priority-based) Lazy Disk No No Yes Quorum Disk Yes No Yes Classic Mirrored Memory/Disk Yes No Yes TTL Memory/Disk Optional No Yes Dead Letter Memory/Disk Optional No Yes Exclusive Memory/Disk No No Yes"},{"location":"06_messaging/rmq/01_kickoff/#c-scalability","title":"C Scalability","text":"<ul> <li>Supports clustering</li> </ul>"},{"location":"06_messaging/rmq/01_kickoff/#d-plugins","title":"D Plugins","text":""},{"location":"06_messaging/rmq/02_project/","title":"02 project","text":""},{"location":"06_messaging/rmq/02_project/#-rabbitmqconfigjava","title":"- RabbitMqConfig.java","text":"<pre><code>    // ============ Connectionfactory ========\n\n    @Bean\n    public ConnectionFactory rmqConnectionfactory(){\n        CachingConnectionFactory factory = new CachingConnectionFactory();\n        factory.setUsername(\"guest\");\n        factory.setPassword(\"guest\");\n        factory.setUri(\"amqps://localhost:5672\");\n        factory.setVirtualHost(\"/\");\n        factory;\n    }\n\n    // ============ RabbitTemplate ========\n\n    @Bean\n    public RabbitTemplate createRabbitTemplate(ConnectionFactory connectionFactory){\n        RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory);\n        rabbitTemplate.setMessageConverter(messageConverter());\n        return rabbitTemplate;\n    }\n\n    // ============ Exchanage,queue and binding ========\n\n    @Bean\n    Queue queue() { \n    return  QueueBuilder.durable(queueName)\n                        .quorum()               # quorum\n                        .build();\n    }\n\n    @Bean\n    DirectExchange exchange() {\n        return ExchangeBuilder\n        .directExchange(exchangeName)           # direct\n        .build();\n        }\n\n    @Bean\n    Binding binding(Queue queue, DirectExchange exchange) {\n        return BindingBuilder\n                .bind(queue)\n                .to(exchange)\n                .with(key);\n    }\n\n    // =============== Receive ==========\n\n    @RabbitListener(queues=\"spring.app.queue1\")\n    public void receiveMessage(String message) {\n        System.out.println(\"Rabbit MQ test Received &lt;\" + message + \"&gt;\");\n    }\n\n\n    // =============== Send ==========\n\n    @Bean\n    CommandLineRunner rabbitMQtest(RabbitTemplate rabbitTemplate){\n        return (args)-&gt;{\n            rabbitTemplate.convertAndSend(exchangeName, key, \"{message}\", m-&gt;m);\n            System.out.println(\"Rabbit MQ test message sent at startup\");\n        };\n    }\n\n    // =============== MessageConverter ==========\n\n    @Bean\n    public MessageConverter messageConverter(){\n        return new Jackson2JsonMessageConverter();\n    }\n</code></pre>"},{"location":"07_scripting/bash_script/00_bash_script_1/","title":"reference","text":"<ul> <li>https://www.youtube.com/watch?v=yLQnpmkNFmk&amp;list=PLBf0hzazHTGMJzHon4YXGscxUvsFpxrZT&amp;index=3&amp;ab_channel=HackerSploit</li> <li>All topic : https://chatgpt.com/c/674528ff-dbc8-800d-9237-9e757230df84</li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#bash","title":"bash","text":"<ul> <li>$( ) : command substitution<ul> <li>is used to execute a command and replace it with its output. </li> <li>preferred over backticks. eg: <code>current_date=`date`</code> <pre><code>    - env_value=$(echo $HOME)   \n    - current_user=$(whoami)\n    - current_date=$(date) \n    - for file in $(ls /path/to/directory); do ... done\n    - file_size=$(stat -c%s \"/path/to/file\")\n    - result=$(($((5 * 10)) + 2))\n    - $(seq 1 3)\n    - trimmed=$(echo \"$str\" | xargs) - trim\n</code></pre></li> <li>$() is for running and capturing the output of commands.</li> <li>$(( )) is for performing arithmetic calculations.    </li> </ul> </li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#bininterpretator-name","title":"!/bin/{interpretator-name}","text":"<ul> <li>bash (linux, WSL)</li> <li>zsh (mac)</li> <li>python (all)</li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#a-variable","title":"A. variable","text":"<ul> <li>https://chatgpt.com/c/6744f7b6-024c-800d-8f1e-cd0fab2299c1</li> <li>variables are untyped, meaning they do not have a specific data type</li> <li>All variables are treated as strings, </li> <li>but you can perform operations that treat them as numbers when needed.</li> <li>Array<ul> <li>FRUITS=(\"F1\" \"F2\" \"F3\")</li> </ul> </li> <li>Associated Array like Map<ul> <li>FRUIT_COLOR(\"F1\")=\"red\"</li> </ul> </li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#b-conditional","title":"B. Conditional","text":"<ul> <li>https://chatgpt.com/c/674504d4-e730-800d-b831-564a15b4b58e</li> <li>&lt;, &gt; are redirection operators, dont use for comparison.</li> <li> <p>help test</p> <ul> <li>run on terminal and check conditional operator list.</li> <li>some eg: <pre><code># Conditional Operators\n##  File Conditions\n-e file : File exists.\n-d file : File is a directory.\n-f file : File is a regular file.\n\n## String Conditions\n[ \"$a\" == \"$b\" ] : Strings are equal.\n[ -z \"$str\" ] : String is empty.\n\n## Arithmetic Comparisons\n[ $a -eq $b ] : Equal.\n[ $a -lt $b ] : Less than.\ngt, ne, ge, le\n</code></pre></li> </ul> </li> <li> <p>[[ ... ]]  vs   [ ... ]</p> </li> <li>new, prefer it in bash.</li> <li>Supports <code>wildcards</code>, e.g., [[ $var == a* ]]</li> <li>Supports =~ for regex matching</li> <li>[[ ... &amp;&amp; ... ]] is valid   vs Requires if [ ... ] &amp;&amp; [ ... ]</li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#c-loop","title":"C .loop","text":"<ul> <li>while</li> <li>until</li> <li>break and continue</li> <li>for (;;)</li> <li>for in array</li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#d-string-manipulation","title":"D .String manipulation","text":"<ul> <li>https://chatgpt.com/c/67454b39-b8f4-800d-8aaf-0eb72bcc568d</li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#with-awk","title":"with awk","text":"<ul> <li>programming capabilities</li> <li>pattern scanning and text processing. </li> <li>You need to process structured data (like CSV or tabular data). </li> <li>Perform calculations, conditional checks, or formatting output. </li> <li>Extract specific fields or records.</li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#with-sed-stream-editor","title":"with sed ( stream editor)","text":"<ul> <li>You need quick <code>search-and-replace</code> </li> <li>text editing in <code>files</code> or <code>streams</code>.</li> <li>Work with line-by-line text transformations.</li> </ul>"},{"location":"07_scripting/bash_script/00_bash_script_1/#f-file","title":"F. file","text":""},{"location":"08_Database/01_rdbms/00_postgress/","title":"Postgres","text":""},{"location":"08_Database/01_rdbms/00_postgress/#kick-off-references","title":"kick off - reference/s","text":"<ul> <li>All - https://chatgpt.com/c/674bee20-d9e4-800d-a31e-8f60a5f511ab</li> <li>core concept: https://chatgpt.com/c/674d6fa4-7e4c-800d-9d48-54f566791d8d</li> <li>ddl/dml : https://chatgpt.com/c/674df644-1984-800d-870c-ccee5069b8e9</li> <li>function: https://chatgpt.com/c/674df7ca-0ed8-800d-a8bf-9404d3ec216d</li> </ul>"},{"location":"08_Database/01_rdbms/00_postgress/#a-architecture","title":"A. Architecture","text":""},{"location":"08_Database/01_rdbms/00_postgress/#processs","title":"Process/s","text":"<ul> <li>operates with a process-based architecture,</li> <li>Backend Processes</li> <li>for each <code>client</code> connection.</li> <li>Handles queries, transactions, and data operations.</li> <li>Postmaster Process (Main Server Process)</li> <li>Manages connections and spawns new backend processes for each client.</li> <li>Coordinates system-level activities, like <code>crash recovery</code>.</li> <li>Background Processes</li> <li><code>WAL Writer</code>: Writes WAL (Write-Ahead Logging) data to disk.</li> <li><code>Checkpointer</code>: Periodically writes dirty pages from shared buffers to disk.</li> <li><code>Archiver</code>: Archives WAL files for point-in-time recovery (if enabled).</li> <li><code>Stats Collector</code>: Gathers performance and usage statistics.</li> <li>Replication Processes</li> <li>WAL Sender: Streams WAL data to replicas for replication.</li> <li>WAL Receiver: Receives WAL data on standby servers.</li> </ul>"},{"location":"08_Database/01_rdbms/00_postgress/#b-transaction","title":"B. Transaction","text":"<ul> <li><code>BEGIN</code></li> <li><code>COMMIT</code></li> <li><code>SAVEPOINT</code> save-point-1,2,...</li> <li><code>ROLLBACK</code> save-point-1,2,..</li> <li>SET TRANSACTION ISOLATION LEVEL SERIALIZABLE; default: <code>read committed</code></li> <li>Best practice:</li> <li>Use transactions for any operation involving multiple steps.</li> <li>Implement appropriate isolation levels based on concurrency requirements.</li> <li>Use savepoints for complex transactions to handle partial rollbacks.</li> <li>Regularly monitor transaction performance and concurrency issues.</li> </ul>"},{"location":"08_Database/01_rdbms/00_postgress/#c-configuring-and-tuning","title":"C. Configuring and tuning","text":"<ul> <li>/etc/postgresql/{version}/main/postgresql.conf (on Linux) </li> <li>data/postgresql.conf (on Windows). </li> <li>max_connections = 100</li> <li>...</li> <li>SELECT * FROM <code>pg_stat_activity</code>;</li> <li>SELECT * FROM <code>pg_stat_statements</code>;</li> <li>Use EXPLAIN and EXPLAIN ANALYZE to understand query performance and add appropriate indexes.</li> </ul>"},{"location":"08_Database/01_rdbms/01_datatype/","title":"postgres - Datatypes","text":""},{"location":"08_Database/01_rdbms/01_datatype/#numeric-types","title":"Numeric Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>SMALLINT</code> <code>short</code> <code>1, 2, -32768</code> <code>INTEGER</code> (<code>INT</code>) <code>int</code> <code>100, -2147483648</code> <code>BIGINT</code> <code>long</code> <code>9223372036854775807</code> <code>DECIMAL</code>/<code>NUMERIC</code> <code>java.math.BigDecimal</code> <code>10.99, -100.5</code> <code>REAL</code> <code>float</code> <code>3.14, 1e10</code> <code>DOUBLE PRECISION</code> <code>double</code> <code>3.14159, 1.2e308</code> <code>SERIAL</code> <code>int</code> <code>1, 2, 3</code> <code>BIGSERIAL</code> <code>long</code> <code>1, 2, 3</code>"},{"location":"08_Database/01_rdbms/01_datatype/#characterstring-types","title":"Character/String Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>CHAR(n)</code> <code>String</code> <code>'John  '</code> (5 chars) <code>VARCHAR(n)</code> <code>String</code> <code>'Hello'</code> (up to <code>n</code>) <code>TEXT</code> <code>String</code> <code>'This is a text.'</code>"},{"location":"08_Database/01_rdbms/01_datatype/#datetime-types","title":"Date/Time Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>DATE</code> <code>java.sql.Date</code> <code>2024-12-01</code> <code>TIME [WITH TZ]</code> <code>java.time.LocalTime</code> (or <code>OffsetTime</code> for TZ) <code>13:45:30</code>, <code>13:45:30+05:30</code> <code>TIMESTAMP [WITH TZ]</code> <code>java.time.LocalDateTime</code> (or <code>OffsetDateTime</code> for TZ) <code>2024-12-01 13:45:30+05:30</code> <code>INTERVAL</code> <code>java.time.Duration</code> <code>1 day</code>, <code>3 hours 15 minutes</code>"},{"location":"08_Database/01_rdbms/01_datatype/#boolean-type","title":"Boolean Type","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>BOOLEAN</code> <code>boolean</code> <code>true, false</code>"},{"location":"08_Database/01_rdbms/01_datatype/#binary-types","title":"Binary Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>BYTEA</code> <code>byte[]</code> <code>new byte[] {0xDE, 0xAD, 0xBE, 0xEF}</code>"},{"location":"08_Database/01_rdbms/01_datatype/#json-and-jsonb-types","title":"JSON and JSONB Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>JSON</code> <code>String</code> <code>'{\"key\": \"value\"}'</code> <code>JSONB</code> <code>String</code> <code>'{\"key\": \"value\"}'</code>"},{"location":"08_Database/01_rdbms/01_datatype/#array-types","title":"Array Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>ARRAY</code> <code>Object[]</code> (or specific type <code>Integer[]</code>, <code>String[]</code>, etc.) <code>{1, 2, 3}</code>, <code>{A, B}</code>"},{"location":"08_Database/01_rdbms/01_datatype/#geometric-types-skip","title":"Geometric Types (skip)","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>POINT</code> <code>java.awt.Point</code> <code>new Point(1, 2)</code> <code>LINE</code> <code>String</code> (representation of a line) `'{1, 2, 3}' <code>POLYGON</code> <code>String</code> (representation of a polygon) <code>'((0,0), (1,1), (2,0))'</code>"},{"location":"08_Database/01_rdbms/01_datatype/#network-address-types","title":"Network Address Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>INET</code> <code>java.net.InetAddress</code> <code>'192.168.1.1'</code> <code>CIDR</code> <code>java.net.InetAddress</code> <code>'192.168.1.0/24'</code> <code>MACADDR</code> <code>String</code> <code>'08:00:2b:01:02:03'</code>"},{"location":"08_Database/01_rdbms/01_datatype/#uuid-type","title":"UUID Type","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>UUID</code> <code>java.util.UUID</code> <code>UUID.fromString(\"550e8400-e29b-41d4-a716-446655440000\")</code>"},{"location":"08_Database/01_rdbms/01_datatype/#other-special-types","title":"Other Special Types","text":"PostgreSQL Data Type Java Equivalent Data Type Example Values <code>ENUM</code> <code>String</code> <code>'small'</code>, <code>'medium'</code> <code>TSVECTOR</code> <code>String</code> <code>'text'</code> <code>XML</code> <code>String</code> <code>'&lt;tag&gt;value&lt;/tag&gt;'</code>"},{"location":"08_Database/01_rdbms/02_constraints/","title":"02 constraints","text":""},{"location":"08_Database/01_rdbms/02_constraints/#a-constraints","title":"A. Constraints","text":"<ul> <li>NOT NULL</li> <li>UNIQUE</li> <li>PRIMARY KEY : <code>unique + not_null</code> </li> <li>FOREIGN KEY : <code>referential integrity</code></li> <li>relationship between columns in two tables.</li> <li>The foreign key column in one table references the primary key in another table</li> <li>CHECK </li> <li>DEFAULT</li> <li>DOMAIN : custom constraint. define and reuse.   <pre><code>CREATE DOMAIN positive_integer AS INT\n  CHECK (VALUE &gt; 0);\n</code></pre></li> <li>Note: can combine multiple. point_left: <pre><code>CREATE TABLE orders (\n    order_id SERIAL PRIMARY KEY,\n    emp_id INT REFERENCES employees(emp_id)   [ ON DELETE CASCADE  |  ON UPDATE CASCADE ]\n    name TEXT UNIQUE NOT NULL DEFAULT 'active',\n    qty INT CHECK (qty &gt; 0) positive_integer,\n);\n\nor \n\nCREATE TABLE orders (\n    order_id SERIAL ,\n    emp_id INT,\n    name TEXT\n\n    PRIMARY KEY (order_id)\n    PRIMARY KEY (order_id, another-column) --composite PK\n    UNIQUE (TEXT)\n    FOREIGN KEY (emp_id) REFERENCES employees(emp_id)    [ ON DELETE CASCADE  |  ON UPDATE CASCADE ]\n);\n\n\nALTER TABLE employees \n  ADD CONSTRAINT emp_name_unique UNIQUE (name);\n\nALTER TABLE employees \n  DROP CONSTRAINT emp_name_unique;\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/","title":"DDL :green_circle:","text":"<ul> <li>define, modify, and manage the structure of database.</li> <li>Implicitly commits changes</li> </ul>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#a-schemas","title":"A. Schemas","text":"<ul> <li>search path : determines the order in which schemas are searched when a table, view, function, or other database objects are referenced by name <pre><code>CREATE SCHEMA hr;\nDROP SCHEMA IF EXISTS hr CASCADE;\nSET search_path TO hr;\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#b-table-and-view","title":"B Table and view","text":"<p><pre><code>CREATE TABLE employees (...);\nDROP TABLE employees;\n\n-- column\nALTER TABLE employees [ ADD | DROP ] COLUMN department VARCHAR(50);     -- new column\nALTER TABLE employees ALTER COLUMN name SET DATA TYPE TEXT;             -- datatype change\nALTER TABLE employees ALTER COLUMN age SET DATA TYPE BIGINT;\n\nALTER TABLE employees ALTER COLUMN name SET NOT NULL;               -- NOT NULL\nALTER TABLE employees ALTER COLUMN name DROP NOT NULL;\n\nALTER TABLE employees ALTER COLUMN name SET DEFAULT 'Unknown';      -- DEFAULT\nALTER TABLE employees ALTER COLUMN name DROP DEFAULT;\n\n-- constraint \nALTER TABLE employees DROP CONSTRAINT constraint-1;             -- DROP constarint\n\nALTER TABLE employees ADD CONSTRAINT unique_email UNIQUE (email);                       -- unique\nALTER TABLE employees ALTER COLUMN name SET NOT NULL;                                   -- not null\nALTER TABLE employees ADD CONSTRAINT chk_hire_date CHECK (hire_date &gt;= '2000-01-01');   -- CHECK\nALTER TABLE employees ADD CONSTRAINT pk_employee_id PRIMARY KEY (id);                   -- pk\nALTER TABLE employees ADD CONSTRAINT fk_department_id FOREIGN KEY (department_id)       -- fk\n    REFERENCES departments(id) ON DELETE CASCADE;\n</code></pre> <pre><code>-- ========== VIEW ==========\nCREATE OR REPLACE VIEW active_employees AS\n    SELECT id, name FROM employees WHERE active = TRUE;\n\nDROP VIEW IF EXISTS active_employees;\n</code></pre></p>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#c-indexes","title":"C Indexes","text":"<ul> <li>improve query performance, but take up additional disk space.</li> <li>speed up SELECT queries</li> <li> <p>slow down INSERT, UPDATE, DELETE,  as the index must be updated whenever the data changes.</p> </li> <li> <p>internal <code>data structure</code> that provides quick access to rows : </p> </li> <li><code>B-tree index</code>, </li> <li><code>Hash Index</code>, </li> <li><code>GIN (Generalized Inverted Index)</code> - useful for indexing composite types like arrays, JSONB</li> <li> <p><code>GiST (Generalized Search Tree)</code></p> </li> <li> <p>best use case:</p> </li> <li>Frequent Query Filtering: When you regularly run queries that filter on specific columns.</li> <li>Join Operations: When you perform join queries based on indexed columns.</li> <li>Range Queries: When you frequently query for ranges (e.g., <code>date</code> ranges).</li> </ul> <pre><code>CREATE INDEX idx_name ON employees(name);               -- Regular Index (Non-Unique)\nCREATE UNIQUE INDEX idx_unique_name ON employees(name); -- Unique Index : adds overhead for enforcing uniqueness\n\nDROP INDEX IF EXISTS idx_name;\n</code></pre>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#d-sequence","title":"D Sequence","text":"<pre><code>CREATE SEQUENCE seq_emp_id START WITH 1 INCREMENT BY 1;\nDROP SEQUENCE IF EXISTS seq_emp_id;\n\n    CREATE TABLE employees (\n    id INT DEFAULT nextval('seq_emp_id'),   -- &lt;&lt;&lt; \n    name VARCHAR(100)\n    );\n</code></pre>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#e-extension","title":"E extension","text":"<ul> <li><code>add-ons</code> that extend PostgreSQL\u2019s functionality.</li> <li>System-wide, available to all schemas.</li> <li>These can provide new:</li> <li>data-types </li> <li>functions </li> <li>operators </li> <li> <p>procedural languages ?</p> </li> <li> <p>Common pre-existing Extensions/add-on:</p> </li> <li>pg_stat_statements: Tracks SQL execution statistics. </li> <li>hstore: Enables key-value storage within PostgreSQL. === datatype</li> <li>postgis: Adds support for geographic objects. </li> <li>uuid-ossp: Generates UUIDs.</li> <li>creating/install custom extension, involve several step. skip. for db admin. <pre><code>-- Install an Extension : Adding support for UUID generation.\nCREATE EXTENSION IF NOT EXISTS \"uuid-ossp\";\nDROP EXTENSION IF EXISTS \"uuid-ossp\";\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#f-triggers","title":"F triggers","text":"<ul> <li>automatically execute :</li> <li>specified function </li> <li>in response to certain events (such as INSERT, UPDATE, or DELETE) occurring on a table/view <pre><code>CREATE TRIGGER after_employee_update\n    AFTER    INSERT OR UPDATE OR DELETE      ON employees\n    FOR EACH ROW\n        EXECUTE FUNCTION log_employee_update();\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#g-function","title":"G Function","text":"<pre><code>CREATE FUNCTION my_function(integer) RETURNS integer AS\n$$\nBEGIN\n    RETURN $1 * $1;\nEND;\n$$ LANGUAGE plpgsql;\n\n\nCREATE FUNCTION my_other_function(text) RETURNS text AS\n$$\nBEGIN\n    RETURN CONCAT('Hello, ', $1);\nEND;\n$$ LANGUAGE plpgsql;\n</code></pre>"},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#h-stored-procedure","title":"H Stored procedure","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#dml-green_circle","title":"DML :green_circle:","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#a-insert","title":"A. INSERT","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#_1","title":"DDL :green_circle:","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#a-update","title":"A. UPDATE","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#_2","title":"DDL :green_circle:","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#a-delete","title":"A. DELETE","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#_3","title":"DDL :green_circle:","text":""},{"location":"08_Database/01_rdbms/02_ddl%2Bdml/#a-select","title":"A. SELECT","text":"<pre><code># 1. JSONB\nCREATE TABLE products ( id SERIAL PRIMARY KEY,data JSONB );\nINSERT INTO products (data) VALUES ('{\"name\": \"Laptop\", \"price\": 1200}');\n\nSELECT data-&gt;&gt;'name', data-&gt;&gt;'price' FROM products WHERE data-&gt;&gt;'name' = 'Laptop';\n</code></pre>"},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/","title":"A. Joins","text":""},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#1-inner","title":"1. inner","text":""},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#2-outer","title":"2. outer","text":"<ul> <li>left outer</li> <li>right outer</li> </ul>"},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#3-cross","title":"3. Cross","text":"<ul> <li>Results in m \u00d7 n rows (where m and n are row counts of each table)</li> <li>every row from the first table is combined with every row from the second table</li> <li>No join condition is specified</li> </ul>"},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#self-join","title":"self join","text":"<ul> <li>special case: regular join (inner, outer, cross) where a table is joined with itself.</li> <li>it's useful for querying hierarchical data or comparing rows within the same table</li> <li>Commonly used eg:</li> <li>Employee-manager relationships</li> <li>Bill of materials (parent-child relationships)</li> <li>Finding duplicate records <pre><code>SELECT e.employee_name, m.employee_name AS manager_name\nFROM employees e\nLEFT JOIN employees m ON e.manager_id = m.employee_id\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#queries","title":"Queries","text":""},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#sub-queries","title":"Sub queries","text":""},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#co-related-queries","title":"co related queries","text":""},{"location":"08_Database/01_rdbms/03_joins%2Bqueries/#recursive-queries","title":"recursive queries","text":""},{"location":"08_Database/01_rdbms/04_function/","title":"postgres - functions","text":""},{"location":"08_Database/01_rdbms/04_function/#1-string-functions","title":"1 String Functions","text":"Function Description Usage Level Example <code>length()</code> Get the length of a string Most Used <code>SELECT length('hello');</code> <code>concat()</code> Concatenate strings Most Used <code>SELECT concat('a', 'b', 'c');</code> <code>upper()</code>/<code>lower()</code> Convert to upper/lowercase Most Used <code>SELECT upper('hello');</code> <code>strpos()</code> Find substring position Rarely Used <code>SELECT strpos('hello', 'e');</code> <code>regexp_replace()</code> Replace substring using regex Advanced Use <code>SELECT regexp_replace('123abc', '[a-z]', '');</code>"},{"location":"08_Database/01_rdbms/04_function/#2-mathematical-functions","title":"2 Mathematical Functions","text":"Function Description Usage Level Example <code>abs()</code> Absolute value Most Used <code>SELECT abs(-5);</code> <code>round()</code> Round to nearest integer Most Used <code>SELECT round(4.6);</code> <code>sqrt()</code> Square root Rarely Used <code>SELECT sqrt(16);</code> <code>power()</code> Raise to a power Rarely Used <code>SELECT power(2, 3);</code> <code>random()</code> Generate random number Advanced Use <code>SELECT random();</code>"},{"location":"08_Database/01_rdbms/04_function/#3-datetime-functions","title":"3 Date/Time Functions","text":"Function Description Usage Level Example <code>now()</code> Current date/time Most Used <code>SELECT now();</code> <code>age()</code> Difference between dates Most Used <code>SELECT age('2024-01-01');</code> <code>date_trunc()</code> Truncate to specified precision Rarely Used <code>SELECT date_trunc('month', now());</code> <code>to_char()</code> Format date/time Rarely Used <code>SELECT to_char(now(), 'YYYY-MM-DD');</code> <code>interval</code> Add/subtract time intervals Advanced Use <code>SELECT now() + interval '1 day';</code>"},{"location":"08_Database/01_rdbms/04_function/#4-aggregate-functions","title":"4 Aggregate Functions","text":"Function Description Usage Level Example <code>COUNT(*)</code> Counts rows. Most Used <code>COUNT(*) \u2192 42</code> <code>SUM(value)</code> Sums values. Most Used <code>SUM(salary) \u2192 50000</code> <code>AVG(value)</code> Calculates average. Most Used <code>AVG(salary) \u2192 5000</code> <code>MIN(value)</code> Finds minimum value. Most Used <code>MIN(salary) \u2192 1000</code> <code>STRING_AGG(value, delimiter)</code> Concatenates strings. Rarely Used <code>STRING_AGG(name, ', ')</code>"},{"location":"08_Database/01_rdbms/04_function/#5-window-functions-skip","title":"5 Window Functions (skip)","text":"Function Description Usage Level Example <code>ROW_NUMBER()</code> Assigns a unique row number. Most Used <code>ROW_NUMBER() OVER (PARTITION BY dept)</code> <code>RANK()</code> Assigns rank with gaps. Most Used <code>RANK() OVER (ORDER BY salary DESC)</code> <code>LEAD(value)</code> Accesses subsequent row value. Advanced <code>LEAD(salary) OVER ()</code> <code>LAG(value)</code> Accesses previous row value. Advanced <code>LAG(salary) OVER ()</code>"},{"location":"08_Database/01_rdbms/04_function/#6-jsonjsonb-functions","title":"6 JSON/JSONB Functions","text":"Function Description Usage Level Example <code>-&gt;</code> Accesses a JSON object field by key. Most Used <code>json_column-&gt;'key' \u2192 \"value\"</code> <code>-&gt;&gt;</code> Accesses a JSON object field as text. Most Used <code>json_column-&gt;&gt;'key' \u2192 value</code> <code>#&gt;</code> Accesses a JSON object using a path. Advanced <code>json_column#&gt;'{path,key}' \u2192 \"value\"</code> <code>#&gt;&gt;</code> Accesses a JSON object field as text using a path. Advanced <code>json_column#&gt;&gt;'{path,key}' \u2192 value</code> <code>JSONB_ARRAY_ELEMENTS(jsonb)</code> Expands a JSON array to a set of rows. Advanced <code>JSONB_ARRAY_ELEMENTS('[1,2,3]') \u2192 1, 2, 3</code> <code>JSON_BUILD_OBJECT(keys, values...)</code> Builds a JSON object from key-value pairs. Most Used <code>JSON_BUILD_OBJECT('a', 1, 'b', 2) \u2192 {\"a\":1,\"b\":2}</code> <code>JSONB_BUILD_ARRAY(values...)</code> Builds a JSONB array. Most Used <code>JSONB_BUILD_ARRAY(1, 2, 'a') \u2192 [1,2,\"a\"]</code> <code>JSONB_SET(jsonb, path, value)</code> Updates a JSONB object by setting a value at a path. Advanced <code>JSONB_SET('{\"a\":1}', '{a}', '2') \u2192 {\"a\":2}</code> <code>JSONB_INSERT(jsonb, path, value)</code> Inserts a value into a JSONB array at a specified path. Rarely Used <code>JSONB_INSERT('[1,2]', '{1}', '1.5') \u2192 [1,1.5,2]</code> <code>TO_JSON(value)</code> Converts a SQL value to JSON. Most Used <code>TO_JSON(ROW('a', 1)) \u2192 {\"f1\":\"a\",\"f2\":1}</code> <code>JSON_EACH(json)</code> Expands JSON object to key-value rows. Rarely Used <code>JSON_EACH('{\"a\":1, \"b\":2}') \u2192 \"a\", 1 and \"b\", 2</code> <code>JSON_OBJECT(keys, values...)</code> Constructs a JSON object from text arrays. Advanced <code>JSON_OBJECT(ARRAY['a','b'], ARRAY[1,2]) \u2192 {\"a\":1,\"b\":2}</code>"},{"location":"08_Database/01_rdbms/04_function/#example","title":"Example:","text":""},{"location":"08_Database/01_rdbms/04_function/#select-name-john-age-30json-name-as-result-john-select-name-john-age-30json-age-as-result-30-not-30-select-jsonb_array_elements10-20-30jsonb-as-value-10-n-20-n-30-select-json_build_objectname-alice-age-25-as-result-namealiceage25","title":"<pre><code> SELECT '{\"name\": \"John\", \"age\": 30}'::json-&gt;'name' AS result; -- \"John\"\n\n SELECT '{\"name\": \"John\", \"age\": 30}'::json-&gt;&gt;'age' AS result; -- \"30\", not 30\n\n SELECT JSONB_ARRAY_ELEMENTS('[10, 20, 30]'::jsonb) AS value; -- 10 \\n 20 \\n 30\n\n SELECT JSON_BUILD_OBJECT('name', 'Alice', 'age', 25) AS result;  -- {\"name\":\"Alice\",\"age\":25}\n</code></pre>","text":""},{"location":"08_Database/01_rdbms/04_function/#7-array-functions","title":"7 Array Functions","text":"Function Description Usage Level Example <code>ARRAY_APPEND(array, value)</code> Appends an element to the end of the array. Most Used <code>ARRAY_APPEND(ARRAY[1, 2], 3) \u2192 {1,2,3}</code> <code>ARRAY_PREPEND(value, array)</code> Prepends an element to the beginning of the array. Most Used <code>ARRAY_PREPEND(0, ARRAY[1, 2]) \u2192 {0,1,2}</code> <code>ARRAY_CAT(array1, array2)</code> Concatenates two arrays. Most Used <code>ARRAY_CAT(ARRAY[1,2], ARRAY[3,4]) \u2192 {1,2,3,4}</code> <code>CARDINALITY(array)</code> Returns the number of elements in the array. Most Used <code>CARDINALITY(ARRAY[1,2,3]) \u2192 3</code> <code>ARRAY_REMOVE(array, value)</code> Removes all occurrences of a value in the array. Rarely Used <code>ARRAY_REMOVE(ARRAY[1,2,2], 2) \u2192 {1}</code> <code>ARRAY_REPLACE(array, search, replace)</code> Replaces occurrences of a value. Rarely Used <code>ARRAY_REPLACE(ARRAY[1,2,3], 2, 99) \u2192 {1,99,3}</code> <code>UNNEST(array)</code> Expands an array into a set of rows. Advanced <code>UNNEST(ARRAY[1,2,3]) \u2192 1, 2, 3</code> <code>ARRAY_POSITION(array, value)</code> Returns the position of the first occurrence. Rarely Used <code>ARRAY_POSITION(ARRAY[10,20,30], 20) \u2192 2</code> <code>ARRAY_AGG(value)</code> Aggregates values into an array. Advanced <code>ARRAY_AGG(column) \u2192 {val1, val2, ...}</code> <code>STRING_TO_ARRAY(string, delimiter)</code> Splits a string into an array. Most Used <code>STRING_TO_ARRAY('a,b,c', ',') \u2192 {a,b,c}</code> <code>ARRAY_TO_STRING(array, delimiter)</code> Joins array elements into a string. Most Used <code>ARRAY_TO_STRING(ARRAY['a', 'b'], ',') \u2192 'a,b'</code>"},{"location":"08_Database/01_rdbms/04_function/#8-full-text-search-functions","title":"8 Full-Text Search Functions","text":"Function Description Usage Level Example <code>TO_TSVECTOR(text)</code> Converts text to tsvector. Rarely Used <code>TO_TSVECTOR('english', 'text')</code> <code>TO_TSQUERY(text)</code> Converts text to tsquery. Rarely Used <code>TO_TSQUERY('english', 'query')</code> <code>TS_RANK(vector, query)</code> Ranks search results. Advanced <code>TS_RANK(vector, query)</code>"},{"location":"08_Database/01_rdbms/04_function/#9-geometric-functions","title":"9 Geometric Functions","text":"Function Description Usage Level Example <code>POINT(x, y)</code> Creates a geometric point. Rarely Used <code>POINT(1, 2)</code> <code>LENGTH(segment)</code> Calculates segment length. Rarely Used <code>LENGTH(LINE((0,0),(3,4))) \u2192 5</code>"},{"location":"08_Database/01_rdbms/04_function/#10-network-functions","title":"10 Network Functions","text":"Function Description Usage Level Example <code>INET_CLIENT_ADDR()</code> Returns client IP. Rarely Used <code>INET_CLIENT_ADDR()</code> <code>HOSTMASK(address)</code> Returns network host mask. Advanced <code>HOSTMASK('192.168.1.0/24')</code>"},{"location":"08_Database/01_rdbms/04_function/#11-system-information-functions","title":"11 System Information Functions","text":"Function Description Usage Level Example <code>VERSION()</code> Returns PostgreSQL version. Most Used <code>VERSION()</code> <code>PG_TABLE_SIZE(table)</code> Gets table size. Advanced <code>PG_TABLE_SIZE('users')</code> <code>CURRENT_SETTING(name)</code> Returns configuration parameter. Advanced <code>CURRENT_SETTING('work_mem')</code>"},{"location":"08_Database/01_rdbms/04_function/#12-advanced-and-rarely-used-functions","title":"12 Advanced and Rarely Used Functions","text":"Function Description Usage Level Example <code>SETVAL(sequence, value)</code> Sets sequence value. Rarely Used <code>SETVAL('seq_name', 42)</code> <code>TS_HEADLINE(text, query)</code> Generates search result snippet. Advanced <code>TS_HEADLINE('document', query)</code>"},{"location":"08_Database/01_rdbms/05_CTE%2Bview/","title":"05 CTE+view","text":""},{"location":"08_Database/01_rdbms/05_CTE%2Bview/#ctes-common-table-expressions","title":"CTEs (Common Table Expressions)","text":"<ul> <li>It improves the readability / maintainability of SQL code.</li> <li>Simplifies complex queries.</li> <li>temporary result set that, can be referenced within a SELECT, INSERT, UPDATE, or DELETE statement</li> <li>re-use result multiple times.</li> <li>can include recursive definitions for hierarchical data. <pre><code># =========== Syntax ==============\n\nWITH cte_name (optional_column_names) AS (  -- explicit\n    query_definition\n),\nWITH cte_name2  AS (  -- Inferred from the query\n    query_definition2\n)\nSELECT * FROM cte_name;\n\n# =========== example 1 ==============\n\nWITH AverageSalary AS (\n    SELECT AVG(salary) AS avg_salary\n    FROM employees\n)\nSELECT name, salary\nFROM employees, AverageSalary\nWHERE salary &gt; avg_salary;\n\n# =========== example 2 ==============\n\nWITH DepartmentSalary AS (\n    SELECT department, AVG(salary) AS avg_salary\n    FROM employees\n    GROUP BY department\n),\nHighEarners AS (\n    SELECT name, salary, department\n    FROM employees\n)\nSELECT he.name, he.salary, ds.avg_salary\nFROM HighEarners he\nJOIN DepartmentSalary ds ON he.department = ds.department\nWHERE he.salary &gt; ds.avg_salary;\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/05_CTE%2Bview/#views","title":"Views","text":""},{"location":"08_Database/01_rdbms/05_CTE%2Bview/#regular","title":"Regular","text":"<ul> <li>virtual and recompute their results every time query them.</li> </ul>"},{"location":"08_Database/01_rdbms/05_CTE%2Bview/#materialized-views","title":"Materialized Views","text":"<ul> <li>object that contains the results of a query and stores them physically on disk.</li> <li>improves performance </li> <li>create indexes on materialized views to further optimize performance</li> <li>limitation:</li> <li>Data is static until refreshed, which can lead to stale results. </li> <li>perform frequent refreshes. <ul> <li>Note: use <code>pg_cron</code> for periodic refresh</li> </ul> </li> <li>Storage Overhead</li> <li>syntax : <pre><code>CREATE MATERIALIZED VIEW view_name AS\nSELECT query\nWITH [NO] DATA;\n\nDROP MATERIALIZED VIEW view_name;\n\nREFRESH MATERIALIZED VIEW view_name WITH DATA;\nREFRESH MATERIALIZED VIEW view_name WITH NO DATA; --&gt; clean up\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/05_CTE%2Bview/#analyze-query","title":"Analyze Query","text":"<ul> <li>EXPLAIN ANALYZE SELECT * FROM employees WHERE age &gt; 30</li> </ul>"},{"location":"08_Database/01_rdbms/05_CTE%2Bview/#partitioning","title":"Partitioning","text":""},{"location":"08_Database/01_rdbms/06_permissions/","title":"Role and permission management","text":"<ul> <li>enabling <code>fine-grained control</code> over database access and operations.</li> <li>FORMAT : GRANT/REVOKE (allw/deny) <code>privileges (action/verbs)</code> on <code>resource</code> to <code>role</code> </li> <li>thinks of IAM policy in aws, k8s RBAC, etc</li> </ul>"},{"location":"08_Database/01_rdbms/06_permissions/#1-user-and-role","title":"1 User and Role","text":"<p><pre><code>======== create role\nCREATE ROLE admin SUPERUSER;\nCREATE ROLE user_role;\n\nCREATE ROLE app_r;\nCREATE ROLE app_rw;\nCREATE ROLE app_rwx;\n</code></pre> <pre><code>======== create user\nCREATE ROLE userAsRole WITH LOGIN PASSWORD 'secure_password'; \n</code></pre></p>"},{"location":"08_Database/01_rdbms/06_permissions/#2-attributes","title":"2 Attributes","text":"<ul> <li>create <code>role</code> and <code>user</code> with attributes. </li> <li>can alter role add/remove attribute.</li> <li>check attributes, run : \\du <pre><code>LOGIN     : Enables the role to log in as a user.\nSUPERUSER : Grants all privileges.\nCREATEDB  : Allows the role to create databases.\nCREATEROLE: Allows the role to create and manage other roles.\nINHERIT   : Allows a role to inherit privileges from granted roles.\nNOINHERIT   : Prevents privilege inheritance.\nREPLICATION : Grants the ability to manage streaming replication.\nPASSWORD: sets login password\n\n-- add \"NO\" prefix to remove. eg: NOLOGIN \n-- WITH is optional.\n</code></pre></li> <li>examples:</li> </ul> <pre><code>CREATE USER bob WITH PASSWORD 'password456' CREATEDB CREATEROLE;\nCREATE USER alice WITH PASSWORD 'password123';\nCREATE USER admin WITH PASSWORD 'adminpassword' SUPERUSER;\n\n--&gt; Alter attribute:\nALTER ROLE admin WITH SUPERUSER;\nALTER ROLE user_role WITH LOGIN NOINHERIT; -- NO\nALTER ROLE user_role NOLOGIN;  -- NO\n\n--&gt;  role inheritance. eg: user_role inherits admin privileges\nGRANT admin TO user_role; \nREVOKE admin FROM user_role;\n</code></pre>"},{"location":"08_Database/01_rdbms/06_permissions/#3-privileges","title":"3 Privileges:","text":"<ul> <li>like verbs in k8s </li> <li>like actions in aws iam <pre><code>  ALL    : Grants all privileges.\n  SELECT : Permission to query data.\n  INSERT : Permission to add data.\n  UPDATE : Permission to modify data.\n  DELETE : Permission to remove data.\n\n  USAGE  : Grants access to schemas or sequences.\n  CONNECT: Permission to connect to the database.\n\n  EXECUTE: SP,Fn\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/06_permissions/#3-db-resourcesobject","title":"3 DB Resources/object:","text":""},{"location":"08_Database/01_rdbms/06_permissions/#-schema-table-view-regular-materialized-function-sp-etc","title":"- schema, table , view (regular/ materialized ), function, SP, etc","text":""},{"location":"08_Database/01_rdbms/06_permissions/#examples-on-permission-yellow_circle","title":"examples on permission :yellow_circle:","text":"<pre><code>-- db\nGRANT CONNECT ON DATABASE mydb TO alice;\n\n-- schema\nGRANT USAGE ON SCHEMA public TO user_role;\nGRANT CREATE ON SCHEMA public TO admin;\n\n-- table\nGRANT ALL ON TABLE employees TO admin; --admin is role\nGRANT SELECT, INSERT ON TABLE employees TO user_role;\nREVOKE DELETE ON TABLE employees FROM user_role;\n\n-- column level\nGRANT SELECT (salary) ON employees TO user_role;\n\n-- function level\nGRANT EXECUTE ON FUNCTION calculate_bonus() TO admin;\n\n-- ==== IMP: privelges on future object/table ====                &lt;&lt;&lt; \nALTER DEFAULT PRIVILEGES IN SCHEMA public  -- add this list first\nGRANT SELECT ON TABLES TO user_role;\n</code></pre>"},{"location":"08_Database/01_rdbms/10_sharding/","title":"kickoff","text":"<ul> <li> <ul> <li>https://chat.deepseek.com/a/chat/s/8483329c-7494-483f-bd9c-f296c81b084e </li> </ul> </li> <li>Sharding vs Partitioning in RDBMS</li> <li>Partitioning splits a table into smaller segments within the same database server (by rows or columns) for performance and manageability.</li> <li>Sharding distributes data across multiple servers (horizontal scaling) to handle large-scale workloads.</li> </ul>"},{"location":"08_Database/01_rdbms/10_sharding/#a-rdbms-partitioning","title":"A. RDBMS partitioning","text":"<ul> <li>https://www.youtube.com/watch?v=oJj-pltxBUM&amp;ab_channel=High-PerformanceProgramming - intro</li> <li>https://www.youtube.com/watch?v=VcTPmEJeKM4&amp;ab_channel=AWSEvents - aws rds sharding</li> </ul> <pre><code>=== TOPICS asked in above deepseek chat =====\n0. sharding vs partitioning in RDBMS.\n1. Database - Sharding and partitioning in RDBMS \n2. Database - Sharding and partitioning in noSQL\n\n3. No SQL DB - ACID \n4. RDBMS  - ACID\n\n5. Blue-Green Partitioning - implementation approach rather than a PostgreSQL feature\n    - Blue (production)\n    - Green (with new partitioning scheme)\n    Enables zero-downtime migration to partitioned tables. like in k8s\n\n6 scenario1: \ntable-1 create without partition. after one year millions of records inserted. can we add partition later.\n\n7 scenario2: \ntable-1 create with range partition. after one year millions of records inserted. \ncan we add update partiton to hash type from  range type.\n\n8 time-based partitioning if historical data grows rapidly. intQ\n</code></pre>"},{"location":"08_Database/01_rdbms/10_sharding/#example","title":"Example","text":"<ul> <li>hash partition <pre><code>CREATE TABLE users (\n    user_id INT,\n    username VARCHAR(50)\n) PARTITION BY HASH (user_id);\n\n-- Partition 0: Stores rows where `hash(user_id) % 4 == 0`\nCREATE TABLE users_p1 PARTITION OF users\n    FOR VALUES WITH (MODULUS 4, REMAINDER 0);\n\n-- Partition 3: Stores rows where `hash(user_id) % 4 == 3`\nCREATE TABLE users_p2 PARTITION OF users\n    FOR VALUES WITH (MODULUS 4, REMAINDER 3);\n</code></pre></li> <li>Time-Based Partitioning <pre><code>-- Parent table (logical)\n  CREATE TABLE sales (\n  id SERIAL,\n  sale_date DATE,\n  customer_id INT,\n  amount DECIMAL(10,2)\n  ) PARTITION BY RANGE (sale_date);\n\n-- Yearly partitions\nCREATE TABLE sales_2023 PARTITION OF sales\nFOR VALUES FROM ('2023-01-01') TO ('2024-01-01');\n\nCREATE TABLE sales_2024 PARTITION OF sales\nFOR VALUES FROM ('2024-01-01') TO ('2025-01-01');\n\n... manually create more in future...\n\n-- ===== Automatic Partition Creation =====\n\n-- PostgreSQL example: Function to create next month's partition\nCREATE OR REPLACE FUNCTION create_next_month_partition()\nRETURNS TRIGGER AS $$\nBEGIN\n    EXECUTE format(\n        'CREATE TABLE IF NOT EXISTS sales_%s PARTITION OF sales '\n        'FOR VALUES FROM (%L) TO (%L)',\n        to_char(NEW.sale_date, 'YYYY_MM'),\n        date_trunc('month', NEW.sale_date),\n        date_trunc('month', NEW.sale_date) + INTERVAL '1 month'\n    );\n    RETURN NEW;\nEND;\n$$ LANGUAGE plpgsql;\n\n\n-- Trigger to run before INSERT\nCREATE TRIGGER trg_sales_partition\nBEFORE INSERT ON sales\nFOR EACH ROW EXECUTE FUNCTION create_next_month_partition();\n\n-- option-2: pg_cron\n</code></pre></li> </ul>"},{"location":"08_Database/01_rdbms/10_sharding/#b-rdbms-sharding","title":"B. RDBMS Sharding","text":""},{"location":"08_Database/01_rdbms/10_sharding/#intro","title":"intro","text":"<ul> <li>https://www.youtube.com/watch?v=be6PLMKKSto&amp;ab_channel=Exponent</li> <li>Sharding splits a large database into smaller, independent chunks (\"shards\") distributed across multiple servers</li> <li>Horizontal Scaling</li> <li>global users table is split by region</li> <li>users table</li> <li>users_europe (PostgreSQL Server 1)</li> <li>users_europe (PostgreSQL Server 2)</li> <li>advantages</li> <li>\u2705 Improved Performance (queries run on smaller datasets).</li> <li>\u2705 Fault Isolation (one shard failing doesn\u2019t crash the whole DB).</li> <li>postgres Doesnot provide automatic sharding</li> <li>do manually</li> <li>Citus (PostgreSQL Extension)</li> <li>useful for : Multi-tenant SaaS apps (isolate customer data). </li> </ul>"},{"location":"08_Database/01_rdbms/10_sharding/#sharding-strategies","title":"Sharding Strategies","text":"<ul> <li>first create/deploy manually db server/s. shard-1,Shard 2,...</li> <li>Application code:</li> <li>Key-Based (Hash) Sharding<ul> <li>-- Shard 1: user_id % 4 = 0</li> <li>-- Shard 2: user_id % 4 = 1</li> </ul> </li> <li>Range-Based Sharding<ul> <li>-- Shard 1: order_id 1-1000</li> <li>-- Shard 2: order_id 1001-2000</li> </ul> </li> <li>Directory-Based Sharding<ul> <li>-- Lookup table: </li> <li>SELECT shard_location FROM shard_map WHERE user_id = 123;</li> </ul> </li> </ul>"},{"location":"08_Database/01_rdbms/10_sharding/#challenges-of-sharding","title":"Challenges of Sharding","text":"<ul> <li>\u274c Complexity (joins across shards are hard).</li> <li>\u274c No ACID across shards (distributed transactions are slow).</li> <li>\u274c Rebalancing (moving data between shards is tricky).</li> </ul>"},{"location":"08_Database/01_rdbms/shopping_app/readme/","title":"Readme","text":""},{"location":"08_Database/01_rdbms/shopping_app/readme/#project","title":"project:","text":"<ul> <li>code: database</li> <li>db: postgres - running locally on pod.</li> <li></li> </ul> <ul> <li>All: https://chatgpt.com/c/674bee20-d9e4-800d-a31e-8f60a5f511ab<ul> <li>core concept: https://chatgpt.com/c/674d6fa4-7e4c-800d-9d48-54f566791d8d</li> </ul> </li> </ul>"},{"location":"09_ETL/01_spring-batch/00_kickoff/","title":"00 kickoff","text":""},{"location":"09_ETL/01_spring-batch/00_kickoff/#spring-batch","title":"Spring batch","text":"<ul> <li>Architecture</li> <li>configure a jobRepository</li> <li>Job parameter</li> <li>Building job with multiple Steps</li> </ul>"},{"location":"09_ETL/01_spring-batch/00_kickoff/#job-flow","title":"Job flow","text":"<ul> <li>status control</li> <li>job flow</li> <li>conditional Flow</li> <li>parallel flow</li> <li>Listeners</li> <li>StepExecutionListener</li> <li>Restarting jobs</li> <li>Reusability - reuse same step among several job.</li> <li>nested jobs <pre><code>job1\n    .listener(listener)                                     # event - job start,end\n    .next(step2())\n    .next(job2Reference())                                          # nested\n    .split(new SimpleAsyncTaskExecutor()).add(step3(), step4())     # parallel\n\nStep1.\n    .&lt;InputType, OutputType&gt;chunk(10)\n    .listener(listener)                                     # event - step start,end\n</code></pre></li> </ul>"},{"location":"09_ETL/01_spring-batch/00_kickoff/#reading","title":"Reading","text":"<ul> <li>chuck-oriented processing</li> <li>ItemReader</li> <li>configure chuck-oriented steps</li> <li>reading from DB (single thread)</li> <li>reading from DB (multiple thread) <pre><code> return new JdbcCursorItemReader&lt;&gt;()\n</code></pre></li> </ul>"},{"location":"09_ETL/01_spring-batch/00_kickoff/#writing","title":"Writing","text":"<ul> <li>ItemWriter </li> <li>Writing flat files </li> <li>Writing to a database with PreparedStatements </li> <li>Writing to a database with named parameters </li> <li>Writing a JSON file  <pre><code> return new JdbcBatchItemWriter&lt;&gt;();\n FlatFileItemWriter&lt;OutputType&gt; writer = new FlatFileItemWriter&lt;&gt;();\n</code></pre></li> </ul>"},{"location":"09_ETL/01_spring-batch/00_kickoff/#processing-items","title":"processing Items","text":"<ul> <li>ItemProcessor <li>ItemProcessor Bean Validation</li> <li>Implementing custom processor logic</li> <li>Chaining ItemProcessors</li> <li>Filtering batch data</li>"},{"location":"09_ETL/01_spring-batch/00_kickoff/#resilient-jobs","title":"Resilient jobs","text":"<ul> <li>skip logic for jobs</li> <li>retry logic for steps</li> <li>multithreaded steps <pre><code>Step1.\n    .skip(Exception.class)\n    .skipLimit(10)\n\nStep1.\n    .retry(Exception.class)\n    .retryLimit(3) \n\nStep1.    \n    .taskExecutor(new SimpleAsyncTaskExecutor())  \n</code></pre></li> </ul>"},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/","title":"01 SpringBatch start","text":"<ul> <li>https://spring.io/projects/spring-batch</li> <li>https://www.linkedin.com/learning/spring-spring-batch</li> <li>project : springbatch</li> </ul>"},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#a-architecture","title":"A. Architecture","text":""},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#key-components","title":"key components","text":"<ul> <li>Job     : Represents the batch process.</li> <li>Step    : A stage in the job (e.g., reading, processing, writing).</li> <li>ItemReader : Reads data from a source.</li> <li>ItemProcessor : Processes data (optional).</li> <li>ItemWriter : Writes processed data to a destination.</li> <li>JobRepository - </li> <li>explicitly handles persistence of batch metadata, ensuring better control and compatibility with the latest versions.</li> <li>set schema:<ul> <li>spring.datasource.url=jdbc:postgresql://localhost:5432/your_db?currentSchema=schema_name</li> <li>String sql = \"SELECT * FROM schema_name.table_name\";</li> <li>jdbcTemplate.execute(\"SET search_path TO schema_name\");</li> <li>dataSource.addDataSourceProperty(\"currentSchema\", \"schema_name\");</li> </ul> </li> </ul>"},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#b-springboot-spring-batch-5xx","title":"B SpringBoot / Spring-batch (5.x.x)","text":"<ul> <li><code>Spring Framework 6.x</code> | <code>Spring Boot 3.x</code> | <code>Java 17</code></li> <li>powerful framework for batch processing in Java.</li> </ul>"},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#1-key-features","title":"1 key features","text":"<ul> <li>it provides the necessary components to build robust, scalable, and customizable ETL pipelines.</li> <li>ETL processes require <code>highly customized transformations</code> and logic that traditional tools may not handle efficiently.</li> <li>Spring Batch is open-source, making it a <code>cost-effective</code> alternative to commercial ETL tools</li> <li>works seamlessly with CI/CD pipelines and modern deployment methods like Docker and Kubernetes. </li> <li>downside:</li> <li>no visual interface.</li> <li>ETL tools are faster to set up for simple tasks, while Spring Batch requires coding and configuration.</li> <li>designed to handle large volumes of data by:</li> <li>dividing it into smaller <code>chunks</code>,</li> <li>providing capabilities like transaction management,</li> <li>Chunk-Based Processing + parallel chunk processing <pre><code>@EnableBatchProcessing(\n        dataSourceRef = \"dataSource_for_postgres2\",\n        transactionManagerRef = \"transactionManager_for_postgres2\"\n)\n\n&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-boot-starter-batch&lt;/artifactId&gt;\n&lt;/dependency&gt;\n\n@EnableAsync \ntells Spring to look for methods annotated with @Async and execute them asynchronously.\n</code></pre></li> </ul>"},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#2-add-dashboard","title":"2 add dashboard","text":""},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#dependency-groupidorgspringframeworkbatchgroupid-artifactidspring-batch-admin-managerartifactid-version200m3version-dependency","title":"<pre><code>&lt;dependency&gt;\n    &lt;groupId&gt;org.springframework.batch&lt;/groupId&gt;\n    &lt;artifactId&gt;spring-batch-admin-manager&lt;/artifactId&gt;\n    &lt;version&gt;2.0.0.M3&lt;/version&gt;\n&lt;/dependency&gt;\n</code></pre>","text":""},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#3-add-observability-for-job","title":"3 add Observability for job","text":"<ul> <li>Out-of-the-box support for <code>distributed tracing</code> and <code>metrics</code> using Micrometer.</li> <li>Compatible with tools like OpenTelemetry for tracing batch jobs.</li> <li>Configure tracing and metrics to monitor your batch jobs in a <code>distributed environment</code> <pre><code>  &lt;dependency&gt;\n  &lt;groupId&gt;io.micrometer&lt;/groupId&gt;\n  &lt;artifactId&gt;micrometer-tracing-bridge-otel&lt;/artifactId&gt;\n   &lt;/dependency&gt;\n\n   &lt;dependency&gt;\n  &lt;groupId&gt;io.opentelemetry&lt;/groupId&gt;\n  &lt;artifactId&gt;opentelemetry-exporter-otlp&lt;/artifactId&gt;\n   &lt;/dependency&gt;\n</code></pre></li> </ul>"},{"location":"09_ETL/01_spring-batch/01_SpringBatch-start/#4-monitor","title":"4 Monitor","text":"<ul> <li>https://github.com/spring-projects/spring-batch/blob/main/spring-batch-core/src/main/resources/org/springframework/batch/core/schema-postgresql.sql</li> <li>BatchDDLRunner.java</li> <li>table (6)</li> <li>batch_job_execution: Stores metadata about job executions, such as job parameters, status, and the time it was started and finished.</li> <li>batch_job_execution_context: Stores execution context data (such as intermediate results or application-specific data) for each job execution. It is associated with batch_job_execution via a foreign key.</li> <li>batch_job_execution_params: Stores the parameters passed to the job during its execution, usually stored as key-value pairs.</li> <li>batch_job_instance: Stores metadata about the job instance. This tracks the distinct logical execution of a job. For example, if you run the same job multiple times with different parameters, each run would have a separate job instance.</li> <li>batch_step_execution: Stores metadata about individual step executions within a job, such as status, start time, and end time for each step.</li> <li>batch_step_execution_context: Similar to batch_job_execution_context, but this table stores the execution context data for each step of the job.</li> </ul>"},{"location":"100_observability/00_kick_off/","title":"00 kick off","text":""},{"location":"100_observability/00_kick_off/#what-are-common-things-in-microservices-developer-instruments","title":"what are common things in microservices, developer instruments","text":"<pre><code>Here are the common elements developers instrument in microservices for monitoring with tools like Prometheus:\n\n1. Application Metrics\n   HTTP Requests: Latency, throughput, error rates (status codes 4xx/5xx)\n\nAPI Endpoints: Performance per endpoint (GET/POST/PUT/DELETE)\n\nCustom Business Metrics: Transactions processed, orders placed, etc.\n\n2. System/Infrastructure Metrics\n   CPU Usage: Process and system-level CPU consumption\n\nMemory Usage: Heap, non-heap, buffer pools (JVM), RSS (native)\n\nDisk I/O: Read/write operations, latency\n\nNetwork: Bandwidth, connections, errors\n\nFile Descriptors: Open files/sockets\n\n3. JVM Metrics (For Java Services)\n   Garbage Collection: GC cycles, pause times, memory reclaimed\n\nThreads: Active, daemon, deadlocked threads\n\nClass Loading: Loaded/unloaded classes\n\nJVM Uptime: Time since last restart\n\n4. Database Metrics\n   Connection Pools: Active/idle connections, wait time\n\nQuery Performance: Slow queries, latency percentiles\n\nTransaction Rates: Commits, rollbacks, deadlocks\n\n5. Cache Metrics\n   Hit/Miss Ratios: Cache effectiveness\n\nEvictions: Items evicted due to size limits\n\nLatency: Read/write times for cache operations\n\n6. Message Queue/Event Metrics\n   Queue Length: Messages waiting to be processed\n\nProcessing Time: Consumer lag, throughput\n\nErrors: Failed deliveries, retries\n\n7. External Service Dependencies\n   HTTP Clients: Latency, errors, retries (outbound calls)\n\nCircuit Breakers: State (open/closed/half-open), failure rates\n\nRetries: Attempt counts, exponential backoff stats\n\n8. Kubernetes/Container Metrics (If Applicable)\n   Pod Resource Usage: CPU/memory requests vs. usage\n\nRestarts: Crash loop detection\n\nLiveness/Readiness: Health check statuses\n\n9. Logging &amp; Errors\n   Error Rates: Exceptions, log error patterns\n\nWarning Signals: Unusual but non-critical events\n\n10. Synthetic Metrics (Proactive Monitoring)\n    Heartbeats: Service alive checks\n\nScheduled Task Metrics: Cron job durations, success/failure\n\n11. Distributed Tracing Metrics\n    Request Flow: Latency across service boundaries\n\nDependency Map: Service-to-service call patterns\n\n12. Security Metrics\n    Authentication Attempts: Success/failure rates\n\nRate Limiting: Throttled requests\n\nKey Non-Metric Considerations\nLabels/Dimensions: Environment, service name, version, region\n\nCardinality Management: Avoid high-cardinality labels\n\nSampling: For high-volume metrics\n\nAlerting Rules: Define meaningful thresholds\n</code></pre>"},{"location":"100_observability/01_Observability-spring/","title":"Observability - spring","text":""},{"location":"100_observability/01_Observability-spring/#1-toolsframeworks-non-aws","title":"1. Tools/frameworks (non-aws )","text":"<ul> <li>https://chat.deepseek.com/a/chat/s/5effe43a-7c05-433f-8df6-3326b6e311c6 </li> <li>actuator<ul> <li>http://localhost:8083/spring/actuator/metrics --&gt; show metric names</li> <li>actuator.json</li> </ul> </li> <li>prometheous<ul> <li>http://localhost:8083/spring/actuator/prometheus</li> <li>PrometheusMicrometerConfig.java</li> </ul> </li> <li>grafana<ul> <li>launch locally : docker run -d -p 3000:3000 --name=grafana grafana/grafana-enterprise</li> <li>http://localhost:3000</li> <li>https://lekhrajdinkar.grafana.net/a/grafana-setupguide-app/getting-started | github ld account </li> <li>admin | admin</li> <li>UI for Prometheus,etc</li> </ul> </li> <li>micro meter<ul> <li>like otel, to instrument, but sends only <code>metric</code> to prometheus server, datadog, etc. dependecies:<ul> <li>micrometer-registry-datadog</li> <li>micrometer-registry-prometheus</li> <li>...</li> </ul> </li> <li>otel (unified : <code>metric</code>, <code>log</code>, <code>trace</code>) , sends to also multiple server</li> <li>eg: MicrometerController.java <pre><code>  test_counter_total{application=\"spring-lekhraj-app\",} 1.0\n  test_counter_total{application=\"spring-lekhraj-app\",} 2.0\n  test_counter_total{application=\"spring-lekhraj-app\",} 3.0\n</code></pre></li> </ul> </li> </ul>"},{"location":"100_observability/02_observabilty-datadog/","title":"Datadog","text":""},{"location":"100_observability/02_observabilty-datadog/#-dashboard-httpsus5datadoghqcomdashboardlistsp1","title":"- DASHBOARD : https://us5.datadoghq.com/dashboard/lists?p=1","text":""},{"location":"100_observability/02_observabilty-datadog/#1-kubernetes-install-the-datadog-agent","title":"1. Kubernetes - Install the Datadog-Agent","text":"<ul> <li>reference:</li> <li>https://us5.datadoghq.com/signup/agent?platform=kubernetes</li> <li>https://docs.datadoghq.com/containers/kubernetes/distributions/?tab=datadogoperator</li> <li> <p>OpenTelemetry Collector : https://docs.datadoghq.com/opentelemetry/setup/ddot_collector/</p> </li> <li> <p>Step-1 Install the Datadog Operator</p> </li> <li>manage your Datadog Cluster Agents     <pre><code>kubectl create namespace datadog \n\n# install the Datadog Operator \nhelm repo add datadog https://helm.datadoghq.com\nhelm install datadog-operator datadog/datadog-operator --namespace=datadog  --set datadog.logs.containerCollectAll=true\nkubectl create secret generic datadog-secret --from-literal api-key=2ba01eb9cb57e01bae167c008872c752 -n datadog\n--- d o n e ---\n\nhelm get manifest datadog-operator -n datadog &gt; datadog-operator-manifest.yaml\n---\nhelm list -n datadog\nNAME                    NAMESPACE       REVISION        UPDATED                                 STATUS          CHART                   APP VERSION\ndatadog-operator        datadog         1               2025-06-04 17:40:48.5564105 -0700 PDT   deployed        datadog-operator-2.9.2  1.14.0\n</code></pre></li> <li>Step-2 Deploy the Datadog Agent</li> <li>kubectl apply -f datadog-agent.yaml</li> <li> <p>datadog-agent.yaml </p> </li> <li> <p>Autodiscovery </p> </li> <li>K8s: https://us5.datadoghq.com/logs/onboarding/container<ul> <li>just ANNOTATE pod   <pre><code>annotations:\n  ad.datadoghq.com/&lt;container identifier&gt;.logs: '[&lt;LOGS_CONFIG&gt;]'\n\neg: ad.datadoghq.com/nginx.logs: '[{\"source\":\"nginx\",\"service\":\"webapp\"}]'\n</code></pre></li> </ul> </li> <li>https://us5.datadoghq.com/logs/onboarding/server?source=java</li> <li>https://us5.datadoghq.com/logs/onboarding/server?source=python</li> <li>https://us5.datadoghq.com/logs/onboarding/server?source=node</li> <li>https://us5.datadoghq.com/logs/onboarding/server?source=kafka</li> <li>https://us5.datadoghq.com/logs/onboarding/server?source=rabbitmq</li> <li>https://us5.datadoghq.com/logs/onboarding/server?source=nginx</li> <li>https://us5.datadoghq.com/logs/onboarding/server?source=postgres</li> <li>Js: https://us5.datadoghq.com/logs/onboarding/client</li> </ul>"},{"location":"100_observability/02_observabilty-datadog/#2-aws-integration","title":"2 AWS integration","text":"<ul> <li>AWS lambda Datadog Forwarder : https://docs.datadoghq.com/logs/guide/forwarder/?site=us5&amp;tab=cloudformation</li> <li>CloudFormation template : https://datadog-cloudformation-template-quickstart.s3.amazonaws.com/aws/v2.1.13/main_v2.yaml</li> <li></li> </ul>"},{"location":"100_observability/02_observabilty-datadog/#101-monitors","title":"101 Monitors","text":""},{"location":"100_observability/02_observabilty-datadog/#102-dashboard","title":"102 Dashboard","text":""},{"location":"10_Architecture/01_web_Security/02_SAML/","title":"02 SAML","text":"<ul> <li>https://chatgpt.com/c/674f757c-65ac-800d-915f-37f764adb69d</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/","title":"A. <code>Design pattern</code>","text":""},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#separation-of-concerns","title":"Separation of Concerns","text":"<ul> <li>Keep frontend, backend, and database independent.</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#service-oriented-architecture-soa","title":"Service-Oriented Architecture (SOA)","text":"<ul> <li>Microservices communicating over: microservice in details </li> <li>REST</li> <li>gRPC</li> <li>messaging systems :<ul> <li>rmq </li> <li>kakfa</li> </ul> </li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#api-first-development","title":"API-first Development:","text":"<ul> <li>Design APIs before implementation to enable parallel development.</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#event-driven-architecture","title":"Event-Driven Architecture","text":"<ul> <li>Use <code>event streams</code> for real-time updates </li> <li>Kafka, </li> <li>AWS::SQS + AWS::EventBridge</li> <li>RMQ::StreamingQueue</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#serverless-architecture-auto-scaleetc","title":"Serverless Architecture (auto-scale,etc)","text":"<ul> <li>AWS :: Lambda</li> <li>for scalable and cost-effective solutions.</li> <li>Other AWS serverless offering </li> <li>fargate (ECS/EKS)</li> <li>sqs,s3</li> <li>AWS DB :: DynamoDB,Aurora</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#twelve-factor-app","title":"Twelve-Factor App","text":"<ul> <li>Guidelines for building <code>scalable</code> and <code>maintainable</code> applications.</li> <li>-02_twelve_factor_app.md</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#b-infrastructure-components","title":"B. Infrastructure <code>components</code>:","text":""},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#front-end","title":"Front-end","text":"<ul> <li>framework:</li> <li><code>Reactjs</code> : project-1 | project-2(redux)</li> <li><code>Angular 2+</code> :  <ul> <li>js/html/css : front-end-pack</li> <li>ng: Angular project-1 MEAN-stack | Angular project-2 OTT</li> <li>css more: css notes-1 | css notes-2</li> </ul> </li> <li><code>Vue.js</code></li> <li>SPA</li> <li>PWA</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#backend","title":"Backend","text":"<ul> <li>GraphQL APIs : pending</li> <li>frameworks for RESTful APIs</li> <li>java --&gt; SpringBoot <ul> <li>00_Springboot</li> </ul> </li> <li>js/ts/nodejs --&gt; Express.js <ul> <li>project-1</li> </ul> </li> <li> <p>py --&gt; Django/fastApi</p> <ul> <li>project-2</li> </ul> </li> <li> <p>API Gateway:</p> </li> <li>Routing, authentication, rate-limiting</li> <li>ingress server in K8s</li> <li>Microservices</li> <li>deploy via<ul> <li>containers (Docker) </li> <li>orchestration (Kubernetes) : pods+services</li> <li>03_Kubernetes</li> </ul> </li> <li>https://github.com/lekhrajdinkar/03-spring-cloud-v2/tree/main/Notes</li> <li>01_monolith_MicroServices.md00_kickOff</li> <li>Load Balancers</li> <li>AWS :: ELB/Elastic Load Balancer - alb, nlb,</li> <li><code>NGINX</code></li> <li>Cloud services : AWS: lambda, s3, sqs, etc</li> <li>01_aws</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#database","title":"Database","text":"<ul> <li>Relational Databases: </li> <li>PostgresSQL / <code>Aurora</code>(serverless)</li> <li>MySQL</li> <li>NoSQL Databases</li> <li>MongoDB, </li> <li>Cassandra, </li> <li>AWS:<code>DynamoDB</code></li> <li>Horizontal scaling : aws serverless takes care</li> <li>Distributed architecture </li> <li>primary writer instance</li> <li>multiple READ instance</li> <li>replication with encryption at rest.</li> <li>AWS serverless takes care.</li> <li>Caching: </li> <li>Redis</li> <li>Memcached</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#cicd-pipeline","title":"CI/CD pipeline","text":"<ul> <li>GitHub Actions</li> <li>Harness</li> <li>containerization: docker/k8s</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#observability-and-monitoring-logmetrictraces","title":"Observability and Monitoring (log,metric,traces)","text":"<ul> <li><code>OpenTelemetry</code></li> <li><code>micrometer</code></li> <li>Prometheus, grafana, AWS:CloudWatch</li> <li>Application health </li> <li>distributed tracing</li> <li>AWS:CloudWatch&gt;x-rays</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#authentication-and-authorization","title":"Authentication and Authorization","text":"<ul> <li>01_web_Security</li> <li>SAML + SSO</li> <li>LDAP</li> <li>Okta</li> <li>OAuth 2.0,</li> <li>OpenID Connect</li> </ul>"},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#c-design-aspect","title":"C Design Aspect","text":""},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#scalability","title":"scalability","text":""},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#reliability","title":"reliability","text":""},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#flexibility","title":"flexibility","text":""},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#maintainability","title":"maintainability","text":""},{"location":"10_Architecture/02_web_modern_architecture/01_kickoff-2024/#observability","title":"Observability","text":""},{"location":"10_Architecture/03_Miscroservice/00_kick_off/","title":"00 kick off","text":"<ul> <li>project : https://github.com/lekhrajdinkar/03-spring-cloud-v2/tree/main/Notes</li> <li>from k8s section : 01_monolith_MicroServices.md</li> <li>Notes: current</li> </ul>"},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/","title":"01 design pattern 1","text":""},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/#reference","title":"reference","text":""},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/#-httpschatdeepseekcomachats81394dc5-20ff-45bb-8fc3-001520d7ef4f","title":"- https://chat.deepseek.com/a/chat/s/81394dc5-20ff-45bb-8fc3-001520d7ef4f","text":""},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/#desifn-patterns","title":"Desifn patterns","text":""},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/#1-saga","title":"1. SAGA","text":"<ul> <li>https://www.youtube.com/watch?v=d2z78guUR4g&amp;ab_channel=ByteMonk</li> <li>Concept of a long-running, interconnected sequence of operations, like a \"saga\" in storytelling</li> <li>data consistency without relying on traditional ACID transactions (which are impractical in distributed systems).</li> <li>steps:</li> <li>Breaks a transaction into smaller, local steps.</li> <li>uses compensating actions (rollback logic) if a step fails.</li> <li>eg: E-Commerce Order     <pre><code>Step 1: Reserve inventory \u2192 Step 2: Charge payment \u2192 Step 3: Ship order.\nIf payment fails: Trigger compensation \u2192 \"Release inventory\" + \"Notify user.\"\n</code></pre> <pre><code>Purpose: \nManage distributed transactions across multiple services.\n\nImplementation:\nChoreography-Based: Each service emits events to trigger the next step.\nOrchestration-Based: A central coordinator manages the transaction flow.\nImplement compensation actions for rollback (e.g., CancelOrder, RefundPayment).\n\nUse Case: \nOrder processing in e-commerce (inventory, payment, shipping services).\n</code></pre></li> <li>SAGA vs 2PC (2 phase commit) </li> </ul>"},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/#2-circuit-breaker","title":"2. Circuit Breaker","text":""},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/#purpose-prevent-cascading-failures-in-distributed-systems-implementation-use-libraries-like-resilience4j-or-hystrix-define-thresholds-eg-failure-rate-timeout-to-trip-the-circuit-implement-fallback-mechanisms-eg-cached-responses-default-values-use-case-microservices-calling-external-apis-eg-payment-gateways-third-party-services","title":"<pre><code>Purpose: \nPrevent cascading failures in distributed systems.\n\nImplementation:\nUse libraries like Resilience4j or Hystrix.\nDefine thresholds (e.g., failure rate, timeout) to trip the circuit.\nImplement fallback mechanisms (e.g., cached responses, default values).\n\nUse Case: \nMicroservices calling external APIs (e.g., payment gateways, third-party services).\n</code></pre>","text":""},{"location":"10_Architecture/03_Miscroservice/01_design_pattern-1/#3-cqrs-command-query-responsibility-segregation","title":"3. CQRS (Command Query Responsibility Segregation)","text":"<pre><code>Purpose: \nSeparate read and write operations for better performance and scalability.\n\nImplementation:\nCommand Side: Handles state-changing operations (e.g., CreateOrder, UpdateUser).\nQuery Side: Optimized for read operations (e.g., GetOrderDetails, GetUserProfile).\nUse Event Sourcing (optional) to store state changes as a sequence of events.\n\nUse Case: \nUseful in systems where read and write workloads are highly imbalanced (e.g., e-commerce, reporting systems).\n</code></pre>"},{"location":"10_Architecture/03_Miscroservice/02_Microservce-communication/","title":"02 Microservce communication","text":"<ul> <li>reference/s</li> <li>CODE : https://github.com/lekhrajdinkar/03-spring-cloud-v2/tree/main/Notes </li> </ul>"},{"location":"10_Architecture/03_Miscroservice/02_Microservce-communication/#1-micro-service-communication","title":"1. Micro service communication","text":"<ul> <li>https://chat.deepseek.com/a/chat/s/6e7456d4-cc1b-42be-ae19-c3ede730936f <pre><code>#1\nmicroservices ms-1 and ms-2 communicaton\n- sysnc\n- asysnc\n\n#2\nms1 (pod-1), ms2 (pod-2)\nservices communing over aws eventbridge - bus-1, async.\ni would like to add distrubted tracing as well.\n\n#3\nms1 (pod-1), ms2 (pod-2) : java springboot on AWS EKS\nservices communing over rabbitMQ - queue-1, async.\ni would like to add distrubuted tracing.\nmonitoring backed : AWS x-rays\n\n#4\nms1 (pod-1), ms2 (pod-2) : java springboot on AWS EKS\nservices communing sysnc over HTTPS.\ni would like to add distributed tracing.\nmonitoring backed : AWS x-rays\n\n#5\nms1 (pod-1), ms2 (pod-2) : java springboot on AWS EKS\nms1 makes call ms2(GET) communing async over SQS. How ms1 will get data from ms2.Also\nAlso i would like to add distributed tracing.\nmonitoring backed : AWS x-rays\n</code></pre></li> </ul>"},{"location":"10_Architecture/03_Miscroservice/04_Deployment/","title":"04 Deployment","text":""},{"location":"10_Architecture/03_Miscroservice/04_Deployment/#-event-drive-deployment-and-domain-drive-deployment","title":"- Event-Drive Deployment and Domain-Drive Deployment","text":""},{"location":"10_Architecture/03_Miscroservice/04_Deployment/#scenarios","title":"Scenarios","text":""},{"location":"10_Architecture/03_Miscroservice/04_Deployment/#1","title":"1","text":"<p><pre><code>having 3 microservice - ms1, ms2, ms3.\nneed to install in production first time. then upgrade it.\ntrigger from CD pipeline-1 &gt; stage: bashScript (run helm command)\n</code></pre> </p>"},{"location":"10_Architecture/03_Miscroservice/04_Deployment/#install-first-time-helm-install-ms1-ms1-namespace-production-values-values-v1yaml-helm-install-ms2-ms2-namespace-production-helm-install-ms3-ms3-namespace-production-upgrade-with-atomic-rollback-on-failure-helm-upgrade-release_name-chart_path-namespace-namespace-atomic-timeout-timeout-install-creates-release-if-not-exists-values-values-v2yaml-override-prod-values-create-post-deployment-checks-kubectl-rollout-status-deployms1-n-production","title":"<pre><code># install first time\nhelm install ms1 ./ms1 --namespace production --values values-v1.yaml\nhelm install ms2 ./ms2 --namespace production\nhelm install ms3 ./ms3 --namespace production\n---\n# Upgrade with atomic rollback on failure\nhelm upgrade $RELEASE_NAME $CHART_PATH \\\n  --namespace $NAMESPACE \\\n  --atomic \\\n  --timeout $TIMEOUT \\\n  --install \\ # Creates release if not exists\n  --values values-v2.yaml  # Override prod values\n  --create ?\n---  \n# Post-Deployment Checks  \nkubectl rollout status deploy/ms1 -n production  \n</code></pre>","text":""},{"location":"10_Architecture/03_Miscroservice/04_Deployment/#2-one-or-multi-helm","title":"2 one or multi helm","text":"<pre><code>ms-1 - git-repo-1\nms-2 - git-repo-2\nms-3 - git-repo-3\nin which repo helm chart ?\nDo i need to change helm chart manually everytime new code in commited into git repo, new image is push \nto aws ECR. how to automate it helm deploymnet ?\n--\nKey Files to Modify in CI/CD pipeline:\n    helm/values.yaml - image tag\n    Chart.yaml  - version\n    templates/*.yaml    - ?\n</code></pre>"},{"location":"10_Architecture/50_PROJ-1/01-PROJ-1_Design-patterns/","title":"A. Design pattern/s","text":""},{"location":"10_Architecture/50_PROJ-1/01-PROJ-1_Design-patterns/#1-proxy-pattern","title":"1. proxy pattern","text":"<ul> <li>s3 file dropped &gt; lambda1 (s3 event)</li> <li>lambda act as proxy</li> <li>process event data and decide which api to call</li> <li>sync: java-api-1 (prepared data-1)</li> <li>...</li> <li>Async: java-api-2 (prepared data-1) &gt; write response to <ul> <li>dynamoDB</li> <li>SQS</li> <li>Aurora + eventBus event **</li> </ul> </li> </ul>"},{"location":"10_Architecture/50_PROJ-1/01-PROJ-1_Design-patterns/#2-event-driven-microservices-using-lambda-and-eventbridge","title":"2. Event-driven microservices using Lambda and EventBridge","text":"<ul> <li>s3 file drop &gt; l1 &gt; java-api-1 &gt; sqs-fifo &gt; l2 &gt; java-api-2 &gt; event-bus-1 &gt; process-api &gt; sqs-2</li> <li>more patterns on MS : 01_design_pattern-1.md</li> <li>engine &gt; SQS</li> <li>l1 &gt; py(add toekn and call jav-api)</li> <li>sns &gt; http (health check api, not secured)</li> <li>eb (pipe)<ul> <li>emph SQS &gt; filter pattern &gt; enrich with lambda + transformation &gt; output</li> <li></li> <li>output: l, kdf, eb, ecs+taskDefination(spawn task) , sns, sqs, step function, etc</li> </ul> </li> </ul>"},{"location":"10_Architecture/50_PROJ-1/01-PROJ-1_Design-patterns/#3-idempotent-consumers","title":"3. Idempotent consumers","text":"<ul> <li>kafka/rabbit consumer.</li> <li>idempotent producer.</li> <li>ack=0,1,all</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/01-PROJ-1_Design-patterns/#4-observability","title":"4. observability","text":""},{"location":"10_Architecture/50_PROJ-1/01-PROJ-1_Design-patterns/#5","title":"5.","text":""},{"location":"10_Architecture/50_PROJ-1/02_PROJ-1_DR/","title":"02 PROJ 1 DR","text":""},{"location":"10_Architecture/50_PROJ-1/02_PROJ-1_DR/#-httpschatdeepseekcomachatsef2aa85a-50b7-4d00-bb42-44275dedf2ba","title":"- https://chat.deepseek.com/a/chat/s/ef2aa85a-50b7-4d00-bb42-44275dedf2ba","text":"<ul> <li>runbook</li> <li>Aurora manual backup ?</li> <li>Schedule quarterly DR drills</li> <li>region replication : S3, SQS, SNS</li> <li>r53 : fail over entry for </li> <li>in helix account, app/pod - ingress controller &gt; ingress &gt; path app.c.com --&gt; service1(k8s):selects - my pods</li> <li>in Aurora</li> <li>active/active</li> <li>app on eks</li> <li>SNS, SQS, S3, secret, etc</li> <li>DB - global Db - standBy + active , with R53</li> <li>cd pipeline</li> <li>stage:deploy (pipeline param - region)</li> <li>assume role harness pipeline</li> <li>read ssm param &gt; kubeconfig</li> <li>helm install</li> <li>DataDog metric</li> <li>pod health/metric</li> <li>kafka cc</li> <li>2 regions</li> <li>just update app prop.</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/03_PROJ-1_release_process/","title":"03 PROJ 1 release process","text":""},{"location":"10_Architecture/50_PROJ-1/03_PROJ-1_release_process/#-httpschatdeepseekcomachats6ae96d81-254a-4034-876a-5c367b97e66f","title":"- https://chat.deepseek.com/a/chat/s/6ae96d81-254a-4034-876a-5c367b97e66f","text":""},{"location":"10_Architecture/50_PROJ-1/03_PROJ-1_release_process/#deployment-process","title":"Deployment process","text":"<ul> <li>We follow a structured monthly release cycle that includes both</li> <li>business requirements </li> <li>technical improvements. \\</li> <li>Release Planning</li> <li>At the start of each cycle, we identify business features and technical items</li> <li>like infrastructure updates or tech debt reduction, for the upcoming release. </li> <li>These are prioritized and assigned to sprints leading up to the release date.</li> <li>idh/kafka update</li> <li>deploymnet infra ahead of time.</li> <li>talking and idh/comet team</li> <li>Development Workflow</li> <li>updating terraform module for tech upgrac</li> <li>business jira</li> <li>peer review</li> <li>offshore code review</li> <li>CI pipeline <ul> <li>Junit</li> <li>synk scan</li> </ul> </li> <li>Release Branch Creation</li> <li>Harness Pipeline for Deployment</li> <li>our deployment orchestration tool.</li> <li>stages for building artifacts, running tests, and deploying through environments (dev \u2192 QA \u2192 staging \u2192 production).</li> <li>nexus / ecr<ul> <li>registry for image + helm package</li> </ul> </li> <li>requires manual approval before production deployment</li> <li>helm chart are version with pipeline var.</li> <li>no blue and green</li> <li>helm release-blue label:blue</li> <li>helm release-green label:green</li> <li>update service </li> <li>rollback</li> <li>roll back to the previous version using Harness + helm</li> <li>Post-Release monitoring</li> <li>retrospective to identify any process improvements for the next cycle.</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/","title":"A. ECS","text":""},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#1-expose","title":"1 Expose","text":"<ul> <li>expose ALB (public subnet)</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#2-rate-limit","title":"2 rate limit","text":"<ul> <li>alb + waf</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#3-tls","title":"3 TLS","text":"<ul> <li>alb --&gt; ACM</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#4-network-filter-ingressegress","title":"4 network filter (ingress/Egress)","text":"<ul> <li>alb &gt; sg</li> <li>tg &gt; sg</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#b-eks-04_eks","title":"B. EKS 04_EKS","text":""},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#1-expose-with-tls","title":"1 Expose with TLS","text":"<ul> <li>clusterIP service for app-service&gt;pod</li> <li>platform team added</li> <li>ingress Controller ( <code>host-main</code> ) <ul> <li>TLS ?</li> <li>rate limiting ?</li> <li>...</li> </ul> </li> <li>ALB controller<ul> <li>security group</li> <li>WAF 08_WAF+FirewallManager.md</li> <li>rate limit</li> <li>...</li> </ul> </li> <li>Routing: </li> <li>helix AWS : R53<ul> <li><code>appl1.org.com</code> --&gt; <code>host-main</code></li> <li>appl2.org.com --&gt; host-main</li> <li>...</li> </ul> </li> <li>App-1 AWS<ul> <li>k8s ingress object :: </li> <li>host: <code>appl1.org.com</code></li> <li>path-1 : service-1</li> <li>path-2 : service-2</li> <li>...</li> <li>tls</li> <li>secret (aws scret &gt; extSecret)</li> <li>encryption Object while cluster setup</li> </ul> </li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#2-rate-limit_1","title":"2 Rate limit","text":"<ul> <li>level-1 : ingress-controller<ul> <li>...</li> <li>...</li> </ul> </li> <li>level-2 : fargate pod</li> <li>...</li> <li>...</li> <li>level-3 : program level</li> <li>...</li> <li>...</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#3-network-filter-ingressegress","title":"3 network filter (ingress/Egress)","text":"<ul> <li>level-1 : ingress-controller</li> <li>...</li> <li>...</li> <li>level-2 : fargate pod</li> <li>attach ENI + sg</li> <li>K8s object: network policy</li> </ul>"},{"location":"10_Architecture/50_PROJ-1/04_PROJ-1_API/#c-more","title":"C More","text":"<ul> <li>Documentation : app level Swagger</li> <li>versioning : app level</li> </ul>"},{"location":"99_temp/00/01_skills/","title":"01 skills","text":""},{"location":"99_temp/00/01_skills/#a-resume","title":"A. Resume","text":"<ul> <li>https://www.resume.com/resume/builder/e5b3121e-3480-4c77-ad83-3c0101f54225/ - <code>not good</code></li> <li>https://www.resume-now.com/build-resume/final-resume?docid=3740611a-211f-4626-a875-7c5814b18581 - <code>paid</code></li> <li>Canva pdf</li> <li>https://www.canva.com/design/DAGoz-fJeaU/ihb3143JTAelUj6xOErfXQ/edit?referrer=pdf-maker-landing-page </li> <li>https://www.canva.com/design/DAGoz-fJeaU/74X71hoM6I7scVlp_bDnRg/view?utm_content=DAGoz-fJeaU&amp;utm_campaign=designshare&amp;utm_medium=link2&amp;utm_source=uniquelinks&amp;utlId=h3465913660</li> <li>https://milkov.tech/assets/psd.pdf</li> <li>certs <pre><code>// |https://www.udemy.com/certificate/UC-8d98a19b-1742-4a02-a612-2b7cc99148dd/Stephane AWS Certified Solutions Architect on Udemy \n// |https://www.udemy.com/certificate/UC-20929e5d-c26f-4861-bad8-c14d5efc7824/Apache Kafka on udemy \n// |https://www.udemy.com/certificate/UC-e19503bb-0bb9-4512-8ece-687fcbb3780f/Kubernetes Certified Application Developer (CKAD) on udemy \n// |https://www.udemy.com/certificate/UC-feee838c-bd35-435c-a3b5-bb2d7d6f5b5a/Angular - The Complete Guide on Udemy \n// |https://www.udemy.com/certificate/UC-8561f28d-11b7-4f2a-a689-b1378a157082/JavaScript - The Complete Guide on Udemy \n// |https://www.udemy.com/certificate/UC-ff2f4ad9-17f3-4630-945f-8c348ecf2db7/\n</code></pre></li> </ul>"},{"location":"99_temp/00/01_skills/#b-my-skills","title":"B. My Skills","text":""},{"location":"99_temp/00/01_skills/#java","title":"java","text":"<ul> <li>java upgrades</li> <li>spring/springBoot 00_Springboot</li> <li>springBatch</li> <li>REST API, web socket, rpc</li> <li>microservices https://github.com/lekhrajdinkar/03-spring-cloud-v2/tree/main/Notes</li> <li>hibernate 03_data-layer</li> <li>lib</li> <li>IBM/MQ, rmq, kafka</li> <li>provider - iso/swift</li> <li>aws sdk</li> <li>lombok, modelmapper</li> <li>json/jackson</li> <li>okta/oidc</li> <li>swagger</li> </ul>"},{"location":"99_temp/00/01_skills/#py","title":"py","text":"<ul> <li>etl : spark https://github.com/lekhrajdinkar/02-backend-java-spring/tree/main/09_ETL/01_spring-batch</li> </ul>"},{"location":"99_temp/00/01_skills/#jsts","title":"JS/TS","text":"<ul> <li>angular 2+</li> <li>html, css, js</li> <li>lib</li> <li>redux</li> <li>rxjs</li> </ul>"},{"location":"99_temp/00/01_skills/#aws","title":"AWS","text":""},{"location":"99_temp/00/01_skills/#-01_aws","title":"- 01_aws","text":""},{"location":"99_temp/00/01_skills/#devops","title":"Devops","text":"<ul> <li>git, maven, npm</li> <li>harness</li> <li>terraform</li> <li>aws cdk</li> <li>aws pipeline,build, deploy</li> <li>docker/k8s</li> </ul>"},{"location":"99_temp/00/01_skills/#more","title":"more","text":"<ul> <li>datadog</li> <li>kafka</li> <li>rmq</li> <li>bash</li> </ul>"},{"location":"99_temp/00/02_profiles/","title":"2024","text":""},{"location":"99_temp/00/02_profiles/#1-solutions-engineer-ii","title":"1 Solutions Engineer II**","text":"<ul> <li>https://capgroup.wd1.myworkdayjobs.com/en-US/capitalgroupcareers/details/Software-Development-Engineer_JR3404?source=CGCareerSite&amp;jobFamilyGroup=d003e6d28e091011fe8da2e495870000</li> <li>SQL and relational databases (especially PostgreSQL). **</li> <li>Design and optimize SQL databases.</li> <li>schema design.</li> <li>indexing.</li> <li>query optimization.</li> <li>Building and consuming RESTful APIs.  **</li> <li>high availability --&gt; aws multiple region</li> <li>fault tolerance --&gt; </li> <li>scalability  --&gt; k8s pod, fargate profile</li> <li>data security and compliance.</li> <li>GraphQL schema design and resolvers </li> <li>TypeScript</li> <li>Microservices architecture.</li> <li>AWS  + serverless architecture **</li> <li>Familiarity with DevOps practices. **</li> <li>Docker and containerization. **</li> </ul>"},{"location":"99_temp/00/02_profiles/#2025","title":"2025","text":""},{"location":"99_temp/00/02_profiles/#1-solutions-engineer-ii_1","title":"1 Solutions Engineer II","text":"<ul> <li>https://capgroup.wd1.myworkdayjobs.com/en-US/capitalgroupcareers/job/Solutions-Engineer-II_JR5025?username=lekhrajdinkarus%2540gmail.com&amp;locations=998fe582cba51010616894e530140000</li> <li>You have a bachelor\u2019s degree in Computer Science, Engineering, or a related technical field. </li> <li>SQL, C#  </li> <li>Angular, Typescript, </li> <li>REST API services, </li> <li>Messaging Service (Kafka), </li> <li>AWS experience preferred.</li> <li>You have experience working with CI/CD tools</li> </ul>"},{"location":"99_temp/00/02_profiles/#2-solutions-engineer-iii-june","title":"2 Solutions Engineer III june","text":"<ul> <li>https://capgroup.wd1.myworkdayjobs.com/en-US/capitalgroupcareers/job/Software-Engineer--Solutions-Engineer-III-_JR4763</li> <li>lekhraj Dinkar-SE-3.pdf</li> </ul>"},{"location":"99_temp/00/02_profiles/#3-senior-software-engineer-solutions-engineer-iv-point_left","title":"3 Senior Software Engineer/ Solutions Engineer IV :point_left","text":"<ul> <li>https://capgroup.wd1.myworkdayjobs.com/en-US/capitalgroupcareers/jobTasks/completed/application  withdrawn</li> <li>https://capgroup.wd1.myworkdayjobs.com/en-US/capitalgroupcareers/job/Solutions-Engineer-IV_JR4532 SE4 again submit from ld@us</li> <li>lekhraj Dinkar-sse-se4.pdf <pre><code>CSS HTML , Relational Database Management System (RDBMS) , kafka confluent\nAngular, Docker, RabbitMQ, OAuth, Kubernetes , HELM Charts, RESTful APIs Microservices Architecture\nTypoScript AWS EKS Agile Methodology AWS ECS AWS Cloud Computing\nWeb Development, harness CD pipeline ,pySpark, ETL ,Back-End Development, Terraform\nSpring, Hibernate, Software Development, Java Spring, Structured Query Language (SQL)\nSpring Boot, Java\n\n---\n\n\u201cI can succeed as a Software Development Engineer at Capital Group \" \nAs a Software Development Engineer in the Capital Solutions Group Technology (CSGT), you will build a suite of applications that support portfolio construction, research and monitoring capabilities for our multi-asset portfolio solutions business. Our investment professionals use the platform to construct, monitor and review their portfolios, and to make investment decisions. You will collaborate with the Product Management and Data Engineering team, investment professionals, and technology associates to create and implement detailed technical designs for mission critical and complex applications using existing and emerging technology platforms. You have an agile mindset and will contribute to the design, implementation, and delivery of large-scale, critical, and complex cloud-based web applications.\u202f  \nYou'll work across the entire product lifecycle from conceptualization through production, spanning multiple capabilities and/or products within an assigned domain. \nLeverage emerging technology patterns, frameworks in architecting and designing solutions. \nDesign and implement scalable and robust solutions. \nProvides technical leadership and guidance to the team.  As well as mentor and coach other associates on the team. \nPartner alongside architecture and other technology teams to understand issues \nSet the standard for quality, simplicity, test coverage, and documentation. \nCollaborate effectively to support team strategy, contributing to architecture and technology choices. \n\n---\n\n&gt;&gt;&gt; software development patterns and frameworks. \n\n&gt;&gt;&gt; cloud-first approach to designing and implementing robust, distributed, and scalable services for data processing \n\n&gt;&gt;&gt; user facing applications from ideation to production using AWS services such as \n  S3, Kubernetes, container services, Lambdas etc  \n\n&gt;&gt;&gt; Software application development experience in at least one of modern language such as\n Python , Fast API, Django, SQL Alchemy etc \n\n&gt;&gt;&gt; complex SQL queries, \nunderstanding of the ETL processes, and exposure to RDBMS databases such as SQL Server, PostgreSQL etc. \n\n&gt;&gt;&gt; Strong object oriented and functional design skills \n&gt;&gt;&gt; common design patterns \n\n&gt;&gt;&gt;  distributed application architecture \n\nunit testing, conducting code reviews, and creating design documentation. \nSDLC (analysis, development, testing, deployment, support, etc.) \nAgile delivery teams. \n</code></pre></li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/","title":"Improvement","text":""},{"location":"99_temp/00/97_achievement%2Blearnings/#a-performance-green_circle","title":"A. performance :green_circle:","text":""},{"location":"99_temp/00/97_achievement%2Blearnings/#achieved","title":"achieved","text":"<ul> <li>TACT / COPS</li> <li>legacy  app performance - inner sql, database connection pool</li> <li>bulk review and approve - UI enhancement + spinner (prevent multiple click)</li> <li>enums</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#proposal","title":"proposal","text":"<ul> <li>cache static data + refresh api</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#b-monitoring-green_circle","title":"B. monitoring :green_circle:","text":""},{"location":"99_temp/00/97_achievement%2Blearnings/#achieved_1","title":"achieved","text":"<ul> <li>built dashboard in angular + s3 URI + s3 metadata on dynamoDB</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#proposal_1","title":"proposal","text":"<ul> <li>custom metric (label, dimension)</li> <li>traceability for l,sqs,eb microservice</li> <li>x-ray, dd(otel)</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#c-core-app-green_circle","title":"C. CORE app :green_circle:","text":""},{"location":"99_temp/00/97_achievement%2Blearnings/#achieved_2","title":"achieved","text":"<ul> <li>maps</li> <li>inbound ETL poc<ul> <li>no autosys jobs, event driven design ::  event-bus + scheduled-event for (SLA) + dependency+check (DB base)</li> <li>ETL driver program : flask / fastapi + unicorn</li> </ul> </li> <li>outbound:<ul> <li>SWIFT - driver program</li> <li>CIT external TD blend (BR/SS) - special series - 166</li> <li>CIAM design + JIRA, coding, refactoring, dashboard API</li> <li>design JSON contract and RDBMS for outbound</li> <li>design event-payload json - allocation (1), re-balance(1), generic(M) trade/s</li> <li>bucket_mapping_id -- driver of all event, metric and dimension</li> </ul> </li> <li>fsr</li> <li>jwt token validation + method based authorization @pre/postAuth + helped to understand Auth/implicit flow</li> <li>suggest implicit flow with pkce</li> <li>batch job 15 sec IAM token</li> <li>disagree with UI arch : forced old them to redux, observability over Js-promises, etc</li> <li>tact :  </li> <li>built screen for TACt fto swift message. no angular Vanilla JS + simulator to fast-forward development</li> <li>refactor</li> <li>eg: swift for AF vs AFIS</li> <li>SB property load, avoid inner class</li> <li>simple, clean</li> <li>utility api : kafka, config, ibm/mq, decode TIP file</li> <li>health check : static vs dynamic factor</li> <li>quick prod fixes:</li> <li>data mod</li> <li>code fix (not delegate to offshore)</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#proposal_2","title":"proposal","text":"<ul> <li>solution-1 : autosys</li> <li>proposal, Custom CRD (jil : yaml) &gt; spin up k8s::Job + side car pod &gt; push event &gt; kafka</li> <li>event processing </li> <li>custom controller (DemonSet) &gt; read yml &gt; spin up other job</li> <li>solution-2 : autosys</li> <li>s3:file-drop &gt; lambda &gt; webhook::harness pipeline</li> <li>fsr autosys </li> <li>custom-metric to create  event Dashboard: eb-event json payload, add tags</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#d-aws-green_circle","title":"D. AWS :green_circle:","text":""},{"location":"99_temp/00/97_achievement%2Blearnings/#achieved_3","title":"achieved","text":"<ul> <li>vpce</li> <li>sqs extended queue 256</li> <li>handle concurrency with fifo queue + isolation level</li> <li>MRAP</li> <li>lambda layer</li> <li>OAuth : token refresh lambda</li> <li>batch job (RDS iam based auth, 15 min expiry)</li> <li>arch disagree</li> <li>s3 &gt; SQS vs S3 &gt; eb:bus &gt;... can replay and archive...</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#proposal_3","title":"proposal","text":"<ul> <li>parallel processing with sns fifo group id </li> <li>event bridge pipe (source&gt; filter &gt; transform &gt; target) + add de-duplication id</li> <li>AWS event-1 data (pass temp result as event data)</li> <li>lambda cold start fix: remove eni, run outside  vpc, layers, use: py</li> <li>IAM based auth, expired in 15 min, best for B2B internal omm, inside VPC, good use-case</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#e-more","title":"E. more","text":"<ul> <li>always checking what going on etacs,fsr,path tech upgrade</li> <li>found k8s - logs temp &gt; not forwarded to dd</li> <li>infosys training cheat jar</li> <li>georgey - decrypt password util</li> <li>footNotes Deletion tools CSV to delete script (cascaded and complex joins, 7 tables)</li> </ul>"},{"location":"99_temp/00/97_achievement%2Blearnings/#learnings","title":"learnings","text":"<ul> <li>Devops</li> <li>did terraform, easy to understand, persnel project done</li> <li>okta, kafka terraform script</li> <li>create harness pipeline + delegates</li> <li>Minikube and persnal EKS</li> <li>kubernetes</li> <li>preparing for CKAD, did training, completing online labs</li> </ul>"},{"location":"99_temp/00/98_behavioural/","title":"cg business","text":"<ul> <li>https://chatgpt.com/c/6850d0a3-3d8c-800d-98ce-1a4b4bd9a2ce</li> </ul>"},{"location":"99_temp/00/98_behavioural/#behavioural-interview","title":"Behavioural Interview","text":"<ul> <li>https://chatgpt.com/c/6850fafa-fc18-800d-9a4a-e8a9641cae8c</li> </ul>"},{"location":"99_temp/00/98_behavioural/#manager-interview","title":"manager interview","text":"<ul> <li>https://chatgpt.com/c/685115cc-eef4-800d-971d-1665c4af2684</li> </ul>"},{"location":"99_temp/00/98_behavioural/#project-achievements","title":"project Achievements","text":"<ul> <li>97_achievement+learnings.md</li> <li>01-PROJ-1_Design-patterns.md</li> </ul>"},{"location":"99_temp/00/99_interview/","title":"A. Frontend","text":"<ul> <li>angular : https://chat.deepseek.com/a/chat/s/cde1169c-f909-4927-a7c7-d3a3b38d5423 :green_circle:</li> <li>typescript: </li> </ul>"},{"location":"99_temp/00/99_interview/#b-backend","title":"B. Backend","text":""},{"location":"99_temp/00/99_interview/#1-middleware","title":"1 middleware","text":"<ul> <li>kafka : https://chat.deepseek.com/a/chat/s/135c1db5-d5c3-4cf3-8172-20d28b51e77d  :green_circle:</li> <li>RMQ :</li> </ul>"},{"location":"99_temp/00/99_interview/#2-java","title":"2 java","text":"<ul> <li>Java</li> <li>SpringBoot</li> <li>Hibernate</li> </ul>"},{"location":"99_temp/00/99_interview/#3-oauth20","title":"3 OAuth2.0","text":"<ul> <li>authorization flow</li> <li>implicit flow:</li> </ul>"},{"location":"99_temp/00/99_interview/#4-py","title":"4 py","text":""},{"location":"99_temp/00/99_interview/#5-sql-rdbms","title":"5 sql / rdbms","text":"<ul> <li>https://chatgpt.com/c/684f8fe5-c36c-800d-b8cd-f9e0b32887ce</li> </ul>"},{"location":"99_temp/00/99_interview/#6-performance","title":"6 performance","text":"<ul> <li>caching app level :</li> <li>cache on AWS :</li> <li>sql tuning : </li> <li>connection pool :not sure</li> </ul>"},{"location":"99_temp/00/99_interview/#c-devops","title":"C. DevOps","text":""},{"location":"99_temp/00/99_interview/#21-docker-green_circle","title":"2.1 docker  :green_circle:","text":"<ul> <li>https://chat.deepseek.com/a/chat/s/91b5b6a2-4aa1-43bf-b594-21bab0c9549c </li> </ul>"},{"location":"99_temp/00/99_interview/#22-k8s-green_circle","title":"2.2 k8s :green_circle:","text":"<ul> <li>Starbucks Q: https://chat.deepseek.com/a/chat/s/da139fc5-e06f-42e3-8419-a2c17a94a9cf</li> <li>01_k8s-interview-question.md</li> <li>HPA : https://chat.deepseek.com/a/chat/s/00db1638-b5bc-4a70-a585-4a487e210a63</li> </ul>"},{"location":"99_temp/00/99_interview/#23-helm","title":"2.3 helm","text":""},{"location":"99_temp/00/99_interview/#24-cicd-pipeline","title":"2.4 CI/Cd pipeline","text":""},{"location":"99_temp/00/99_interview/#25-terraform-cloud-formation","title":"2.5 terraform / Cloud Formation","text":""},{"location":"99_temp/00/99_interview/#26-observability","title":"2.6 Observability","text":"<ul> <li>AWS CW</li> <li>DataDog</li> <li>prometheous</li> <li>otel / micrometer</li> </ul>"},{"location":"99_temp/00/99_interview/#d-aws","title":"D. AWS","text":"<ul> <li>scenarios : https://chatgpt.com/c/68511f33-9680-800d-afe7-d7512848aeed</li> </ul>"},{"location":"99_temp/00/99_interview/#1-dr-release-green_circle","title":"1 DR + release  :green_circle:","text":"<ul> <li>https://chat.deepseek.com/a/chat/s/6ae96d81-254a-4034-876a-5c367b97e66f</li> <li>00_01_DR.md</li> </ul>"},{"location":"99_temp/00/99_interview/#2-aurora-green_circle","title":"2 Aurora :green_circle:","text":"<ul> <li>https://chatgpt.com/c/684cc581-6c3c-800d-9a2f-dbfbe1e8a353</li> <li>https://chatgpt.com/c/684d3c4c-82d8-800d-92c3-4ca50e71d841 (paper notes)</li> </ul>"},{"location":"99_temp/00/99_interview/#3-ecs-eks-green_circle","title":"3 ECS / EKS  :green_circle:","text":"<ul> <li>https://chatgpt.com/c/684b7e2d-0224-800d-a691-d2d1be4a7233</li> <li>https://chatgpt.com/share/684dcfe0-a214-800d-9d65-c5e79af9cc75 (public-link)</li> </ul>"},{"location":"99_temp/00/99_interview/#4-networking","title":"4 Networking","text":""},{"location":"99_temp/00/99_interview/#elb-green_circle","title":"ELB :green_circle:","text":"<ul> <li>https://chatgpt.com/c/684f8847-c760-800d-903c-d86c1ebdd8f6</li> <li>https://chatgpt.com/share/684f88fe-12d0-800d-aa10-3669a29b5301 (public-link)</li> </ul>"},{"location":"99_temp/00/99_interview/#api-gateway-green_circle","title":"API gateway :green_circle:","text":"<ul> <li>https://chatgpt.com/share/684f8917-1a9c-800d-8dc9-d3ecd05a0d39 (public link)</li> <li>VTL (velocity template language) : https://chatgpt.com/c/68506cfe-9d68-800d-b0a6-a2471d33e514</li> <li> </li> </ul>"},{"location":"99_temp/00/99_interview/#1-httpschatgptcomc684f8889-3744-800d-9b8c-97f019931060-till-3040-q","title":"1 https://chatgpt.com/c/684f8889-3744-800d-9b8c-97f019931060 , till 30/40 q","text":""},{"location":"99_temp/00/99_interview/#2-httpschatgptcomc68508a49-ff44-800d-93db-08808f55ccd7","title":"2 https://chatgpt.com/c/68508a49-ff44-800d-93db-08808f55ccd7","text":""},{"location":"99_temp/00/99_interview/#vpc-subnet","title":"VPC + Subnet","text":""},{"location":"99_temp/00/99_interview/#r53","title":"R53","text":"<ul> <li>skip for now</li> </ul>"},{"location":"99_temp/00/99_interview/#topology-transient-gateway-s2s-dx-etc","title":"Topology : Transient-gateway, s2s, Dx, etc","text":"<ul> <li>skip for now</li> </ul>"},{"location":"99_temp/00/99_interview/#5-lambda-green_circle","title":"5 Lambda :green_circle:","text":"<ul> <li>https://chatgpt.com/c/684e2c1f-e040-800d-b0a6-48e345a7b9f1</li> </ul>"},{"location":"99_temp/00/99_interview/#6-s3-green_circle","title":"6 S3 :green_circle:","text":"<ul> <li>MRAP : https://chat.deepseek.com/a/chat/s/d41490fe-a389-40b5-896d-67e3f9476d8c</li> <li>https://chatgpt.com/c/684e115a-1404-800d-8610-cc6600417f02</li> </ul>"},{"location":"99_temp/00/99_interview/#7-sqs-sns-eventbridge-green_circle","title":"7 SQS / SNS / EventBridge :green_circle:","text":"<ul> <li>https://chatgpt.com/c/684e7573-afb0-800d-ae9d-6fd4b32cffc8 sqs</li> <li>https://chatgpt.com/c/684e7596-67a8-800d-b010-495371801137 sns</li> <li>https://chatgpt.com/c/684e75a3-5c84-800d-8b7a-2be49b76fc83 eb</li> </ul>"},{"location":"99_temp/00/99_interview/#8-security","title":"8 Security","text":""},{"location":"99_temp/00/99_interview/#iam","title":"IAM","text":""},{"location":"99_temp/00/99_interview/#kms","title":"KMS","text":""},{"location":"99_temp/00/99_interview/#aws-org-identity-provider","title":"AWS org + Identity provider","text":""},{"location":"99_temp/00/99_interview/#secret-manager-ssm","title":"Secret Manager + SSM","text":""}]}