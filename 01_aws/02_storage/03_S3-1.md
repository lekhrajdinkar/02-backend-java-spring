# SSS - Simple storage service / S3 (Regional) :yellow_circle:
## A. S3: Intro
- **infinitely scaling**  + highly **durable** + highly **available** 
- Also **foundation service**
  - other services use S3 as an integration 
  - main building blocks of AWS
- **bucket-name** must be globally unique, 3-63
- performance:
  - latency (low) : `100-200 ms` :point_left:
  - throughput : `3500-5500 request/sec/prefix`

- **fact**
  - update and read in || --> replace existing > try read > **always return latest value**.
  - upload object to :
    - S3 directly - slow/internet
    - CF-distribution ==> origin:s3 
      - fast/edge-loc (S3 transfer Acceleration)
---
## B. S3: Usecase
- **Hybrid-Cloud-storage** 
  - Archival
  - Backup (eg: snapshot : ebs,efs,db )
  - ...
- **hosting**
  - Media,
  - Static website, 
  - Application/Software delivery
- **DR** 
  - cross-region-replication, 
  - move data from region/az to another then restore.
- **BigData Analytics**
  - run Data lakes in s3 

---
## C. S3 Bucket
- s3://my-bucket/prefix-1/`my_file.txt`
  - looks like directory but **no-concept-of-directory**
  
- **bucket type**
  - general-purpose **
  - Directory (New)
  
### C1. **Object** 
- max size :`5TB`
- can enable **version + replication**

#### access endpoint
- expose s3 object as public access endpoint
  - attach **access point policy**
  - select object by **prefix**
  - creates **dns** entry

#### access endpoint (with lambda )
- once object is fetch want to run some operation on object using lambda.
- kind of ETL::transform

- ![img.png](../99_img/storage/snow/img-98.png)

- ![img.png](../99_img/storage/s3-3/img-99.png)   

---
### C2. Object: Storage Classes
#### Amazon S3 Standard / frequent
- General Purpose : highly durable/available.
#### Infrequent Access (IA) 
- low cost
- usecase - DR-backup/recovery
#### One Zone-Infrequent Access 
- single-AZ,  low ava
- usecase - data which can recreate.

#### Amazon S3 Glacier 
- low cost  
- retrieval mode:
  - **Instant Retrieval** : 
    - in ms
    - min:90 days
  - **Flexible Retrieval** 
    - 1-5 min
    - 3-5 hr 
    - 5-12 hr `free`
    - min:90 days
  - **Deep Archive** 
    - 12-48 hr `free`
    - min:180 days

#### Amazon S3 Intelligent Tiering
- move object b/w tier based on (usage + config)
- mix of above classes into single
- tiers
  - `Frequent Access` tier (automatic): default tier
  - `Infrequent Access` tier (automatic): objects not accessed for 30 days
  - `Archive Instant Access` tier (automatic): objects not accessed for 90 days
  - `Archive Access tier` (optional): configurable from 90 days to 700+ days
  - `Deep-Archive Access` tier (optional): config. from 180 days to 700+ days
- more
  - on bucketObject (standard GP / Standard IA) --> run **s3 analytics** --> take 24/28 hrs --> **CSV report**
  - report gives recommendation 
    - to create life cycle rule to move object b/w storage classes.

#### comparison
- ![img_4.png](../99_img/storage/s3-1/img_4.png)
- ![img.png](../99_img/storage/s3-2/img.png)
- ![img_1.png](../99_img/storage/s3-2/img_1.png)


---
## B. S3 : Batch Operation
- Perform `bulk` operations on `existing` S3 objects with a single request.
- `job` : [ list of Object + action + optional param ]
-  Flow ` s3:Inventary` > `s3:Select` > `S3:batch/JOB`  > processed object/s
- use-case/s:
  - Modify object metadata & properties
  - `replication` : Copy objects between S3 buckets
  - `Encrypt` un-encrypted objects
  - Modify ACLs, tags
  - Restore objects from S3 Glacier
  - Invoke Lambda function to perform custom action on each object

---
### C.1. S3 bucket: versioning
- enable for each bucket + UI:showVersion.
- can roll back to previous version/s
- protect again un-intended delete.
- delete:
  - `delete` : adds delete marker.
  - `delete marker` : undo delete.
  - UI: show-version > select version > `delete the version` : permanent deletes.

---
### C.2. S3 bucket: Replication (async)
- create replication `rule`.
  - First, `enable version` is must on src and dest buckets + `attach IAM`
  - replicate object + replicate delete marker(y/n)

- only `new` object will be replicated.
- for `old` objects : use `S3 Batch replication`  separately.
- `No chaining`:
  - having b1 --> b2 | b2 --> b3
  - if obj-1 added in b1, it will be replicated to b2 only.
- Type:SRR (same region) + CRR (Cross region)
- CRR (encryption options )
  - `kms keys (single region)` 
    - un-encrypted object --> Replicated to region-2
    - encrypted object (sse-s3, sse-c) --> Replicated to region-2
    - encrypted object (sse-kms) : `key-region-1`
      - specify the kms-key in another region, which will be used for encryption : `key-region-2`
      - update  key-region-2::`custom policy` for your specific access.
      - or, use key-region-2::`default policy` : access already given to all principle in same account.
      - Re-encrypt with key-region-2  
      - finally, replicated to region-2
     
  - `kms keys (multi-region) `
    - un-encrypted object --> Replicated to region-2 : same as abv
    - encrypted object (sse-s3, sse-c) --> Replicated to region-2  : same as abv
    - encrypted object (sse-kms) : `key-1`
      - same key-1 is present in region-1 and region-2
      - but s3 will treat then as diff keys 
      - and, perform: `decryption and rn-encryption` again [IMP]
 


---
## E. S3 : Event Notification
- sends `event` to target, quickly.
- target: sns,lambda,SQS, etc
  - s3 --> event --> `sns` (update `sns-policy`, to allow to send event)
  - s3 --> event --> `Lambda` (update `lambda-policy`, to allow to send event)
  - s3 --> event --> `SQS` (update `sqs-policy`, to allow to send event)
  - bts : s3 --> EventBridge (filtering) --> target(18+ services) | also `archive event`, `replay event`, etc
  - could assign iam-role to S3 ?

---
## F. S3 : More
- `multipart`, `transfer-acceleration (UP)`, `byte-range fetch (DOWN)`:
  - upload in multipart if 100MB+,  recommended for 5GB+
  - transfer acceleration (upload) - 4 cent extra/GB, uses `edge-locations`.
  - parallelize GETS to speed up download. can configure how many `bytes` to read.
  - ![img_3.png](../99_img/storage/s3-2/img_3.png)
  - ![img_4.png](../99_img/storage/s3-2/img_4.png)

- `server side filtering` 
  - use `S3-select` + `Glacier-Select`
  - filters csv row and column, more like SQL queries. 
  - ![img_5.png](../99_img/storage/s3-2/img_5.png)

- `requester pay`: network cost on requester
  - ![img_2.png](../99_img/storage/s3-2/img_2.png)

---
## F. S3 : hands on
```  
  - create bucket - bucket-1-us-west-2, will be created in all AZ.
  - disable : ACL, , versioning
  - enable : public access + attach BUCKET POLICIES (read from any principle, resource:*)
  - encryption: SSE-S3 *, SSE-KMS, DSSE-KMS
  - upload png file
  - https://bucket-1-us-west-2.s3.us-west-2.amazonaws.com/Screenshot+2024-07-16+002401.png
  - inspect : 
      - Open link --> `s3 pre-signed url`, credential-info are encode in url.
      - access with public-url :  failed | ok after making public.
  - static website hoisting : enable on bucket + index.html
    - endpoints: https://bucket-1.s3-website.region.amazon.com
    
  // Replication
  - create another  buvket-2-us-west-1
  - create replication rule:
    - add target bucket : bucket-1-us-west-2
    - enable versionsing
    - craete new IAM
    
  // storage classes:
  - bucket-1 > mgt > create Life Cycle rule
    - select object: ALL /  by-prefix/suffix / by-tag
    - create transistion Rule/s
      - rule-1 : move from class1 to clas2 after xxdays
      - ...
      - ... 
    - -create deletion Rule/s
      - delete old version/s
      - delete all version/s
      - mark for delete
      - delete incomplete multi-part
```
---
# S3 Glacier object : Vault lock :yellow_circle:
- WORM policy : write once, read many.
- set `retention period`, can be extend.
- `usecase`: data retention. and compliance
- `lock` object in glacier
- retention mode: 
  - `compliance` --> no longer be deleted/updated in the future, not even by root.


## S3 oject : lock
- WORM policy.
- set `retention period`, can be extend.
- set (optional) `legal hold` : lock `indefinitely`. (irrespective of retention-period)
- retention mode: 
  - `compliance` --> no longer be deleted/updated in the future, not even by root.
  - `Governance` --> root user can update/delete.

---
# Storage lens service  :yellow_circle:
- Understand, analyze, and `optimize` storage across entire `AWS Organization` (acct > region > bucket)
- `dashboard` : enable by default/cant delete.
  - aggregated reports/csv gernerted by specific metric --> can publish to CW for free.
  - `advance` metric (available for 15 month), paid
  - `free` metric (available for 14 day, once generated)
  - metric/s :
    - `summary` metric : insight to object -size, count, fastest growing bucket, etc
    - `cost-optimization` metric : insight to non-current, incomplete multiparts, etc
    - `Data protection` metric: count of encrypted Bucket, replication rule
    - `Access-mgt` : object owner
    - `event` metric : s3-eventNotification count, etc
    - `Activity` + `statusCode` : GET, POST, etc +   count of 200, 404, etc
    - `performance` : s3 transfer acce enable count
    
- ![img_6.png](../99_img/storage/s3-2/img_6.png)

  



